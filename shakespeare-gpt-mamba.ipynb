{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8613427,"sourceType":"datasetVersion","datasetId":5155031}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q clu","metadata":{"id":"gS6euWNvHFye","outputId":"45b149a7-9450-439c-da67-ab8678a3b0d0","execution":{"iopub.status.busy":"2024-06-05T13:08:01.858653Z","iopub.execute_input":"2024-06-05T13:08:01.859093Z","iopub.status.idle":"2024-06-05T13:08:19.323257Z","shell.execute_reply.started":"2024-06-05T13:08:01.859049Z","shell.execute_reply":"2024-06-05T13:08:19.322294Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\ntensorflow 2.15.0 requires ml-dtypes~=0.2.0, but you have ml-dtypes 0.4.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# # We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt","metadata":{"id":"7jjCLfuUHFyg","outputId":"dfe048f0-dd44-40ef-edf3-2fa56558672f","execution":{"iopub.status.busy":"2024-06-05T13:08:19.325196Z","iopub.execute_input":"2024-06-05T13:08:19.325500Z","iopub.status.idle":"2024-06-05T13:08:19.330723Z","shell.execute_reply.started":"2024-06-05T13:08:19.325473Z","shell.execute_reply":"2024-06-05T13:08:19.329832Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from functools import partial\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom jax.nn.initializers import lecun_normal, normal\nfrom jax.numpy.linalg import eigh, inv, matrix_power\nfrom jax.scipy.signal import convolve\n\nimport torch\n\nfrom dataclasses import dataclass\n\nfrom typing import Union\n\nimport matplotlib.pyplot as plt\nimport seaborn\n\nfrom clu import metrics\nfrom flax.training import train_state  # Useful dataclass to keep train state\nfrom flax import struct                # Flax dataclasses\nimport optax                           # Common loss functions and optimizers\nfrom tqdm import tqdm","metadata":{"id":"YXSCJzupHFyh","execution":{"iopub.status.busy":"2024-06-05T13:08:19.332135Z","iopub.execute_input":"2024-06-05T13:08:19.332466Z","iopub.status.idle":"2024-06-05T13:08:25.591401Z","shell.execute_reply.started":"2024-06-05T13:08:19.332442Z","shell.execute_reply":"2024-06-05T13:08:25.590539Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# read it in to inspect it\nwith open('/kaggle/input/shak-new-input/input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()","metadata":{"id":"KpJoV3KQHFyh","execution":{"iopub.status.busy":"2024-06-05T13:08:25.593468Z","iopub.execute_input":"2024-06-05T13:08:25.593901Z","iopub.status.idle":"2024-06-05T13:08:25.650865Z","shell.execute_reply.started":"2024-06-05T13:08:25.593876Z","shell.execute_reply":"2024-06-05T13:08:25.649800Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# here are all the unique characters that occur in this text\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"id":"PsWxZqyRHFyi","outputId":"b1730724-647e-45cd-edfa-97af24995830","execution":{"iopub.status.busy":"2024-06-05T13:08:25.652218Z","iopub.execute_input":"2024-06-05T13:08:25.652613Z","iopub.status.idle":"2024-06-05T13:08:25.700710Z","shell.execute_reply.started":"2024-06-05T13:08:25.652578Z","shell.execute_reply":"2024-06-05T13:08:25.699710Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\n !\"&',-.:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n64\n","output_type":"stream"}]},{"cell_type":"code","source":"# from transformers import AutoTokenizer\n\n# tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Phi-3-mini-4k-instruct\", padding_side=\"left\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:25.702111Z","iopub.execute_input":"2024-06-05T13:08:25.702813Z","iopub.status.idle":"2024-06-05T13:08:25.714592Z","shell.execute_reply.started":"2024-06-05T13:08:25.702759Z","shell.execute_reply":"2024-06-05T13:08:25.713670Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# text_inputs = tokenizer(text, return_tensors=\"np\")\n# data = jnp.array(text_inputs['input_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:25.715635Z","iopub.execute_input":"2024-06-05T13:08:25.715904Z","iopub.status.idle":"2024-06-05T13:08:25.724812Z","shell.execute_reply.started":"2024-06-05T13:08:25.715882Z","shell.execute_reply":"2024-06-05T13:08:25.723926Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# vocab_size = tokenizer.vocab_size\n# print(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:25.726187Z","iopub.execute_input":"2024-06-05T13:08:25.726567Z","iopub.status.idle":"2024-06-05T13:08:25.735319Z","shell.execute_reply.started":"2024-06-05T13:08:25.726517Z","shell.execute_reply":"2024-06-05T13:08:25.734440Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# print(tokenizer.decode((text_inputs['input_ids'][0][0:100]).tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:25.736405Z","iopub.execute_input":"2024-06-05T13:08:25.736703Z","iopub.status.idle":"2024-06-05T13:08:25.746057Z","shell.execute_reply.started":"2024-06-05T13:08:25.736678Z","shell.execute_reply":"2024-06-05T13:08:25.745096Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# create a mapping from characters to integers\nstoi = { ch: i for i,ch in enumerate(chars) }\nitos = { i: ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n\nprint(encode(\"hii there\"))\nprint(decode(encode(\"hii there\")))","metadata":{"id":"S-mzLOk1HFyi","outputId":"f56e2f85-5a1c-4099-87df-436ba39f4363","execution":{"iopub.status.busy":"2024-06-05T13:08:25.749717Z","iopub.execute_input":"2024-06-05T13:08:25.750140Z","iopub.status.idle":"2024-06-05T13:08:25.758759Z","shell.execute_reply.started":"2024-06-05T13:08:25.750115Z","shell.execute_reply":"2024-06-05T13:08:25.757796Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[45, 46, 46, 1, 57, 45, 42, 55, 42]\nhii there\n","output_type":"stream"}]},{"cell_type":"code","source":"data = jnp.array(encode(text), dtype=jnp.int32)\nprint(data.shape, data.dtype)\nprint(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this","metadata":{"id":"HImuqDd8HFyj","outputId":"91dcd15f-f068-4551-ad29-e6e41e52fd91","execution":{"iopub.status.busy":"2024-06-05T13:08:25.760137Z","iopub.execute_input":"2024-06-05T13:08:25.760421Z","iopub.status.idle":"2024-06-05T13:08:31.305317Z","shell.execute_reply.started":"2024-06-05T13:08:25.760398Z","shell.execute_reply":"2024-06-05T13:08:31.304261Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"(2643247,) int32\n[17 46 55 56 57  1 14 46 57 46 63 42 51  9  0 13 42 43 52 55 42  1 60 42\n  1 53 55 52 40 42 42 41  1 38 51 62  1 43 58 55 57 45 42 55  6  1 45 42\n 38 55  1 50 42  1 56 53 42 38 48  8  0  0 12 49 49  9  0 30 53 42 38 48\n  6  1 56 53 42 38 48  8  0  0 17 46 55 56 57  1 14 46 57 46 63 42 51  9\n  0 36 52 58  1 38 55 42  1 38 49 49  1 55 42 56 52 49 59 42 41  1 55 38\n 57 45 42 55  1 57 52  1 41 46 42  1 57 45 38 51  1 57 52  1 43 38 50 46\n 56 45 11  0  0 12 49 49  9  0 29 42 56 52 49 59 42 41  8  1 55 42 56 52\n 49 59 42 41  8  0  0 17 46 55 56 57  1 14 46 57 46 63 42 51  9  0 17 46\n 55 56 57  6  1 62 52 58  1 48 51 52 60  1 14 38 46 58 56  1 24 38 55 40\n 46 58 56  1 46 56  1 40 45 46 42 43  1 42 51 42 50 62  1 57 52  1 57 45\n 42  1 53 42 52 53 49 42  8  0  0 12 49 49  9  0 34 42  1 48 51 52 60  5\n 57  6  1 60 42  1 48 51 52 60  5 57  8  0  0 17 46 55 56 57  1 14 46 57\n 46 63 42 51  9  0 23 42 57  1 58 56  1 48 46 49 49  1 45 46 50  6  1 38\n 51 41  1 60 42  5 49 49  1 45 38 59 42  1 40 52 55 51  1 38 57  1 52 58\n 55  1 52 60 51  1 53 55 46 40 42  8  0 20 56  5 57  1 38  1 59 42 55 41\n 46 40 57 11  0  0 12 49 49  9  0 25 52  1 50 52 55 42  1 57 38 49 48 46\n 51 44  1 52 51  5 57 10  1 49 42 57  1 46 57  1 39 42  1 41 52 51 42  9\n  1 38 60 38 62  6  1 38 60 38 62  2  0  0 30 42 40 52 51 41  1 14 46 57\n 46 63 42 51  9  0 26 51 42  1 60 52 55 41  6  1 44 52 52 41  1 40 46 57\n 46 63 42 51 56  8  0  0 17 46 55 56 57  1 14 46 57 46 63 42 51  9  0 34\n 42  1 38 55 42  1 38 40 40 52 58 51 57 42 41  1 53 52 52 55  1 40 46 57\n 46 63 42 51 56  6  1 57 45 42  1 53 38 57 55 46 40 46 38 51 56  1 44 52\n 52 41  8  0 34 45 38 57  1 38 58 57 45 52 55 46 57 62  1 56 58 55 43 42\n 46 57 56  1 52 51  1 60 52 58 49 41  1 55 42 49 46 42 59 42  1 58 56  9\n  1 46 43  1 57 45 42 62  0 60 52 58 49 41  1 62 46 42 49 41  1 58 56  1\n 39 58 57  1 57 45 42  1 56 58 53 42 55 43 49 58 46 57 62  6  1 60 45 46\n 49 42  1 46 57  1 60 42 55 42  0 60 45 52 49 42 56 52 50 42  6  1 60 42\n  1 50 46 44 45 57  1 44 58 42 56 56  1 57 45 42 62  1 55 42 49 46 42 59\n 42 41  1 58 56  1 45 58 50 38 51 42 49 62 10  0 39 58 57  1 57 45 42 62\n  1 57 45 46 51 48  1 60 42  1 38 55 42  1 57 52 52  1 41 42 38 55  9  1\n 57 45 42  1 49 42 38 51 51 42 56 56  1 57 45 38 57  0 38 43 43 49 46 40\n 57 56  1 58 56  6  1 57 45 42  1 52 39 47 42 40 57  1 52 43  1 52 58 55\n  1 50 46 56 42 55 62  6  1 46 56  1 38 56  1 38 51  0 46 51 59 42 51 57\n 52 55 62  1 57 52  1 53 38 55 57 46 40 58 49 38 55 46 56 42  1 57 45 42\n 46 55  1 38 39 58 51 41 38 51 40 42 10  1 52 58 55  0 56 58 43 43 42 55\n 38 51 40 42  1 46 56  1 38  1 44 38 46 51  1 57 52  1 57 45 42 50  1 23\n 42 57  1 58 56  1 55 42 59 42 51 44 42  1 57 45 46 56  1 60 46 57 45  0\n 52 58 55  1 53 46 48 42 56  6  1 42 55 42  1 60 42  1 39 42 40 52 50 42\n  1 55 38 48 42 56  9  1 43 52 55  1 57 45 42  1 44 52 41 56  1 48 51 52\n 60  1 20  0 56 53 42 38 48  1 57 45 46 56  1 46 51  1 45 58 51 44 42 55\n  1 43 52 55  1 39 55 42 38 41  6  1 51 52 57  1 46 51  1 57 45 46 55 56\n 57  1 43 52 55  1 55 42 59 42 51 44 42  8  0  0]\n","output_type":"stream"}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:31.306909Z","iopub.execute_input":"2024-06-05T13:08:31.307200Z","iopub.status.idle":"2024-06-05T13:08:31.317082Z","shell.execute_reply.started":"2024-06-05T13:08:31.307176Z","shell.execute_reply":"2024-06-05T13:08:31.316175Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Array([17, 46, 55, ..., 38, 62,  8], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"len(data)/64/32","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:31.318320Z","iopub.execute_input":"2024-06-05T13:08:31.319075Z","iopub.status.idle":"2024-06-05T13:08:31.331378Z","shell.execute_reply.started":"2024-06-05T13:08:31.319026Z","shell.execute_reply":"2024-06-05T13:08:31.330285Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"1290.64794921875"},"metadata":{}}]},{"cell_type":"code","source":"# train_test_split = 0.9\n# n = int(train_test_split*len(data))\n# train_data = data[:n]\n# test_data = data[n:]\n\ntrain_test_split = 0.9\nn = int(train_test_split*len(data))\ntrain_data = data[:n]\ntest_data = data[n:]","metadata":{"id":"pXrAqMxRHFyj","execution":{"iopub.status.busy":"2024-06-05T13:08:31.332796Z","iopub.execute_input":"2024-06-05T13:08:31.333122Z","iopub.status.idle":"2024-06-05T13:08:31.502801Z","shell.execute_reply.started":"2024-06-05T13:08:31.333099Z","shell.execute_reply":"2024-06-05T13:08:31.501966Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"block_size = 8\ntrain_data[:block_size+1]","metadata":{"id":"ahhKyiAzHFyj","outputId":"98306c96-5082-4dfa-ba66-915051831fc8","execution":{"iopub.status.busy":"2024-06-05T13:08:31.504014Z","iopub.execute_input":"2024-06-05T13:08:31.504329Z","iopub.status.idle":"2024-06-05T13:08:31.586899Z","shell.execute_reply.started":"2024-06-05T13:08:31.504304Z","shell.execute_reply":"2024-06-05T13:08:31.585960Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Array([17, 46, 55, 56, 57,  1, 14, 46, 57], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target: {target}\")","metadata":{"id":"HIpsznQmHFyk","outputId":"be9d197b-0b79-43ed-f3a9-e74295d51c79","execution":{"iopub.status.busy":"2024-06-05T13:08:31.588233Z","iopub.execute_input":"2024-06-05T13:08:31.588587Z","iopub.status.idle":"2024-06-05T13:08:32.237608Z","shell.execute_reply.started":"2024-06-05T13:08:31.588555Z","shell.execute_reply":"2024-06-05T13:08:32.236498Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"when input is [17] the target: 46\nwhen input is [17 46] the target: 55\nwhen input is [17 46 55] the target: 56\nwhen input is [17 46 55 56] the target: 57\nwhen input is [17 46 55 56 57] the target: 1\nwhen input is [17 46 55 56 57  1] the target: 14\nwhen input is [17 46 55 56 57  1 14] the target: 46\nwhen input is [17 46 55 56 57  1 14 46] the target: 57\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 128 # how many independent sequences will we process in parallel?\nblock_size = 32 # what is the maximum context length for predictions?\nmax_iters = 15000\nlearning_rate = 5e-4\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 100\nn_embd = 256\nexpans = 2\nn_heads = 1\nchannel_size = n_embd // n_heads\nn_layers = 6\ndropout = 0.2\nconv_k_size = 3\nn_latent_dim = 16\nn_tokens = 1\n\nrng_key = jax.random.PRNGKey(1564)\n\ndynamic_slice_vmap = jax.vmap(jax.lax.dynamic_slice, in_axes=(None, 0, None))\n\n@jax.jit\ndef get_batch(random_key, data):\n    \"\"\"Prepares a random batch of training data.\n\n    Args:\n      random_key: A random seed for sampling a batch.\n      data: The complete training dataset.\n\n    Returns:\n      x: Input sequences.\n      y: Target sequences (shifted inputs).\n    \"\"\"\n    ix = jax.random.randint(\n      random_key, shape=(batch_size, 1), minval=0, maxval=len(data) - block_size\n    )\n    x = dynamic_slice_vmap(data, ix, (block_size,))\n    y = dynamic_slice_vmap(data, ix + n_tokens, (block_size,))\n    return x, y\n\nxb, yb = get_batch(rng_key, train_data)\ntrain_shape = xb.shape\nprint('inputs:')\nprint(xb.shape)\nprint(xb)\nprint('targets:')\nprint(yb.shape)\nprint(yb)\n\n# print('----')\n\n# for b in range(batch_size): # batch dimension\n#     for t in range(block_size): # time dimension\n#         context = xb[b, :t+1]\n#         target = yb[b,t]\n#         print(f\"when input is {context} the target: {target}\")","metadata":{"id":"UuAjtqPeHFyk","outputId":"6a88fb2b-b798-4ee9-9f4f-f38ce898d576","execution":{"iopub.status.busy":"2024-06-05T13:08:32.238961Z","iopub.execute_input":"2024-06-05T13:08:32.239273Z","iopub.status.idle":"2024-06-05T13:08:32.648633Z","shell.execute_reply.started":"2024-06-05T13:08:32.239247Z","shell.execute_reply":"2024-06-05T13:08:32.647577Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"inputs:\n(128, 32)\n[[12 56  1 ... 52 51 56]\n [52 51 56 ... 42 10  0]\n [23 52 55 ... 46 56  1]\n ...\n [ 8  1 17 ... 38 50  1]\n [55 38 57 ...  0 31 45]\n [55  1 46 ...  1 45 42]]\ntargets:\n(128, 32)\n[[56  1 20 ... 51 56  6]\n [51 56 46 ... 10  0 34]\n [52 55 41 ... 56  1 57]\n ...\n [ 1 17 52 ... 50  1 38]\n [38 57 56 ... 31 45 38]\n [ 1 46 51 ... 45 42  1]]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(xb[0])\nprint(yb[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:32.650264Z","iopub.execute_input":"2024-06-05T13:08:32.650683Z","iopub.status.idle":"2024-06-05T13:08:32.761693Z","shell.execute_reply.started":"2024-06-05T13:08:32.650647Z","shell.execute_reply":"2024-06-05T13:08:32.760628Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[12 56  1 20  1 45 38 59 42  1 44 46 59 42 51  1 52 58 57  1 45 46 50  8\n  1 24 62  1 56 52 51 56]\n[56  1 20  1 45 38 59 42  1 44 46 59 42 51  1 52 58 57  1 45 46 50  8  1\n 24 62  1 56 52 51 56  6]\n","output_type":"stream"}]},{"cell_type":"code","source":"# hidden_state = [jnp.zeros((1,n_latent_dim, n_embd * expans)) for _ in range(n_layers)]\n# hidden_state[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:32.763157Z","iopub.execute_input":"2024-06-05T13:08:32.763570Z","iopub.status.idle":"2024-06-05T13:08:32.768348Z","shell.execute_reply.started":"2024-06-05T13:08:32.763534Z","shell.execute_reply":"2024-06-05T13:08:32.767313Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Mamba Block\nDense --> Conv1D --> Silu --> SSM --> Silu -->","metadata":{"id":"yOccqzJlHFym"}},{"cell_type":"code","source":"class Mamba(nn.Module):\n\n    def setup(self):\n        emb_features = n_embd * expans\n        self.in_proj1 = nn.Dense(features=emb_features)\n        self.in_proj2 = nn.Dense(features=emb_features)\n\n        # Adjusted for Flax. Flax does not have nn.Conv1d, so you might need to reshape or use a different approach\n        self.conv1d = nn.Conv(features=emb_features,\n                              kernel_size=conv_k_size,\n                              padding=1,\n                              )\n\n        self.A = -1*self.param('A', nn.initializers.ones, (1, n_latent_dim, emb_features, 1))\n        self.B = 0.1*self.param('B', nn.initializers.ones, (1, n_latent_dim, 1, block_size))\n        self.C = self.param('C', jax.random.normal, (1, n_latent_dim, 1, block_size))\n#         self.D = self.param('D', jax.random.normal, (1, self.args.d_state, self.args.d_model, 1))\n        self.delta = self.param('delta', jax.random.normal, (1, 1,emb_features, block_size))\n\n        self.out_proj = nn.Dense(n_embd // n_heads)\n        \n        self.hidden_state = self.variable('other_variables','hidden_state', \n                                          jnp.zeros, \n                                          (1,n_latent_dim, emb_features))\n#         self.rms_norm = nn.RMSNorm()\n\n    def __call__(self, embeds):\n        x = self.in_proj1(embeds)\n        x = self.conv1d(x)\n        x = jax.nn.silu(x)\n        x = x.reshape((x.shape[0],1,x.shape[2],x.shape[1]))\n        x = self.ssm(x)\n        x = x.reshape((x.shape[0],x.shape[3],x.shape[2]))\n        x = x*jax.nn.silu(self.in_proj2(embeds))\n\n        x = self.out_proj(x)\n\n#         x = self.rms_norm(x)\n\n        return x\n    def discretize(self):\n        da = self.delta * self.A\n        a_ = jnp.exp(da)\n        b_ = self.B * self.delta\n        return a_, b_\n\n    def ssm(self, x):\n        y = []\n        a_, b_ = self.discretize()\n        h = 0\n        for k in range(x.shape[-1]):\n            h = a_[..., k] * h + b_[..., k] * x[..., k]\n            \n#         for l in range(x.shape[-1]):\n#             print(self.C.shape, h.shape)\n\n        y = ((self.C * jax.lax.expand_dims(h,[3])).sum(1, keepdims=True))\n        \n#         self.hidden_state.value = jax.nn.standardize(h.mean(0, keepdims=True))\n        return y","metadata":{"id":"4qOdblU5HFyo","execution":{"iopub.status.busy":"2024-06-05T13:08:32.769912Z","iopub.execute_input":"2024-06-05T13:08:32.770221Z","iopub.status.idle":"2024-06-05T13:08:32.790774Z","shell.execute_reply.started":"2024-06-05T13:08:32.770189Z","shell.execute_reply":"2024-06-05T13:08:32.789696Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class MultiHeadMamba(nn.Module):\n    def setup(self):\n        self.heads = [Mamba() for _ in range(n_heads)]\n        self.rms_norm = nn.RMSNorm()\n\n    def __call__(self, x):\n        out = jnp.concatenate([h(x) for h in self.heads], axis=-1)\n        x = self.rms_norm(out)\n        return x","metadata":{"id":"0bH9vlLZHFyq","execution":{"iopub.status.busy":"2024-06-05T13:08:32.792070Z","iopub.execute_input":"2024-06-05T13:08:32.792379Z","iopub.status.idle":"2024-06-05T13:08:32.806695Z","shell.execute_reply.started":"2024-06-05T13:08:32.792353Z","shell.execute_reply":"2024-06-05T13:08:32.805618Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# class FeedForward(nn.Module):\n#     def setup(self):\n#         self.ffn = nn.Sequential([\n#             nn.Dense(4 * n_embd),\n#             nn.relu,\n#             nn.Dense(n_embd)]\n#         )\n#     def __call__(self, x):\n#         return self.ffn(x)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:32.807831Z","iopub.execute_input":"2024-06-05T13:08:32.808125Z","iopub.status.idle":"2024-06-05T13:08:32.820585Z","shell.execute_reply.started":"2024-06-05T13:08:32.808101Z","shell.execute_reply":"2024-06-05T13:08:32.819517Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# class MambaBlock(nn.Module):\n#     def setup(self):\n#         self.mamba_block = Mamba()\n#         self.ln1 = nn.RMSNorm()\n#         self.ffn = FeedForward()\n#         self.ln2 = nn.LayerNorm()\n\n#     def __call__(self, x):\n#         x = x + self.mamba_block(self.ln2(x))\n#         x = x + self.ffn(self.ln1(x))\n#         return x\n","metadata":{"id":"UiCxIjoEp2QA","execution":{"iopub.status.busy":"2024-06-05T13:08:32.821929Z","iopub.execute_input":"2024-06-05T13:08:32.822256Z","iopub.status.idle":"2024-06-05T13:08:32.831709Z","shell.execute_reply.started":"2024-06-05T13:08:32.822225Z","shell.execute_reply":"2024-06-05T13:08:32.830666Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# class MambaModel(nn.Module):\n\n#     def setup(self):\n#         self.tok_embeddings = nn.Embed(vocab_size, n_embd)\n#         self.pos_embeddings = nn.Embed(block_size, n_embd)\n#         self.ln = nn.LayerNorm()\n#         self.mamba_layers = [MambaBlock() for _ in range(n_layers)]\n#         self.preds_out = nn.Dense(vocab_size)\n\n#     def __call__(self, x, training: bool):\n#         x = self.tok_embeddings(x) + self.pos_embeddings(jnp.arange(block_size))\n# #         x = self.ln(x)\n#         for layer in self.mamba_layers:\n#             x = layer(x)\n            \n#         return self.preds_out(x)\n\n#     @jax.jit\n#     def generate(self, idx, max_new_tokens, params):\n#     # idx is (B, T) array of indices in the current context\n#         for _ in range(max_new_tokens):\n#             # crop idx to the last block_size tokens\n#             idx_cond = idx[:, -block_size:]\n#             # get the predictions\n#             logits = self.apply(params, idx_cond)\n#             # focus only on the last time step\n#             logits = logits[:, -1, :] # becomes (B, C)\n#             # apply softmax to get probabilities\n#             ##probs = tf.keras.activations.softmax(logits, dim=-1) # (B, C)\n#             # sample from the distribution\n#             idx_next = jax.random.categorical(jax.random.PRNGKey(52), logits) # (B, 1)\n#             # append sampled index to the running sequence\n#             idx = jax.numpy.expand_dims(jnp.concatenate([idx[0], idx_next], axis=0), 0) # (B, T+1)\n#     #         print(idx_next)\n#     #         print(idx)\n\n#         return idx","metadata":{"id":"y4C7OWL8HFyq","execution":{"iopub.status.busy":"2024-06-05T13:08:32.833099Z","iopub.execute_input":"2024-06-05T13:08:32.833417Z","iopub.status.idle":"2024-06-05T13:08:32.841674Z","shell.execute_reply.started":"2024-06-05T13:08:32.833392Z","shell.execute_reply":"2024-06-05T13:08:32.840873Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# model = Mamba()\n# params = model.init(jax.random.key(42), jnp.ones((1,64,256)))\n# # print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# # print(model.tabulate(jax.random.key(0), jnp.ones((1,64,256)),\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xs = model.apply(params, jnp.ones((1,64,256)), mutable=['other_variables'])\n# # # print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# xb.shape, xs[0].shape, xs[1].keys()","metadata":{"id":"wTd3jSQWHFyp","execution":{"iopub.status.busy":"2024-06-05T13:08:32.842922Z","iopub.execute_input":"2024-06-05T13:08:32.843661Z","iopub.status.idle":"2024-06-05T13:08:32.854671Z","shell.execute_reply.started":"2024-06-05T13:08:32.843633Z","shell.execute_reply":"2024-06-05T13:08:32.853834Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# print(xs[1]['other_variables']['hidden_state'].shape, xs[1]['other_variables']['hidden_state'].min(), xs[1]['other_variables']['hidden_state'].max())","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:32.855750Z","iopub.execute_input":"2024-06-05T13:08:32.856037Z","iopub.status.idle":"2024-06-05T13:08:32.867647Z","shell.execute_reply.started":"2024-06-05T13:08:32.856015Z","shell.execute_reply":"2024-06-05T13:08:32.866794Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# xfs = model.apply(params, 2*jnp.ones((1,64,256)), mutable=['other_variables'])\n# print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# print(xfs[1]['other_variables']['hidden_state'].shape, xfs[1]['other_variables']['hidden_state'].min(), xfs[1]['other_variables']['hidden_state'].max())","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:32.868702Z","iopub.execute_input":"2024-06-05T13:08:32.869006Z","iopub.status.idle":"2024-06-05T13:08:32.877926Z","shell.execute_reply.started":"2024-06-05T13:08:32.868982Z","shell.execute_reply":"2024-06-05T13:08:32.877038Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# test_model = Mamba()\n# test_params = test_model.init(jax.random.key(42), xb)\n# n_params = sum(p.size for p in jax.tree_util.tree_leaves(test_params))\n# print(f\"Total number of parameters: {n_params:_}\")\n# # print(fin_model.tabulate(jax.random.key(42), xb,\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xf = test_model.apply(test_params, xb)\n# xb.shape, xf.shape","metadata":{"id":"cm2a0nepHFyq","execution":{"iopub.status.busy":"2024-06-05T13:08:32.886192Z","iopub.execute_input":"2024-06-05T13:08:32.886508Z","iopub.status.idle":"2024-06-05T13:08:32.891082Z","shell.execute_reply.started":"2024-06-05T13:08:32.886482Z","shell.execute_reply":"2024-06-05T13:08:32.890196Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class NanoLM(nn.Module):\n    \"\"\"NanoLM model.\"\"\"\n    vocab_size: int = 65\n    num_layers: int = 6\n    num_heads: int = 8\n    head_size: int = 32\n    dropout_rate: float = 0.2\n    embed_size: int = 256\n    block_size: int = 64\n\n    @nn.compact\n    def __call__(self, x, training: bool):\n        x = nn.Embed(self.vocab_size, self.embed_size)(x) + nn.Embed(\n            self.block_size, self.embed_size\n        )(jnp.arange(self.block_size))\n        \n        for i in range(self.num_layers):\n#             x = x + nn.MultiHeadDotProductAttention(\n#               num_heads=self.num_heads,\n#               qkv_features=self.head_size,\n#               out_features=self.head_size * self.num_heads,\n#               dropout_rate=self.dropout_rate,\n#             )(\n#               x_norm,\n#               x_norm,\n#               mask=jnp.tril(jnp.ones((x.shape[-2], x.shape[-2]))),\n#               deterministic=not training,\n#             )\n    \n            x = x + MultiHeadMamba()(nn.RMSNorm()(x))\n\n#             x = x + nn.Sequential([\n#               nn.Dense(4 * self.embed_size),\n#               nn.relu,\n#               nn.Dropout(self.dropout_rate, deterministic=not training),\n#               nn.Dense(self.embed_size),\n#             ])(nn.LayerNorm()(x))\n\n        x = nn.Dense(self.vocab_size)(nn.RMSNorm()(x))\n        return x","metadata":{"id":"zuiaFP6WHFyr","execution":{"iopub.status.busy":"2024-06-05T13:08:32.892157Z","iopub.execute_input":"2024-06-05T13:08:32.892415Z","iopub.status.idle":"2024-06-05T13:08:32.904150Z","shell.execute_reply.started":"2024-06-05T13:08:32.892384Z","shell.execute_reply":"2024-06-05T13:08:32.903240Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# key = jax.random.key(42)\n\n# # fin_model = MambaModel()\n# # fin_params = fin_model.init(key, xb, training=False)\n\n\n# fin_model = NanoLM(\n#     vocab_size=vocab_size,\n#     num_layers=n_layers,\n#     num_heads=8,\n#     head_size=32,\n#     dropout_rate=0.2,\n#     embed_size=n_embd,\n#     block_size=block_size,\n# )\n\n# fin_params = fin_model.init(\n#     {'params': key},\n#     jnp.ones((batch_size, block_size), dtype=jnp.int32),\n#     training=False\n# )\n\n# n_params = sum(p.size for p in jax.tree_util.tree_leaves(fin_params))\n# print(f\"Total number of parameters: {n_params:_}\")\n# # print(fin_model.tabulate(jax.random.key(42), xb,\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xf = fin_model.apply(fin_params, xb, training=False)[0]\n# xb.shape, xf.shape","metadata":{"id":"fnUQPyuvHFys","outputId":"f04ebf31-d67f-4488-dd5d-7fd5b20dd1ea","execution":{"iopub.status.busy":"2024-06-05T13:08:32.905248Z","iopub.execute_input":"2024-06-05T13:08:32.905525Z","iopub.status.idle":"2024-06-05T13:08:32.918823Z","shell.execute_reply.started":"2024-06-05T13:08:32.905500Z","shell.execute_reply":"2024-06-05T13:08:32.917840Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def loss_fun(params, x, y, var_params,dropout_key):\n    logits, updated_variables = model.apply({'params': params, **var_params}, x, training=True, rngs={\"dropout\": dropout_key}, mutable=['other_variables'])\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), (updated_variables, accuracy)\n\n@jax.jit\ndef eval_step(params, x, y, var_params):\n    logits, _ = model.apply({'params': params, **var_params}, x, training=False, mutable=['other_variables'])\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), accuracy","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:32.919917Z","iopub.execute_input":"2024-06-05T13:08:32.920210Z","iopub.status.idle":"2024-06-05T13:08:32.933953Z","shell.execute_reply.started":"2024-06-05T13:08:32.920185Z","shell.execute_reply":"2024-06-05T13:08:32.932978Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"key = jax.random.PRNGKey(42)\nkey, subkey = jax.random.split(key)\n\nmodel = NanoLM(\n    vocab_size=vocab_size,\n    num_layers=n_layers,\n    num_heads=8,\n    head_size=32,\n    dropout_rate=0.2,\n    embed_size=n_embd,\n    block_size=block_size,\n)\n\nvar_params = model.init(\n    key,\n    jnp.ones((batch_size, block_size), dtype=jnp.int32),\n    training=False,\n)\nprint(var_params.keys())\nn_params = sum(p.size for p in jax.tree_util.tree_leaves(var_params))\n\nprint(f\"Total number of parameters: {n_params:_}\")","metadata":{"id":"PKpb3864HFyt","execution":{"iopub.status.busy":"2024-06-05T13:08:32.936814Z","iopub.execute_input":"2024-06-05T13:08:32.937270Z","iopub.status.idle":"2024-06-05T13:08:41.579177Z","shell.execute_reply.started":"2024-06-05T13:08:32.937243Z","shell.execute_reply":"2024-06-05T13:08:41.578151Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"dict_keys(['params', 'other_variables'])\nTotal number of parameters: 7_335_744\n","output_type":"stream"}]},{"cell_type":"code","source":"var_params['params']['Embed_0']['embedding'].shape","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:41.580527Z","iopub.execute_input":"2024-06-05T13:08:41.581080Z","iopub.status.idle":"2024-06-05T13:08:41.587698Z","shell.execute_reply.started":"2024-06-05T13:08:41.581041Z","shell.execute_reply":"2024-06-05T13:08:41.586594Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(64, 256)"},"metadata":{}}]},{"cell_type":"code","source":"params = var_params.pop('params')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:41.588953Z","iopub.execute_input":"2024-06-05T13:08:41.589370Z","iopub.status.idle":"2024-06-05T13:08:41.601680Z","shell.execute_reply.started":"2024-06-05T13:08:41.589338Z","shell.execute_reply":"2024-06-05T13:08:41.600737Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"var_params = jax.tree_map(lambda x: jnp.zeros_like(x), var_params)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:41.602717Z","iopub.execute_input":"2024-06-05T13:08:41.603096Z","iopub.status.idle":"2024-06-05T13:08:41.616249Z","shell.execute_reply.started":"2024-06-05T13:08:41.603072Z","shell.execute_reply":"2024-06-05T13:08:41.615274Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# decay_rate = 0.96\n# learning_rate_schedule = optax.exponential_decay(learning_rate, decay_rate, max_iters//1000)\nopt = optax.adamw(learning_rate=learning_rate)\n\nopt_state = opt.init(params)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:41.617754Z","iopub.execute_input":"2024-06-05T13:08:41.618087Z","iopub.status.idle":"2024-06-05T13:08:41.968334Z","shell.execute_reply.started":"2024-06-05T13:08:41.618063Z","shell.execute_reply":"2024-06-05T13:08:41.967396Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"%%time\n\nall_train_losses = []\nall_eval_losses = []\n\nall_train_accuracy =  []\nall_test_accuracy = []\n\n# we define one iteration of the optimizer and JIT this function\n@jax.jit\ndef step(key, params, var_params, opt_state):\n    key, subkey = jax.random.split(key)\n    xb, yb = get_batch(key, train_data)\n    (loss, aux_data), grad = jax.value_and_grad(loss_fun, has_aux=True)(params, xb, yb, var_params, subkey)\n    var_params, train_accuracy = aux_data\n    updates, opt_state = opt.update(grad, opt_state, params)\n    params = optax.apply_updates(params, updates)\n    return params, key, opt_state, loss, var_params, train_accuracy\n\n# for i in tqdm(range(max_iters)):\ncounter = 0\nloss = 10\nwhile counter<max_iters: # and loss > 1.0:\n\n    params, key, opt_state, loss, var_params, train_accuracy = step(key, params, var_params, opt_state)\n    \n\n    # once every N_FREQ_EVAL we compute loss on the validation set\n    if counter % eval_iters == 0:\n        key, subkey = jax.random.split(key)\n        eval_loss, eval_accuracy = eval_step(params, *get_batch(subkey, test_data), var_params)\n        all_train_losses.append(loss)\n        all_eval_losses.append(eval_loss)\n        all_train_accuracy.append(train_accuracy)\n        all_test_accuracy.append(eval_accuracy)\n        print('##########################################################')\n        print(\"Step: \", counter,\"\\t Train Loss: \", loss,\"\\t Train Accuracy: \", format(train_accuracy, \".2%\"))\n        print(\"Step: \", counter,\"\\t Eval Loss: \", eval_loss,\"\\t Eval Accuracy: \", format(eval_accuracy, \".2%\"))\n        \n    counter += 1\n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:08:41.969466Z","iopub.execute_input":"2024-06-05T13:08:41.969764Z","iopub.status.idle":"2024-06-05T13:24:10.040664Z","shell.execute_reply.started":"2024-06-05T13:08:41.969739Z","shell.execute_reply":"2024-06-05T13:24:10.039645Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"##########################################################\nStep:  0 \t Train Loss:  4.6483355 \t Train Accuracy:  1.59%\nStep:  0 \t Eval Loss:  4.5737243 \t Eval Accuracy:  2.00%\n##########################################################\nStep:  100 \t Train Loss:  1.140375 \t Train Accuracy:  73.80%\nStep:  100 \t Eval Loss:  1.1581485 \t Eval Accuracy:  73.00%\n##########################################################\nStep:  200 \t Train Loss:  0.28420007 \t Train Accuracy:  94.26%\nStep:  200 \t Eval Loss:  0.28925347 \t Eval Accuracy:  94.17%\n##########################################################\nStep:  300 \t Train Loss:  0.13898157 \t Train Accuracy:  96.90%\nStep:  300 \t Eval Loss:  0.14732699 \t Eval Accuracy:  96.88%\n##########################################################\nStep:  400 \t Train Loss:  0.09705131 \t Train Accuracy:  97.56%\nStep:  400 \t Eval Loss:  0.10704507 \t Eval Accuracy:  97.34%\n##########################################################\nStep:  500 \t Train Loss:  0.07381515 \t Train Accuracy:  98.00%\nStep:  500 \t Eval Loss:  0.09046472 \t Eval Accuracy:  97.71%\n##########################################################\nStep:  600 \t Train Loss:  0.079024285 \t Train Accuracy:  97.83%\nStep:  600 \t Eval Loss:  0.08905488 \t Eval Accuracy:  97.44%\n##########################################################\nStep:  700 \t Train Loss:  0.08512084 \t Train Accuracy:  97.68%\nStep:  700 \t Eval Loss:  0.08910262 \t Eval Accuracy:  97.61%\n##########################################################\nStep:  800 \t Train Loss:  0.083847724 \t Train Accuracy:  97.90%\nStep:  800 \t Eval Loss:  0.079774514 \t Eval Accuracy:  97.80%\n##########################################################\nStep:  900 \t Train Loss:  0.078815386 \t Train Accuracy:  97.92%\nStep:  900 \t Eval Loss:  0.0738196 \t Eval Accuracy:  98.07%\n##########################################################\nStep:  1000 \t Train Loss:  0.07329782 \t Train Accuracy:  97.85%\nStep:  1000 \t Eval Loss:  0.07370163 \t Eval Accuracy:  97.83%\n##########################################################\nStep:  1100 \t Train Loss:  0.073106736 \t Train Accuracy:  97.80%\nStep:  1100 \t Eval Loss:  0.072739944 \t Eval Accuracy:  98.07%\n##########################################################\nStep:  1200 \t Train Loss:  0.07390317 \t Train Accuracy:  97.90%\nStep:  1200 \t Eval Loss:  0.07308414 \t Eval Accuracy:  98.02%\n##########################################################\nStep:  1300 \t Train Loss:  0.06315262 \t Train Accuracy:  98.19%\nStep:  1300 \t Eval Loss:  0.06345657 \t Eval Accuracy:  98.14%\n##########################################################\nStep:  1400 \t Train Loss:  0.06876154 \t Train Accuracy:  98.00%\nStep:  1400 \t Eval Loss:  0.06959231 \t Eval Accuracy:  97.95%\n##########################################################\nStep:  1500 \t Train Loss:  0.06310598 \t Train Accuracy:  98.22%\nStep:  1500 \t Eval Loss:  0.06234932 \t Eval Accuracy:  98.17%\n##########################################################\nStep:  1600 \t Train Loss:  0.0839109 \t Train Accuracy:  97.53%\nStep:  1600 \t Eval Loss:  0.08537512 \t Eval Accuracy:  97.61%\n##########################################################\nStep:  1700 \t Train Loss:  0.120284244 \t Train Accuracy:  96.66%\nStep:  1700 \t Eval Loss:  0.07939312 \t Eval Accuracy:  97.75%\n##########################################################\nStep:  1800 \t Train Loss:  0.061580203 \t Train Accuracy:  98.24%\nStep:  1800 \t Eval Loss:  0.06618432 \t Eval Accuracy:  98.00%\n##########################################################\nStep:  1900 \t Train Loss:  0.07190303 \t Train Accuracy:  97.71%\nStep:  1900 \t Eval Loss:  0.07137936 \t Eval Accuracy:  97.92%\n##########################################################\nStep:  2000 \t Train Loss:  0.2547297 \t Train Accuracy:  94.07%\nStep:  2000 \t Eval Loss:  0.19731337 \t Eval Accuracy:  95.17%\n##########################################################\nStep:  2100 \t Train Loss:  0.07234214 \t Train Accuracy:  98.05%\nStep:  2100 \t Eval Loss:  0.072513014 \t Eval Accuracy:  97.75%\n##########################################################\nStep:  2200 \t Train Loss:  0.071117416 \t Train Accuracy:  97.92%\nStep:  2200 \t Eval Loss:  0.074159876 \t Eval Accuracy:  97.75%\n##########################################################\nStep:  2300 \t Train Loss:  0.069778524 \t Train Accuracy:  97.85%\nStep:  2300 \t Eval Loss:  0.06713259 \t Eval Accuracy:  98.02%\n##########################################################\nStep:  2400 \t Train Loss:  0.058772027 \t Train Accuracy:  98.29%\nStep:  2400 \t Eval Loss:  0.0714866 \t Eval Accuracy:  98.00%\n##########################################################\nStep:  2500 \t Train Loss:  0.06514082 \t Train Accuracy:  98.07%\nStep:  2500 \t Eval Loss:  0.06827072 \t Eval Accuracy:  98.10%\n##########################################################\nStep:  2600 \t Train Loss:  0.06572631 \t Train Accuracy:  98.07%\nStep:  2600 \t Eval Loss:  0.06574885 \t Eval Accuracy:  98.10%\n##########################################################\nStep:  2700 \t Train Loss:  0.06454188 \t Train Accuracy:  98.00%\nStep:  2700 \t Eval Loss:  0.062008977 \t Eval Accuracy:  98.24%\n##########################################################\nStep:  2800 \t Train Loss:  0.06329726 \t Train Accuracy:  98.36%\nStep:  2800 \t Eval Loss:  0.067980364 \t Eval Accuracy:  98.07%\n##########################################################\nStep:  2900 \t Train Loss:  0.06920564 \t Train Accuracy:  98.02%\nStep:  2900 \t Eval Loss:  0.06444866 \t Eval Accuracy:  98.00%\n##########################################################\nStep:  3000 \t Train Loss:  0.0682879 \t Train Accuracy:  98.12%\nStep:  3000 \t Eval Loss:  0.06590421 \t Eval Accuracy:  98.02%\n##########################################################\nStep:  3100 \t Train Loss:  0.062113177 \t Train Accuracy:  98.14%\nStep:  3100 \t Eval Loss:  0.066275805 \t Eval Accuracy:  98.00%\n##########################################################\nStep:  3200 \t Train Loss:  0.06530884 \t Train Accuracy:  98.07%\nStep:  3200 \t Eval Loss:  0.06338353 \t Eval Accuracy:  98.19%\n##########################################################\nStep:  3300 \t Train Loss:  0.06727858 \t Train Accuracy:  98.10%\nStep:  3300 \t Eval Loss:  0.06640312 \t Eval Accuracy:  98.10%\n##########################################################\nStep:  3400 \t Train Loss:  0.063335136 \t Train Accuracy:  98.12%\nStep:  3400 \t Eval Loss:  0.068076424 \t Eval Accuracy:  98.07%\n##########################################################\nStep:  3500 \t Train Loss:  0.06254688 \t Train Accuracy:  98.27%\nStep:  3500 \t Eval Loss:  0.070057206 \t Eval Accuracy:  98.02%\n##########################################################\nStep:  3600 \t Train Loss:  0.05894044 \t Train Accuracy:  98.19%\nStep:  3600 \t Eval Loss:  0.064766146 \t Eval Accuracy:  98.02%\n##########################################################\nStep:  3700 \t Train Loss:  0.058475062 \t Train Accuracy:  98.14%\nStep:  3700 \t Eval Loss:  0.07384147 \t Eval Accuracy:  97.92%\n##########################################################\nStep:  3800 \t Train Loss:  0.06473999 \t Train Accuracy:  98.07%\nStep:  3800 \t Eval Loss:  0.05861271 \t Eval Accuracy:  98.32%\n##########################################################\nStep:  3900 \t Train Loss:  0.06952878 \t Train Accuracy:  97.97%\nStep:  3900 \t Eval Loss:  0.068126574 \t Eval Accuracy:  98.07%\n##########################################################\nStep:  4000 \t Train Loss:  0.06292398 \t Train Accuracy:  98.17%\nStep:  4000 \t Eval Loss:  0.062101822 \t Eval Accuracy:  98.19%\n##########################################################\nStep:  4100 \t Train Loss:  0.055000223 \t Train Accuracy:  98.27%\nStep:  4100 \t Eval Loss:  0.061974104 \t Eval Accuracy:  98.29%\n##########################################################\nStep:  4200 \t Train Loss:  0.06307179 \t Train Accuracy:  98.10%\nStep:  4200 \t Eval Loss:  0.07140504 \t Eval Accuracy:  98.00%\n##########################################################\nStep:  4300 \t Train Loss:  0.054671526 \t Train Accuracy:  98.49%\nStep:  4300 \t Eval Loss:  0.063673705 \t Eval Accuracy:  98.10%\n##########################################################\nStep:  4400 \t Train Loss:  0.061364092 \t Train Accuracy:  98.05%\nStep:  4400 \t Eval Loss:  0.076763615 \t Eval Accuracy:  98.00%\n##########################################################\nStep:  4500 \t Train Loss:  0.061070256 \t Train Accuracy:  98.24%\nStep:  4500 \t Eval Loss:  0.06324427 \t Eval Accuracy:  98.27%\n##########################################################\nStep:  4600 \t Train Loss:  0.064783305 \t Train Accuracy:  97.92%\nStep:  4600 \t Eval Loss:  0.058774237 \t Eval Accuracy:  98.27%\n##########################################################\nStep:  4700 \t Train Loss:  0.068711825 \t Train Accuracy:  98.14%\nStep:  4700 \t Eval Loss:  0.059345156 \t Eval Accuracy:  98.19%\n##########################################################\nStep:  4800 \t Train Loss:  0.05677375 \t Train Accuracy:  98.34%\nStep:  4800 \t Eval Loss:  0.06454967 \t Eval Accuracy:  97.97%\n##########################################################\nStep:  4900 \t Train Loss:  0.060074605 \t Train Accuracy:  98.22%\nStep:  4900 \t Eval Loss:  0.065087155 \t Eval Accuracy:  98.00%\n##########################################################\nStep:  5000 \t Train Loss:  0.06094893 \t Train Accuracy:  98.19%\nStep:  5000 \t Eval Loss:  0.06728891 \t Eval Accuracy:  98.22%\n##########################################################\nStep:  5100 \t Train Loss:  0.064632855 \t Train Accuracy:  98.07%\nStep:  5100 \t Eval Loss:  0.080295965 \t Eval Accuracy:  97.44%\n##########################################################\nStep:  5200 \t Train Loss:  0.062425748 \t Train Accuracy:  98.14%\nStep:  5200 \t Eval Loss:  0.071674325 \t Eval Accuracy:  98.02%\n##########################################################\nStep:  5300 \t Train Loss:  0.06280973 \t Train Accuracy:  98.29%\nStep:  5300 \t Eval Loss:  0.0649804 \t Eval Accuracy:  98.17%\n##########################################################\nStep:  5400 \t Train Loss:  0.06618816 \t Train Accuracy:  98.02%\nStep:  5400 \t Eval Loss:  0.06891323 \t Eval Accuracy:  98.02%\n##########################################################\nStep:  5500 \t Train Loss:  0.052725174 \t Train Accuracy:  98.34%\nStep:  5500 \t Eval Loss:  0.064253226 \t Eval Accuracy:  98.24%\n##########################################################\nStep:  5600 \t Train Loss:  0.052357927 \t Train Accuracy:  98.41%\nStep:  5600 \t Eval Loss:  0.051868826 \t Eval Accuracy:  98.46%\n##########################################################\nStep:  5700 \t Train Loss:  0.056101624 \t Train Accuracy:  98.19%\nStep:  5700 \t Eval Loss:  0.0600401 \t Eval Accuracy:  98.07%\n##########################################################\nStep:  5800 \t Train Loss:  0.060397092 \t Train Accuracy:  98.36%\nStep:  5800 \t Eval Loss:  0.061562024 \t Eval Accuracy:  98.44%\n##########################################################\nStep:  5900 \t Train Loss:  0.05095134 \t Train Accuracy:  98.49%\nStep:  5900 \t Eval Loss:  0.053390536 \t Eval Accuracy:  98.41%\n##########################################################\nStep:  6000 \t Train Loss:  0.05673578 \t Train Accuracy:  98.36%\nStep:  6000 \t Eval Loss:  0.07108343 \t Eval Accuracy:  97.92%\n##########################################################\nStep:  6100 \t Train Loss:  0.054431327 \t Train Accuracy:  98.39%\nStep:  6100 \t Eval Loss:  0.057849735 \t Eval Accuracy:  98.49%\n##########################################################\nStep:  6200 \t Train Loss:  0.05748964 \t Train Accuracy:  98.22%\nStep:  6200 \t Eval Loss:  0.06268491 \t Eval Accuracy:  98.07%\n##########################################################\nStep:  6300 \t Train Loss:  0.06684935 \t Train Accuracy:  98.17%\nStep:  6300 \t Eval Loss:  0.06902182 \t Eval Accuracy:  98.02%\n##########################################################\nStep:  6400 \t Train Loss:  0.0669917 \t Train Accuracy:  98.17%\nStep:  6400 \t Eval Loss:  0.06670464 \t Eval Accuracy:  98.02%\n##########################################################\nStep:  6500 \t Train Loss:  0.06306067 \t Train Accuracy:  98.12%\nStep:  6500 \t Eval Loss:  0.061579533 \t Eval Accuracy:  98.24%\n##########################################################\nStep:  6600 \t Train Loss:  0.05099079 \t Train Accuracy:  98.39%\nStep:  6600 \t Eval Loss:  0.06613675 \t Eval Accuracy:  98.12%\n##########################################################\nStep:  6700 \t Train Loss:  0.058556944 \t Train Accuracy:  98.39%\nStep:  6700 \t Eval Loss:  0.06444131 \t Eval Accuracy:  98.29%\n##########################################################\nStep:  6800 \t Train Loss:  0.04975302 \t Train Accuracy:  98.66%\nStep:  6800 \t Eval Loss:  0.067771554 \t Eval Accuracy:  97.92%\n##########################################################\nStep:  6900 \t Train Loss:  0.050302632 \t Train Accuracy:  98.46%\nStep:  6900 \t Eval Loss:  0.0645423 \t Eval Accuracy:  98.32%\n##########################################################\nStep:  7000 \t Train Loss:  0.054945625 \t Train Accuracy:  98.29%\nStep:  7000 \t Eval Loss:  0.06263736 \t Eval Accuracy:  98.34%\n##########################################################\nStep:  7100 \t Train Loss:  0.054334275 \t Train Accuracy:  98.63%\nStep:  7100 \t Eval Loss:  0.061474863 \t Eval Accuracy:  98.24%\n##########################################################\nStep:  7200 \t Train Loss:  0.056037195 \t Train Accuracy:  98.46%\nStep:  7200 \t Eval Loss:  0.056087766 \t Eval Accuracy:  98.41%\n##########################################################\nStep:  7300 \t Train Loss:  0.052207455 \t Train Accuracy:  98.36%\nStep:  7300 \t Eval Loss:  0.063506074 \t Eval Accuracy:  98.12%\n##########################################################\nStep:  7400 \t Train Loss:  0.05466548 \t Train Accuracy:  98.44%\nStep:  7400 \t Eval Loss:  0.060400616 \t Eval Accuracy:  98.19%\n##########################################################\nStep:  7500 \t Train Loss:  0.0577498 \t Train Accuracy:  98.22%\nStep:  7500 \t Eval Loss:  0.057601053 \t Eval Accuracy:  98.29%\n##########################################################\nStep:  7600 \t Train Loss:  0.06712293 \t Train Accuracy:  98.02%\nStep:  7600 \t Eval Loss:  0.059055865 \t Eval Accuracy:  98.22%\n##########################################################\nStep:  7700 \t Train Loss:  0.05981619 \t Train Accuracy:  98.19%\nStep:  7700 \t Eval Loss:  0.070223555 \t Eval Accuracy:  97.92%\n##########################################################\nStep:  7800 \t Train Loss:  0.05454555 \t Train Accuracy:  98.41%\nStep:  7800 \t Eval Loss:  0.06849603 \t Eval Accuracy:  98.12%\n##########################################################\nStep:  7900 \t Train Loss:  0.04706849 \t Train Accuracy:  98.54%\nStep:  7900 \t Eval Loss:  0.064150505 \t Eval Accuracy:  98.22%\n##########################################################\nStep:  8000 \t Train Loss:  0.05777713 \t Train Accuracy:  98.44%\nStep:  8000 \t Eval Loss:  0.06077466 \t Eval Accuracy:  98.14%\n##########################################################\nStep:  8100 \t Train Loss:  0.058113478 \t Train Accuracy:  98.22%\nStep:  8100 \t Eval Loss:  0.061987728 \t Eval Accuracy:  98.19%\n##########################################################\nStep:  8200 \t Train Loss:  0.046342395 \t Train Accuracy:  98.63%\nStep:  8200 \t Eval Loss:  0.051310822 \t Eval Accuracy:  98.36%\n##########################################################\nStep:  8300 \t Train Loss:  0.05529532 \t Train Accuracy:  98.32%\nStep:  8300 \t Eval Loss:  0.06262377 \t Eval Accuracy:  98.32%\n##########################################################\nStep:  8400 \t Train Loss:  0.056347616 \t Train Accuracy:  98.46%\nStep:  8400 \t Eval Loss:  0.057527725 \t Eval Accuracy:  98.14%\n##########################################################\nStep:  8500 \t Train Loss:  0.04871119 \t Train Accuracy:  98.66%\nStep:  8500 \t Eval Loss:  0.059384346 \t Eval Accuracy:  98.36%\n##########################################################\nStep:  8600 \t Train Loss:  0.058248006 \t Train Accuracy:  98.12%\nStep:  8600 \t Eval Loss:  0.064645946 \t Eval Accuracy:  98.14%\n##########################################################\nStep:  8700 \t Train Loss:  0.053644024 \t Train Accuracy:  98.44%\nStep:  8700 \t Eval Loss:  0.06291075 \t Eval Accuracy:  98.29%\n##########################################################\nStep:  8800 \t Train Loss:  0.062840864 \t Train Accuracy:  98.17%\nStep:  8800 \t Eval Loss:  0.07155503 \t Eval Accuracy:  98.00%\n##########################################################\nStep:  8900 \t Train Loss:  0.060270905 \t Train Accuracy:  98.19%\nStep:  8900 \t Eval Loss:  0.06556943 \t Eval Accuracy:  98.29%\n##########################################################\nStep:  9000 \t Train Loss:  0.054514803 \t Train Accuracy:  98.36%\nStep:  9000 \t Eval Loss:  0.06792356 \t Eval Accuracy:  98.10%\n##########################################################\nStep:  9100 \t Train Loss:  0.06003473 \t Train Accuracy:  98.22%\nStep:  9100 \t Eval Loss:  0.072056115 \t Eval Accuracy:  97.97%\n##########################################################\nStep:  9200 \t Train Loss:  0.058504447 \t Train Accuracy:  98.29%\nStep:  9200 \t Eval Loss:  0.05941967 \t Eval Accuracy:  98.19%\n##########################################################\nStep:  9300 \t Train Loss:  0.055250578 \t Train Accuracy:  98.36%\nStep:  9300 \t Eval Loss:  0.06386374 \t Eval Accuracy:  98.36%\n##########################################################\nStep:  9400 \t Train Loss:  0.060278147 \t Train Accuracy:  97.97%\nStep:  9400 \t Eval Loss:  0.059204638 \t Eval Accuracy:  98.12%\n##########################################################\nStep:  9500 \t Train Loss:  0.054301754 \t Train Accuracy:  98.54%\nStep:  9500 \t Eval Loss:  0.060102344 \t Eval Accuracy:  98.32%\n##########################################################\nStep:  9600 \t Train Loss:  0.051145744 \t Train Accuracy:  98.36%\nStep:  9600 \t Eval Loss:  0.059758455 \t Eval Accuracy:  98.24%\n##########################################################\nStep:  9700 \t Train Loss:  0.04495226 \t Train Accuracy:  98.63%\nStep:  9700 \t Eval Loss:  0.06836738 \t Eval Accuracy:  98.19%\n##########################################################\nStep:  9800 \t Train Loss:  0.051484898 \t Train Accuracy:  98.58%\nStep:  9800 \t Eval Loss:  0.06776455 \t Eval Accuracy:  97.90%\n##########################################################\nStep:  9900 \t Train Loss:  0.060426358 \t Train Accuracy:  98.24%\nStep:  9900 \t Eval Loss:  0.07802527 \t Eval Accuracy:  97.80%\n##########################################################\nStep:  10000 \t Train Loss:  0.05574525 \t Train Accuracy:  98.39%\nStep:  10000 \t Eval Loss:  0.06077834 \t Eval Accuracy:  98.36%\n##########################################################\nStep:  10100 \t Train Loss:  0.057791613 \t Train Accuracy:  98.27%\nStep:  10100 \t Eval Loss:  0.057769 \t Eval Accuracy:  98.34%\n##########################################################\nStep:  10200 \t Train Loss:  0.048110932 \t Train Accuracy:  98.49%\nStep:  10200 \t Eval Loss:  0.059027944 \t Eval Accuracy:  98.39%\n##########################################################\nStep:  10300 \t Train Loss:  0.049994573 \t Train Accuracy:  98.44%\nStep:  10300 \t Eval Loss:  0.06560962 \t Eval Accuracy:  98.19%\n##########################################################\nStep:  10400 \t Train Loss:  0.053293258 \t Train Accuracy:  98.44%\nStep:  10400 \t Eval Loss:  0.06165733 \t Eval Accuracy:  98.41%\n##########################################################\nStep:  10500 \t Train Loss:  0.053641774 \t Train Accuracy:  98.39%\nStep:  10500 \t Eval Loss:  0.06323944 \t Eval Accuracy:  98.27%\n##########################################################\nStep:  10600 \t Train Loss:  0.055065736 \t Train Accuracy:  98.41%\nStep:  10600 \t Eval Loss:  0.060566023 \t Eval Accuracy:  98.29%\n##########################################################\nStep:  10700 \t Train Loss:  0.05135727 \t Train Accuracy:  98.56%\nStep:  10700 \t Eval Loss:  0.058440637 \t Eval Accuracy:  98.29%\n##########################################################\nStep:  10800 \t Train Loss:  0.048863858 \t Train Accuracy:  98.54%\nStep:  10800 \t Eval Loss:  0.057963856 \t Eval Accuracy:  98.24%\n##########################################################\nStep:  10900 \t Train Loss:  0.04792896 \t Train Accuracy:  98.54%\nStep:  10900 \t Eval Loss:  0.058850836 \t Eval Accuracy:  98.39%\n##########################################################\nStep:  11000 \t Train Loss:  0.06476654 \t Train Accuracy:  98.10%\nStep:  11000 \t Eval Loss:  0.056815192 \t Eval Accuracy:  98.49%\n##########################################################\nStep:  11100 \t Train Loss:  0.054955833 \t Train Accuracy:  98.46%\nStep:  11100 \t Eval Loss:  0.057362687 \t Eval Accuracy:  98.14%\n##########################################################\nStep:  11200 \t Train Loss:  0.06072795 \t Train Accuracy:  98.12%\nStep:  11200 \t Eval Loss:  0.061286505 \t Eval Accuracy:  98.05%\n##########################################################\nStep:  11300 \t Train Loss:  0.04929348 \t Train Accuracy:  98.56%\nStep:  11300 \t Eval Loss:  0.058904506 \t Eval Accuracy:  98.29%\n##########################################################\nStep:  11400 \t Train Loss:  0.046222877 \t Train Accuracy:  98.78%\nStep:  11400 \t Eval Loss:  0.058757287 \t Eval Accuracy:  98.39%\n##########################################################\nStep:  11500 \t Train Loss:  0.056757033 \t Train Accuracy:  98.36%\nStep:  11500 \t Eval Loss:  0.053854585 \t Eval Accuracy:  98.36%\n##########################################################\nStep:  11600 \t Train Loss:  0.045849293 \t Train Accuracy:  98.56%\nStep:  11600 \t Eval Loss:  0.06394942 \t Eval Accuracy:  97.92%\n##########################################################\nStep:  11700 \t Train Loss:  0.04447467 \t Train Accuracy:  98.63%\nStep:  11700 \t Eval Loss:  0.05275182 \t Eval Accuracy:  98.49%\n##########################################################\nStep:  11800 \t Train Loss:  0.049713783 \t Train Accuracy:  98.49%\nStep:  11800 \t Eval Loss:  0.055970542 \t Eval Accuracy:  98.32%\n##########################################################\nStep:  11900 \t Train Loss:  0.048728306 \t Train Accuracy:  98.54%\nStep:  11900 \t Eval Loss:  0.06060513 \t Eval Accuracy:  98.24%\n##########################################################\nStep:  12000 \t Train Loss:  0.05610963 \t Train Accuracy:  98.32%\nStep:  12000 \t Eval Loss:  0.063494384 \t Eval Accuracy:  97.95%\n##########################################################\nStep:  12100 \t Train Loss:  0.058696046 \t Train Accuracy:  98.24%\nStep:  12100 \t Eval Loss:  0.066156544 \t Eval Accuracy:  98.14%\n##########################################################\nStep:  12200 \t Train Loss:  0.05515468 \t Train Accuracy:  98.29%\nStep:  12200 \t Eval Loss:  0.054323733 \t Eval Accuracy:  98.46%\n##########################################################\nStep:  12300 \t Train Loss:  0.047391653 \t Train Accuracy:  98.63%\nStep:  12300 \t Eval Loss:  0.058860112 \t Eval Accuracy:  98.32%\n##########################################################\nStep:  12400 \t Train Loss:  0.054600462 \t Train Accuracy:  98.27%\nStep:  12400 \t Eval Loss:  0.060301434 \t Eval Accuracy:  98.34%\n##########################################################\nStep:  12500 \t Train Loss:  0.05326399 \t Train Accuracy:  98.41%\nStep:  12500 \t Eval Loss:  0.055942688 \t Eval Accuracy:  98.34%\n##########################################################\nStep:  12600 \t Train Loss:  0.049827207 \t Train Accuracy:  98.41%\nStep:  12600 \t Eval Loss:  0.06676568 \t Eval Accuracy:  97.88%\n##########################################################\nStep:  12700 \t Train Loss:  0.057134137 \t Train Accuracy:  98.32%\nStep:  12700 \t Eval Loss:  0.05666122 \t Eval Accuracy:  98.29%\n##########################################################\nStep:  12800 \t Train Loss:  0.05548221 \t Train Accuracy:  98.12%\nStep:  12800 \t Eval Loss:  0.05816418 \t Eval Accuracy:  98.29%\n##########################################################\nStep:  12900 \t Train Loss:  0.0504898 \t Train Accuracy:  98.54%\nStep:  12900 \t Eval Loss:  0.052358694 \t Eval Accuracy:  98.44%\n##########################################################\nStep:  13000 \t Train Loss:  0.054576274 \t Train Accuracy:  98.39%\nStep:  13000 \t Eval Loss:  0.056461684 \t Eval Accuracy:  98.17%\n##########################################################\nStep:  13100 \t Train Loss:  0.056234334 \t Train Accuracy:  98.41%\nStep:  13100 \t Eval Loss:  0.055957668 \t Eval Accuracy:  98.51%\n##########################################################\nStep:  13200 \t Train Loss:  0.04691461 \t Train Accuracy:  98.73%\nStep:  13200 \t Eval Loss:  0.057228252 \t Eval Accuracy:  98.29%\n##########################################################\nStep:  13300 \t Train Loss:  0.06058421 \t Train Accuracy:  98.34%\nStep:  13300 \t Eval Loss:  0.066159666 \t Eval Accuracy:  98.12%\n##########################################################\nStep:  13400 \t Train Loss:  0.05000709 \t Train Accuracy:  98.61%\nStep:  13400 \t Eval Loss:  0.06515638 \t Eval Accuracy:  98.14%\n##########################################################\nStep:  13500 \t Train Loss:  0.051137764 \t Train Accuracy:  98.34%\nStep:  13500 \t Eval Loss:  0.05835392 \t Eval Accuracy:  98.27%\n##########################################################\nStep:  13600 \t Train Loss:  0.04800617 \t Train Accuracy:  98.49%\nStep:  13600 \t Eval Loss:  0.055361975 \t Eval Accuracy:  98.34%\n##########################################################\nStep:  13700 \t Train Loss:  0.05606557 \t Train Accuracy:  98.39%\nStep:  13700 \t Eval Loss:  0.060457487 \t Eval Accuracy:  98.12%\n##########################################################\nStep:  13800 \t Train Loss:  0.04921646 \t Train Accuracy:  98.49%\nStep:  13800 \t Eval Loss:  0.054544773 \t Eval Accuracy:  98.46%\n##########################################################\nStep:  13900 \t Train Loss:  0.0525408 \t Train Accuracy:  98.58%\nStep:  13900 \t Eval Loss:  0.05743926 \t Eval Accuracy:  98.32%\n##########################################################\nStep:  14000 \t Train Loss:  0.050579272 \t Train Accuracy:  98.63%\nStep:  14000 \t Eval Loss:  0.06943905 \t Eval Accuracy:  98.19%\n##########################################################\nStep:  14100 \t Train Loss:  0.05144316 \t Train Accuracy:  98.46%\nStep:  14100 \t Eval Loss:  0.055316515 \t Eval Accuracy:  98.54%\n##########################################################\nStep:  14200 \t Train Loss:  0.049560554 \t Train Accuracy:  98.51%\nStep:  14200 \t Eval Loss:  0.053876348 \t Eval Accuracy:  98.34%\n##########################################################\nStep:  14300 \t Train Loss:  0.05572778 \t Train Accuracy:  98.39%\nStep:  14300 \t Eval Loss:  0.05315096 \t Eval Accuracy:  98.46%\n##########################################################\nStep:  14400 \t Train Loss:  0.05403774 \t Train Accuracy:  98.49%\nStep:  14400 \t Eval Loss:  0.06444295 \t Eval Accuracy:  98.29%\n##########################################################\nStep:  14500 \t Train Loss:  0.057780594 \t Train Accuracy:  98.27%\nStep:  14500 \t Eval Loss:  0.062964156 \t Eval Accuracy:  98.44%\n##########################################################\nStep:  14600 \t Train Loss:  0.054016024 \t Train Accuracy:  98.39%\nStep:  14600 \t Eval Loss:  0.06267901 \t Eval Accuracy:  98.17%\n##########################################################\nStep:  14700 \t Train Loss:  0.051995512 \t Train Accuracy:  98.44%\nStep:  14700 \t Eval Loss:  0.046558328 \t Eval Accuracy:  98.46%\n##########################################################\nStep:  14800 \t Train Loss:  0.050678335 \t Train Accuracy:  98.49%\nStep:  14800 \t Eval Loss:  0.061937712 \t Eval Accuracy:  98.14%\n##########################################################\nStep:  14900 \t Train Loss:  0.049237728 \t Train Accuracy:  98.49%\nStep:  14900 \t Eval Loss:  0.059879307 \t Eval Accuracy:  98.41%\nCPU times: user 10min 11s, sys: 5min 20s, total: 15min 31s\nWall time: 15min 28s\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt  # Visualization\n\n# Plot loss and accuracy in subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.set_title('Loss')\nax2.set_title('Accuracy')\n\n\n\nax1.plot(all_train_losses, label='train_loss')\nax1.plot(all_eval_losses, label='eval_loss')\n\nax2.plot(all_train_accuracy, label='train_accuracy')\nax2.plot(all_test_accuracy, label='eval_accuracy')\n\nax1.legend()\nax2.legend()\nplt.show()\nplt.clf()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:10.041923Z","iopub.execute_input":"2024-06-05T13:24:10.042235Z","iopub.status.idle":"2024-06-05T13:24:10.620590Z","shell.execute_reply.started":"2024-06-05T13:24:10.042210Z","shell.execute_reply":"2024-06-05T13:24:10.619588Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x500 with 2 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"@partial(jax.jit, static_argnames=(\"length\"))\ndef generate_text(rng, params, var_params, length):\n    def _scan_generate(carry, _):\n        random_key, context = carry\n        logits = model.apply({'params': params, **var_params}, context, training=False, mutable=['other_variables'])[0]\n        rng, rng_subkey = jax.random.split(random_key)\n        new_token = jax.random.categorical(\n          rng_subkey, logits[:, -n_tokens, :], axis=-1, shape=(1, 1)\n        )\n        context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n        print(context.shape)\n        return (rng, context), new_token\n\n    _, new_tokens = jax.lax.scan(\n    _scan_generate,\n    (rng, jnp.expand_dims(test_data[850:850+block_size], axis=0)),\n    (),\n    length=length,\n    )\n    return new_tokens","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:10.621840Z","iopub.execute_input":"2024-06-05T13:24:10.622148Z","iopub.status.idle":"2024-06-05T13:24:10.631824Z","shell.execute_reply.started":"2024-06-05T13:24:10.622122Z","shell.execute_reply":"2024-06-05T13:24:10.630691Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"test_data[850:850+block_size]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:10.632945Z","iopub.execute_input":"2024-06-05T13:24:10.633310Z","iopub.status.idle":"2024-06-05T13:24:10.729569Z","shell.execute_reply.started":"2024-06-05T13:24:10.633276Z","shell.execute_reply":"2024-06-05T13:24:10.728685Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"Array([58, 41,  1, 12, 57, 45, 42, 51, 56,  1, 52, 51,  1, 38,  1, 45, 42,\n       38, 53,  7,  0,  0, 31, 20, 24, 26, 25,  9,  0, 34, 38, 55],      dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"new_tokenz = 1000\nkey, subkey = jax.random.split(jax.random.PRNGKey(156))\n# key, subkey = jax.random.split(key)\n# token_gen = generate_text(jnp.zeros((1,block_size)).astype(jnp.int32), new_tokenz, {'params': state.params})\ntoken_gen = generate_text(key, params, var_params, new_tokenz)[:, 0, 0].tolist()\nprint(token_gen)\nprint(decode(token_gen))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:10.730760Z","iopub.execute_input":"2024-06-05T13:24:10.731074Z","iopub.status.idle":"2024-06-05T13:24:18.298566Z","shell.execute_reply.started":"2024-06-05T13:24:10.731050Z","shell.execute_reply":"2024-06-05T13:24:18.297625Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"(1, 32)\n[60, 46, 40, 57, 45, 9, 0, 19, 42, 49, 53, 46, 51, 44, 56, 57, 55, 38, 46, 51, 1, 60, 42, 51, 55, 62, 5, 56, 57, 1, 46, 56, 1, 53, 58, 49, 59, 42, 40, 45, 38, 49, 49, 1, 57, 45, 42, 1, 39, 46, 57, 42, 41, 1, 62, 52, 58, 1, 57, 45, 46, 56, 8, 0, 0, 23, 12, 16, 23, 23, 12, 9, 0, 17, 52, 55, 1, 38, 1, 57, 42, 38, 57, 45, 42, 55, 42, 8, 1, 27, 62, 38, 50, 46, 56, 42, 8, 0, 0, 34, 20, 23, 23, 16, 30, 9, 0, 24, 62, 1, 49, 52, 55, 41, 6, 1, 45, 46, 56, 1, 39, 42, 38, 55, 1, 52, 43, 1, 48, 46, 51, 44, 56, 1, 57, 52, 1, 43, 38, 46, 55, 1, 53, 55, 52, 56, 56, 1, 45, 42, 55, 42, 6, 1, 56, 46, 51, 44, 1, 60, 46, 57, 45, 1, 13, 46, 38, 51, 5, 41, 1, 44, 55, 52, 38, 41, 1, 39, 42, 1, 45, 52, 60, 1, 52, 43, 1, 62, 52, 58, 55, 1, 57, 52, 1, 49, 42, 38, 55, 1, 62, 52, 58, 55, 0, 20, 56, 1, 46, 51, 1, 45, 46, 57, 45, 38, 48, 8, 1, 26, 2, 1, 18, 52, 41, 6, 1, 45, 46, 50, 46, 56, 45, 6, 1, 49, 42, 42, 59, 42, 55, 1, 49, 52, 55, 41, 10, 0, 26, 50, 46, 51, 44, 56, 1, 60, 46, 49, 49, 1, 62, 52, 58, 1, 52, 51, 40, 42, 0, 25, 46, 43, 57, 1, 45, 46, 50, 56, 42, 49, 43, 2, 1, 18, 52, 6, 1, 40, 52, 58, 55, 57, 45, 8, 1, 31, 45, 42, 55, 42, 1, 57, 45, 52, 58, 1, 41, 42, 38, 41, 8, 1, 34, 45, 46, 57, 45, 38, 49, 8, 0, 0, 30, 42, 42, 8, 1, 31, 45, 46, 51, 48, 8, 0, 0, 24, 16, 29, 14, 19, 12, 15, 29, 20, 12, 29, 1, 23, 26, 29, 15, 9, 0, 13, 62, 1, 57, 52, 1, 39, 38, 57, 45, 1, 41, 46, 38, 44, 58, 46, 51, 44, 1, 55, 42, 50, 38, 46, 41, 6, 1, 38, 42, 50, 42, 57, 1, 57, 45, 42, 55, 42, 8, 1, 34, 45, 38, 57, 10, 0, 0, 20, 12, 14, 19, 20, 15, 26, 27, 9, 0, 0, 29, 20, 14, 19, 12, 29, 15, 1, 24, 12, 29, 14, 20, 32, 30, 9, 0, 20, 51, 1, 55, 42, 40, 52, 58, 51, 44, 39, 38, 40, 48, 8, 0, 0, 27, 52, 50, 38, 57, 57, 42, 55, 56, 1, 57, 60, 38, 44, 45, 57, 56, 6, 1, 56, 49, 38, 46, 57, 58, 56, 42, 6, 1, 57, 45, 38, 57, 1, 57, 52, 1, 45, 42, 1, 60, 42, 55, 42, 0, 17, 45, 38, 57, 45, 46, 51, 44, 5, 41, 1, 39, 62, 1, 57, 45, 52, 58, 1, 55, 38, 49, 46, 38, 49, 1, 62, 52, 58, 55, 1, 43, 52, 55, 1, 49, 52, 55, 41, 6, 1, 57, 45, 52, 58, 10, 0, 20, 5, 49, 49, 1, 38, 62, 1, 46, 57, 1, 50, 62, 1, 43, 42, 38, 55, 1, 50, 42, 9, 0, 30, 45, 42, 1, 57, 45, 38, 57, 1, 57, 46, 50, 42, 1, 52, 39, 55, 42, 42, 6, 1, 31, 52, 1, 43, 5, 41, 46, 42, 8, 0, 0, 19, 16, 29, 24, 20, 12, 25, 12, 9, 0, 20, 1, 48, 51, 52, 60, 1, 51, 52, 57, 1, 49, 38, 51, 44, 46, 42, 1, 43, 49, 58, 41, 62, 0, 0, 22, 12, 31, 19, 12, 29, 20, 37, 16, 29, 9, 0, 5, 31, 46, 56, 1, 57, 45, 42, 1, 44, 46, 59, 42, 1, 57, 46, 50, 42, 1, 38, 51, 41, 1, 43, 52, 55, 1, 52, 43, 1, 45, 38, 51, 40, 42, 7, 49, 52, 52, 48, 56, 6, 1, 40, 52, 51, 56, 42, 50, 52, 51, 6, 1, 41, 52, 57, 45, 6, 1, 20, 1, 57, 45, 42, 51, 10, 1, 46, 56, 1, 45, 42, 38, 55, 57, 45, 46, 51, 44, 1, 46, 56, 1, 52, 43, 1, 50, 62, 1, 57, 42, 38, 59, 42, 51, 57, 9, 0, 0, 22, 20, 25, 18, 1, 21, 26, 19, 25, 9, 0, 34, 45, 62, 1, 60, 46, 57, 45, 52, 58, 1, 41, 46, 42, 51, 42, 56, 57, 1, 51, 42, 60, 56, 1, 38, 51, 41, 1, 38, 51, 56, 60, 46, 51, 44, 7, 57, 45, 46, 51, 44, 50, 52, 51, 57, 42, 51, 0, 0, 19, 26, 29, 31, 16, 25, 30, 19, 12, 24, 13, 16, 25, 29, 36, 9, 0, 30, 57, 55, 58, 56, 57, 0, 12, 31, 16, 29, 9, 0, 17, 52, 55, 1, 60, 52, 55, 41, 6, 1, 12, 62, 6, 1, 60, 45, 42, 55, 42, 1, 51, 42, 60, 56, 1, 60, 52, 50, 62, 6, 0, 39, 52, 41, 42, 1, 46, 57, 1, 46, 50, 38, 56, 57, 1, 57, 45, 46, 51, 44, 10, 0, 0, 13, 29, 32, 31, 32, 30, 9, 0, 20, 1, 60, 46, 49, 49, 1, 41, 46, 41, 6, 1, 56, 46, 55, 55, 38, 45, 42, 60, 56, 6, 1, 38, 49, 49, 1, 21, 46, 55, 38, 40, 42, 10, 0, 0, 23, 12, 29, 31, 16, 29, 9, 0, 12, 62, 6, 1, 38, 51, 41, 1, 53, 38, 46, 51, 57, 49, 42, 50, 52, 51, 44, 1, 56, 45, 38, 49, 49, 1, 57, 45, 46, 56, 1, 49, 38, 59, 42, 1, 46, 56, 1, 56, 45, 38, 49, 48, 56, 62, 1, 57, 45, 46, 50, 1, 49, 46, 44, 45, 57, 42, 51, 6, 1, 49, 52, 59, 42, 10]\nwicth:\nHelpingstrain wenry'st is pulvechall the bited you this.\n\nLAELLA:\nFor a teathere. Pyamise.\n\nWILLES:\nMy lord, his bear of kings to fair pross here, sing with Bian'd groad be how of your to lear your\nIs in hithak. O! God, himish, leever lord;\nOmings will you once\nNift himself! Go, courth. There thou dead. Whithal.\n\nSee. Think.\n\nMERCHADRIAR LORD:\nBy to bath diaguing remaid, aemet there. What;\n\nIACHIDOP:\n\nRICHARD MARCIUS:\nIn recoungback.\n\nPomatters twaghts, slaituse, that to he were\nFhathing'd by thou ralial your for lord, thou;\nI'll ay it my fear me:\nShe that time obree, To f'die.\n\nHERMIANA:\nI know not langie fludy\n\nKATHARIZER:\n'Tis the give time and for of hance-looks, consemon, doth, I then; is hearthing is of my teavent:\n\nKING JOHN:\nWhy withou dienest news and answing-thingmonten\n\nHORTENSHAMBENRY:\nStrust\nATER:\nFor word, Ay, where news womy,\nbode it imast thing;\n\nBRUTUS:\nI will did, sirrahews, all Jirace;\n\nLARTER:\nAy, and paintlemong shall this lave is shalksy thim lighten, love;\n","output_type":"stream"}]},{"cell_type":"code","source":"dsfsdhfgjdg hfdgjdgjgfjhs'####################","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:18.299812Z","iopub.execute_input":"2024-06-05T13:24:18.300112Z","iopub.status.idle":"2024-06-05T13:24:18.305702Z","shell.execute_reply.started":"2024-06-05T13:24:18.300087Z","shell.execute_reply":"2024-06-05T13:24:18.304522Z"},"trusted":true},"execution_count":42,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[42], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    dsfsdhfgjdg hfdgjdgjgfjhs'####################\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"],"ename":"SyntaxError","evalue":"unterminated string literal (detected at line 1) (2630675753.py, line 1)","output_type":"error"}]},{"cell_type":"code","source":"len(token_gen)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:18.306955Z","iopub.status.idle":"2024-06-05T13:24:18.307502Z","shell.execute_reply.started":"2024-06-05T13:24:18.307257Z","shell.execute_reply":"2024-06-05T13:24:18.307277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 882\ntokenizer.decode(test_data[idx:idx+32])","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:18.308857Z","iopub.status.idle":"2024-06-05T13:24:18.309204Z","shell.execute_reply.started":"2024-06-05T13:24:18.309032Z","shell.execute_reply":"2024-06-05T13:24:18.309046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer('bestopleled', return_tensors='np')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:18.310723Z","iopub.status.idle":"2024-06-05T13:24:18.311082Z","shell.execute_reply.started":"2024-06-05T13:24:18.310922Z","shell.execute_reply":"2024-06-05T13:24:18.310936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode([1991])","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:18.312522Z","iopub.status.idle":"2024-06-05T13:24:18.312875Z","shell.execute_reply.started":"2024-06-05T13:24:18.312688Z","shell.execute_reply":"2024-06-05T13:24:18.312702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params['Dense_12']['kernel'].shape","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:18.314035Z","iopub.status.idle":"2024-06-05T13:24:18.314359Z","shell.execute_reply.started":"2024-06-05T13:24:18.314200Z","shell.execute_reply":"2024-06-05T13:24:18.314215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rngk = jax.random.PRNGKey(389)\nxs, ys = get_batch(rngk, train_data)\nprint(xs[0])\nprint(ys[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:18.316043Z","iopub.status.idle":"2024-06-05T13:24:18.316344Z","shell.execute_reply.started":"2024-06-05T13:24:18.316195Z","shell.execute_reply":"2024-06-05T13:24:18.316207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits = model.apply({'params': params, **var_params}, xs[0].reshape((1,64)), training=False, mutable=['other_variables'])[0]\nrng, rng_subkey = jax.random.split(rngk)\nfor pso in range(n_tokens):\n    new_token = jax.random.categorical(\n      rng_subkey, logits[:, -1*(n_tokens-pso), :], axis=-1, shape=(1, 1)\n    )\n    print(new_token)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:18.317523Z","iopub.status.idle":"2024-06-05T13:24:18.317864Z","shell.execute_reply.started":"2024-06-05T13:24:18.317677Z","shell.execute_reply":"2024-06-05T13:24:18.317689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_tok = [51,49,46,46,46,52]\nprint(decode(ys[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:18.319175Z","iopub.status.idle":"2024-06-05T13:24:18.319548Z","shell.execute_reply.started":"2024-06-05T13:24:18.319375Z","shell.execute_reply":"2024-06-05T13:24:18.319390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"act_tk = [60, 43, 50, 57,  1, 47]\nprint(decode(act_tk))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:18.320438Z","iopub.status.idle":"2024-06-05T13:24:18.320737Z","shell.execute_reply.started":"2024-06-05T13:24:18.320589Z","shell.execute_reply":"2024-06-05T13:24:18.320601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jax.nn.standardize(jnp.array([2.0,3.0,4.0]))","metadata":{"id":"Oe_GIDP2HFyt","outputId":"5d3dce16-fcc2-40b9-c49a-00a8c4013ca2","execution":{"iopub.status.busy":"2024-06-05T13:24:18.322416Z","iopub.status.idle":"2024-06-05T13:24:18.322716Z","shell.execute_reply.started":"2024-06-05T13:24:18.322566Z","shell.execute_reply":"2024-06-05T13:24:18.322578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@struct.dataclass\nclass Metrics(metrics.Collection):\n    accuracy: metrics.Accuracy\n    loss: metrics.Average.from_output('loss')","metadata":{"id":"s3nN1jOiHFyu","execution":{"iopub.status.busy":"2024-06-05T13:24:18.323852Z","iopub.status.idle":"2024-06-05T13:24:18.324173Z","shell.execute_reply.started":"2024-06-05T13:24:18.324015Z","shell.execute_reply":"2024-06-05T13:24:18.324029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainState(train_state.TrainState):\n    metrics: Metrics\n\ndef create_train_state(module, rng, learning_rate, train_shape):\n    \"\"\"Creates an initial `TrainState`.\"\"\"\n    params = module.init(rng, jnp.ones(train_shape).astype(jnp.int32), \n                         training=False)['params'] # initialize parameters by passing a template image\n    tx = optax.adamw(learning_rate)\n    return TrainState.create(\n      apply_fn=module.apply, params=params, tx=tx,\n      metrics=Metrics.empty(),\n    )","metadata":{"id":"7LLDTSFQHFyu","execution":{"iopub.status.busy":"2024-06-05T13:24:18.325434Z","iopub.status.idle":"2024-06-05T13:24:18.325745Z","shell.execute_reply.started":"2024-06-05T13:24:18.325591Z","shell.execute_reply":"2024-06-05T13:24:18.325604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TrainState.create(","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:18.327822Z","iopub.status.idle":"2024-06-05T13:24:18.328259Z","shell.execute_reply.started":"2024-06-05T13:24:18.328032Z","shell.execute_reply":"2024-06-05T13:24:18.328049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@jax.jit\ndef train_step(state, inputs, targets):\n    \"\"\"Train for a single step.\"\"\"\n    def loss_fn(params):\n        logits = state.apply_fn({'params': params}, inputs, training=True, \n                                rngs={\"dropout\": key})[0]\n        loss = optax.softmax_cross_entropy_with_integer_labels(\n            logits=logits, labels=targets).mean()\n        return loss\n    grad_fn = jax.grad(loss_fn)\n    grads = grad_fn(state.params)\n    state = state.apply_gradients(grads=grads)\n    return state","metadata":{"id":"zApWXUDaHFyu","execution":{"iopub.status.busy":"2024-06-05T13:24:18.329724Z","iopub.status.idle":"2024-06-05T13:24:18.330188Z","shell.execute_reply.started":"2024-06-05T13:24:18.329961Z","shell.execute_reply":"2024-06-05T13:24:18.329981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@jax.jit\ndef compute_metrics(*, state, inputs, targets):\n    logits = state.apply_fn({'params': state.params}, inputs, training=False)[0]\n    loss = optax.softmax_cross_entropy_with_integer_labels(\n        logits=logits, labels=targets).mean()\n    metric_updates = state.metrics.single_from_model_output(\n    logits=logits, labels=targets, loss=loss)\n    metrics = state.metrics.merge(metric_updates)\n    state = state.replace(metrics=metrics)\n    return state","metadata":{"id":"VzukZ4iEHFyv","execution":{"iopub.status.busy":"2024-06-05T13:24:18.331707Z","iopub.status.idle":"2024-06-05T13:24:18.332044Z","shell.execute_reply.started":"2024-06-05T13:24:18.331881Z","shell.execute_reply":"2024-06-05T13:24:18.331894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nlearning_rate = 0.005\ninit_rng = jax.random.key(0)","metadata":{"id":"ehYvMeuNHFyv","execution":{"iopub.status.busy":"2024-06-05T13:24:18.333102Z","iopub.status.idle":"2024-06-05T13:24:18.333413Z","shell.execute_reply.started":"2024-06-05T13:24:18.333258Z","shell.execute_reply":"2024-06-05T13:24:18.333271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state = create_train_state(fin_model, init_rng, learning_rate, train_shape)\ndel init_rng  # Must not be used anymore.","metadata":{"id":"D60UHLFHHFyv","execution":{"iopub.status.busy":"2024-06-05T13:24:18.334458Z","iopub.status.idle":"2024-06-05T13:24:18.334768Z","shell.execute_reply.started":"2024-06-05T13:24:18.334614Z","shell.execute_reply":"2024-06-05T13:24:18.334627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics_history = {'train_loss': [],\n                   'train_accuracy': [],\n                   'test_loss': [],\n                   'test_accuracy': []}","metadata":{"id":"Jl-9TlHEHFyv","execution":{"iopub.status.busy":"2024-06-05T13:24:18.336040Z","iopub.status.idle":"2024-06-05T13:24:18.336360Z","shell.execute_reply.started":"2024-06-05T13:24:18.336203Z","shell.execute_reply":"2024-06-05T13:24:18.336217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 442\nkey = jax.random.PRNGKey(SEED)\nloss = 10\ncounter = 0\n# for step in tqdm(range(max_iters)): # increase number of steps for good results...\nwhile counter==max_iters or loss > 1.0:\n\n      # sample a batch of data\n    xb, yb = get_batch(key, train_data)\n    state = train_step(state, xb, yb)\n    state = compute_metrics(state=state, inputs=xb, targets=yb)\n\n    key = (jax.random.split(key)[0])\n\n    if step == 0 or (step+1) % 100 == 0: # one training epoch has passed\n        for metric,value in state.metrics.compute().items(): # compute metrics\n            metrics_history[f'train_{metric}'].append(value) # record metrics\n        state = state.replace(metrics=state.metrics.empty()) # reset train_metrics for next training epoch\n\n        # Compute metrics on the test set after each training epoch\n        test_state = state\n        x_test, y_test = get_batch(key, test_data)\n    #     for test_batch in test_ds.as_numpy_iterator():\n        test_state = compute_metrics(state=test_state, inputs=x_test, targets=y_test)\n\n        for metric,value in test_state.metrics.compute().items():\n            metrics_history[f'test_{metric}'].append(value)\n\n        print(f\"train epoch: {(step+1)}, \"\n              f\"loss: {metrics_history['train_loss'][-1]}, \"\n              f\"accuracy: {metrics_history['train_accuracy'][-1] * 100}\")\n        print(f\"test epoch: {(step+1) }, \"\n          f\"loss: {metrics_history['test_loss'][-1]}, \"\n          f\"accuracy: {metrics_history['test_accuracy'][-1] * 100}\")","metadata":{"id":"CaNt9JazHFyw","outputId":"ba447ddf-9940-44a6-f4b2-d27ed78a88c2","execution":{"iopub.status.busy":"2024-06-05T13:24:18.337904Z","iopub.status.idle":"2024-06-05T13:24:18.338212Z","shell.execute_reply.started":"2024-06-05T13:24:18.338062Z","shell.execute_reply":"2024-06-05T13:24:18.338075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt  # Visualization\n\n# Plot loss and accuracy in subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.set_title('Loss')\nax2.set_title('Accuracy')\nfor dataset in ('train','test'):\n    ax1.plot(metrics_history[f'{dataset}_loss'], label=f'{dataset}_loss')\n    ax2.plot(metrics_history[f'{dataset}_accuracy'], label=f'{dataset}_accuracy')\nax1.legend()\nax2.legend()\nplt.show()\nplt.clf()","metadata":{"id":"Y40JGx1YHFyw","execution":{"iopub.status.busy":"2024-06-05T13:24:18.339100Z","iopub.status.idle":"2024-06-05T13:24:18.339391Z","shell.execute_reply.started":"2024-06-05T13:24:18.339244Z","shell.execute_reply":"2024-06-05T13:24:18.339256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlogits = fin_model.apply(fin_params, xb, training=False)[0]\nloss = optax.softmax_cross_entropy_with_integer_labels(\n            logits=logits, labels=yb).mean()\n\nprint(loss)","metadata":{"id":"7pJlFXpVHFyw","execution":{"iopub.status.busy":"2024-06-05T13:24:18.340751Z","iopub.status.idle":"2024-06-05T13:24:18.341086Z","shell.execute_reply.started":"2024-06-05T13:24:18.340929Z","shell.execute_reply":"2024-06-05T13:24:18.340942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def generate_text(idx, max_new_tokens, params):\n# # idx is (B, T) array of indices in the current context\n#     for i in range(max_new_tokens):\n#         # crop idx to the last block_size tokens\n#         idx_cond = idx[:, -block_size:]\n#         # get the predictions\n#         logits = fin_model.apply(params, idx_cond)\n#         # focus only on the last time step\n#         logits = logits[:, -1, :] # becomes (B, C)\n\n#         if i == 0:\n#             rng, rng_subkey = jax.random.split(jax.random.PRNGKey(12))\n#         else:\n#             rng, rng_subkey = jax.random.split(rng)\n\n#         idx_next = jax.random.categorical(rng_subkey, logits, axis=-1, shape=(1, 1)) # (B, 1)\n\n\n#         # append sampled index to the running sequence\n#         idx = jnp.concatenate([idx, idx_next], axis=-1) # (B, T+1)\n\n#     return idx","metadata":{"id":"9d28o-dTHFyx","execution":{"iopub.status.busy":"2024-06-05T13:24:18.342146Z","iopub.status.idle":"2024-06-05T13:24:18.342490Z","shell.execute_reply.started":"2024-06-05T13:24:18.342324Z","shell.execute_reply":"2024-06-05T13:24:18.342338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@partial(jax.jit, static_argnames=(\"self\", \"length\"))\ndef generate_text(rng, params, length):\n    def _scan_generate(carry, _):\n        random_key, context = carry\n        logits = fin_model.apply(params, context, training=False)[0]\n        rng, rng_subkey = jax.random.split(random_key)\n        new_token = jax.random.categorical(\n          rng_subkey, logits[:, -1, :], axis=-1, shape=(1, 1)\n        )\n        context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n        return (rng, context), new_token\n\n    _, new_tokens = jax.lax.scan(\n    _scan_generate,\n    (rng, jnp.zeros((1, block_size), dtype=jnp.int32)),\n    (),\n    length=length,\n    )\n    return new_tokens","metadata":{"id":"WB0og7pAHFyx","execution":{"iopub.status.busy":"2024-06-05T13:24:18.343358Z","iopub.status.idle":"2024-06-05T13:24:18.343698Z","shell.execute_reply.started":"2024-06-05T13:24:18.343541Z","shell.execute_reply":"2024-06-05T13:24:18.343554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_tokenz = 1000\nkey, subkey = jax.random.split(jax.random.PRNGKey(156))\n# key, subkey = jax.random.split(key)\n# token_gen = generate_text(jnp.zeros((1,block_size)).astype(jnp.int32), new_tokenz, {'params': state.params})\ntoken_gen = generate_text(key, {'params': state.params}, new_tokenz)[:, 0, 0].tolist()\nprint(token_gen)\nprint(decode(token_gen))","metadata":{"id":"50Vpg2lEHFyx","execution":{"iopub.status.busy":"2024-06-05T13:24:18.344752Z","iopub.status.idle":"2024-06-05T13:24:18.345104Z","shell.execute_reply.started":"2024-06-05T13:24:18.344939Z","shell.execute_reply":"2024-06-05T13:24:18.344952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdgh  fs","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:18.346367Z","iopub.status.idle":"2024-06-05T13:24:18.346664Z","shell.execute_reply.started":"2024-06-05T13:24:18.346516Z","shell.execute_reply":"2024-06-05T13:24:18.346529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state.params","metadata":{"execution":{"iopub.status.busy":"2024-06-05T13:24:18.347884Z","iopub.status.idle":"2024-06-05T13:24:18.348189Z","shell.execute_reply.started":"2024-06-05T13:24:18.348040Z","shell.execute_reply":"2024-06-05T13:24:18.348053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install mamba-ssm","metadata":{"id":"MOw_xjbrHFy0","execution":{"iopub.status.busy":"2024-06-05T13:24:18.349212Z","iopub.status.idle":"2024-06-05T13:24:18.349508Z","shell.execute_reply.started":"2024-06-05T13:24:18.349360Z","shell.execute_reply":"2024-06-05T13:24:18.349373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ones = lambda *size: torch.ones(*size).float().cuda()\nzeros = lambda *size: torch.zeros(*size).float().cuda()\narange = lambda n: torch.arange(n).float().cuda()\nrand = lambda size: torch.rand(*size).abs().float().cuda()\n\ndef create_torch(S = 128, Ba = 2, D = 4, N = 4):\n    x = rand((Ba, 1, D, S))\n    a = -ones((Ba, N, D, 1))\n    b = ones((Ba, N, 1, S)) * 0.1\n    c = rand((Ba, N, 1, S)) * 0.1\n    delta = rand((Ba, 1, D, S)) * 0.1\n    return x, a, b, c, delta","metadata":{"id":"W_PAnYcEOR22","execution":{"iopub.status.busy":"2024-06-05T13:24:18.350572Z","iopub.status.idle":"2024-06-05T13:24:18.350896Z","shell.execute_reply.started":"2024-06-05T13:24:18.350717Z","shell.execute_reply":"2024-06-05T13:24:18.350729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import selective_scan_cuda\n\nxx, aa, bb, cc, ddelta = create_torch()\ny_from_repo = selective_scan_cuda.fwd(xx.squeeze(1), ddelta.squeeze(1), aa[0].squeeze(-1).T, bb.squeeze(-2)[:, None, :, :], cc.squeeze(-2)[:, None, :, :], None, None, None, False)\ny_from_repo","metadata":{"id":"ykh4GTvtOrak","execution":{"iopub.status.busy":"2024-06-05T13:24:18.352284Z","iopub.status.idle":"2024-06-05T13:24:18.352747Z","shell.execute_reply.started":"2024-06-05T13:24:18.352508Z","shell.execute_reply":"2024-06-05T13:24:18.352529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discretize(a, b, delta):\n    da = delta * a\n    a_ = jnp.exp(da)\n    b_ = b * delta\n    return a_, b_\n\ndef ssm(x, a, b, c, delta):\n    \"Jax Implementation\"\n    y = []\n    h = 0\n    a_, b_ = discretize(a, b, delta)\n    for k in range(x.shape[-1]):\n        h = a_[..., k] * h + b_[..., k] * x[..., k]\n        y.append((c[..., k] * h).sum(1, keepdims=True))\n    return h, jnp.stack(y, -1)\n","metadata":{"id":"NEdG1yPNOtxU","execution":{"iopub.status.busy":"2024-06-05T13:24:18.354332Z","iopub.status.idle":"2024-06-05T13:24:18.354791Z","shell.execute_reply.started":"2024-06-05T13:24:18.354550Z","shell.execute_reply":"2024-06-05T13:24:18.354568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, y_ = ssm(xx.cpu().numpy(), aa.cpu().numpy(), bb.cpu().numpy(), cc.cpu().numpy(), ddelta.cpu().numpy())","metadata":{"id":"GEjNcZSZPIp_","execution":{"iopub.status.busy":"2024-06-05T13:24:18.355824Z","iopub.status.idle":"2024-06-05T13:24:18.356251Z","shell.execute_reply.started":"2024-06-05T13:24:18.356030Z","shell.execute_reply":"2024-06-05T13:24:18.356048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"tWlqZZOmPnYk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mamba_ssm import Mamba as Mamba_T\ntorch_mamba = Mamba_T(\n      # This module uses roughly 3 * expand * d_model^2 parameters\n      d_model=n_embd, # Model dimension d_model\n      d_state=16,  # SSM state expansion factor\n      d_conv=4,    # Local convolution width\n      expand=2,    # Block expansion factor\n)","metadata":{"id":"5RHAE_I1Pql9","execution":{"iopub.status.busy":"2024-06-05T13:24:18.357401Z","iopub.status.idle":"2024-06-05T13:24:18.357930Z","shell.execute_reply.started":"2024-06-05T13:24:18.357671Z","shell.execute_reply":"2024-06-05T13:24:18.357691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xm = x = rand((1, 1, n_embd, 32))\nxm.shape","metadata":{"id":"l9zw_M-USrDt","execution":{"iopub.status.busy":"2024-06-05T13:24:18.359578Z","iopub.status.idle":"2024-06-05T13:24:18.359926Z","shell.execute_reply.started":"2024-06-05T13:24:18.359743Z","shell.execute_reply":"2024-06-05T13:24:18.359757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_mamba(xm.squeeze(1))","metadata":{"id":"gGmA2EWlTCo0","execution":{"iopub.status.busy":"2024-06-05T13:24:18.361141Z","iopub.status.idle":"2024-06-05T13:24:18.361462Z","shell.execute_reply.started":"2024-06-05T13:24:18.361305Z","shell.execute_reply":"2024-06-05T13:24:18.361319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_mamba.in_proj","metadata":{"id":"73ek9mx9UBBl","execution":{"iopub.status.busy":"2024-06-05T13:24:18.362806Z","iopub.status.idle":"2024-06-05T13:24:18.363231Z","shell.execute_reply.started":"2024-06-05T13:24:18.363012Z","shell.execute_reply":"2024-06-05T13:24:18.363030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import CLIPTokenizer\ntokenizer_1 = CLIPTokenizer.from_pretrained('openai/clip-vit-base-patch32')","metadata":{"id":"P3l_ssIYbiYT","execution":{"iopub.status.busy":"2024-06-05T13:24:18.364646Z","iopub.status.idle":"2024-06-05T13:24:18.365095Z","shell.execute_reply.started":"2024-06-05T13:24:18.364864Z","shell.execute_reply":"2024-06-05T13:24:18.364882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenise_prompts(prompt):\n    inputs = []\n    for tokenizer in [tokenizer_1, tokenizer_2]:\n        text_inputs = tokenizer(\n            positive_prompt,\n            padding=\"max_length\",\n            max_length=tokenizer.model_max_length,\n            truncation=True,\n            return_tensors=\"np\",\n        )\n        inputs.append(text_inputs.input_ids)\n    return jnp.stack(inputs, axis=1)","metadata":{"id":"-X7hXQRMZhl3","execution":{"iopub.status.busy":"2024-06-05T13:24:18.366583Z","iopub.status.idle":"2024-06-05T13:24:18.367118Z","shell.execute_reply.started":"2024-06-05T13:24:18.366835Z","shell.execute_reply":"2024-06-05T13:24:18.366854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xm.squeeze(1).shape","metadata":{"id":"rJhKQ_Oua9Gy","execution":{"iopub.status.busy":"2024-06-05T13:24:18.369156Z","iopub.status.idle":"2024-06-05T13:24:18.369597Z","shell.execute_reply.started":"2024-06-05T13:24:18.369372Z","shell.execute_reply":"2024-06-05T13:24:18.369391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"mzkoYrSVkoJj"},"execution_count":null,"outputs":[]}]}