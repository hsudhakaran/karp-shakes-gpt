{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from functools import partial\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom jax.nn.initializers import lecun_normal, normal\nfrom jax.numpy.linalg import eigh, inv, matrix_power\nfrom jax.scipy.signal import convolve\n\nimport tensorflow_datasets as tfds\n\nimport torch\n\nfrom dataclasses import dataclass\n\nfrom typing import Union\n\nimport matplotlib.pyplot as plt\nimport seaborn\n\n# from clu import metrics\nfrom flax.training import train_state  # Useful dataclass to keep train state\nfrom flax import struct                # Flax dataclasses\nimport optax                           # Common loss functions and optimizers\nfrom tqdm import tqdm\n\nimport pdb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-01T06:56:57.879588Z","iopub.execute_input":"2024-07-01T06:56:57.880010Z","iopub.status.idle":"2024-07-01T06:57:01.913300Z","shell.execute_reply.started":"2024-07-01T06:56:57.879977Z","shell.execute_reply":"2024-07-01T06:57:01.912499Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/shak-new-input/train.txt', 'r', encoding='utf-8') as f:\n    text_train = f.read()\n    \nwith open('/kaggle/input/shak-new-input/test.txt', 'r', encoding='utf-8') as f:\n    text_validation = f.read()    ","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:57:01.914868Z","iopub.execute_input":"2024-07-01T06:57:01.915560Z","iopub.status.idle":"2024-07-01T06:57:01.925666Z","shell.execute_reply.started":"2024-07-01T06:57:01.915486Z","shell.execute_reply":"2024-07-01T06:57:01.924844Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# here are all the unique characters that occur in this text\nchars = sorted(list(set(text_train+text_validation)))\n# chars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:57:01.926617Z","iopub.execute_input":"2024-07-01T06:57:01.926873Z","iopub.status.idle":"2024-07-01T06:57:01.950919Z","shell.execute_reply.started":"2024-07-01T06:57:01.926850Z","shell.execute_reply":"2024-07-01T06:57:01.950099Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n65\n","output_type":"stream"}]},{"cell_type":"code","source":"# create a mapping from characters to integers\nstoi = { ch: i for i,ch in enumerate(chars) }\nitos = { i: ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n\nprint(encode(\"hii there\"))\nprint(decode(encode(\"hii there\")))","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:57:01.951897Z","iopub.execute_input":"2024-07-01T06:57:01.952142Z","iopub.status.idle":"2024-07-01T06:57:01.962781Z","shell.execute_reply.started":"2024-07-01T06:57:01.952119Z","shell.execute_reply":"2024-07-01T06:57:01.961817Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[46, 47, 47, 1, 58, 46, 43, 56, 43]\nhii there\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = jnp.array(encode(text_train), dtype=jnp.int32)\ntest_data = jnp.array(encode(text_validation), dtype=jnp.int32)\nblock_size = 8\ntrain_data[:block_size+1]","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:57:01.965065Z","iopub.execute_input":"2024-07-01T06:57:01.965319Z","iopub.status.idle":"2024-07-01T06:57:04.335888Z","shell.execute_reply.started":"2024-07-01T06:57:01.965296Z","shell.execute_reply":"2024-07-01T06:57:04.334946Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Array([18, 47, 56, 57, 58,  1, 15, 47, 58], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target: {target}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:57:04.337062Z","iopub.execute_input":"2024-07-01T06:57:04.337397Z","iopub.status.idle":"2024-07-01T06:57:04.843753Z","shell.execute_reply.started":"2024-07-01T06:57:04.337369Z","shell.execute_reply":"2024-07-01T06:57:04.842550Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"when input is [18] the target: 47\nwhen input is [18 47] the target: 56\nwhen input is [18 47 56] the target: 57\nwhen input is [18 47 56 57] the target: 58\nwhen input is [18 47 56 57 58] the target: 1\nwhen input is [18 47 56 57 58  1] the target: 15\nwhen input is [18 47 56 57 58  1 15] the target: 47\nwhen input is [18 47 56 57 58  1 15 47] the target: 58\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 128 # how many independent sequences will we process in parallel?\nblock_size = 64 # what is the maximum context length for predictions?\nseq_size = block_size//8\n\nmax_iters = 50000\nlearning_rate = 5e-4\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 100\nn_embd = 64\nexpans = 2\nhidden_dim = n_embd*expans*4\nconv_k_size = 3\nn_latent_dim = 16\nn_tokens = 1\n\nrng_key = jax.random.PRNGKey(1564)\n\ndynamic_slice_vmap = jax.vmap(jax.lax.dynamic_slice, in_axes=(None, 0, None))\n\n@jax.jit\ndef get_batch(random_key, data):\n    \"\"\"Prepares a random batch of training data.\n\n    Args:\n      random_key: A random seed for sampling a batch.\n      data: The complete training dataset.\n\n    Returns:\n      x: Input sequences.\n      y: Target sequences (shifted inputs).\n    \"\"\"\n    ix = jax.random.randint(\n      random_key, shape=(batch_size, 1), minval=0, maxval=len(data) - block_size\n    )\n    x = dynamic_slice_vmap(data, ix, (block_size,))\n    y = dynamic_slice_vmap(data, ix + n_tokens, (block_size,))\n    return x, y\n\nxb, yb = get_batch(rng_key, train_data)\ntrain_shape = xb.shape\nprint('inputs:')\nprint(xb.shape)\nprint(xb)\nprint('targets:')\nprint(yb.shape)\nprint(yb)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:57:04.845237Z","iopub.execute_input":"2024-07-01T06:57:04.845627Z","iopub.status.idle":"2024-07-01T06:57:05.086752Z","shell.execute_reply.started":"2024-07-01T06:57:04.845592Z","shell.execute_reply":"2024-07-01T06:57:05.085802Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"inputs:\n(128, 64)\n[[12  0  0 ... 53 42  1]\n [ 1 44 39 ... 56  1 45]\n [56 57  8 ... 10  0 17]\n ...\n [54 53 53 ... 17 17 26]\n [59 58 58 ... 16 21 33]\n [50  1 57 ... 47 58  1]]\ntargets:\n(128, 64)\n[[ 0  0 15 ... 42  1 40]\n [44 39 56 ...  1 45 56]\n [57  8  0 ...  0 17 47]\n ...\n [53 53 56 ... 17 26  1]\n [58 58 43 ... 21 33 31]\n [ 1 57 53 ... 58  1 40]]\n","output_type":"stream"}]},{"cell_type":"code","source":"class Mamba_Unet(nn.Module):\n    \n    @nn.compact\n    def __call__(self, x):\n        embeds = nn.Embed(vocab_size, n_embd)(x) + nn.Embed(\n            block_size, n_embd)(jnp.arange(block_size))\n        \n        conv1 = jax.nn.silu(nn.Conv(features=n_embd*expans, kernel_size=conv_k_size,padding=1)(embeds))\n        \n        max_pool1 = nn.max_pool(conv1 , window_shape=(2,), strides=(2,), padding='valid')\n        max_pool1_ind = (conv1 == jnp.repeat(max_pool1 , repeats=2, axis=1)).astype(jnp.int32)\n        \n        conv2 = jax.nn.silu(nn.Conv(features=n_embd*expans*2, kernel_size=conv_k_size,padding=1)(max_pool1))\n    \n        max_pool2 = nn.max_pool(conv2 , window_shape=(2,), strides=(2,), padding='valid')\n        max_pool2_ind = (conv2 == jnp.repeat(max_pool2 , repeats=2, axis=1)).astype(jnp.int32)   \n        \n        conv3 = jax.nn.silu(nn.Conv(features=n_embd*expans*4, kernel_size=conv_k_size,padding=1)(max_pool2))\n    \n        max_pool3 = nn.max_pool(conv3 , window_shape=(2,), strides=(2,), padding='valid')\n        max_pool3_ind = (conv3 == jnp.repeat(max_pool3 , repeats=2, axis=1)).astype(jnp.int32)\n        \n        A = -1*self.param('A', nn.initializers.ones, (1, n_latent_dim, hidden_dim, 1))\n        B = 0.1*self.param('B', nn.initializers.ones, (1, n_latent_dim, 1, seq_size))\n        C = 0.09*self.param('C', jax.random.normal, (1, n_latent_dim, 1, seq_size))\n        D = 0.1*self.param('D', jax.random.normal, (1, 1,hidden_dim, seq_size))\n        delta = 0.05*self.param('delta', jax.random.normal, (1, 1, hidden_dim, seq_size))\n        \n        x = nn.RMSNorm()(jnp.expand_dims(jnp.transpose(max_pool3,(0,2,1)), axis=1))\n        x = self.ssm(x, A, B, C, D, delta)\n        x = jnp.transpose(x[:,0,:,:],(0,2,1))\n        ###############\n        uconv3 = jnp.repeat(x, repeats=2, axis=1)*jnp.concatenate([max_pool3_ind[:,1:,:],jnp.ones((max_pool3_ind.shape[0],1,max_pool3_ind.shape[-1]))], axis=1)\n        \n        cat_conv3 = jnp.concatenate([conv3, uconv3], axis=-1)\n        conv4 = jax.nn.silu(nn.Conv(features=cat_conv3.shape[-1]//2, kernel_size=conv_k_size,padding=1)(cat_conv3))\n        \n        conv3T = nn.ConvTranspose(conv4.shape[-1]//2, kernel_size = 3, padding = 1)(conv4)\n        ###############\n        uconv2 = jnp.repeat(conv3T, repeats=2, axis=1)*jnp.concatenate([max_pool2_ind[:,1:,:],jnp.ones((max_pool2_ind.shape[0],1,max_pool2_ind.shape[-1]))], axis=1)\n        \n        cat_conv2 = jnp.concatenate([conv2, uconv2], axis=-1)\n        conv5 = jax.nn.silu(nn.Conv(features=cat_conv2.shape[-1]//2, kernel_size=conv_k_size,padding=1)(cat_conv2))\n        \n        conv2T = nn.ConvTranspose(conv5.shape[-1]//2, kernel_size = 3, padding = 1)(conv5)\n        \n        ###############\n        uconv1 = jnp.repeat(conv2T, repeats=2, axis=1)*jnp.concatenate([max_pool1_ind[:,1:,:],jnp.ones((max_pool1_ind.shape[0],1,max_pool1_ind.shape[-1]))], axis=1)\n        \n        cat_conv1 = jnp.concatenate([conv1, uconv1], axis=-1)\n        conv6 = jax.nn.silu(nn.Conv(features=cat_conv1.shape[-1]//2, kernel_size=conv_k_size,padding=1)(cat_conv1))\n        \n        conv1T = nn.ConvTranspose(conv6.shape[-1]//2, kernel_size = 3, padding = 1)(conv6)\n        ##############\n#         pdb.set_trace()\n        output = nn.Dense(vocab_size)(nn.RMSNorm()(conv1T))\n        \n                \n#         first_uconv = jnp.repeat(max_pool1, repeats=2, axis=1)*max_pool1_ind\n        \n        \n        return output\n    \n    def discretize(self, A, B, delta):\n        da = delta * A\n        a_ = jnp.exp(da)\n        b_ = B * delta\n        return a_, b_\n\n    def ssm(self, x, A, B, C, D, delta):\n        a_, b_ = self.discretize(A, B, delta)\n        h = 0\n        for k in range(x.shape[-1]):\n            h = a_[..., k] * h + b_[..., k] * x[..., k]\n#         _, N, D, S = a_.shape\n#         indices = jnp.tril(jnp.ones((S-1,S-1))) \n#         indices = jnp.expand_dims(a_[...,1:],axis=4)*jnp.expand_dims(indices, axis=(0,1,2)) + jnp.expand_dims(jnp.triu(jnp.ones((S-1,S-1)),1), axis=(0,1,2))\n#         indices = (jnp.concatenate((indices, jnp.ones((1,N,D,S-1,1))), axis=-1)).prod(axis=-2)\n#         h = (indices*(b_*x)).sum(axis=-1)\n\n        y = ((C * jax.lax.expand_dims(h,[3])).sum(1, keepdims=True) + D*x)\n        \n#         self.hidden_state.value = jax.nn.standardize(h.mean(0, keepdims=True))\n        return y    \n                ","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:57:05.088313Z","iopub.execute_input":"2024-07-01T06:57:05.088635Z","iopub.status.idle":"2024-07-01T06:57:05.114788Z","shell.execute_reply.started":"2024-07-01T06:57:05.088607Z","shell.execute_reply":"2024-07-01T06:57:05.113889Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def loss_fun(params, x, y, dropout_key):\n    logits = model.apply(params, x)\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), accuracy\n\n@jax.jit\ndef eval_step(params, x, y):\n    logits = model.apply(params, x)\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), accuracy","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:57:05.115877Z","iopub.execute_input":"2024-07-01T06:57:05.116137Z","iopub.status.idle":"2024-07-01T06:57:05.127308Z","shell.execute_reply.started":"2024-07-01T06:57:05.116113Z","shell.execute_reply":"2024-07-01T06:57:05.126607Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"key = jax.random.PRNGKey(42)\n# x = jnp.expand_dims(xb[0],axis=0)\nx = xb\nmodel = Mamba_Unet()\n\nparams = model.init(jax.random.PRNGKey(45),x)\nprint(params.keys())\nn_params = sum(p.size for p in jax.tree_util.tree_leaves(params))\n\nprint(f\"Total number of parameters: {n_params:_}\")\n\noutput = model.apply(params, x)\nprint(output.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:57:05.128396Z","iopub.execute_input":"2024-07-01T06:57:05.128737Z","iopub.status.idle":"2024-07-01T06:57:15.102361Z","shell.execute_reply.started":"2024-07-01T06:57:05.128713Z","shell.execute_reply":"2024-07-01T06:57:15.101443Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"dict_keys(['params'])\nTotal number of parameters: 3_128_009\n(128, 64, 65)\n","output_type":"stream"}]},{"cell_type":"code","source":"opt = optax.adamw(learning_rate=learning_rate)\n\nopt_state = opt.init(params)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:57:15.103391Z","iopub.execute_input":"2024-07-01T06:57:15.103692Z","iopub.status.idle":"2024-07-01T06:57:15.381655Z","shell.execute_reply.started":"2024-07-01T06:57:15.103665Z","shell.execute_reply":"2024-07-01T06:57:15.380841Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"%%time\n\nall_train_losses = []\nall_eval_losses = []\n\nall_train_accuracy =  []\nall_test_accuracy = []\n\n# we define one iteration of the optimizer and JIT this function\n@jax.jit\ndef step(key, params, opt_state):\n    key, subkey = jax.random.split(key)\n    xb, yb = get_batch(key, train_data)\n    (loss, train_accuracy), grad = jax.value_and_grad(loss_fun, has_aux=True)(params, xb, yb, subkey)\n    updates, opt_state = opt.update(grad, opt_state, params)\n    params = optax.apply_updates(params, updates)\n    return params, key, opt_state, loss, train_accuracy\n\n# for i in tqdm(range(max_iters)):\ncounter = 0\nloss = 10\nwhile counter<max_iters: # and loss > 1.0:\n\n    params, key, opt_state, loss, train_accuracy = step(key, params, opt_state)\n    \n\n    # once every N_FREQ_EVAL we compute loss on the validation set\n    if counter % eval_iters == 0:\n        key, subkey = jax.random.split(key)\n        eval_loss, eval_accuracy = eval_step(params, *get_batch(subkey, test_data))\n        all_train_losses.append(loss)\n        all_eval_losses.append(eval_loss)\n        all_train_accuracy.append(train_accuracy)\n        all_test_accuracy.append(eval_accuracy)\n        print('##########################################################')\n        print(\"Step: \", counter,\"\\t Train Loss: \", loss,\"\\t Train Accuracy: \", format(train_accuracy, \".2%\"))\n        print(\"Step: \", counter,\"\\t Eval Loss: \", eval_loss,\"\\t Eval Accuracy: \", format(eval_accuracy, \".2%\"))\n        \n    counter += 1\n        ","metadata":{"execution":{"iopub.status.busy":"2024-07-01T06:57:15.382713Z","iopub.execute_input":"2024-07-01T06:57:15.382980Z","iopub.status.idle":"2024-07-01T07:08:49.635435Z","shell.execute_reply.started":"2024-07-01T06:57:15.382956Z","shell.execute_reply":"2024-07-01T07:08:49.634394Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"##########################################################\nStep:  0 \t Train Loss:  4.6028643 \t Train Accuracy:  1.03%\nStep:  0 \t Eval Loss:  3.993373 \t Eval Accuracy:  6.58%\n##########################################################\nStep:  100 \t Train Loss:  0.11316575 \t Train Accuracy:  98.54%\nStep:  100 \t Eval Loss:  0.102712765 \t Eval Accuracy:  98.68%\n##########################################################\nStep:  200 \t Train Loss:  0.062377915 \t Train Accuracy:  98.90%\nStep:  200 \t Eval Loss:  0.06413266 \t Eval Accuracy:  98.84%\n##########################################################\nStep:  300 \t Train Loss:  0.05092697 \t Train Accuracy:  98.95%\nStep:  300 \t Eval Loss:  0.054274704 \t Eval Accuracy:  98.86%\n##########################################################\nStep:  400 \t Train Loss:  0.04722541 \t Train Accuracy:  98.95%\nStep:  400 \t Eval Loss:  0.04943958 \t Eval Accuracy:  98.90%\n##########################################################\nStep:  500 \t Train Loss:  0.03726171 \t Train Accuracy:  99.11%\nStep:  500 \t Eval Loss:  0.04414152 \t Eval Accuracy:  98.91%\n##########################################################\nStep:  600 \t Train Loss:  0.038950246 \t Train Accuracy:  98.91%\nStep:  600 \t Eval Loss:  0.04082024 \t Eval Accuracy:  98.99%\n##########################################################\nStep:  700 \t Train Loss:  0.036001287 \t Train Accuracy:  99.08%\nStep:  700 \t Eval Loss:  0.03913818 \t Eval Accuracy:  99.01%\n##########################################################\nStep:  800 \t Train Loss:  0.03599914 \t Train Accuracy:  99.08%\nStep:  800 \t Eval Loss:  0.03760847 \t Eval Accuracy:  99.00%\n##########################################################\nStep:  900 \t Train Loss:  0.034171 \t Train Accuracy:  99.11%\nStep:  900 \t Eval Loss:  0.03548225 \t Eval Accuracy:  99.06%\n##########################################################\nStep:  1000 \t Train Loss:  0.033285405 \t Train Accuracy:  99.15%\nStep:  1000 \t Eval Loss:  0.03672134 \t Eval Accuracy:  98.99%\n##########################################################\nStep:  1100 \t Train Loss:  0.03101384 \t Train Accuracy:  99.19%\nStep:  1100 \t Eval Loss:  0.036474608 \t Eval Accuracy:  99.05%\n##########################################################\nStep:  1200 \t Train Loss:  0.037251443 \t Train Accuracy:  98.96%\nStep:  1200 \t Eval Loss:  0.033353478 \t Eval Accuracy:  98.99%\n##########################################################\nStep:  1300 \t Train Loss:  0.0345857 \t Train Accuracy:  99.08%\nStep:  1300 \t Eval Loss:  0.031882286 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  1400 \t Train Loss:  0.0346205 \t Train Accuracy:  99.16%\nStep:  1400 \t Eval Loss:  0.03147396 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  1500 \t Train Loss:  0.028879544 \t Train Accuracy:  99.13%\nStep:  1500 \t Eval Loss:  0.031355113 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  1600 \t Train Loss:  0.03372013 \t Train Accuracy:  99.04%\nStep:  1600 \t Eval Loss:  0.036038175 \t Eval Accuracy:  99.00%\n##########################################################\nStep:  1700 \t Train Loss:  0.033363767 \t Train Accuracy:  99.08%\nStep:  1700 \t Eval Loss:  0.03342916 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  1800 \t Train Loss:  0.030621327 \t Train Accuracy:  99.23%\nStep:  1800 \t Eval Loss:  0.034221344 \t Eval Accuracy:  99.06%\n##########################################################\nStep:  1900 \t Train Loss:  0.030699205 \t Train Accuracy:  99.17%\nStep:  1900 \t Eval Loss:  0.03470331 \t Eval Accuracy:  99.00%\n##########################################################\nStep:  2000 \t Train Loss:  0.033905968 \t Train Accuracy:  98.96%\nStep:  2000 \t Eval Loss:  0.032447144 \t Eval Accuracy:  99.07%\n##########################################################\nStep:  2100 \t Train Loss:  0.027250638 \t Train Accuracy:  99.18%\nStep:  2100 \t Eval Loss:  0.032331772 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  2200 \t Train Loss:  0.03302566 \t Train Accuracy:  99.01%\nStep:  2200 \t Eval Loss:  0.029919665 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  2300 \t Train Loss:  0.030346878 \t Train Accuracy:  99.21%\nStep:  2300 \t Eval Loss:  0.032274682 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  2400 \t Train Loss:  0.028228868 \t Train Accuracy:  99.21%\nStep:  2400 \t Eval Loss:  0.02943239 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  2500 \t Train Loss:  0.026202727 \t Train Accuracy:  99.21%\nStep:  2500 \t Eval Loss:  0.032150287 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  2600 \t Train Loss:  0.02920108 \t Train Accuracy:  99.18%\nStep:  2600 \t Eval Loss:  0.032623723 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  2700 \t Train Loss:  0.026042454 \t Train Accuracy:  99.27%\nStep:  2700 \t Eval Loss:  0.03360035 \t Eval Accuracy:  99.12%\n##########################################################\nStep:  2800 \t Train Loss:  0.0319162 \t Train Accuracy:  99.05%\nStep:  2800 \t Eval Loss:  0.03155814 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  2900 \t Train Loss:  0.028214129 \t Train Accuracy:  99.23%\nStep:  2900 \t Eval Loss:  0.029492235 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  3000 \t Train Loss:  0.02782578 \t Train Accuracy:  99.23%\nStep:  3000 \t Eval Loss:  0.033015005 \t Eval Accuracy:  99.06%\n##########################################################\nStep:  3100 \t Train Loss:  0.028918963 \t Train Accuracy:  99.15%\nStep:  3100 \t Eval Loss:  0.029413002 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  3200 \t Train Loss:  0.0312898 \t Train Accuracy:  99.16%\nStep:  3200 \t Eval Loss:  0.030046426 \t Eval Accuracy:  99.06%\n##########################################################\nStep:  3300 \t Train Loss:  0.02758389 \t Train Accuracy:  99.22%\nStep:  3300 \t Eval Loss:  0.02839626 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  3400 \t Train Loss:  0.024038061 \t Train Accuracy:  99.24%\nStep:  3400 \t Eval Loss:  0.02168631 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  3500 \t Train Loss:  0.03006898 \t Train Accuracy:  99.10%\nStep:  3500 \t Eval Loss:  0.033783898 \t Eval Accuracy:  99.06%\n##########################################################\nStep:  3600 \t Train Loss:  0.031149259 \t Train Accuracy:  99.15%\nStep:  3600 \t Eval Loss:  0.0262812 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  3700 \t Train Loss:  0.028937899 \t Train Accuracy:  99.15%\nStep:  3700 \t Eval Loss:  0.029751413 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  3800 \t Train Loss:  0.0274644 \t Train Accuracy:  99.15%\nStep:  3800 \t Eval Loss:  0.029915972 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  3900 \t Train Loss:  0.025297746 \t Train Accuracy:  99.33%\nStep:  3900 \t Eval Loss:  0.028271072 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  4000 \t Train Loss:  0.02664107 \t Train Accuracy:  99.24%\nStep:  4000 \t Eval Loss:  0.029277112 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  4100 \t Train Loss:  0.027818833 \t Train Accuracy:  99.26%\nStep:  4100 \t Eval Loss:  0.034042906 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  4200 \t Train Loss:  0.027493017 \t Train Accuracy:  99.19%\nStep:  4200 \t Eval Loss:  0.031546067 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  4300 \t Train Loss:  0.025252916 \t Train Accuracy:  99.23%\nStep:  4300 \t Eval Loss:  0.026888154 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  4400 \t Train Loss:  0.030768512 \t Train Accuracy:  99.07%\nStep:  4400 \t Eval Loss:  0.03121984 \t Eval Accuracy:  99.04%\n##########################################################\nStep:  4500 \t Train Loss:  0.027534354 \t Train Accuracy:  99.26%\nStep:  4500 \t Eval Loss:  0.027672403 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  4600 \t Train Loss:  0.030465543 \t Train Accuracy:  99.22%\nStep:  4600 \t Eval Loss:  0.025099184 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  4700 \t Train Loss:  0.024017118 \t Train Accuracy:  99.28%\nStep:  4700 \t Eval Loss:  0.031486694 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  4800 \t Train Loss:  0.024416195 \t Train Accuracy:  99.23%\nStep:  4800 \t Eval Loss:  0.02539281 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  4900 \t Train Loss:  0.023409372 \t Train Accuracy:  99.37%\nStep:  4900 \t Eval Loss:  0.026086427 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  5000 \t Train Loss:  0.025499763 \t Train Accuracy:  99.29%\nStep:  5000 \t Eval Loss:  0.031110268 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  5100 \t Train Loss:  0.027168026 \t Train Accuracy:  99.26%\nStep:  5100 \t Eval Loss:  0.030247042 \t Eval Accuracy:  99.04%\n##########################################################\nStep:  5200 \t Train Loss:  0.02389824 \t Train Accuracy:  99.28%\nStep:  5200 \t Eval Loss:  0.027012892 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  5300 \t Train Loss:  0.02526359 \t Train Accuracy:  99.27%\nStep:  5300 \t Eval Loss:  0.030060878 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  5400 \t Train Loss:  0.027129823 \t Train Accuracy:  99.23%\nStep:  5400 \t Eval Loss:  0.02926705 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  5500 \t Train Loss:  0.02678654 \t Train Accuracy:  99.18%\nStep:  5500 \t Eval Loss:  0.027883641 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  5600 \t Train Loss:  0.025789019 \t Train Accuracy:  99.24%\nStep:  5600 \t Eval Loss:  0.028486956 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  5700 \t Train Loss:  0.024938012 \t Train Accuracy:  99.26%\nStep:  5700 \t Eval Loss:  0.028577454 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  5800 \t Train Loss:  0.022443531 \t Train Accuracy:  99.32%\nStep:  5800 \t Eval Loss:  0.028455745 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  5900 \t Train Loss:  0.02656291 \t Train Accuracy:  99.16%\nStep:  5900 \t Eval Loss:  0.029452145 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  6000 \t Train Loss:  0.02995876 \t Train Accuracy:  99.16%\nStep:  6000 \t Eval Loss:  0.02841397 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  6100 \t Train Loss:  0.024683513 \t Train Accuracy:  99.22%\nStep:  6100 \t Eval Loss:  0.03046183 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  6200 \t Train Loss:  0.02997052 \t Train Accuracy:  99.17%\nStep:  6200 \t Eval Loss:  0.026749164 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  6300 \t Train Loss:  0.021946315 \t Train Accuracy:  99.37%\nStep:  6300 \t Eval Loss:  0.02706413 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  6400 \t Train Loss:  0.023412876 \t Train Accuracy:  99.29%\nStep:  6400 \t Eval Loss:  0.03207996 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  6500 \t Train Loss:  0.025932364 \t Train Accuracy:  99.29%\nStep:  6500 \t Eval Loss:  0.028588217 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  6600 \t Train Loss:  0.02814305 \t Train Accuracy:  99.12%\nStep:  6600 \t Eval Loss:  0.026153637 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  6700 \t Train Loss:  0.021733511 \t Train Accuracy:  99.35%\nStep:  6700 \t Eval Loss:  0.028858176 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  6800 \t Train Loss:  0.024116956 \t Train Accuracy:  99.24%\nStep:  6800 \t Eval Loss:  0.025378443 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  6900 \t Train Loss:  0.024647508 \t Train Accuracy:  99.24%\nStep:  6900 \t Eval Loss:  0.025969096 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  7000 \t Train Loss:  0.028207049 \t Train Accuracy:  99.17%\nStep:  7000 \t Eval Loss:  0.029112503 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  7100 \t Train Loss:  0.025029194 \t Train Accuracy:  99.28%\nStep:  7100 \t Eval Loss:  0.027153485 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  7200 \t Train Loss:  0.027699478 \t Train Accuracy:  99.16%\nStep:  7200 \t Eval Loss:  0.029078148 \t Eval Accuracy:  99.12%\n##########################################################\nStep:  7300 \t Train Loss:  0.022946116 \t Train Accuracy:  99.27%\nStep:  7300 \t Eval Loss:  0.02838583 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  7400 \t Train Loss:  0.024347039 \t Train Accuracy:  99.29%\nStep:  7400 \t Eval Loss:  0.023835765 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  7500 \t Train Loss:  0.026461344 \t Train Accuracy:  99.18%\nStep:  7500 \t Eval Loss:  0.02651523 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  7600 \t Train Loss:  0.02632021 \t Train Accuracy:  99.21%\nStep:  7600 \t Eval Loss:  0.02433873 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  7700 \t Train Loss:  0.025281573 \t Train Accuracy:  99.29%\nStep:  7700 \t Eval Loss:  0.022771142 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  7800 \t Train Loss:  0.026123093 \t Train Accuracy:  99.23%\nStep:  7800 \t Eval Loss:  0.029754275 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  7900 \t Train Loss:  0.022256149 \t Train Accuracy:  99.27%\nStep:  7900 \t Eval Loss:  0.023937795 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  8000 \t Train Loss:  0.024694579 \t Train Accuracy:  99.30%\nStep:  8000 \t Eval Loss:  0.025824068 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  8100 \t Train Loss:  0.026565108 \t Train Accuracy:  99.19%\nStep:  8100 \t Eval Loss:  0.026660103 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  8200 \t Train Loss:  0.022592604 \t Train Accuracy:  99.28%\nStep:  8200 \t Eval Loss:  0.025624929 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  8300 \t Train Loss:  0.026804846 \t Train Accuracy:  99.24%\nStep:  8300 \t Eval Loss:  0.027277216 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  8400 \t Train Loss:  0.022300847 \t Train Accuracy:  99.40%\nStep:  8400 \t Eval Loss:  0.023990314 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  8500 \t Train Loss:  0.025246527 \t Train Accuracy:  99.27%\nStep:  8500 \t Eval Loss:  0.024643194 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  8600 \t Train Loss:  0.024459917 \t Train Accuracy:  99.28%\nStep:  8600 \t Eval Loss:  0.029545352 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  8700 \t Train Loss:  0.022204358 \t Train Accuracy:  99.35%\nStep:  8700 \t Eval Loss:  0.028747043 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  8800 \t Train Loss:  0.024047695 \t Train Accuracy:  99.30%\nStep:  8800 \t Eval Loss:  0.025703799 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  8900 \t Train Loss:  0.022728391 \t Train Accuracy:  99.22%\nStep:  8900 \t Eval Loss:  0.02712933 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  9000 \t Train Loss:  0.024552234 \t Train Accuracy:  99.28%\nStep:  9000 \t Eval Loss:  0.026332654 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  9100 \t Train Loss:  0.025441438 \t Train Accuracy:  99.22%\nStep:  9100 \t Eval Loss:  0.022528391 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  9200 \t Train Loss:  0.023798224 \t Train Accuracy:  99.27%\nStep:  9200 \t Eval Loss:  0.0238464 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  9300 \t Train Loss:  0.027177319 \t Train Accuracy:  99.12%\nStep:  9300 \t Eval Loss:  0.026911173 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  9400 \t Train Loss:  0.024276799 \t Train Accuracy:  99.30%\nStep:  9400 \t Eval Loss:  0.02941734 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  9500 \t Train Loss:  0.023913484 \t Train Accuracy:  99.27%\nStep:  9500 \t Eval Loss:  0.02609511 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  9600 \t Train Loss:  0.024963362 \t Train Accuracy:  99.28%\nStep:  9600 \t Eval Loss:  0.0252825 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  9700 \t Train Loss:  0.022713307 \t Train Accuracy:  99.37%\nStep:  9700 \t Eval Loss:  0.025436435 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  9800 \t Train Loss:  0.023779226 \t Train Accuracy:  99.29%\nStep:  9800 \t Eval Loss:  0.02604539 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  9900 \t Train Loss:  0.02972076 \t Train Accuracy:  99.06%\nStep:  9900 \t Eval Loss:  0.02354212 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  10000 \t Train Loss:  0.026049273 \t Train Accuracy:  99.21%\nStep:  10000 \t Eval Loss:  0.02633522 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  10100 \t Train Loss:  0.021082353 \t Train Accuracy:  99.30%\nStep:  10100 \t Eval Loss:  0.028486453 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  10200 \t Train Loss:  0.025353646 \t Train Accuracy:  99.26%\nStep:  10200 \t Eval Loss:  0.023979314 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  10300 \t Train Loss:  0.024627391 \t Train Accuracy:  99.24%\nStep:  10300 \t Eval Loss:  0.024226038 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  10400 \t Train Loss:  0.0189387 \t Train Accuracy:  99.35%\nStep:  10400 \t Eval Loss:  0.026573485 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  10500 \t Train Loss:  0.025378622 \t Train Accuracy:  99.26%\nStep:  10500 \t Eval Loss:  0.027212663 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  10600 \t Train Loss:  0.02754654 \t Train Accuracy:  99.12%\nStep:  10600 \t Eval Loss:  0.024227697 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  10700 \t Train Loss:  0.02289924 \t Train Accuracy:  99.37%\nStep:  10700 \t Eval Loss:  0.02654021 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  10800 \t Train Loss:  0.021079052 \t Train Accuracy:  99.32%\nStep:  10800 \t Eval Loss:  0.023334969 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  10900 \t Train Loss:  0.024357079 \t Train Accuracy:  99.23%\nStep:  10900 \t Eval Loss:  0.023883507 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  11000 \t Train Loss:  0.025537945 \t Train Accuracy:  99.17%\nStep:  11000 \t Eval Loss:  0.025615457 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  11100 \t Train Loss:  0.025105773 \t Train Accuracy:  99.27%\nStep:  11100 \t Eval Loss:  0.026620733 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  11200 \t Train Loss:  0.025199622 \t Train Accuracy:  99.27%\nStep:  11200 \t Eval Loss:  0.026238047 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  11300 \t Train Loss:  0.020692475 \t Train Accuracy:  99.41%\nStep:  11300 \t Eval Loss:  0.020858157 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  11400 \t Train Loss:  0.019793544 \t Train Accuracy:  99.37%\nStep:  11400 \t Eval Loss:  0.024283957 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  11500 \t Train Loss:  0.021651823 \t Train Accuracy:  99.37%\nStep:  11500 \t Eval Loss:  0.02736571 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  11600 \t Train Loss:  0.024294252 \t Train Accuracy:  99.26%\nStep:  11600 \t Eval Loss:  0.023030985 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  11700 \t Train Loss:  0.023658963 \t Train Accuracy:  99.35%\nStep:  11700 \t Eval Loss:  0.026635006 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  11800 \t Train Loss:  0.022613347 \t Train Accuracy:  99.32%\nStep:  11800 \t Eval Loss:  0.029717203 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  11900 \t Train Loss:  0.027763538 \t Train Accuracy:  99.17%\nStep:  11900 \t Eval Loss:  0.029629532 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  12000 \t Train Loss:  0.02055326 \t Train Accuracy:  99.30%\nStep:  12000 \t Eval Loss:  0.023389714 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  12100 \t Train Loss:  0.020125257 \t Train Accuracy:  99.41%\nStep:  12100 \t Eval Loss:  0.028004574 \t Eval Accuracy:  99.08%\n##########################################################\nStep:  12200 \t Train Loss:  0.023144532 \t Train Accuracy:  99.26%\nStep:  12200 \t Eval Loss:  0.024396233 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  12300 \t Train Loss:  0.024139985 \t Train Accuracy:  99.23%\nStep:  12300 \t Eval Loss:  0.028174426 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  12400 \t Train Loss:  0.024454363 \t Train Accuracy:  99.28%\nStep:  12400 \t Eval Loss:  0.02780983 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  12500 \t Train Loss:  0.023106316 \t Train Accuracy:  99.33%\nStep:  12500 \t Eval Loss:  0.027536806 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  12600 \t Train Loss:  0.021990709 \t Train Accuracy:  99.35%\nStep:  12600 \t Eval Loss:  0.025268316 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  12700 \t Train Loss:  0.025860455 \t Train Accuracy:  99.23%\nStep:  12700 \t Eval Loss:  0.026579943 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  12800 \t Train Loss:  0.022624386 \t Train Accuracy:  99.32%\nStep:  12800 \t Eval Loss:  0.021058537 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  12900 \t Train Loss:  0.024521347 \t Train Accuracy:  99.30%\nStep:  12900 \t Eval Loss:  0.02530511 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  13000 \t Train Loss:  0.023763578 \t Train Accuracy:  99.30%\nStep:  13000 \t Eval Loss:  0.023764227 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  13100 \t Train Loss:  0.02362148 \t Train Accuracy:  99.37%\nStep:  13100 \t Eval Loss:  0.02518877 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  13200 \t Train Loss:  0.025407445 \t Train Accuracy:  99.21%\nStep:  13200 \t Eval Loss:  0.025856638 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  13300 \t Train Loss:  0.023059923 \t Train Accuracy:  99.29%\nStep:  13300 \t Eval Loss:  0.021018004 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  13400 \t Train Loss:  0.024127072 \t Train Accuracy:  99.24%\nStep:  13400 \t Eval Loss:  0.02307291 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  13500 \t Train Loss:  0.020043693 \t Train Accuracy:  99.35%\nStep:  13500 \t Eval Loss:  0.024376139 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  13600 \t Train Loss:  0.02501471 \t Train Accuracy:  99.26%\nStep:  13600 \t Eval Loss:  0.027156213 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  13700 \t Train Loss:  0.02628223 \t Train Accuracy:  99.22%\nStep:  13700 \t Eval Loss:  0.02397283 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  13800 \t Train Loss:  0.018547365 \t Train Accuracy:  99.49%\nStep:  13800 \t Eval Loss:  0.022065843 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  13900 \t Train Loss:  0.023048352 \t Train Accuracy:  99.33%\nStep:  13900 \t Eval Loss:  0.026473606 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  14000 \t Train Loss:  0.027050857 \t Train Accuracy:  99.27%\nStep:  14000 \t Eval Loss:  0.022841526 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  14100 \t Train Loss:  0.02406644 \t Train Accuracy:  99.30%\nStep:  14100 \t Eval Loss:  0.024211468 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  14200 \t Train Loss:  0.02297562 \t Train Accuracy:  99.29%\nStep:  14200 \t Eval Loss:  0.026014607 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  14300 \t Train Loss:  0.02307149 \t Train Accuracy:  99.35%\nStep:  14300 \t Eval Loss:  0.025620334 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  14400 \t Train Loss:  0.023551261 \t Train Accuracy:  99.17%\nStep:  14400 \t Eval Loss:  0.024475345 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  14500 \t Train Loss:  0.022321638 \t Train Accuracy:  99.30%\nStep:  14500 \t Eval Loss:  0.027843492 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  14600 \t Train Loss:  0.024297256 \t Train Accuracy:  99.24%\nStep:  14600 \t Eval Loss:  0.022254335 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  14700 \t Train Loss:  0.023507882 \t Train Accuracy:  99.26%\nStep:  14700 \t Eval Loss:  0.020367699 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  14800 \t Train Loss:  0.024193656 \t Train Accuracy:  99.27%\nStep:  14800 \t Eval Loss:  0.027831092 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  14900 \t Train Loss:  0.025425903 \t Train Accuracy:  99.18%\nStep:  14900 \t Eval Loss:  0.02842465 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  15000 \t Train Loss:  0.025528925 \t Train Accuracy:  99.26%\nStep:  15000 \t Eval Loss:  0.028137725 \t Eval Accuracy:  99.12%\n##########################################################\nStep:  15100 \t Train Loss:  0.024581807 \t Train Accuracy:  99.30%\nStep:  15100 \t Eval Loss:  0.022806322 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  15200 \t Train Loss:  0.024357084 \t Train Accuracy:  99.26%\nStep:  15200 \t Eval Loss:  0.025893144 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  15300 \t Train Loss:  0.02186542 \t Train Accuracy:  99.34%\nStep:  15300 \t Eval Loss:  0.019789021 \t Eval Accuracy:  99.44%\n##########################################################\nStep:  15400 \t Train Loss:  0.021947233 \t Train Accuracy:  99.34%\nStep:  15400 \t Eval Loss:  0.027014712 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  15500 \t Train Loss:  0.023448642 \t Train Accuracy:  99.28%\nStep:  15500 \t Eval Loss:  0.020622924 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  15600 \t Train Loss:  0.024380967 \t Train Accuracy:  99.21%\nStep:  15600 \t Eval Loss:  0.02898072 \t Eval Accuracy:  99.12%\n##########################################################\nStep:  15700 \t Train Loss:  0.02478548 \t Train Accuracy:  99.30%\nStep:  15700 \t Eval Loss:  0.025920259 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  15800 \t Train Loss:  0.020359008 \t Train Accuracy:  99.33%\nStep:  15800 \t Eval Loss:  0.025307491 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  15900 \t Train Loss:  0.02200627 \t Train Accuracy:  99.33%\nStep:  15900 \t Eval Loss:  0.025341384 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  16000 \t Train Loss:  0.021412132 \t Train Accuracy:  99.32%\nStep:  16000 \t Eval Loss:  0.022896413 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  16100 \t Train Loss:  0.02097063 \t Train Accuracy:  99.32%\nStep:  16100 \t Eval Loss:  0.027867889 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  16200 \t Train Loss:  0.023507714 \t Train Accuracy:  99.23%\nStep:  16200 \t Eval Loss:  0.024942406 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  16300 \t Train Loss:  0.02219695 \t Train Accuracy:  99.33%\nStep:  16300 \t Eval Loss:  0.025438882 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  16400 \t Train Loss:  0.019543972 \t Train Accuracy:  99.48%\nStep:  16400 \t Eval Loss:  0.02748885 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  16500 \t Train Loss:  0.025972687 \t Train Accuracy:  99.27%\nStep:  16500 \t Eval Loss:  0.022062799 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  16600 \t Train Loss:  0.024341267 \t Train Accuracy:  99.23%\nStep:  16600 \t Eval Loss:  0.023882747 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  16700 \t Train Loss:  0.021113314 \t Train Accuracy:  99.39%\nStep:  16700 \t Eval Loss:  0.026117153 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  16800 \t Train Loss:  0.024385873 \t Train Accuracy:  99.29%\nStep:  16800 \t Eval Loss:  0.027661152 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  16900 \t Train Loss:  0.02008593 \t Train Accuracy:  99.32%\nStep:  16900 \t Eval Loss:  0.023044355 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  17000 \t Train Loss:  0.024847645 \t Train Accuracy:  99.21%\nStep:  17000 \t Eval Loss:  0.024864119 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  17100 \t Train Loss:  0.023690753 \t Train Accuracy:  99.24%\nStep:  17100 \t Eval Loss:  0.024850516 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  17200 \t Train Loss:  0.021209568 \t Train Accuracy:  99.44%\nStep:  17200 \t Eval Loss:  0.023066845 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  17300 \t Train Loss:  0.021163853 \t Train Accuracy:  99.35%\nStep:  17300 \t Eval Loss:  0.025918012 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  17400 \t Train Loss:  0.02565973 \t Train Accuracy:  99.29%\nStep:  17400 \t Eval Loss:  0.027460191 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  17500 \t Train Loss:  0.019705072 \t Train Accuracy:  99.43%\nStep:  17500 \t Eval Loss:  0.02488938 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  17600 \t Train Loss:  0.022184197 \t Train Accuracy:  99.39%\nStep:  17600 \t Eval Loss:  0.028726127 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  17700 \t Train Loss:  0.024053693 \t Train Accuracy:  99.29%\nStep:  17700 \t Eval Loss:  0.022652581 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  17800 \t Train Loss:  0.023979641 \t Train Accuracy:  99.27%\nStep:  17800 \t Eval Loss:  0.03100304 \t Eval Accuracy:  99.12%\n##########################################################\nStep:  17900 \t Train Loss:  0.024355888 \t Train Accuracy:  99.23%\nStep:  17900 \t Eval Loss:  0.02391034 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  18000 \t Train Loss:  0.020537507 \t Train Accuracy:  99.39%\nStep:  18000 \t Eval Loss:  0.026940051 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  18100 \t Train Loss:  0.024441825 \t Train Accuracy:  99.27%\nStep:  18100 \t Eval Loss:  0.023959119 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  18200 \t Train Loss:  0.01903814 \t Train Accuracy:  99.44%\nStep:  18200 \t Eval Loss:  0.025643516 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  18300 \t Train Loss:  0.022414368 \t Train Accuracy:  99.29%\nStep:  18300 \t Eval Loss:  0.024088986 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  18400 \t Train Loss:  0.022190709 \t Train Accuracy:  99.33%\nStep:  18400 \t Eval Loss:  0.02499993 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  18500 \t Train Loss:  0.024941783 \t Train Accuracy:  99.28%\nStep:  18500 \t Eval Loss:  0.027621508 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  18600 \t Train Loss:  0.02286494 \t Train Accuracy:  99.32%\nStep:  18600 \t Eval Loss:  0.029982664 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  18700 \t Train Loss:  0.021209396 \t Train Accuracy:  99.26%\nStep:  18700 \t Eval Loss:  0.023912802 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  18800 \t Train Loss:  0.021801312 \t Train Accuracy:  99.40%\nStep:  18800 \t Eval Loss:  0.026249226 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  18900 \t Train Loss:  0.024857298 \t Train Accuracy:  99.27%\nStep:  18900 \t Eval Loss:  0.023015661 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  19000 \t Train Loss:  0.020591265 \t Train Accuracy:  99.38%\nStep:  19000 \t Eval Loss:  0.026051912 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  19100 \t Train Loss:  0.025285752 \t Train Accuracy:  99.26%\nStep:  19100 \t Eval Loss:  0.023903338 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  19200 \t Train Loss:  0.020975437 \t Train Accuracy:  99.38%\nStep:  19200 \t Eval Loss:  0.02293305 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  19300 \t Train Loss:  0.025720373 \t Train Accuracy:  99.24%\nStep:  19300 \t Eval Loss:  0.02108116 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  19400 \t Train Loss:  0.023909435 \t Train Accuracy:  99.28%\nStep:  19400 \t Eval Loss:  0.023385828 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  19500 \t Train Loss:  0.020013109 \t Train Accuracy:  99.43%\nStep:  19500 \t Eval Loss:  0.024520954 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  19600 \t Train Loss:  0.021690592 \t Train Accuracy:  99.24%\nStep:  19600 \t Eval Loss:  0.022702739 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  19700 \t Train Loss:  0.026594311 \t Train Accuracy:  99.22%\nStep:  19700 \t Eval Loss:  0.02549073 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  19800 \t Train Loss:  0.02430319 \t Train Accuracy:  99.19%\nStep:  19800 \t Eval Loss:  0.022289071 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  19900 \t Train Loss:  0.020592421 \t Train Accuracy:  99.35%\nStep:  19900 \t Eval Loss:  0.026518527 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  20000 \t Train Loss:  0.018596448 \t Train Accuracy:  99.45%\nStep:  20000 \t Eval Loss:  0.02172095 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  20100 \t Train Loss:  0.021746239 \t Train Accuracy:  99.38%\nStep:  20100 \t Eval Loss:  0.02853781 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  20200 \t Train Loss:  0.022687364 \t Train Accuracy:  99.23%\nStep:  20200 \t Eval Loss:  0.024592597 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  20300 \t Train Loss:  0.020347292 \t Train Accuracy:  99.39%\nStep:  20300 \t Eval Loss:  0.022442158 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  20400 \t Train Loss:  0.024071082 \t Train Accuracy:  99.34%\nStep:  20400 \t Eval Loss:  0.025110854 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  20500 \t Train Loss:  0.02388747 \t Train Accuracy:  99.30%\nStep:  20500 \t Eval Loss:  0.025845487 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  20600 \t Train Loss:  0.022535829 \t Train Accuracy:  99.29%\nStep:  20600 \t Eval Loss:  0.024171138 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  20700 \t Train Loss:  0.021341618 \t Train Accuracy:  99.33%\nStep:  20700 \t Eval Loss:  0.021138469 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  20800 \t Train Loss:  0.020408785 \t Train Accuracy:  99.33%\nStep:  20800 \t Eval Loss:  0.028149188 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  20900 \t Train Loss:  0.02019133 \t Train Accuracy:  99.35%\nStep:  20900 \t Eval Loss:  0.025077876 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  21000 \t Train Loss:  0.020296784 \t Train Accuracy:  99.33%\nStep:  21000 \t Eval Loss:  0.02317989 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  21100 \t Train Loss:  0.02313687 \t Train Accuracy:  99.24%\nStep:  21100 \t Eval Loss:  0.025946189 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  21200 \t Train Loss:  0.021552984 \t Train Accuracy:  99.38%\nStep:  21200 \t Eval Loss:  0.026933134 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  21300 \t Train Loss:  0.024678927 \t Train Accuracy:  99.24%\nStep:  21300 \t Eval Loss:  0.025226727 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  21400 \t Train Loss:  0.025221352 \t Train Accuracy:  99.21%\nStep:  21400 \t Eval Loss:  0.027712677 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  21500 \t Train Loss:  0.023620723 \t Train Accuracy:  99.24%\nStep:  21500 \t Eval Loss:  0.026190348 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  21600 \t Train Loss:  0.020176277 \t Train Accuracy:  99.39%\nStep:  21600 \t Eval Loss:  0.022288106 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  21700 \t Train Loss:  0.018932454 \t Train Accuracy:  99.45%\nStep:  21700 \t Eval Loss:  0.022041833 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  21800 \t Train Loss:  0.023303188 \t Train Accuracy:  99.33%\nStep:  21800 \t Eval Loss:  0.022255331 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  21900 \t Train Loss:  0.023826297 \t Train Accuracy:  99.24%\nStep:  21900 \t Eval Loss:  0.026387153 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  22000 \t Train Loss:  0.026208 \t Train Accuracy:  99.21%\nStep:  22000 \t Eval Loss:  0.030915003 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  22100 \t Train Loss:  0.021560106 \t Train Accuracy:  99.28%\nStep:  22100 \t Eval Loss:  0.02288087 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  22200 \t Train Loss:  0.021624038 \t Train Accuracy:  99.27%\nStep:  22200 \t Eval Loss:  0.023842867 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  22300 \t Train Loss:  0.020203937 \t Train Accuracy:  99.44%\nStep:  22300 \t Eval Loss:  0.022204962 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  22400 \t Train Loss:  0.024012865 \t Train Accuracy:  99.29%\nStep:  22400 \t Eval Loss:  0.026227124 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  22500 \t Train Loss:  0.0230253 \t Train Accuracy:  99.27%\nStep:  22500 \t Eval Loss:  0.020543704 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  22600 \t Train Loss:  0.02018828 \t Train Accuracy:  99.30%\nStep:  22600 \t Eval Loss:  0.022598194 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  22700 \t Train Loss:  0.023586206 \t Train Accuracy:  99.23%\nStep:  22700 \t Eval Loss:  0.026539251 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  22800 \t Train Loss:  0.021247845 \t Train Accuracy:  99.29%\nStep:  22800 \t Eval Loss:  0.02403037 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  22900 \t Train Loss:  0.021198414 \t Train Accuracy:  99.34%\nStep:  22900 \t Eval Loss:  0.022456769 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  23000 \t Train Loss:  0.023552591 \t Train Accuracy:  99.21%\nStep:  23000 \t Eval Loss:  0.026394403 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  23100 \t Train Loss:  0.022825317 \t Train Accuracy:  99.28%\nStep:  23100 \t Eval Loss:  0.02559637 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  23200 \t Train Loss:  0.023273243 \t Train Accuracy:  99.30%\nStep:  23200 \t Eval Loss:  0.023132192 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  23300 \t Train Loss:  0.022540178 \t Train Accuracy:  99.33%\nStep:  23300 \t Eval Loss:  0.0217929 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  23400 \t Train Loss:  0.021474564 \t Train Accuracy:  99.35%\nStep:  23400 \t Eval Loss:  0.029074363 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  23500 \t Train Loss:  0.02246327 \t Train Accuracy:  99.28%\nStep:  23500 \t Eval Loss:  0.02581164 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  23600 \t Train Loss:  0.024684414 \t Train Accuracy:  99.34%\nStep:  23600 \t Eval Loss:  0.024970269 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  23700 \t Train Loss:  0.022814384 \t Train Accuracy:  99.33%\nStep:  23700 \t Eval Loss:  0.020364162 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  23800 \t Train Loss:  0.022625215 \t Train Accuracy:  99.28%\nStep:  23800 \t Eval Loss:  0.024186075 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  23900 \t Train Loss:  0.023400584 \t Train Accuracy:  99.35%\nStep:  23900 \t Eval Loss:  0.02429309 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  24000 \t Train Loss:  0.020981915 \t Train Accuracy:  99.32%\nStep:  24000 \t Eval Loss:  0.021507744 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  24100 \t Train Loss:  0.02483469 \t Train Accuracy:  99.29%\nStep:  24100 \t Eval Loss:  0.024740694 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  24200 \t Train Loss:  0.022535242 \t Train Accuracy:  99.33%\nStep:  24200 \t Eval Loss:  0.024886843 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  24300 \t Train Loss:  0.018335247 \t Train Accuracy:  99.44%\nStep:  24300 \t Eval Loss:  0.025608193 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  24400 \t Train Loss:  0.020021174 \t Train Accuracy:  99.39%\nStep:  24400 \t Eval Loss:  0.026179077 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  24500 \t Train Loss:  0.023180872 \t Train Accuracy:  99.33%\nStep:  24500 \t Eval Loss:  0.021992007 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  24600 \t Train Loss:  0.020455915 \t Train Accuracy:  99.37%\nStep:  24600 \t Eval Loss:  0.02049699 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  24700 \t Train Loss:  0.021397084 \t Train Accuracy:  99.33%\nStep:  24700 \t Eval Loss:  0.023232805 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  24800 \t Train Loss:  0.023822378 \t Train Accuracy:  99.33%\nStep:  24800 \t Eval Loss:  0.025392652 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  24900 \t Train Loss:  0.021695262 \t Train Accuracy:  99.34%\nStep:  24900 \t Eval Loss:  0.024996238 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  25000 \t Train Loss:  0.023885755 \t Train Accuracy:  99.23%\nStep:  25000 \t Eval Loss:  0.022892319 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  25100 \t Train Loss:  0.022887468 \t Train Accuracy:  99.28%\nStep:  25100 \t Eval Loss:  0.02250756 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  25200 \t Train Loss:  0.020964481 \t Train Accuracy:  99.41%\nStep:  25200 \t Eval Loss:  0.022402544 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  25300 \t Train Loss:  0.01947257 \t Train Accuracy:  99.39%\nStep:  25300 \t Eval Loss:  0.027297968 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  25400 \t Train Loss:  0.019135546 \t Train Accuracy:  99.40%\nStep:  25400 \t Eval Loss:  0.021761375 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  25500 \t Train Loss:  0.018454123 \t Train Accuracy:  99.37%\nStep:  25500 \t Eval Loss:  0.022798471 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  25600 \t Train Loss:  0.020474927 \t Train Accuracy:  99.29%\nStep:  25600 \t Eval Loss:  0.019887537 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  25700 \t Train Loss:  0.021748602 \t Train Accuracy:  99.35%\nStep:  25700 \t Eval Loss:  0.028408602 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  25800 \t Train Loss:  0.017705876 \t Train Accuracy:  99.48%\nStep:  25800 \t Eval Loss:  0.02591894 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  25900 \t Train Loss:  0.0204028 \t Train Accuracy:  99.32%\nStep:  25900 \t Eval Loss:  0.028139371 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  26000 \t Train Loss:  0.023226775 \t Train Accuracy:  99.28%\nStep:  26000 \t Eval Loss:  0.027732337 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  26100 \t Train Loss:  0.02238128 \t Train Accuracy:  99.39%\nStep:  26100 \t Eval Loss:  0.023189552 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  26200 \t Train Loss:  0.022245234 \t Train Accuracy:  99.29%\nStep:  26200 \t Eval Loss:  0.026369926 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  26300 \t Train Loss:  0.019876413 \t Train Accuracy:  99.38%\nStep:  26300 \t Eval Loss:  0.02304541 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  26400 \t Train Loss:  0.020505402 \t Train Accuracy:  99.39%\nStep:  26400 \t Eval Loss:  0.021589823 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  26500 \t Train Loss:  0.022302303 \t Train Accuracy:  99.24%\nStep:  26500 \t Eval Loss:  0.025511483 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  26600 \t Train Loss:  0.021165445 \t Train Accuracy:  99.32%\nStep:  26600 \t Eval Loss:  0.02212744 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  26700 \t Train Loss:  0.0229672 \t Train Accuracy:  99.27%\nStep:  26700 \t Eval Loss:  0.022856846 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  26800 \t Train Loss:  0.02479966 \t Train Accuracy:  99.29%\nStep:  26800 \t Eval Loss:  0.021465607 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  26900 \t Train Loss:  0.018587437 \t Train Accuracy:  99.41%\nStep:  26900 \t Eval Loss:  0.024049625 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  27000 \t Train Loss:  0.018632356 \t Train Accuracy:  99.40%\nStep:  27000 \t Eval Loss:  0.02455785 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  27100 \t Train Loss:  0.020829381 \t Train Accuracy:  99.33%\nStep:  27100 \t Eval Loss:  0.021446522 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  27200 \t Train Loss:  0.022256218 \t Train Accuracy:  99.30%\nStep:  27200 \t Eval Loss:  0.019956399 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  27300 \t Train Loss:  0.019488115 \t Train Accuracy:  99.43%\nStep:  27300 \t Eval Loss:  0.02793454 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  27400 \t Train Loss:  0.021926653 \t Train Accuracy:  99.38%\nStep:  27400 \t Eval Loss:  0.021459948 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  27500 \t Train Loss:  0.018912822 \t Train Accuracy:  99.38%\nStep:  27500 \t Eval Loss:  0.025468795 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  27600 \t Train Loss:  0.0172631 \t Train Accuracy:  99.51%\nStep:  27600 \t Eval Loss:  0.024204833 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  27700 \t Train Loss:  0.020753015 \t Train Accuracy:  99.34%\nStep:  27700 \t Eval Loss:  0.024870805 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  27800 \t Train Loss:  0.022189356 \t Train Accuracy:  99.32%\nStep:  27800 \t Eval Loss:  0.023456678 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  27900 \t Train Loss:  0.025140747 \t Train Accuracy:  99.27%\nStep:  27900 \t Eval Loss:  0.021010246 \t Eval Accuracy:  99.45%\n##########################################################\nStep:  28000 \t Train Loss:  0.020711161 \t Train Accuracy:  99.37%\nStep:  28000 \t Eval Loss:  0.020804971 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  28100 \t Train Loss:  0.022533134 \t Train Accuracy:  99.29%\nStep:  28100 \t Eval Loss:  0.025521016 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  28200 \t Train Loss:  0.019488141 \t Train Accuracy:  99.43%\nStep:  28200 \t Eval Loss:  0.021973485 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  28300 \t Train Loss:  0.018940262 \t Train Accuracy:  99.43%\nStep:  28300 \t Eval Loss:  0.027299732 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  28400 \t Train Loss:  0.020133715 \t Train Accuracy:  99.38%\nStep:  28400 \t Eval Loss:  0.021634836 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  28500 \t Train Loss:  0.022471758 \t Train Accuracy:  99.27%\nStep:  28500 \t Eval Loss:  0.025807723 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  28600 \t Train Loss:  0.021794483 \t Train Accuracy:  99.34%\nStep:  28600 \t Eval Loss:  0.024166891 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  28700 \t Train Loss:  0.022831678 \t Train Accuracy:  99.33%\nStep:  28700 \t Eval Loss:  0.027154349 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  28800 \t Train Loss:  0.021922491 \t Train Accuracy:  99.32%\nStep:  28800 \t Eval Loss:  0.023245227 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  28900 \t Train Loss:  0.022746282 \t Train Accuracy:  99.32%\nStep:  28900 \t Eval Loss:  0.025816463 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  29000 \t Train Loss:  0.019769767 \t Train Accuracy:  99.39%\nStep:  29000 \t Eval Loss:  0.021366905 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  29100 \t Train Loss:  0.018386032 \t Train Accuracy:  99.45%\nStep:  29100 \t Eval Loss:  0.024278164 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  29200 \t Train Loss:  0.020709198 \t Train Accuracy:  99.33%\nStep:  29200 \t Eval Loss:  0.023616249 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  29300 \t Train Loss:  0.019117631 \t Train Accuracy:  99.34%\nStep:  29300 \t Eval Loss:  0.023596678 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  29400 \t Train Loss:  0.024360107 \t Train Accuracy:  99.26%\nStep:  29400 \t Eval Loss:  0.020416211 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  29500 \t Train Loss:  0.023337971 \t Train Accuracy:  99.30%\nStep:  29500 \t Eval Loss:  0.030289777 \t Eval Accuracy:  99.05%\n##########################################################\nStep:  29600 \t Train Loss:  0.019249097 \t Train Accuracy:  99.35%\nStep:  29600 \t Eval Loss:  0.025006223 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  29700 \t Train Loss:  0.02202473 \t Train Accuracy:  99.33%\nStep:  29700 \t Eval Loss:  0.022915147 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  29800 \t Train Loss:  0.02081234 \t Train Accuracy:  99.33%\nStep:  29800 \t Eval Loss:  0.022471122 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  29900 \t Train Loss:  0.017844744 \t Train Accuracy:  99.44%\nStep:  29900 \t Eval Loss:  0.023707211 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  30000 \t Train Loss:  0.019629661 \t Train Accuracy:  99.41%\nStep:  30000 \t Eval Loss:  0.025241384 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  30100 \t Train Loss:  0.019336488 \t Train Accuracy:  99.35%\nStep:  30100 \t Eval Loss:  0.022669092 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  30200 \t Train Loss:  0.020946234 \t Train Accuracy:  99.32%\nStep:  30200 \t Eval Loss:  0.02456693 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  30300 \t Train Loss:  0.020493153 \t Train Accuracy:  99.37%\nStep:  30300 \t Eval Loss:  0.025090719 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  30400 \t Train Loss:  0.017599128 \t Train Accuracy:  99.44%\nStep:  30400 \t Eval Loss:  0.02034111 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  30500 \t Train Loss:  0.01913488 \t Train Accuracy:  99.37%\nStep:  30500 \t Eval Loss:  0.02122601 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  30600 \t Train Loss:  0.016506754 \t Train Accuracy:  99.54%\nStep:  30600 \t Eval Loss:  0.023683447 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  30700 \t Train Loss:  0.020062417 \t Train Accuracy:  99.48%\nStep:  30700 \t Eval Loss:  0.023234671 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  30800 \t Train Loss:  0.01846053 \t Train Accuracy:  99.48%\nStep:  30800 \t Eval Loss:  0.021651922 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  30900 \t Train Loss:  0.020203121 \t Train Accuracy:  99.44%\nStep:  30900 \t Eval Loss:  0.022526857 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  31000 \t Train Loss:  0.018464763 \t Train Accuracy:  99.43%\nStep:  31000 \t Eval Loss:  0.022152174 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  31100 \t Train Loss:  0.020462055 \t Train Accuracy:  99.35%\nStep:  31100 \t Eval Loss:  0.0189993 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  31200 \t Train Loss:  0.018192394 \t Train Accuracy:  99.43%\nStep:  31200 \t Eval Loss:  0.02275983 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  31300 \t Train Loss:  0.01903848 \t Train Accuracy:  99.43%\nStep:  31300 \t Eval Loss:  0.025241593 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  31400 \t Train Loss:  0.020587258 \t Train Accuracy:  99.40%\nStep:  31400 \t Eval Loss:  0.02603864 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  31500 \t Train Loss:  0.019108776 \t Train Accuracy:  99.43%\nStep:  31500 \t Eval Loss:  0.02579968 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  31600 \t Train Loss:  0.02195352 \t Train Accuracy:  99.33%\nStep:  31600 \t Eval Loss:  0.025702277 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  31700 \t Train Loss:  0.02179427 \t Train Accuracy:  99.32%\nStep:  31700 \t Eval Loss:  0.022332609 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  31800 \t Train Loss:  0.019739892 \t Train Accuracy:  99.41%\nStep:  31800 \t Eval Loss:  0.026400145 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  31900 \t Train Loss:  0.01910447 \t Train Accuracy:  99.37%\nStep:  31900 \t Eval Loss:  0.022240892 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  32000 \t Train Loss:  0.020990789 \t Train Accuracy:  99.32%\nStep:  32000 \t Eval Loss:  0.025477935 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  32100 \t Train Loss:  0.024187189 \t Train Accuracy:  99.24%\nStep:  32100 \t Eval Loss:  0.023797313 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  32200 \t Train Loss:  0.019873157 \t Train Accuracy:  99.35%\nStep:  32200 \t Eval Loss:  0.021283917 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  32300 \t Train Loss:  0.020553993 \t Train Accuracy:  99.32%\nStep:  32300 \t Eval Loss:  0.02526987 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  32400 \t Train Loss:  0.020484734 \t Train Accuracy:  99.30%\nStep:  32400 \t Eval Loss:  0.023521276 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  32500 \t Train Loss:  0.021701979 \t Train Accuracy:  99.35%\nStep:  32500 \t Eval Loss:  0.027203748 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  32600 \t Train Loss:  0.019784853 \t Train Accuracy:  99.33%\nStep:  32600 \t Eval Loss:  0.02599261 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  32700 \t Train Loss:  0.021107163 \t Train Accuracy:  99.33%\nStep:  32700 \t Eval Loss:  0.026838357 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  32800 \t Train Loss:  0.019492554 \t Train Accuracy:  99.38%\nStep:  32800 \t Eval Loss:  0.02142838 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  32900 \t Train Loss:  0.020024672 \t Train Accuracy:  99.38%\nStep:  32900 \t Eval Loss:  0.022563022 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  33000 \t Train Loss:  0.022128591 \t Train Accuracy:  99.43%\nStep:  33000 \t Eval Loss:  0.020027459 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  33100 \t Train Loss:  0.023532674 \t Train Accuracy:  99.22%\nStep:  33100 \t Eval Loss:  0.024473026 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  33200 \t Train Loss:  0.020219818 \t Train Accuracy:  99.40%\nStep:  33200 \t Eval Loss:  0.021357942 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  33300 \t Train Loss:  0.023206592 \t Train Accuracy:  99.33%\nStep:  33300 \t Eval Loss:  0.02263175 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  33400 \t Train Loss:  0.023075141 \t Train Accuracy:  99.29%\nStep:  33400 \t Eval Loss:  0.020991467 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  33500 \t Train Loss:  0.020630654 \t Train Accuracy:  99.40%\nStep:  33500 \t Eval Loss:  0.025172975 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  33600 \t Train Loss:  0.02217947 \t Train Accuracy:  99.38%\nStep:  33600 \t Eval Loss:  0.022641338 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  33700 \t Train Loss:  0.019405443 \t Train Accuracy:  99.40%\nStep:  33700 \t Eval Loss:  0.020161502 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  33800 \t Train Loss:  0.020040408 \t Train Accuracy:  99.46%\nStep:  33800 \t Eval Loss:  0.020253554 \t Eval Accuracy:  99.43%\n##########################################################\nStep:  33900 \t Train Loss:  0.021522295 \t Train Accuracy:  99.40%\nStep:  33900 \t Eval Loss:  0.023092631 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  34000 \t Train Loss:  0.017036742 \t Train Accuracy:  99.46%\nStep:  34000 \t Eval Loss:  0.018404273 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  34100 \t Train Loss:  0.023925912 \t Train Accuracy:  99.28%\nStep:  34100 \t Eval Loss:  0.021326588 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  34200 \t Train Loss:  0.021483812 \t Train Accuracy:  99.41%\nStep:  34200 \t Eval Loss:  0.024516772 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  34300 \t Train Loss:  0.021262355 \t Train Accuracy:  99.35%\nStep:  34300 \t Eval Loss:  0.023037508 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  34400 \t Train Loss:  0.017748764 \t Train Accuracy:  99.44%\nStep:  34400 \t Eval Loss:  0.023309022 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  34500 \t Train Loss:  0.02246724 \t Train Accuracy:  99.27%\nStep:  34500 \t Eval Loss:  0.022176862 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  34600 \t Train Loss:  0.019630289 \t Train Accuracy:  99.44%\nStep:  34600 \t Eval Loss:  0.024455428 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  34700 \t Train Loss:  0.020612694 \t Train Accuracy:  99.38%\nStep:  34700 \t Eval Loss:  0.021839663 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  34800 \t Train Loss:  0.02244449 \t Train Accuracy:  99.34%\nStep:  34800 \t Eval Loss:  0.02790318 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  34900 \t Train Loss:  0.018278386 \t Train Accuracy:  99.43%\nStep:  34900 \t Eval Loss:  0.017528472 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  35000 \t Train Loss:  0.021620262 \t Train Accuracy:  99.33%\nStep:  35000 \t Eval Loss:  0.026498668 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  35100 \t Train Loss:  0.02279377 \t Train Accuracy:  99.23%\nStep:  35100 \t Eval Loss:  0.020963915 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  35200 \t Train Loss:  0.019290637 \t Train Accuracy:  99.43%\nStep:  35200 \t Eval Loss:  0.022569356 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  35300 \t Train Loss:  0.018281577 \t Train Accuracy:  99.43%\nStep:  35300 \t Eval Loss:  0.025948089 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  35400 \t Train Loss:  0.022253238 \t Train Accuracy:  99.32%\nStep:  35400 \t Eval Loss:  0.021378208 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  35500 \t Train Loss:  0.02422582 \t Train Accuracy:  99.23%\nStep:  35500 \t Eval Loss:  0.027250905 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  35600 \t Train Loss:  0.018839514 \t Train Accuracy:  99.40%\nStep:  35600 \t Eval Loss:  0.02521329 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  35700 \t Train Loss:  0.018699313 \t Train Accuracy:  99.37%\nStep:  35700 \t Eval Loss:  0.022706937 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  35800 \t Train Loss:  0.021648038 \t Train Accuracy:  99.38%\nStep:  35800 \t Eval Loss:  0.022669442 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  35900 \t Train Loss:  0.022608299 \t Train Accuracy:  99.27%\nStep:  35900 \t Eval Loss:  0.026262907 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  36000 \t Train Loss:  0.020645984 \t Train Accuracy:  99.40%\nStep:  36000 \t Eval Loss:  0.026919616 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  36100 \t Train Loss:  0.020094797 \t Train Accuracy:  99.35%\nStep:  36100 \t Eval Loss:  0.023291385 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  36200 \t Train Loss:  0.019066416 \t Train Accuracy:  99.44%\nStep:  36200 \t Eval Loss:  0.02132791 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  36300 \t Train Loss:  0.01907864 \t Train Accuracy:  99.37%\nStep:  36300 \t Eval Loss:  0.023717608 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  36400 \t Train Loss:  0.017052494 \t Train Accuracy:  99.46%\nStep:  36400 \t Eval Loss:  0.02422477 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  36500 \t Train Loss:  0.018375821 \t Train Accuracy:  99.46%\nStep:  36500 \t Eval Loss:  0.02175418 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  36600 \t Train Loss:  0.017617367 \t Train Accuracy:  99.41%\nStep:  36600 \t Eval Loss:  0.023919227 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  36700 \t Train Loss:  0.020799976 \t Train Accuracy:  99.38%\nStep:  36700 \t Eval Loss:  0.024097241 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  36800 \t Train Loss:  0.019225955 \t Train Accuracy:  99.34%\nStep:  36800 \t Eval Loss:  0.029893123 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  36900 \t Train Loss:  0.019043297 \t Train Accuracy:  99.43%\nStep:  36900 \t Eval Loss:  0.022797152 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  37000 \t Train Loss:  0.021063574 \t Train Accuracy:  99.38%\nStep:  37000 \t Eval Loss:  0.021143388 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  37100 \t Train Loss:  0.021195684 \t Train Accuracy:  99.35%\nStep:  37100 \t Eval Loss:  0.021864513 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  37200 \t Train Loss:  0.019677982 \t Train Accuracy:  99.33%\nStep:  37200 \t Eval Loss:  0.026909448 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  37300 \t Train Loss:  0.020106783 \t Train Accuracy:  99.38%\nStep:  37300 \t Eval Loss:  0.023408113 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  37400 \t Train Loss:  0.018052649 \t Train Accuracy:  99.38%\nStep:  37400 \t Eval Loss:  0.024502795 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  37500 \t Train Loss:  0.022571748 \t Train Accuracy:  99.33%\nStep:  37500 \t Eval Loss:  0.022473566 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  37600 \t Train Loss:  0.018027768 \t Train Accuracy:  99.57%\nStep:  37600 \t Eval Loss:  0.021110266 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  37700 \t Train Loss:  0.020142946 \t Train Accuracy:  99.43%\nStep:  37700 \t Eval Loss:  0.024056206 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  37800 \t Train Loss:  0.020053973 \t Train Accuracy:  99.44%\nStep:  37800 \t Eval Loss:  0.020684762 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  37900 \t Train Loss:  0.019398805 \t Train Accuracy:  99.38%\nStep:  37900 \t Eval Loss:  0.024576407 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  38000 \t Train Loss:  0.020592626 \t Train Accuracy:  99.28%\nStep:  38000 \t Eval Loss:  0.021457955 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  38100 \t Train Loss:  0.017624555 \t Train Accuracy:  99.43%\nStep:  38100 \t Eval Loss:  0.023380566 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  38200 \t Train Loss:  0.020333305 \t Train Accuracy:  99.35%\nStep:  38200 \t Eval Loss:  0.027818795 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  38300 \t Train Loss:  0.022701558 \t Train Accuracy:  99.35%\nStep:  38300 \t Eval Loss:  0.022320133 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  38400 \t Train Loss:  0.021180408 \t Train Accuracy:  99.35%\nStep:  38400 \t Eval Loss:  0.023632873 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  38500 \t Train Loss:  0.017905712 \t Train Accuracy:  99.45%\nStep:  38500 \t Eval Loss:  0.021870472 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  38600 \t Train Loss:  0.019366689 \t Train Accuracy:  99.41%\nStep:  38600 \t Eval Loss:  0.023861054 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  38700 \t Train Loss:  0.018302914 \t Train Accuracy:  99.40%\nStep:  38700 \t Eval Loss:  0.028379485 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  38800 \t Train Loss:  0.017632749 \t Train Accuracy:  99.50%\nStep:  38800 \t Eval Loss:  0.024293069 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  38900 \t Train Loss:  0.018891457 \t Train Accuracy:  99.48%\nStep:  38900 \t Eval Loss:  0.023149488 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  39000 \t Train Loss:  0.023065282 \t Train Accuracy:  99.30%\nStep:  39000 \t Eval Loss:  0.021369506 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  39100 \t Train Loss:  0.023382412 \t Train Accuracy:  99.24%\nStep:  39100 \t Eval Loss:  0.028961703 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  39200 \t Train Loss:  0.019330518 \t Train Accuracy:  99.44%\nStep:  39200 \t Eval Loss:  0.025091356 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  39300 \t Train Loss:  0.017659321 \t Train Accuracy:  99.43%\nStep:  39300 \t Eval Loss:  0.024897695 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  39400 \t Train Loss:  0.020369599 \t Train Accuracy:  99.38%\nStep:  39400 \t Eval Loss:  0.030864226 \t Eval Accuracy:  99.05%\n##########################################################\nStep:  39500 \t Train Loss:  0.019237118 \t Train Accuracy:  99.41%\nStep:  39500 \t Eval Loss:  0.02301069 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  39600 \t Train Loss:  0.020847479 \t Train Accuracy:  99.34%\nStep:  39600 \t Eval Loss:  0.021018876 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  39700 \t Train Loss:  0.019669361 \t Train Accuracy:  99.35%\nStep:  39700 \t Eval Loss:  0.024429811 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  39800 \t Train Loss:  0.016648438 \t Train Accuracy:  99.46%\nStep:  39800 \t Eval Loss:  0.023718433 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  39900 \t Train Loss:  0.021941667 \t Train Accuracy:  99.32%\nStep:  39900 \t Eval Loss:  0.024603438 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  40000 \t Train Loss:  0.017657695 \t Train Accuracy:  99.45%\nStep:  40000 \t Eval Loss:  0.020942379 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  40100 \t Train Loss:  0.016269747 \t Train Accuracy:  99.51%\nStep:  40100 \t Eval Loss:  0.018490398 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  40200 \t Train Loss:  0.0174804 \t Train Accuracy:  99.44%\nStep:  40200 \t Eval Loss:  0.026499644 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  40300 \t Train Loss:  0.019600142 \t Train Accuracy:  99.40%\nStep:  40300 \t Eval Loss:  0.026914656 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  40400 \t Train Loss:  0.020008363 \t Train Accuracy:  99.43%\nStep:  40400 \t Eval Loss:  0.022895336 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  40500 \t Train Loss:  0.01895313 \t Train Accuracy:  99.43%\nStep:  40500 \t Eval Loss:  0.024162957 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  40600 \t Train Loss:  0.024227433 \t Train Accuracy:  99.30%\nStep:  40600 \t Eval Loss:  0.022207307 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  40700 \t Train Loss:  0.015010357 \t Train Accuracy:  99.58%\nStep:  40700 \t Eval Loss:  0.022849018 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  40800 \t Train Loss:  0.020219088 \t Train Accuracy:  99.35%\nStep:  40800 \t Eval Loss:  0.027074706 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  40900 \t Train Loss:  0.019483343 \t Train Accuracy:  99.41%\nStep:  40900 \t Eval Loss:  0.021723889 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  41000 \t Train Loss:  0.016242633 \t Train Accuracy:  99.50%\nStep:  41000 \t Eval Loss:  0.023245784 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  41100 \t Train Loss:  0.018605586 \t Train Accuracy:  99.39%\nStep:  41100 \t Eval Loss:  0.025293658 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  41200 \t Train Loss:  0.019028686 \t Train Accuracy:  99.40%\nStep:  41200 \t Eval Loss:  0.025707927 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  41300 \t Train Loss:  0.021285295 \t Train Accuracy:  99.29%\nStep:  41300 \t Eval Loss:  0.026995484 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  41400 \t Train Loss:  0.023110691 \t Train Accuracy:  99.29%\nStep:  41400 \t Eval Loss:  0.024949513 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  41500 \t Train Loss:  0.023268597 \t Train Accuracy:  99.30%\nStep:  41500 \t Eval Loss:  0.025306381 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  41600 \t Train Loss:  0.020480938 \t Train Accuracy:  99.33%\nStep:  41600 \t Eval Loss:  0.024489757 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  41700 \t Train Loss:  0.016562086 \t Train Accuracy:  99.45%\nStep:  41700 \t Eval Loss:  0.024776608 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  41800 \t Train Loss:  0.021639053 \t Train Accuracy:  99.37%\nStep:  41800 \t Eval Loss:  0.023298176 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  41900 \t Train Loss:  0.01884322 \t Train Accuracy:  99.34%\nStep:  41900 \t Eval Loss:  0.025185272 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  42000 \t Train Loss:  0.020388756 \t Train Accuracy:  99.37%\nStep:  42000 \t Eval Loss:  0.026412997 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  42100 \t Train Loss:  0.018224705 \t Train Accuracy:  99.46%\nStep:  42100 \t Eval Loss:  0.023627881 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  42200 \t Train Loss:  0.020614019 \t Train Accuracy:  99.35%\nStep:  42200 \t Eval Loss:  0.023320451 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  42300 \t Train Loss:  0.016294435 \t Train Accuracy:  99.39%\nStep:  42300 \t Eval Loss:  0.021672564 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  42400 \t Train Loss:  0.018805854 \t Train Accuracy:  99.45%\nStep:  42400 \t Eval Loss:  0.022532716 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  42500 \t Train Loss:  0.017210523 \t Train Accuracy:  99.46%\nStep:  42500 \t Eval Loss:  0.027189922 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  42600 \t Train Loss:  0.015851121 \t Train Accuracy:  99.55%\nStep:  42600 \t Eval Loss:  0.020343583 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  42700 \t Train Loss:  0.02030819 \t Train Accuracy:  99.43%\nStep:  42700 \t Eval Loss:  0.028025633 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  42800 \t Train Loss:  0.02148261 \t Train Accuracy:  99.32%\nStep:  42800 \t Eval Loss:  0.025030235 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  42900 \t Train Loss:  0.020122636 \t Train Accuracy:  99.39%\nStep:  42900 \t Eval Loss:  0.02100442 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  43000 \t Train Loss:  0.022737505 \t Train Accuracy:  99.32%\nStep:  43000 \t Eval Loss:  0.023803312 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  43100 \t Train Loss:  0.026287511 \t Train Accuracy:  99.21%\nStep:  43100 \t Eval Loss:  0.027491488 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  43200 \t Train Loss:  0.016894296 \t Train Accuracy:  99.50%\nStep:  43200 \t Eval Loss:  0.028785529 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  43300 \t Train Loss:  0.018449998 \t Train Accuracy:  99.44%\nStep:  43300 \t Eval Loss:  0.024445947 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  43400 \t Train Loss:  0.01775892 \t Train Accuracy:  99.48%\nStep:  43400 \t Eval Loss:  0.025493953 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  43500 \t Train Loss:  0.019683745 \t Train Accuracy:  99.39%\nStep:  43500 \t Eval Loss:  0.02243229 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  43600 \t Train Loss:  0.021871015 \t Train Accuracy:  99.28%\nStep:  43600 \t Eval Loss:  0.024371518 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  43700 \t Train Loss:  0.018188994 \t Train Accuracy:  99.44%\nStep:  43700 \t Eval Loss:  0.021073224 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  43800 \t Train Loss:  0.02265248 \t Train Accuracy:  99.38%\nStep:  43800 \t Eval Loss:  0.022686249 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  43900 \t Train Loss:  0.018850502 \t Train Accuracy:  99.39%\nStep:  43900 \t Eval Loss:  0.025417527 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  44000 \t Train Loss:  0.02004027 \t Train Accuracy:  99.30%\nStep:  44000 \t Eval Loss:  0.02604042 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  44100 \t Train Loss:  0.02165065 \t Train Accuracy:  99.27%\nStep:  44100 \t Eval Loss:  0.026769834 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  44200 \t Train Loss:  0.019627012 \t Train Accuracy:  99.41%\nStep:  44200 \t Eval Loss:  0.022252709 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  44300 \t Train Loss:  0.016060475 \t Train Accuracy:  99.48%\nStep:  44300 \t Eval Loss:  0.020917367 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  44400 \t Train Loss:  0.021785937 \t Train Accuracy:  99.30%\nStep:  44400 \t Eval Loss:  0.025728114 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  44500 \t Train Loss:  0.018484484 \t Train Accuracy:  99.39%\nStep:  44500 \t Eval Loss:  0.02553548 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  44600 \t Train Loss:  0.0211021 \t Train Accuracy:  99.28%\nStep:  44600 \t Eval Loss:  0.027910184 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  44700 \t Train Loss:  0.018575042 \t Train Accuracy:  99.46%\nStep:  44700 \t Eval Loss:  0.023293283 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  44800 \t Train Loss:  0.017298307 \t Train Accuracy:  99.46%\nStep:  44800 \t Eval Loss:  0.021596443 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  44900 \t Train Loss:  0.019879118 \t Train Accuracy:  99.39%\nStep:  44900 \t Eval Loss:  0.02159401 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  45000 \t Train Loss:  0.016615564 \t Train Accuracy:  99.54%\nStep:  45000 \t Eval Loss:  0.02660776 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  45100 \t Train Loss:  0.016629774 \t Train Accuracy:  99.51%\nStep:  45100 \t Eval Loss:  0.02161479 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  45200 \t Train Loss:  0.01907527 \t Train Accuracy:  99.48%\nStep:  45200 \t Eval Loss:  0.022816114 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  45300 \t Train Loss:  0.02107555 \t Train Accuracy:  99.37%\nStep:  45300 \t Eval Loss:  0.022075024 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  45400 \t Train Loss:  0.015146252 \t Train Accuracy:  99.49%\nStep:  45400 \t Eval Loss:  0.021818489 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  45500 \t Train Loss:  0.017368041 \t Train Accuracy:  99.52%\nStep:  45500 \t Eval Loss:  0.020864118 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  45600 \t Train Loss:  0.01942046 \t Train Accuracy:  99.37%\nStep:  45600 \t Eval Loss:  0.023420068 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  45700 \t Train Loss:  0.021591375 \t Train Accuracy:  99.33%\nStep:  45700 \t Eval Loss:  0.028540272 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  45800 \t Train Loss:  0.018891556 \t Train Accuracy:  99.44%\nStep:  45800 \t Eval Loss:  0.023333687 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  45900 \t Train Loss:  0.020282453 \t Train Accuracy:  99.39%\nStep:  45900 \t Eval Loss:  0.02443552 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  46000 \t Train Loss:  0.020411316 \t Train Accuracy:  99.43%\nStep:  46000 \t Eval Loss:  0.023267701 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  46100 \t Train Loss:  0.019657139 \t Train Accuracy:  99.40%\nStep:  46100 \t Eval Loss:  0.024003167 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  46200 \t Train Loss:  0.020069486 \t Train Accuracy:  99.38%\nStep:  46200 \t Eval Loss:  0.021374095 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  46300 \t Train Loss:  0.018260263 \t Train Accuracy:  99.38%\nStep:  46300 \t Eval Loss:  0.024101675 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  46400 \t Train Loss:  0.021596259 \t Train Accuracy:  99.39%\nStep:  46400 \t Eval Loss:  0.025007213 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  46500 \t Train Loss:  0.014890968 \t Train Accuracy:  99.49%\nStep:  46500 \t Eval Loss:  0.027371679 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  46600 \t Train Loss:  0.018220263 \t Train Accuracy:  99.38%\nStep:  46600 \t Eval Loss:  0.024328765 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  46700 \t Train Loss:  0.017072383 \t Train Accuracy:  99.48%\nStep:  46700 \t Eval Loss:  0.023993222 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  46800 \t Train Loss:  0.014980882 \t Train Accuracy:  99.46%\nStep:  46800 \t Eval Loss:  0.0267477 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  46900 \t Train Loss:  0.02044312 \t Train Accuracy:  99.39%\nStep:  46900 \t Eval Loss:  0.021438943 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  47000 \t Train Loss:  0.020023573 \t Train Accuracy:  99.44%\nStep:  47000 \t Eval Loss:  0.024746202 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  47100 \t Train Loss:  0.018482577 \t Train Accuracy:  99.44%\nStep:  47100 \t Eval Loss:  0.0224859 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  47200 \t Train Loss:  0.022098297 \t Train Accuracy:  99.34%\nStep:  47200 \t Eval Loss:  0.026262436 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  47300 \t Train Loss:  0.01958386 \t Train Accuracy:  99.41%\nStep:  47300 \t Eval Loss:  0.022055618 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  47400 \t Train Loss:  0.019809911 \t Train Accuracy:  99.40%\nStep:  47400 \t Eval Loss:  0.022385355 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  47500 \t Train Loss:  0.018577332 \t Train Accuracy:  99.41%\nStep:  47500 \t Eval Loss:  0.026403978 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  47600 \t Train Loss:  0.01774196 \t Train Accuracy:  99.48%\nStep:  47600 \t Eval Loss:  0.022277847 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  47700 \t Train Loss:  0.021233607 \t Train Accuracy:  99.35%\nStep:  47700 \t Eval Loss:  0.021399513 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  47800 \t Train Loss:  0.018666472 \t Train Accuracy:  99.38%\nStep:  47800 \t Eval Loss:  0.025431788 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  47900 \t Train Loss:  0.01961032 \t Train Accuracy:  99.33%\nStep:  47900 \t Eval Loss:  0.025973637 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  48000 \t Train Loss:  0.018996276 \t Train Accuracy:  99.43%\nStep:  48000 \t Eval Loss:  0.021188911 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  48100 \t Train Loss:  0.022839688 \t Train Accuracy:  99.32%\nStep:  48100 \t Eval Loss:  0.024414271 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  48200 \t Train Loss:  0.01808673 \t Train Accuracy:  99.41%\nStep:  48200 \t Eval Loss:  0.022259288 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  48300 \t Train Loss:  0.019988554 \t Train Accuracy:  99.37%\nStep:  48300 \t Eval Loss:  0.023962291 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  48400 \t Train Loss:  0.019003708 \t Train Accuracy:  99.41%\nStep:  48400 \t Eval Loss:  0.024040386 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  48500 \t Train Loss:  0.01791176 \t Train Accuracy:  99.39%\nStep:  48500 \t Eval Loss:  0.022758499 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  48600 \t Train Loss:  0.020076238 \t Train Accuracy:  99.41%\nStep:  48600 \t Eval Loss:  0.021518212 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  48700 \t Train Loss:  0.020610526 \t Train Accuracy:  99.34%\nStep:  48700 \t Eval Loss:  0.020982994 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  48800 \t Train Loss:  0.022184942 \t Train Accuracy:  99.28%\nStep:  48800 \t Eval Loss:  0.023923732 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  48900 \t Train Loss:  0.015388401 \t Train Accuracy:  99.45%\nStep:  48900 \t Eval Loss:  0.02417292 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  49000 \t Train Loss:  0.01738462 \t Train Accuracy:  99.50%\nStep:  49000 \t Eval Loss:  0.027751556 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  49100 \t Train Loss:  0.020454165 \t Train Accuracy:  99.44%\nStep:  49100 \t Eval Loss:  0.021491304 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  49200 \t Train Loss:  0.02098432 \t Train Accuracy:  99.33%\nStep:  49200 \t Eval Loss:  0.023721341 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  49300 \t Train Loss:  0.018472169 \t Train Accuracy:  99.40%\nStep:  49300 \t Eval Loss:  0.023123937 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  49400 \t Train Loss:  0.020847011 \t Train Accuracy:  99.35%\nStep:  49400 \t Eval Loss:  0.02145738 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  49500 \t Train Loss:  0.019918155 \t Train Accuracy:  99.39%\nStep:  49500 \t Eval Loss:  0.026334684 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  49600 \t Train Loss:  0.017305886 \t Train Accuracy:  99.41%\nStep:  49600 \t Eval Loss:  0.022253372 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  49700 \t Train Loss:  0.020604195 \t Train Accuracy:  99.38%\nStep:  49700 \t Eval Loss:  0.02632647 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  49800 \t Train Loss:  0.017443787 \t Train Accuracy:  99.57%\nStep:  49800 \t Eval Loss:  0.023464654 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  49900 \t Train Loss:  0.021581307 \t Train Accuracy:  99.39%\nStep:  49900 \t Eval Loss:  0.020430572 \t Eval Accuracy:  99.38%\nCPU times: user 6min 34s, sys: 4min 21s, total: 10min 56s\nWall time: 11min 34s\n","output_type":"stream"}]},{"cell_type":"code","source":"# Plot loss and accuracy in subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.set_title('Loss')\nax2.set_title('Accuracy')\n\n\n\nax1.plot(all_train_losses, label='train_loss')\nax1.plot(all_eval_losses, label='eval_loss')\n\nax2.plot(all_train_accuracy, label='train_accuracy')\nax2.plot(all_test_accuracy, label='eval_accuracy')\n\nax1.legend()\nax2.legend()\nplt.show()\nplt.clf()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:08:49.636750Z","iopub.execute_input":"2024-07-01T07:08:49.637064Z","iopub.status.idle":"2024-07-01T07:08:50.122105Z","shell.execute_reply.started":"2024-07-01T07:08:49.637038Z","shell.execute_reply":"2024-07-01T07:08:50.121172Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x500 with 2 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"@partial(jax.jit, static_argnames=(\"length\"))\ndef generate_text(rng, params, length):\n    def _scan_generate(carry, _):\n        random_key, context = carry\n        logits = model.apply(params, context)\n#         pdb.set_trace()\n        rng, rng_subkey = jax.random.split(random_key)\n        new_token = jax.random.categorical(\n          rng_subkey, logits[:, -n_tokens, :], axis=-1, shape=(1, 1)\n        )\n        context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n        print(context.shape)\n        return (rng, context), new_token\n\n    _, new_tokens = jax.lax.scan(\n    _scan_generate,\n    (rng, jnp.expand_dims(test_data[852:852+block_size], axis=0)),\n    (),\n    length=length,\n    )\n    return new_tokens","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:08:50.125455Z","iopub.execute_input":"2024-07-01T07:08:50.125789Z","iopub.status.idle":"2024-07-01T07:08:50.133761Z","shell.execute_reply.started":"2024-07-01T07:08:50.125761Z","shell.execute_reply":"2024-07-01T07:08:50.132685Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test_data[852:852+block_size]","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:08:50.134888Z","iopub.execute_input":"2024-07-01T07:08:50.135218Z","iopub.status.idle":"2024-07-01T07:08:50.205812Z","shell.execute_reply.started":"2024-07-01T07:08:50.135186Z","shell.execute_reply":"2024-07-01T07:08:50.204965Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Array([51,  6,  1, 53, 56,  1, 43, 50, 57, 43,  1, 63, 53, 59,  1, 42, 53,\n        1, 51, 43,  1, 61, 56, 53, 52, 45, 10,  0, 20, 47, 57,  1, 52, 39,\n       51, 43,  1, 47, 57,  1, 24, 47, 41, 47, 53,  6,  1, 40, 53, 56, 52,\n        1, 47, 52,  1, 25, 39, 52, 58, 59, 39,  8,  0,  0], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"i = 852\ndecode(test_data[i:i+block_size].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:08:50.206882Z","iopub.execute_input":"2024-07-01T07:08:50.207127Z","iopub.status.idle":"2024-07-01T07:08:50.213642Z","shell.execute_reply.started":"2024-07-01T07:08:50.207104Z","shell.execute_reply":"2024-07-01T07:08:50.212661Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'m, or else you do me wrong:\\nHis name is Licio, born in Mantua.\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"new_tokenz = 1000\nkey, subkey = jax.random.split(jax.random.PRNGKey(156))\n# key, subkey = jax.random.split(key)\n# token_gen = generate_text(jnp.zeros((1,block_size)).astype(jnp.int32), new_tokenz, {'params': state.params})\ntoken_gen = generate_text(key, params, new_tokenz)[:, 0, 0].tolist()\nprint(token_gen)\nprint('\\n')\nprint(decode(token_gen))","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:08:50.214767Z","iopub.execute_input":"2024-07-01T07:08:50.215081Z","iopub.status.idle":"2024-07-01T07:08:52.243705Z","shell.execute_reply.started":"2024-07-01T07:08:50.215047Z","shell.execute_reply":"2024-07-01T07:08:52.242777Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"(1, 64)\n[24, 33, 15, 21, 27, 10, 0, 21, 5, 50, 50, 1, 41, 53, 52, 57, 43, 55, 59, 43, 1, 58, 46, 47, 52, 45, 1, 44, 53, 56, 1, 63, 53, 59, 56, 1, 40, 39, 57, 58, 56, 43, 6, 1, 57, 61, 53, 56, 42, 57, 12, 0, 0, 29, 33, 17, 17, 26, 1, 25, 13, 30, 19, 13, 30, 17, 32, 10, 0, 17, 56, 43, 1, 21, 1, 51, 39, 63, 1, 14, 53, 50, 53, 52, 45, 43, 56, 5, 42, 1, 58, 53, 52, 45, 59, 43, 57, 6, 1, 39, 52, 53, 58, 46, 43, 56, 6, 0, 13, 57, 1, 46, 43, 1, 58, 46, 47, 50, 50, 7, 44, 47, 52, 52, 1, 63, 53, 59, 1, 39, 54, 43, 1, 63, 43, 58, 1, 51, 43, 1, 58, 53, 1, 54, 56, 39, 52, 41, 43, 11, 0, 14, 59, 58, 1, 58, 46, 43, 1, 58, 46, 43, 1, 57, 58, 56, 39, 47, 52, 5, 42, 1, 53, 44, 1, 46, 43, 56, 1, 45, 56, 47, 51, 43, 42, 1, 47, 52, 1, 40, 43, 57, 58, 10, 0, 19, 53, 42, 1, 58, 47, 51, 43, 1, 46, 47, 58, 1, 44, 56, 47, 43, 52, 42, 57, 1, 40, 43, 44, 53, 56, 43, 1, 58, 46, 43, 1, 43, 39, 56, 58, 46, 6, 0, 32, 46, 39, 58, 1, 57, 46, 43, 1, 50, 53, 53, 58, 1, 58, 39, 49, 43, 57, 1, 46, 47, 51, 1, 59, 52, 44, 53, 50, 42, 1, 63, 53, 59, 56, 1, 40, 56, 53, 58, 46, 43, 56, 57, 11, 0, 37, 53, 59, 56, 1, 61, 43, 39, 58, 46, 43, 42, 1, 57, 39, 42, 1, 40, 43, 1, 56, 43, 50, 43, 43, 52, 1, 53, 44, 1, 51, 59, 41, 46, 1, 57, 47, 52, 41, 43, 1, 21, 1, 41, 46, 53, 56, 57, 43, 0, 35, 47, 50, 50, 1, 63, 53, 59, 1, 45, 53, 1, 39, 50, 53, 52, 45, 8, 5, 1, 53, 52, 1, 58, 53, 53, 10, 1, 42, 53, 1, 63, 53, 59, 56, 6, 1, 46, 43, 1, 61, 43, 56, 43, 1, 39, 1, 40, 43, 57, 54, 43, 41, 58, 0, 32, 46, 63, 1, 53, 52, 43, 7, 7, 61, 46, 47, 41, 46, 1, 61, 47, 50, 42, 1, 63, 53, 59, 1, 46, 39, 60, 43, 1, 51, 39, 42, 43, 1, 56, 53, 53, 51, 1, 39, 1, 61, 53, 56, 42, 11, 0, 14, 59, 58, 1, 58, 46, 39, 58, 1, 61, 46, 43, 52, 1, 63, 53, 59, 1, 39, 50, 50, 1, 58, 46, 43, 1, 52, 39, 58, 59, 56, 43, 1, 53, 44, 1, 41, 56, 53, 61, 52, 1, 47, 57, 0, 22, 53, 60, 43, 57, 1, 56, 47, 53, 52, 57, 6, 1, 50, 53, 60, 43, 1, 51, 63, 1, 46, 43, 39, 56, 58, 57, 2, 1, 31, 53, 11, 1, 46, 43, 39, 60, 43, 52, 1, 41, 53, 51, 43, 11, 0, 27, 56, 1, 42, 43, 39, 58, 46, 6, 1, 45, 53, 53, 42, 1, 21, 1, 41, 39, 50, 50, 5, 42, 1, 46, 43, 39, 56, 58, 1, 57, 53, 1, 56, 53, 50, 53, 45, 59, 43, 1, 58, 46, 47, 52, 45, 6, 0, 58, 46, 57, 1, 58, 43, 50, 50, 1, 51, 43, 1, 52, 53, 58, 1, 53, 52, 43, 57, 6, 1, 53, 59, 56, 1, 58, 46, 43, 56, 43, 1, 57, 46, 39, 50, 50, 1, 44, 53, 50, 50, 53, 61, 10, 0, 32, 47, 52, 49, 50, 59, 6, 1, 57, 47, 57, 58, 43, 56, 6, 1, 21, 1, 61, 47, 50, 50, 1, 57, 58, 39, 52, 42, 5, 1, 52, 39, 63, 6, 1, 46, 53, 61, 1, 63, 43, 1, 42, 43, 45, 39, 58, 53, 56, 43, 8, 0, 0, 18, 56, 56, 43, 61, 10, 0, 30, 43, 60, 53, 58, 43, 6, 1, 40, 47, 58, 1, 30, 53, 51, 43, 6, 1, 58, 46, 43, 56, 43, 1, 57, 58, 56, 47, 52, 45, 1, 58, 39, 50, 43, 1, 51, 39, 49, 43, 57, 1, 53, 52, 43, 57, 11, 0, 13, 52, 42, 1, 54, 56, 43, 58, 1, 58, 46, 63, 1, 40, 47, 56, 42, 52, 43, 57, 57, 1, 57, 53, 1, 53, 59, 58, 1, 53, 44, 1, 45, 56, 39, 41, 43, 8, 0, 13, 52, 42, 1, 21, 6, 1, 44, 43, 58, 50, 47, 52, 45, 8, 0, 0, 15, 13, 25, 21, 24, 24, 27, 10, 0, 15, 53, 59, 50, 42, 1, 52, 53, 58, 1, 45, 53, 1, 42, 53, 5, 58, 6, 0, 32, 46, 43, 52, 1, 63, 53, 59, 56, 1, 41, 50, 53, 60, 43, 56, 0, 32, 46, 43, 1, 43, 57, 41, 43, 52, 47, 52, 45, 1, 52, 39, 58, 47, 53, 52, 1, 61, 46, 47, 41, 46, 1, 21, 57, 39, 40, 43, 52, 6, 0, 16, 53, 6, 1, 58, 46, 43, 52, 1, 39, 50, 50, 1, 58, 46, 39, 58, 6, 1, 58, 43, 50, 50, 1, 51, 43, 1, 46, 59, 57, 40, 39, 52, 42, 1, 61, 47, 50, 50, 1, 52, 53, 58, 6, 0, 24, 43, 58, 1, 43, 58, 43, 57, 1, 51, 63, 1, 46, 39, 52, 42, 6, 1, 21, 1, 57, 43, 43, 6, 1, 58, 53, 1, 58, 46, 63, 1, 55, 59, 43, 43, 52, 0, 35, 47, 58, 46, 1, 42, 59, 58, 63, 1, 32, 46, 63, 1, 51, 43, 50, 50, 39, 58, 43, 1, 41, 53, 51, 43, 57, 1, 51, 43, 1, 58, 53, 1, 63, 53, 59, 10, 0, 31, 58, 43, 61, 1, 39, 1, 44, 43, 39, 56, 12, 0, 0, 31, 21, 15, 21]\n\n\nLUCIO:\nI'll conseque thing for your bastre, swords?\n\nQUEEN MARGARET:\nEre I may Bolonger'd tongues, another,\nAs he thill-finn you ape yet me to prance;\nBut the the strain'd of her grimed in best:\nGod time hit friends before the earth,\nThat she loot takes him unfold your brothers;\nYour weathed sad be releen of much since I chorse\nWill you go along.' on too: do your, he were a bespect\nThy one--which wild you have made room a word;\nBut that when you all the nature of crown is\nJoves rions, love my hearts! So; heaven come;\nOr death, good I call'd heart so rologue thing,\nths tell me not ones, our there shall follow:\nTinklu, sister, I will stand' nay, how ye degatore.\n\nFrrew:\nRevote, bit Rome, there string tale makes ones;\nAnd pret thy birdness so out of grace.\nAnd I, fetling.\n\nCAMILLO:\nCould not go do't,\nThen your clover\nThe escening nation which Isaben,\nDo, then all that, tell me husband will not,\nLet etes my hand, I see, to thy queen\nWith duty Thy mellate comes me to you:\nStew a fear?\n\nSICI\n","output_type":"stream"}]},{"cell_type":"code","source":"params['params'].keys()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:08:52.244887Z","iopub.execute_input":"2024-07-01T07:08:52.245181Z","iopub.status.idle":"2024-07-01T07:08:52.250974Z","shell.execute_reply.started":"2024-07-01T07:08:52.245154Z","shell.execute_reply":"2024-07-01T07:08:52.250121Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"dict_keys(['A', 'B', 'C', 'ConvTranspose_0', 'ConvTranspose_1', 'ConvTranspose_2', 'Conv_0', 'Conv_1', 'Conv_2', 'Conv_3', 'Conv_4', 'Conv_5', 'D', 'Dense_0', 'Embed_0', 'Embed_1', 'RMSNorm_0', 'RMSNorm_1', 'delta'])"},"metadata":{}}]},{"cell_type":"code","source":"var_params = {'params':{}}","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:08:52.252039Z","iopub.execute_input":"2024-07-01T07:08:52.252314Z","iopub.status.idle":"2024-07-01T07:08:52.260336Z","shell.execute_reply.started":"2024-07-01T07:08:52.252278Z","shell.execute_reply":"2024-07-01T07:08:52.259519Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"var_params['params']['Conv_0'] = params['params']['Conv_0']","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:08:52.261351Z","iopub.execute_input":"2024-07-01T07:08:52.261623Z","iopub.status.idle":"2024-07-01T07:08:52.269865Z","shell.execute_reply.started":"2024-07-01T07:08:52.261600Z","shell.execute_reply":"2024-07-01T07:08:52.269042Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"for key in params['params'].keys():\n    \n    n_params = sum(p.size for p in jax.tree_util.tree_leaves(params['params'][key]))\n\n    print(f\"Total number of parameters in {key}: {n_params:_}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:08:52.270960Z","iopub.execute_input":"2024-07-01T07:08:52.271217Z","iopub.status.idle":"2024-07-01T07:08:52.280325Z","shell.execute_reply.started":"2024-07-01T07:08:52.271194Z","shell.execute_reply":"2024-07-01T07:08:52.279518Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Total number of parameters in A: 8_192\nTotal number of parameters in B: 128\nTotal number of parameters in C: 128\nTotal number of parameters in ConvTranspose_0: 393_472\nTotal number of parameters in ConvTranspose_1: 98_432\nTotal number of parameters in ConvTranspose_2: 24_640\nTotal number of parameters in Conv_0: 24_704\nTotal number of parameters in Conv_1: 98_560\nTotal number of parameters in Conv_2: 393_728\nTotal number of parameters in Conv_3: 1_573_376\nTotal number of parameters in Conv_4: 393_472\nTotal number of parameters in Conv_5: 98_432\nTotal number of parameters in D: 4_096\nTotal number of parameters in Dense_0: 4_225\nTotal number of parameters in Embed_0: 4_160\nTotal number of parameters in Embed_1: 4_096\nTotal number of parameters in RMSNorm_0: 8\nTotal number of parameters in RMSNorm_1: 64\nTotal number of parameters in delta: 4_096\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}