{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from functools import partial\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom jax.nn.initializers import lecun_normal, normal\nfrom jax.numpy.linalg import eigh, inv, matrix_power\nfrom jax.scipy.signal import convolve\n\nimport tensorflow_datasets as tfds\n\nimport torch\n\nfrom dataclasses import dataclass\n\nfrom typing import Union\n\nimport matplotlib.pyplot as plt\nimport seaborn\n\n# from clu import metrics\nfrom flax.training import train_state  # Useful dataclass to keep train state\nfrom flax import struct                # Flax dataclasses\nimport optax                           # Common loss functions and optimizers\nfrom tqdm import tqdm\n\nimport pdb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-28T09:07:05.431146Z","iopub.execute_input":"2024-06-28T09:07:05.431753Z","iopub.status.idle":"2024-06-28T09:07:09.519385Z","shell.execute_reply.started":"2024-06-28T09:07:05.431719Z","shell.execute_reply":"2024-06-28T09:07:09.518256Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/shak-new-input/train.txt', 'r', encoding='utf-8') as f:\n    text_train = f.read()\n    \nwith open('/kaggle/input/shak-new-input/test.txt', 'r', encoding='utf-8') as f:\n    text_validation = f.read()    ","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:07:09.521293Z","iopub.execute_input":"2024-06-28T09:07:09.522105Z","iopub.status.idle":"2024-06-28T09:07:09.536809Z","shell.execute_reply.started":"2024-06-28T09:07:09.522068Z","shell.execute_reply":"2024-06-28T09:07:09.535904Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# here are all the unique characters that occur in this text\nchars = sorted(list(set(text_train+text_validation)))\n# chars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:07:09.538134Z","iopub.execute_input":"2024-06-28T09:07:09.538406Z","iopub.status.idle":"2024-06-28T09:07:09.561194Z","shell.execute_reply.started":"2024-06-28T09:07:09.538382Z","shell.execute_reply":"2024-06-28T09:07:09.560303Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n65\n","output_type":"stream"}]},{"cell_type":"code","source":"# create a mapping from characters to integers\nstoi = { ch: i for i,ch in enumerate(chars) }\nitos = { i: ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n\nprint(encode(\"hii there\"))\nprint(decode(encode(\"hii there\")))","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:07:09.563160Z","iopub.execute_input":"2024-06-28T09:07:09.563468Z","iopub.status.idle":"2024-06-28T09:07:09.575171Z","shell.execute_reply.started":"2024-06-28T09:07:09.563438Z","shell.execute_reply":"2024-06-28T09:07:09.574268Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[46, 47, 47, 1, 58, 46, 43, 56, 43]\nhii there\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = jnp.array(encode(text_train), dtype=jnp.int32)\ntest_data = jnp.array(encode(text_validation), dtype=jnp.int32)\nblock_size = 8\ntrain_data[:block_size+1]","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:07:09.576312Z","iopub.execute_input":"2024-06-28T09:07:09.576605Z","iopub.status.idle":"2024-06-28T09:07:11.906846Z","shell.execute_reply.started":"2024-06-28T09:07:09.576569Z","shell.execute_reply":"2024-06-28T09:07:11.905963Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Array([18, 47, 56, 57, 58,  1, 15, 47, 58], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target: {target}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:07:11.908311Z","iopub.execute_input":"2024-06-28T09:07:11.908660Z","iopub.status.idle":"2024-06-28T09:07:12.390849Z","shell.execute_reply.started":"2024-06-28T09:07:11.908630Z","shell.execute_reply":"2024-06-28T09:07:12.389861Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"when input is [18] the target: 47\nwhen input is [18 47] the target: 56\nwhen input is [18 47 56] the target: 57\nwhen input is [18 47 56 57] the target: 58\nwhen input is [18 47 56 57 58] the target: 1\nwhen input is [18 47 56 57 58  1] the target: 15\nwhen input is [18 47 56 57 58  1 15] the target: 47\nwhen input is [18 47 56 57 58  1 15 47] the target: 58\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 128 # how many independent sequences will we process in parallel?\nblock_size = 64 # what is the maximum context length for predictions?\nseq_size = block_size//8\n\nmax_iters = 50000\nlearning_rate = 5e-4\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 100\nn_embd = 256\nexpans = 2\nhidden_dim = n_embd*expans*4\nconv_k_size = 3\nn_latent_dim = 16\nn_tokens = 1\n\nrng_key = jax.random.PRNGKey(1564)\n\ndynamic_slice_vmap = jax.vmap(jax.lax.dynamic_slice, in_axes=(None, 0, None))\n\n@jax.jit\ndef get_batch(random_key, data):\n    \"\"\"Prepares a random batch of training data.\n\n    Args:\n      random_key: A random seed for sampling a batch.\n      data: The complete training dataset.\n\n    Returns:\n      x: Input sequences.\n      y: Target sequences (shifted inputs).\n    \"\"\"\n    ix = jax.random.randint(\n      random_key, shape=(batch_size, 1), minval=0, maxval=len(data) - block_size\n    )\n    x = dynamic_slice_vmap(data, ix, (block_size,))\n    y = dynamic_slice_vmap(data, ix + n_tokens, (block_size,))\n    return x, y\n\nxb, yb = get_batch(rng_key, train_data)\ntrain_shape = xb.shape\nprint('inputs:')\nprint(xb.shape)\nprint(xb)\nprint('targets:')\nprint(yb.shape)\nprint(yb)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:07:12.391956Z","iopub.execute_input":"2024-06-28T09:07:12.392315Z","iopub.status.idle":"2024-06-28T09:07:12.624160Z","shell.execute_reply.started":"2024-06-28T09:07:12.392288Z","shell.execute_reply":"2024-06-28T09:07:12.623141Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"inputs:\n(128, 64)\n[[12  0  0 ... 53 42  1]\n [ 1 44 39 ... 56  1 45]\n [56 57  8 ... 10  0 17]\n ...\n [54 53 53 ... 17 17 26]\n [59 58 58 ... 16 21 33]\n [50  1 57 ... 47 58  1]]\ntargets:\n(128, 64)\n[[ 0  0 15 ... 42  1 40]\n [44 39 56 ...  1 45 56]\n [57  8  0 ...  0 17 47]\n ...\n [53 53 56 ... 17 26  1]\n [58 58 43 ... 21 33 31]\n [ 1 57 53 ... 58  1 40]]\n","output_type":"stream"}]},{"cell_type":"code","source":"class Mamba_Unet(nn.Module):\n    \n    @nn.compact\n    def __call__(self, x):\n        embeds = nn.Embed(vocab_size, n_embd)(x) + nn.Embed(\n            block_size, n_embd)(jnp.arange(block_size))\n        \n        conv1 = jax.nn.silu(nn.Conv(features=n_embd*expans, kernel_size=conv_k_size,padding=1)(embeds))\n        \n        max_pool1 = nn.max_pool(conv1 , window_shape=(2,), strides=(2,), padding='valid')\n        max_pool1_ind = (conv1 == jnp.repeat(max_pool1 , repeats=2, axis=1)).astype(jnp.int32)\n        \n        conv2 = jax.nn.silu(nn.Conv(features=n_embd*expans*2, kernel_size=conv_k_size,padding=1)(max_pool1))\n    \n        max_pool2 = nn.max_pool(conv2 , window_shape=(2,), strides=(2,), padding='valid')\n        max_pool2_ind = (conv2 == jnp.repeat(max_pool2 , repeats=2, axis=1)).astype(jnp.int32)   \n        \n        conv3 = jax.nn.silu(nn.Conv(features=n_embd*expans*4, kernel_size=conv_k_size,padding=1)(max_pool2))\n    \n        max_pool3 = nn.max_pool(conv3 , window_shape=(2,), strides=(2,), padding='valid')\n        max_pool3_ind = (conv3 == jnp.repeat(max_pool3 , repeats=2, axis=1)).astype(jnp.int32)\n        \n        A = -1*self.param('A', nn.initializers.ones, (1, n_latent_dim, hidden_dim, 1))\n        B = 0.1*self.param('B', nn.initializers.ones, (1, n_latent_dim, 1, seq_size))\n        C = 0.09*self.param('C', jax.random.normal, (1, n_latent_dim, 1, seq_size))\n        D = 0.1*self.param('D', jax.random.normal, (1, 1,hidden_dim, seq_size))\n        delta = 0.05*self.param('delta', jax.random.normal, (1, 1, hidden_dim, seq_size))\n        \n        x = nn.RMSNorm()(jnp.expand_dims(jnp.transpose(max_pool3,(0,2,1)), axis=1))\n        x = self.ssm(x, A, B, C, D, delta)\n        x = jnp.transpose(x[:,0,:,:],(0,2,1))\n        ###############\n        uconv3 = jnp.repeat(x, repeats=2, axis=1)*jnp.concatenate([max_pool3_ind[:,1:,:],jnp.ones((max_pool3_ind.shape[0],1,max_pool3_ind.shape[-1]))], axis=1)\n        \n        cat_conv3 = jnp.concatenate([conv3, uconv3], axis=-1)\n        conv4 = jax.nn.silu(nn.Conv(features=cat_conv3.shape[-1]//2, kernel_size=conv_k_size,padding=1)(cat_conv3))\n        \n        conv3T = nn.ConvTranspose(conv4.shape[-1]//2, kernel_size = 3, padding = 1)(conv4)\n        ###############\n        uconv2 = jnp.repeat(conv3T, repeats=2, axis=1)*jnp.concatenate([max_pool2_ind[:,1:,:],jnp.ones((max_pool2_ind.shape[0],1,max_pool2_ind.shape[-1]))], axis=1)\n        \n        cat_conv2 = jnp.concatenate([conv2, uconv2], axis=-1)\n        conv5 = jax.nn.silu(nn.Conv(features=cat_conv2.shape[-1]//2, kernel_size=conv_k_size,padding=1)(cat_conv2))\n        \n        conv2T = nn.ConvTranspose(conv5.shape[-1]//2, kernel_size = 3, padding = 1)(conv5)\n        \n        ###############\n        uconv1 = jnp.repeat(conv2T, repeats=2, axis=1)*jnp.concatenate([max_pool1_ind[:,1:,:],jnp.ones((max_pool1_ind.shape[0],1,max_pool1_ind.shape[-1]))], axis=1)\n        \n        cat_conv1 = jnp.concatenate([conv1, uconv1], axis=-1)\n        conv6 = jax.nn.silu(nn.Conv(features=cat_conv1.shape[-1]//2, kernel_size=conv_k_size,padding=1)(cat_conv1))\n        \n        conv1T = nn.ConvTranspose(conv6.shape[-1]//2, kernel_size = 3, padding = 1)(conv6)\n        ##############\n#         pdb.set_trace()\n        output = nn.Dense(vocab_size)(nn.RMSNorm()(conv1T))\n        \n                \n#         first_uconv = jnp.repeat(max_pool1, repeats=2, axis=1)*max_pool1_ind\n        \n        \n        return output\n    \n    def discretize(self, A, B, delta):\n        da = delta * A\n        a_ = jnp.exp(da)\n        b_ = B * delta\n        return a_, b_\n\n    def ssm(self, x, A, B, C, D, delta):\n        a_, b_ = self.discretize(A, B, delta)\n        h = 0\n        for k in range(x.shape[-1]):\n            h = a_[..., k] * h + b_[..., k] * x[..., k]\n#         _, N, D, S = a_.shape\n#         indices = jnp.tril(jnp.ones((S-1,S-1))) \n#         indices = jnp.expand_dims(a_[...,1:],axis=4)*jnp.expand_dims(indices, axis=(0,1,2)) + jnp.expand_dims(jnp.triu(jnp.ones((S-1,S-1)),1), axis=(0,1,2))\n#         indices = (jnp.concatenate((indices, jnp.ones((1,N,D,S-1,1))), axis=-1)).prod(axis=-2)\n#         h = (indices*(b_*x)).sum(axis=-1)\n\n        y = ((C * jax.lax.expand_dims(h,[3])).sum(1, keepdims=True) + D*x)\n        \n#         self.hidden_state.value = jax.nn.standardize(h.mean(0, keepdims=True))\n        return y    \n                ","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:07:12.625230Z","iopub.execute_input":"2024-06-28T09:07:12.625517Z","iopub.status.idle":"2024-06-28T09:07:12.652048Z","shell.execute_reply.started":"2024-06-28T09:07:12.625492Z","shell.execute_reply":"2024-06-28T09:07:12.651102Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def loss_fun(params, x, y, dropout_key):\n    logits = model.apply(params, x)\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), accuracy\n\n@jax.jit\ndef eval_step(params, x, y):\n    logits = model.apply(params, x)\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), accuracy","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:07:12.653108Z","iopub.execute_input":"2024-06-28T09:07:12.653367Z","iopub.status.idle":"2024-06-28T09:07:12.666244Z","shell.execute_reply.started":"2024-06-28T09:07:12.653344Z","shell.execute_reply":"2024-06-28T09:07:12.665454Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"key = jax.random.PRNGKey(42)\n# x = jnp.expand_dims(xb[0],axis=0)\nx = xb\nmodel = Mamba_Unet()\n\nparams = model.init(jax.random.PRNGKey(45),x)\nprint(params.keys())\nn_params = sum(p.size for p in jax.tree_util.tree_leaves(params))\n\nprint(f\"Total number of parameters: {n_params:_}\")\n\noutput = model.apply(params, x)\nprint(output.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:07:12.669421Z","iopub.execute_input":"2024-06-28T09:07:12.669710Z","iopub.status.idle":"2024-06-28T09:07:24.602367Z","shell.execute_reply.started":"2024-06-28T09:07:12.669675Z","shell.execute_reply":"2024-06-28T09:07:24.601456Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"dict_keys(['params'])\nTotal number of parameters: 49_669_961\n(128, 64, 65)\n","output_type":"stream"}]},{"cell_type":"code","source":"opt = optax.adamw(learning_rate=learning_rate)\n\nopt_state = opt.init(params)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:07:24.603555Z","iopub.execute_input":"2024-06-28T09:07:24.603864Z","iopub.status.idle":"2024-06-28T09:07:24.950404Z","shell.execute_reply.started":"2024-06-28T09:07:24.603837Z","shell.execute_reply":"2024-06-28T09:07:24.949572Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"%%time\n\nall_train_losses = []\nall_eval_losses = []\n\nall_train_accuracy =  []\nall_test_accuracy = []\n\n# we define one iteration of the optimizer and JIT this function\n@jax.jit\ndef step(key, params, opt_state):\n    key, subkey = jax.random.split(key)\n    xb, yb = get_batch(key, train_data)\n    (loss, train_accuracy), grad = jax.value_and_grad(loss_fun, has_aux=True)(params, xb, yb, subkey)\n    updates, opt_state = opt.update(grad, opt_state, params)\n    params = optax.apply_updates(params, updates)\n    return params, key, opt_state, loss, train_accuracy\n\n# for i in tqdm(range(max_iters)):\ncounter = 0\nloss = 10\nwhile counter<max_iters: # and loss > 1.0:\n\n    params, key, opt_state, loss, train_accuracy = step(key, params, opt_state)\n    \n\n    # once every N_FREQ_EVAL we compute loss on the validation set\n    if counter % eval_iters == 0:\n        key, subkey = jax.random.split(key)\n        eval_loss, eval_accuracy = eval_step(params, *get_batch(subkey, test_data))\n        all_train_losses.append(loss)\n        all_eval_losses.append(eval_loss)\n        all_train_accuracy.append(train_accuracy)\n        all_test_accuracy.append(eval_accuracy)\n        print('##########################################################')\n        print(\"Step: \", counter,\"\\t Train Loss: \", loss,\"\\t Train Accuracy: \", format(train_accuracy, \".2%\"))\n        print(\"Step: \", counter,\"\\t Eval Loss: \", eval_loss,\"\\t Eval Accuracy: \", format(eval_accuracy, \".2%\"))\n        \n    counter += 1\n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:07:24.951495Z","iopub.execute_input":"2024-06-28T09:07:24.951798Z","iopub.status.idle":"2024-06-28T11:19:47.351034Z","shell.execute_reply.started":"2024-06-28T09:07:24.951774Z","shell.execute_reply":"2024-06-28T11:19:47.350054Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2024-06-28 09:07:31.672403: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[128,2048,32]{2,1,0}, u8[0]{0}) custom-call(f32[128,1024,32]{2,1,0}, f32[1024,2048,3]{2,1,0}), window={size=3 pad=1_1}, dim_labels=bf0_oi0->bf0, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2024-06-28 09:07:32.020330: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.348057411s\nTrying algorithm eng0{} for conv (f32[128,2048,32]{2,1,0}, u8[0]{0}) custom-call(f32[128,1024,32]{2,1,0}, f32[1024,2048,3]{2,1,0}), window={size=3 pad=1_1}, dim_labels=bf0_oi0->bf0, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2024-06-28 09:07:34.566572: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[128,4096,16]{2,1,0}, u8[0]{0}) custom-call(f32[128,2048,16]{2,1,0}, f32[2048,4096,3]{2,1,0}), window={size=3 pad=1_1}, dim_labels=bf0_oi0->bf0, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2024-06-28 09:07:36.260959: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.694502131s\nTrying algorithm eng0{} for conv (f32[128,4096,16]{2,1,0}, u8[0]{0}) custom-call(f32[128,2048,16]{2,1,0}, f32[2048,4096,3]{2,1,0}), window={size=3 pad=1_1}, dim_labels=bf0_oi0->bf0, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n","output_type":"stream"},{"name":"stdout","text":"##########################################################\nStep:  0 \t Train Loss:  4.6463537 \t Train Accuracy:  1.78%\nStep:  0 \t Eval Loss:  2.465721 \t Eval Accuracy:  40.80%\n##########################################################\nStep:  100 \t Train Loss:  0.04393089 \t Train Accuracy:  98.86%\nStep:  100 \t Eval Loss:  0.03904993 \t Eval Accuracy:  99.05%\n##########################################################\nStep:  200 \t Train Loss:  0.037410073 \t Train Accuracy:  99.00%\nStep:  200 \t Eval Loss:  0.038721446 \t Eval Accuracy:  98.94%\n##########################################################\nStep:  300 \t Train Loss:  0.037078798 \t Train Accuracy:  98.97%\nStep:  300 \t Eval Loss:  0.039507095 \t Eval Accuracy:  98.90%\n##########################################################\nStep:  400 \t Train Loss:  0.03759235 \t Train Accuracy:  98.91%\nStep:  400 \t Eval Loss:  0.040213272 \t Eval Accuracy:  98.88%\n##########################################################\nStep:  500 \t Train Loss:  0.02929571 \t Train Accuracy:  99.19%\nStep:  500 \t Eval Loss:  0.039663117 \t Eval Accuracy:  98.93%\n##########################################################\nStep:  600 \t Train Loss:  0.032925457 \t Train Accuracy:  99.05%\nStep:  600 \t Eval Loss:  0.035496406 \t Eval Accuracy:  98.97%\n##########################################################\nStep:  700 \t Train Loss:  0.032330137 \t Train Accuracy:  99.18%\nStep:  700 \t Eval Loss:  0.03598881 \t Eval Accuracy:  98.95%\n##########################################################\nStep:  800 \t Train Loss:  0.03158319 \t Train Accuracy:  99.12%\nStep:  800 \t Eval Loss:  0.03542679 \t Eval Accuracy:  99.02%\n##########################################################\nStep:  900 \t Train Loss:  0.031692438 \t Train Accuracy:  99.06%\nStep:  900 \t Eval Loss:  0.033412553 \t Eval Accuracy:  99.04%\n##########################################################\nStep:  1000 \t Train Loss:  0.030770436 \t Train Accuracy:  99.12%\nStep:  1000 \t Eval Loss:  0.03568877 \t Eval Accuracy:  98.96%\n##########################################################\nStep:  1100 \t Train Loss:  0.028849814 \t Train Accuracy:  99.17%\nStep:  1100 \t Eval Loss:  0.033643045 \t Eval Accuracy:  99.01%\n##########################################################\nStep:  1200 \t Train Loss:  0.03351627 \t Train Accuracy:  99.04%\nStep:  1200 \t Eval Loss:  0.03230492 \t Eval Accuracy:  98.95%\n##########################################################\nStep:  1300 \t Train Loss:  0.0316471 \t Train Accuracy:  99.07%\nStep:  1300 \t Eval Loss:  0.030136466 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  1400 \t Train Loss:  0.03388741 \t Train Accuracy:  99.02%\nStep:  1400 \t Eval Loss:  0.031029291 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  1500 \t Train Loss:  0.02671986 \t Train Accuracy:  99.16%\nStep:  1500 \t Eval Loss:  0.028909745 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  1600 \t Train Loss:  0.031826407 \t Train Accuracy:  99.08%\nStep:  1600 \t Eval Loss:  0.034201756 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  1700 \t Train Loss:  0.03406976 \t Train Accuracy:  99.02%\nStep:  1700 \t Eval Loss:  0.03257915 \t Eval Accuracy:  99.05%\n##########################################################\nStep:  1800 \t Train Loss:  0.030232195 \t Train Accuracy:  99.13%\nStep:  1800 \t Eval Loss:  0.033742733 \t Eval Accuracy:  98.96%\n##########################################################\nStep:  1900 \t Train Loss:  0.03041638 \t Train Accuracy:  99.16%\nStep:  1900 \t Eval Loss:  0.033692684 \t Eval Accuracy:  99.01%\n##########################################################\nStep:  2000 \t Train Loss:  0.03338916 \t Train Accuracy:  99.04%\nStep:  2000 \t Eval Loss:  0.030985657 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  2100 \t Train Loss:  0.027016642 \t Train Accuracy:  99.24%\nStep:  2100 \t Eval Loss:  0.031292893 \t Eval Accuracy:  99.08%\n##########################################################\nStep:  2200 \t Train Loss:  0.03348297 \t Train Accuracy:  99.02%\nStep:  2200 \t Eval Loss:  0.028779946 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  2300 \t Train Loss:  0.027651874 \t Train Accuracy:  99.23%\nStep:  2300 \t Eval Loss:  0.031971022 \t Eval Accuracy:  99.08%\n##########################################################\nStep:  2400 \t Train Loss:  0.027578156 \t Train Accuracy:  99.21%\nStep:  2400 \t Eval Loss:  0.028425397 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  2500 \t Train Loss:  0.025246114 \t Train Accuracy:  99.24%\nStep:  2500 \t Eval Loss:  0.031949133 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  2600 \t Train Loss:  0.028530922 \t Train Accuracy:  99.24%\nStep:  2600 \t Eval Loss:  0.031992726 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  2700 \t Train Loss:  0.025846 \t Train Accuracy:  99.28%\nStep:  2700 \t Eval Loss:  0.03228864 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  2800 \t Train Loss:  0.031670153 \t Train Accuracy:  99.06%\nStep:  2800 \t Eval Loss:  0.02992167 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  2900 \t Train Loss:  0.027058728 \t Train Accuracy:  99.24%\nStep:  2900 \t Eval Loss:  0.028237458 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  3000 \t Train Loss:  0.026995678 \t Train Accuracy:  99.21%\nStep:  3000 \t Eval Loss:  0.033924773 \t Eval Accuracy:  99.08%\n##########################################################\nStep:  3100 \t Train Loss:  0.028461667 \t Train Accuracy:  99.24%\nStep:  3100 \t Eval Loss:  0.031310063 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  3200 \t Train Loss:  0.029869072 \t Train Accuracy:  99.13%\nStep:  3200 \t Eval Loss:  0.02845874 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  3300 \t Train Loss:  0.027539028 \t Train Accuracy:  99.18%\nStep:  3300 \t Eval Loss:  0.02859509 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  3400 \t Train Loss:  0.024452593 \t Train Accuracy:  99.28%\nStep:  3400 \t Eval Loss:  0.021671522 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  3500 \t Train Loss:  0.029529769 \t Train Accuracy:  99.10%\nStep:  3500 \t Eval Loss:  0.032714814 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  3600 \t Train Loss:  0.028752027 \t Train Accuracy:  99.22%\nStep:  3600 \t Eval Loss:  0.026114339 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  3700 \t Train Loss:  0.028849173 \t Train Accuracy:  99.08%\nStep:  3700 \t Eval Loss:  0.028130211 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  3800 \t Train Loss:  0.027329132 \t Train Accuracy:  99.18%\nStep:  3800 \t Eval Loss:  0.030269124 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  3900 \t Train Loss:  0.025337499 \t Train Accuracy:  99.27%\nStep:  3900 \t Eval Loss:  0.029069541 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  4000 \t Train Loss:  0.026295684 \t Train Accuracy:  99.26%\nStep:  4000 \t Eval Loss:  0.02918595 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  4100 \t Train Loss:  0.027769173 \t Train Accuracy:  99.19%\nStep:  4100 \t Eval Loss:  0.033227354 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  4200 \t Train Loss:  0.02827999 \t Train Accuracy:  99.16%\nStep:  4200 \t Eval Loss:  0.03236985 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  4300 \t Train Loss:  0.024536088 \t Train Accuracy:  99.21%\nStep:  4300 \t Eval Loss:  0.027642623 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  4400 \t Train Loss:  0.030802129 \t Train Accuracy:  99.08%\nStep:  4400 \t Eval Loss:  0.030507594 \t Eval Accuracy:  99.06%\n##########################################################\nStep:  4500 \t Train Loss:  0.028148187 \t Train Accuracy:  99.18%\nStep:  4500 \t Eval Loss:  0.028279377 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  4600 \t Train Loss:  0.028904201 \t Train Accuracy:  99.12%\nStep:  4600 \t Eval Loss:  0.026387084 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  4700 \t Train Loss:  0.024582282 \t Train Accuracy:  99.19%\nStep:  4700 \t Eval Loss:  0.029965974 \t Eval Accuracy:  99.08%\n##########################################################\nStep:  4800 \t Train Loss:  0.024627794 \t Train Accuracy:  99.30%\nStep:  4800 \t Eval Loss:  0.027854834 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  4900 \t Train Loss:  0.022940371 \t Train Accuracy:  99.35%\nStep:  4900 \t Eval Loss:  0.028017808 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  5000 \t Train Loss:  0.02481278 \t Train Accuracy:  99.26%\nStep:  5000 \t Eval Loss:  0.030685455 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  5100 \t Train Loss:  0.027429592 \t Train Accuracy:  99.18%\nStep:  5100 \t Eval Loss:  0.030766584 \t Eval Accuracy:  99.06%\n##########################################################\nStep:  5200 \t Train Loss:  0.023322597 \t Train Accuracy:  99.24%\nStep:  5200 \t Eval Loss:  0.027344458 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  5300 \t Train Loss:  0.025430033 \t Train Accuracy:  99.26%\nStep:  5300 \t Eval Loss:  0.029243361 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  5400 \t Train Loss:  0.026927412 \t Train Accuracy:  99.27%\nStep:  5400 \t Eval Loss:  0.028714318 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  5500 \t Train Loss:  0.027341072 \t Train Accuracy:  99.17%\nStep:  5500 \t Eval Loss:  0.028629234 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  5600 \t Train Loss:  0.026132857 \t Train Accuracy:  99.26%\nStep:  5600 \t Eval Loss:  0.029379748 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  5700 \t Train Loss:  0.025665998 \t Train Accuracy:  99.24%\nStep:  5700 \t Eval Loss:  0.027146738 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  5800 \t Train Loss:  0.022599407 \t Train Accuracy:  99.33%\nStep:  5800 \t Eval Loss:  0.026439115 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  5900 \t Train Loss:  0.027141713 \t Train Accuracy:  99.18%\nStep:  5900 \t Eval Loss:  0.02929217 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  6000 \t Train Loss:  0.030010384 \t Train Accuracy:  99.12%\nStep:  6000 \t Eval Loss:  0.02833435 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  6100 \t Train Loss:  0.024461403 \t Train Accuracy:  99.26%\nStep:  6100 \t Eval Loss:  0.029648533 \t Eval Accuracy:  99.08%\n##########################################################\nStep:  6200 \t Train Loss:  0.029923366 \t Train Accuracy:  99.15%\nStep:  6200 \t Eval Loss:  0.02588378 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  6300 \t Train Loss:  0.023024112 \t Train Accuracy:  99.33%\nStep:  6300 \t Eval Loss:  0.028164174 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  6400 \t Train Loss:  0.023322023 \t Train Accuracy:  99.32%\nStep:  6400 \t Eval Loss:  0.02970941 \t Eval Accuracy:  99.12%\n##########################################################\nStep:  6500 \t Train Loss:  0.026707914 \t Train Accuracy:  99.22%\nStep:  6500 \t Eval Loss:  0.029434552 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  6600 \t Train Loss:  0.02760222 \t Train Accuracy:  99.13%\nStep:  6600 \t Eval Loss:  0.028673712 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  6700 \t Train Loss:  0.02178508 \t Train Accuracy:  99.34%\nStep:  6700 \t Eval Loss:  0.029256186 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  6800 \t Train Loss:  0.023953479 \t Train Accuracy:  99.23%\nStep:  6800 \t Eval Loss:  0.026296765 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  6900 \t Train Loss:  0.027904388 \t Train Accuracy:  99.18%\nStep:  6900 \t Eval Loss:  0.026229039 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  7000 \t Train Loss:  0.0272104 \t Train Accuracy:  99.15%\nStep:  7000 \t Eval Loss:  0.029783014 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  7100 \t Train Loss:  0.024640892 \t Train Accuracy:  99.23%\nStep:  7100 \t Eval Loss:  0.02679039 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  7200 \t Train Loss:  0.028361106 \t Train Accuracy:  99.18%\nStep:  7200 \t Eval Loss:  0.029752847 \t Eval Accuracy:  99.08%\n##########################################################\nStep:  7300 \t Train Loss:  0.023656443 \t Train Accuracy:  99.27%\nStep:  7300 \t Eval Loss:  0.027807545 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  7400 \t Train Loss:  0.024829343 \t Train Accuracy:  99.29%\nStep:  7400 \t Eval Loss:  0.024682678 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  7500 \t Train Loss:  0.027282178 \t Train Accuracy:  99.15%\nStep:  7500 \t Eval Loss:  0.027683478 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  7600 \t Train Loss:  0.027019322 \t Train Accuracy:  99.16%\nStep:  7600 \t Eval Loss:  0.025883019 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  7700 \t Train Loss:  0.026239429 \t Train Accuracy:  99.26%\nStep:  7700 \t Eval Loss:  0.022742065 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  7800 \t Train Loss:  0.026353177 \t Train Accuracy:  99.23%\nStep:  7800 \t Eval Loss:  0.028605398 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  7900 \t Train Loss:  0.023340229 \t Train Accuracy:  99.35%\nStep:  7900 \t Eval Loss:  0.025217852 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  8000 \t Train Loss:  0.025655104 \t Train Accuracy:  99.23%\nStep:  8000 \t Eval Loss:  0.02441698 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  8100 \t Train Loss:  0.02432069 \t Train Accuracy:  99.24%\nStep:  8100 \t Eval Loss:  0.027439676 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  8200 \t Train Loss:  0.022714837 \t Train Accuracy:  99.29%\nStep:  8200 \t Eval Loss:  0.027435254 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  8300 \t Train Loss:  0.027114034 \t Train Accuracy:  99.17%\nStep:  8300 \t Eval Loss:  0.027130783 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  8400 \t Train Loss:  0.02312949 \t Train Accuracy:  99.35%\nStep:  8400 \t Eval Loss:  0.026555266 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  8500 \t Train Loss:  0.025224786 \t Train Accuracy:  99.30%\nStep:  8500 \t Eval Loss:  0.024852216 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  8600 \t Train Loss:  0.024286084 \t Train Accuracy:  99.22%\nStep:  8600 \t Eval Loss:  0.029178923 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  8700 \t Train Loss:  0.02387465 \t Train Accuracy:  99.28%\nStep:  8700 \t Eval Loss:  0.028450811 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  8800 \t Train Loss:  0.024519065 \t Train Accuracy:  99.30%\nStep:  8800 \t Eval Loss:  0.024891904 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  8900 \t Train Loss:  0.024061289 \t Train Accuracy:  99.24%\nStep:  8900 \t Eval Loss:  0.029066315 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  9000 \t Train Loss:  0.024495319 \t Train Accuracy:  99.24%\nStep:  9000 \t Eval Loss:  0.027248457 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  9100 \t Train Loss:  0.02699146 \t Train Accuracy:  99.12%\nStep:  9100 \t Eval Loss:  0.021975568 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  9200 \t Train Loss:  0.024750587 \t Train Accuracy:  99.27%\nStep:  9200 \t Eval Loss:  0.025297105 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  9300 \t Train Loss:  0.027255917 \t Train Accuracy:  99.13%\nStep:  9300 \t Eval Loss:  0.026713042 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  9400 \t Train Loss:  0.026621463 \t Train Accuracy:  99.15%\nStep:  9400 \t Eval Loss:  0.029861387 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  9500 \t Train Loss:  0.023648607 \t Train Accuracy:  99.30%\nStep:  9500 \t Eval Loss:  0.024617681 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  9600 \t Train Loss:  0.024636764 \t Train Accuracy:  99.28%\nStep:  9600 \t Eval Loss:  0.0259622 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  9700 \t Train Loss:  0.022161774 \t Train Accuracy:  99.34%\nStep:  9700 \t Eval Loss:  0.025814436 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  9800 \t Train Loss:  0.023898013 \t Train Accuracy:  99.23%\nStep:  9800 \t Eval Loss:  0.026581801 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  9900 \t Train Loss:  0.029102657 \t Train Accuracy:  99.04%\nStep:  9900 \t Eval Loss:  0.024707172 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  10000 \t Train Loss:  0.0269291 \t Train Accuracy:  99.22%\nStep:  10000 \t Eval Loss:  0.025314935 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  10100 \t Train Loss:  0.023332741 \t Train Accuracy:  99.27%\nStep:  10100 \t Eval Loss:  0.02764589 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  10200 \t Train Loss:  0.025213588 \t Train Accuracy:  99.33%\nStep:  10200 \t Eval Loss:  0.022205057 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  10300 \t Train Loss:  0.02619458 \t Train Accuracy:  99.24%\nStep:  10300 \t Eval Loss:  0.026354995 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  10400 \t Train Loss:  0.020252682 \t Train Accuracy:  99.40%\nStep:  10400 \t Eval Loss:  0.025847813 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  10500 \t Train Loss:  0.025594354 \t Train Accuracy:  99.23%\nStep:  10500 \t Eval Loss:  0.02599545 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  10600 \t Train Loss:  0.028121844 \t Train Accuracy:  99.17%\nStep:  10600 \t Eval Loss:  0.025655229 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  10700 \t Train Loss:  0.02334939 \t Train Accuracy:  99.34%\nStep:  10700 \t Eval Loss:  0.026426274 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  10800 \t Train Loss:  0.02139936 \t Train Accuracy:  99.35%\nStep:  10800 \t Eval Loss:  0.023110868 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  10900 \t Train Loss:  0.025389787 \t Train Accuracy:  99.24%\nStep:  10900 \t Eval Loss:  0.022322875 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  11000 \t Train Loss:  0.025730979 \t Train Accuracy:  99.23%\nStep:  11000 \t Eval Loss:  0.026205879 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  11100 \t Train Loss:  0.02525917 \t Train Accuracy:  99.28%\nStep:  11100 \t Eval Loss:  0.027516743 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  11200 \t Train Loss:  0.024784815 \t Train Accuracy:  99.16%\nStep:  11200 \t Eval Loss:  0.02836334 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  11300 \t Train Loss:  0.02085963 \t Train Accuracy:  99.35%\nStep:  11300 \t Eval Loss:  0.021693848 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  11400 \t Train Loss:  0.0195621 \t Train Accuracy:  99.40%\nStep:  11400 \t Eval Loss:  0.024894223 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  11500 \t Train Loss:  0.021127824 \t Train Accuracy:  99.34%\nStep:  11500 \t Eval Loss:  0.02656075 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  11600 \t Train Loss:  0.025103915 \t Train Accuracy:  99.24%\nStep:  11600 \t Eval Loss:  0.023403293 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  11700 \t Train Loss:  0.025540704 \t Train Accuracy:  99.27%\nStep:  11700 \t Eval Loss:  0.026031662 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  11800 \t Train Loss:  0.023198519 \t Train Accuracy:  99.32%\nStep:  11800 \t Eval Loss:  0.028869433 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  11900 \t Train Loss:  0.026981553 \t Train Accuracy:  99.23%\nStep:  11900 \t Eval Loss:  0.02835761 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  12000 \t Train Loss:  0.021629153 \t Train Accuracy:  99.27%\nStep:  12000 \t Eval Loss:  0.02465721 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  12100 \t Train Loss:  0.023022234 \t Train Accuracy:  99.38%\nStep:  12100 \t Eval Loss:  0.025824483 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  12200 \t Train Loss:  0.02308938 \t Train Accuracy:  99.23%\nStep:  12200 \t Eval Loss:  0.02393581 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  12300 \t Train Loss:  0.02371021 \t Train Accuracy:  99.22%\nStep:  12300 \t Eval Loss:  0.028693834 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  12400 \t Train Loss:  0.024548192 \t Train Accuracy:  99.33%\nStep:  12400 \t Eval Loss:  0.027072176 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  12500 \t Train Loss:  0.023634609 \t Train Accuracy:  99.30%\nStep:  12500 \t Eval Loss:  0.026882902 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  12600 \t Train Loss:  0.023287527 \t Train Accuracy:  99.30%\nStep:  12600 \t Eval Loss:  0.02542431 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  12700 \t Train Loss:  0.025868364 \t Train Accuracy:  99.23%\nStep:  12700 \t Eval Loss:  0.02340126 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  12800 \t Train Loss:  0.022689268 \t Train Accuracy:  99.34%\nStep:  12800 \t Eval Loss:  0.021579726 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  12900 \t Train Loss:  0.023879703 \t Train Accuracy:  99.32%\nStep:  12900 \t Eval Loss:  0.026476111 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  13000 \t Train Loss:  0.025665756 \t Train Accuracy:  99.26%\nStep:  13000 \t Eval Loss:  0.022905406 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  13100 \t Train Loss:  0.023133315 \t Train Accuracy:  99.33%\nStep:  13100 \t Eval Loss:  0.024660103 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  13200 \t Train Loss:  0.025951255 \t Train Accuracy:  99.21%\nStep:  13200 \t Eval Loss:  0.02446258 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  13300 \t Train Loss:  0.021914255 \t Train Accuracy:  99.32%\nStep:  13300 \t Eval Loss:  0.021617044 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  13400 \t Train Loss:  0.0223555 \t Train Accuracy:  99.29%\nStep:  13400 \t Eval Loss:  0.023063783 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  13500 \t Train Loss:  0.019362658 \t Train Accuracy:  99.28%\nStep:  13500 \t Eval Loss:  0.022291731 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  13600 \t Train Loss:  0.024080995 \t Train Accuracy:  99.26%\nStep:  13600 \t Eval Loss:  0.026641306 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  13700 \t Train Loss:  0.025209432 \t Train Accuracy:  99.21%\nStep:  13700 \t Eval Loss:  0.023893872 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  13800 \t Train Loss:  0.017987443 \t Train Accuracy:  99.49%\nStep:  13800 \t Eval Loss:  0.022263281 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  13900 \t Train Loss:  0.022915348 \t Train Accuracy:  99.39%\nStep:  13900 \t Eval Loss:  0.024838593 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  14000 \t Train Loss:  0.025474092 \t Train Accuracy:  99.26%\nStep:  14000 \t Eval Loss:  0.02188899 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  14100 \t Train Loss:  0.023605661 \t Train Accuracy:  99.28%\nStep:  14100 \t Eval Loss:  0.022837732 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  14200 \t Train Loss:  0.023282379 \t Train Accuracy:  99.28%\nStep:  14200 \t Eval Loss:  0.025450502 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  14300 \t Train Loss:  0.022146173 \t Train Accuracy:  99.34%\nStep:  14300 \t Eval Loss:  0.024631277 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  14400 \t Train Loss:  0.022885922 \t Train Accuracy:  99.26%\nStep:  14400 \t Eval Loss:  0.025585448 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  14500 \t Train Loss:  0.022049174 \t Train Accuracy:  99.29%\nStep:  14500 \t Eval Loss:  0.025951248 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  14600 \t Train Loss:  0.024517875 \t Train Accuracy:  99.26%\nStep:  14600 \t Eval Loss:  0.023513466 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  14700 \t Train Loss:  0.02369273 \t Train Accuracy:  99.24%\nStep:  14700 \t Eval Loss:  0.021898607 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  14800 \t Train Loss:  0.025296945 \t Train Accuracy:  99.23%\nStep:  14800 \t Eval Loss:  0.02554803 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  14900 \t Train Loss:  0.023796694 \t Train Accuracy:  99.26%\nStep:  14900 \t Eval Loss:  0.026610848 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  15000 \t Train Loss:  0.024399305 \t Train Accuracy:  99.24%\nStep:  15000 \t Eval Loss:  0.028413463 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  15100 \t Train Loss:  0.023236578 \t Train Accuracy:  99.37%\nStep:  15100 \t Eval Loss:  0.02249986 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  15200 \t Train Loss:  0.02327997 \t Train Accuracy:  99.32%\nStep:  15200 \t Eval Loss:  0.024301123 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  15300 \t Train Loss:  0.021767544 \t Train Accuracy:  99.28%\nStep:  15300 \t Eval Loss:  0.020746134 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  15400 \t Train Loss:  0.021564662 \t Train Accuracy:  99.37%\nStep:  15400 \t Eval Loss:  0.024755709 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  15500 \t Train Loss:  0.02400315 \t Train Accuracy:  99.21%\nStep:  15500 \t Eval Loss:  0.019515222 \t Eval Accuracy:  99.46%\n##########################################################\nStep:  15600 \t Train Loss:  0.023235645 \t Train Accuracy:  99.27%\nStep:  15600 \t Eval Loss:  0.026776899 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  15700 \t Train Loss:  0.024961278 \t Train Accuracy:  99.29%\nStep:  15700 \t Eval Loss:  0.024867605 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  15800 \t Train Loss:  0.019352008 \t Train Accuracy:  99.39%\nStep:  15800 \t Eval Loss:  0.024144948 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  15900 \t Train Loss:  0.022955786 \t Train Accuracy:  99.33%\nStep:  15900 \t Eval Loss:  0.024704445 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  16000 \t Train Loss:  0.019765843 \t Train Accuracy:  99.38%\nStep:  16000 \t Eval Loss:  0.021116585 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  16100 \t Train Loss:  0.021125613 \t Train Accuracy:  99.33%\nStep:  16100 \t Eval Loss:  0.025885025 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  16200 \t Train Loss:  0.023481354 \t Train Accuracy:  99.22%\nStep:  16200 \t Eval Loss:  0.024242634 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  16300 \t Train Loss:  0.02207725 \t Train Accuracy:  99.32%\nStep:  16300 \t Eval Loss:  0.024498025 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  16400 \t Train Loss:  0.019793428 \t Train Accuracy:  99.40%\nStep:  16400 \t Eval Loss:  0.026705902 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  16500 \t Train Loss:  0.024184283 \t Train Accuracy:  99.22%\nStep:  16500 \t Eval Loss:  0.020922769 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  16600 \t Train Loss:  0.023107493 \t Train Accuracy:  99.28%\nStep:  16600 \t Eval Loss:  0.024685578 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  16700 \t Train Loss:  0.020431705 \t Train Accuracy:  99.39%\nStep:  16700 \t Eval Loss:  0.02642816 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  16800 \t Train Loss:  0.024371054 \t Train Accuracy:  99.30%\nStep:  16800 \t Eval Loss:  0.02568806 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  16900 \t Train Loss:  0.019414097 \t Train Accuracy:  99.37%\nStep:  16900 \t Eval Loss:  0.02185105 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  17000 \t Train Loss:  0.0266102 \t Train Accuracy:  99.21%\nStep:  17000 \t Eval Loss:  0.02388704 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  17100 \t Train Loss:  0.02418382 \t Train Accuracy:  99.22%\nStep:  17100 \t Eval Loss:  0.023424458 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  17200 \t Train Loss:  0.02047125 \t Train Accuracy:  99.39%\nStep:  17200 \t Eval Loss:  0.022879943 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  17300 \t Train Loss:  0.018929135 \t Train Accuracy:  99.46%\nStep:  17300 \t Eval Loss:  0.023695363 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  17400 \t Train Loss:  0.023801027 \t Train Accuracy:  99.32%\nStep:  17400 \t Eval Loss:  0.027272342 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  17500 \t Train Loss:  0.018497592 \t Train Accuracy:  99.39%\nStep:  17500 \t Eval Loss:  0.02328267 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  17600 \t Train Loss:  0.021072121 \t Train Accuracy:  99.43%\nStep:  17600 \t Eval Loss:  0.026978785 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  17700 \t Train Loss:  0.022246359 \t Train Accuracy:  99.40%\nStep:  17700 \t Eval Loss:  0.022009175 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  17800 \t Train Loss:  0.023993239 \t Train Accuracy:  99.28%\nStep:  17800 \t Eval Loss:  0.027633306 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  17900 \t Train Loss:  0.023760626 \t Train Accuracy:  99.17%\nStep:  17900 \t Eval Loss:  0.022399794 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  18000 \t Train Loss:  0.02155574 \t Train Accuracy:  99.40%\nStep:  18000 \t Eval Loss:  0.025967132 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  18100 \t Train Loss:  0.023424052 \t Train Accuracy:  99.30%\nStep:  18100 \t Eval Loss:  0.02235078 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  18200 \t Train Loss:  0.018763373 \t Train Accuracy:  99.44%\nStep:  18200 \t Eval Loss:  0.023797117 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  18300 \t Train Loss:  0.020994585 \t Train Accuracy:  99.38%\nStep:  18300 \t Eval Loss:  0.02044418 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  18400 \t Train Loss:  0.021883614 \t Train Accuracy:  99.33%\nStep:  18400 \t Eval Loss:  0.026382225 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  18500 \t Train Loss:  0.024010714 \t Train Accuracy:  99.34%\nStep:  18500 \t Eval Loss:  0.025643311 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  18600 \t Train Loss:  0.022727476 \t Train Accuracy:  99.34%\nStep:  18600 \t Eval Loss:  0.029428463 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  18700 \t Train Loss:  0.020488832 \t Train Accuracy:  99.28%\nStep:  18700 \t Eval Loss:  0.022524077 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  18800 \t Train Loss:  0.021305326 \t Train Accuracy:  99.35%\nStep:  18800 \t Eval Loss:  0.025711186 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  18900 \t Train Loss:  0.021142274 \t Train Accuracy:  99.35%\nStep:  18900 \t Eval Loss:  0.022319753 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  19000 \t Train Loss:  0.020427074 \t Train Accuracy:  99.34%\nStep:  19000 \t Eval Loss:  0.026724167 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  19100 \t Train Loss:  0.024400104 \t Train Accuracy:  99.24%\nStep:  19100 \t Eval Loss:  0.023125496 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  19200 \t Train Loss:  0.020630721 \t Train Accuracy:  99.41%\nStep:  19200 \t Eval Loss:  0.022546258 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  19300 \t Train Loss:  0.02379096 \t Train Accuracy:  99.27%\nStep:  19300 \t Eval Loss:  0.0212593 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  19400 \t Train Loss:  0.021602545 \t Train Accuracy:  99.33%\nStep:  19400 \t Eval Loss:  0.023492701 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  19500 \t Train Loss:  0.020812996 \t Train Accuracy:  99.37%\nStep:  19500 \t Eval Loss:  0.024321489 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  19600 \t Train Loss:  0.020022891 \t Train Accuracy:  99.32%\nStep:  19600 \t Eval Loss:  0.021097805 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  19700 \t Train Loss:  0.024621233 \t Train Accuracy:  99.27%\nStep:  19700 \t Eval Loss:  0.023273658 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  19800 \t Train Loss:  0.02342515 \t Train Accuracy:  99.21%\nStep:  19800 \t Eval Loss:  0.023216099 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  19900 \t Train Loss:  0.019458069 \t Train Accuracy:  99.40%\nStep:  19900 \t Eval Loss:  0.024716534 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  20000 \t Train Loss:  0.018050583 \t Train Accuracy:  99.45%\nStep:  20000 \t Eval Loss:  0.020317277 \t Eval Accuracy:  99.43%\n##########################################################\nStep:  20100 \t Train Loss:  0.019676534 \t Train Accuracy:  99.39%\nStep:  20100 \t Eval Loss:  0.026553642 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  20200 \t Train Loss:  0.019616557 \t Train Accuracy:  99.38%\nStep:  20200 \t Eval Loss:  0.02450952 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  20300 \t Train Loss:  0.021109637 \t Train Accuracy:  99.32%\nStep:  20300 \t Eval Loss:  0.021889158 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  20400 \t Train Loss:  0.022587232 \t Train Accuracy:  99.39%\nStep:  20400 \t Eval Loss:  0.023894971 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  20500 \t Train Loss:  0.022547606 \t Train Accuracy:  99.34%\nStep:  20500 \t Eval Loss:  0.025212124 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  20600 \t Train Loss:  0.021062545 \t Train Accuracy:  99.35%\nStep:  20600 \t Eval Loss:  0.024241915 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  20700 \t Train Loss:  0.020238902 \t Train Accuracy:  99.34%\nStep:  20700 \t Eval Loss:  0.021525014 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  20800 \t Train Loss:  0.019128636 \t Train Accuracy:  99.34%\nStep:  20800 \t Eval Loss:  0.026708417 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  20900 \t Train Loss:  0.019809522 \t Train Accuracy:  99.34%\nStep:  20900 \t Eval Loss:  0.02289954 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  21000 \t Train Loss:  0.019605484 \t Train Accuracy:  99.30%\nStep:  21000 \t Eval Loss:  0.021742374 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  21100 \t Train Loss:  0.02135484 \t Train Accuracy:  99.32%\nStep:  21100 \t Eval Loss:  0.02507951 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  21200 \t Train Loss:  0.020408105 \t Train Accuracy:  99.37%\nStep:  21200 \t Eval Loss:  0.025896128 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  21300 \t Train Loss:  0.022964958 \t Train Accuracy:  99.33%\nStep:  21300 \t Eval Loss:  0.023956753 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  21400 \t Train Loss:  0.023861364 \t Train Accuracy:  99.28%\nStep:  21400 \t Eval Loss:  0.027997818 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  21500 \t Train Loss:  0.022284988 \t Train Accuracy:  99.29%\nStep:  21500 \t Eval Loss:  0.02374446 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  21600 \t Train Loss:  0.02069129 \t Train Accuracy:  99.40%\nStep:  21600 \t Eval Loss:  0.020869747 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  21700 \t Train Loss:  0.017869743 \t Train Accuracy:  99.45%\nStep:  21700 \t Eval Loss:  0.021891672 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  21800 \t Train Loss:  0.020964095 \t Train Accuracy:  99.38%\nStep:  21800 \t Eval Loss:  0.021076433 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  21900 \t Train Loss:  0.02171433 \t Train Accuracy:  99.39%\nStep:  21900 \t Eval Loss:  0.024252698 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  22000 \t Train Loss:  0.025272124 \t Train Accuracy:  99.24%\nStep:  22000 \t Eval Loss:  0.029339047 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  22100 \t Train Loss:  0.020317066 \t Train Accuracy:  99.32%\nStep:  22100 \t Eval Loss:  0.02191864 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  22200 \t Train Loss:  0.019709015 \t Train Accuracy:  99.44%\nStep:  22200 \t Eval Loss:  0.021963982 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  22300 \t Train Loss:  0.018728074 \t Train Accuracy:  99.49%\nStep:  22300 \t Eval Loss:  0.019405153 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  22400 \t Train Loss:  0.021737806 \t Train Accuracy:  99.34%\nStep:  22400 \t Eval Loss:  0.025333114 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  22500 \t Train Loss:  0.02123956 \t Train Accuracy:  99.34%\nStep:  22500 \t Eval Loss:  0.020548984 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  22600 \t Train Loss:  0.018714294 \t Train Accuracy:  99.41%\nStep:  22600 \t Eval Loss:  0.02143102 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  22700 \t Train Loss:  0.020305175 \t Train Accuracy:  99.35%\nStep:  22700 \t Eval Loss:  0.025099857 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  22800 \t Train Loss:  0.020200187 \t Train Accuracy:  99.32%\nStep:  22800 \t Eval Loss:  0.022837063 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  22900 \t Train Loss:  0.020703116 \t Train Accuracy:  99.38%\nStep:  22900 \t Eval Loss:  0.021581626 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  23000 \t Train Loss:  0.021925077 \t Train Accuracy:  99.33%\nStep:  23000 \t Eval Loss:  0.026050996 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  23100 \t Train Loss:  0.021147635 \t Train Accuracy:  99.28%\nStep:  23100 \t Eval Loss:  0.025318248 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  23200 \t Train Loss:  0.023005646 \t Train Accuracy:  99.33%\nStep:  23200 \t Eval Loss:  0.022944402 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  23300 \t Train Loss:  0.020526947 \t Train Accuracy:  99.38%\nStep:  23300 \t Eval Loss:  0.022401316 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  23400 \t Train Loss:  0.019114986 \t Train Accuracy:  99.38%\nStep:  23400 \t Eval Loss:  0.02618542 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  23500 \t Train Loss:  0.020383922 \t Train Accuracy:  99.38%\nStep:  23500 \t Eval Loss:  0.026693705 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  23600 \t Train Loss:  0.02272827 \t Train Accuracy:  99.29%\nStep:  23600 \t Eval Loss:  0.023861758 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  23700 \t Train Loss:  0.020750917 \t Train Accuracy:  99.43%\nStep:  23700 \t Eval Loss:  0.019874167 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  23800 \t Train Loss:  0.021336425 \t Train Accuracy:  99.35%\nStep:  23800 \t Eval Loss:  0.023008104 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  23900 \t Train Loss:  0.020689398 \t Train Accuracy:  99.37%\nStep:  23900 \t Eval Loss:  0.022507168 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  24000 \t Train Loss:  0.02080605 \t Train Accuracy:  99.33%\nStep:  24000 \t Eval Loss:  0.021167254 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  24100 \t Train Loss:  0.024322877 \t Train Accuracy:  99.26%\nStep:  24100 \t Eval Loss:  0.022973198 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  24200 \t Train Loss:  0.019474246 \t Train Accuracy:  99.38%\nStep:  24200 \t Eval Loss:  0.022985484 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  24300 \t Train Loss:  0.01872518 \t Train Accuracy:  99.40%\nStep:  24300 \t Eval Loss:  0.02521518 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  24400 \t Train Loss:  0.019002717 \t Train Accuracy:  99.40%\nStep:  24400 \t Eval Loss:  0.027059015 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  24500 \t Train Loss:  0.022765879 \t Train Accuracy:  99.29%\nStep:  24500 \t Eval Loss:  0.022588933 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  24600 \t Train Loss:  0.019050954 \t Train Accuracy:  99.40%\nStep:  24600 \t Eval Loss:  0.019738846 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  24700 \t Train Loss:  0.020618066 \t Train Accuracy:  99.35%\nStep:  24700 \t Eval Loss:  0.022579527 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  24800 \t Train Loss:  0.021073487 \t Train Accuracy:  99.39%\nStep:  24800 \t Eval Loss:  0.024158005 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  24900 \t Train Loss:  0.018059554 \t Train Accuracy:  99.44%\nStep:  24900 \t Eval Loss:  0.025491517 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  25000 \t Train Loss:  0.022809748 \t Train Accuracy:  99.26%\nStep:  25000 \t Eval Loss:  0.021908928 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  25100 \t Train Loss:  0.021289298 \t Train Accuracy:  99.39%\nStep:  25100 \t Eval Loss:  0.022591718 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  25200 \t Train Loss:  0.020561272 \t Train Accuracy:  99.45%\nStep:  25200 \t Eval Loss:  0.022402233 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  25300 \t Train Loss:  0.01891446 \t Train Accuracy:  99.43%\nStep:  25300 \t Eval Loss:  0.027799888 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  25400 \t Train Loss:  0.019136406 \t Train Accuracy:  99.43%\nStep:  25400 \t Eval Loss:  0.021227121 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  25500 \t Train Loss:  0.01626069 \t Train Accuracy:  99.52%\nStep:  25500 \t Eval Loss:  0.022746716 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  25600 \t Train Loss:  0.01989457 \t Train Accuracy:  99.32%\nStep:  25600 \t Eval Loss:  0.018005326 \t Eval Accuracy:  99.44%\n##########################################################\nStep:  25700 \t Train Loss:  0.018480953 \t Train Accuracy:  99.44%\nStep:  25700 \t Eval Loss:  0.026354978 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  25800 \t Train Loss:  0.017766308 \t Train Accuracy:  99.46%\nStep:  25800 \t Eval Loss:  0.026299141 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  25900 \t Train Loss:  0.01979192 \t Train Accuracy:  99.37%\nStep:  25900 \t Eval Loss:  0.026874328 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  26000 \t Train Loss:  0.022420026 \t Train Accuracy:  99.37%\nStep:  26000 \t Eval Loss:  0.024617216 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  26100 \t Train Loss:  0.020166185 \t Train Accuracy:  99.43%\nStep:  26100 \t Eval Loss:  0.021952057 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  26200 \t Train Loss:  0.019048322 \t Train Accuracy:  99.37%\nStep:  26200 \t Eval Loss:  0.025175778 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  26300 \t Train Loss:  0.018296901 \t Train Accuracy:  99.41%\nStep:  26300 \t Eval Loss:  0.021139551 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  26400 \t Train Loss:  0.01885033 \t Train Accuracy:  99.40%\nStep:  26400 \t Eval Loss:  0.021130772 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  26500 \t Train Loss:  0.02018456 \t Train Accuracy:  99.33%\nStep:  26500 \t Eval Loss:  0.022089016 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  26600 \t Train Loss:  0.02016149 \t Train Accuracy:  99.37%\nStep:  26600 \t Eval Loss:  0.02149998 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  26700 \t Train Loss:  0.019966582 \t Train Accuracy:  99.40%\nStep:  26700 \t Eval Loss:  0.020581132 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  26800 \t Train Loss:  0.022124743 \t Train Accuracy:  99.32%\nStep:  26800 \t Eval Loss:  0.020950427 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  26900 \t Train Loss:  0.0164604 \t Train Accuracy:  99.46%\nStep:  26900 \t Eval Loss:  0.024034757 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  27000 \t Train Loss:  0.01759845 \t Train Accuracy:  99.51%\nStep:  27000 \t Eval Loss:  0.022687811 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  27100 \t Train Loss:  0.018998161 \t Train Accuracy:  99.43%\nStep:  27100 \t Eval Loss:  0.020839028 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  27200 \t Train Loss:  0.019181855 \t Train Accuracy:  99.33%\nStep:  27200 \t Eval Loss:  0.020952683 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  27300 \t Train Loss:  0.017799616 \t Train Accuracy:  99.49%\nStep:  27300 \t Eval Loss:  0.030932808 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  27400 \t Train Loss:  0.021570254 \t Train Accuracy:  99.34%\nStep:  27400 \t Eval Loss:  0.020655815 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  27500 \t Train Loss:  0.016928816 \t Train Accuracy:  99.49%\nStep:  27500 \t Eval Loss:  0.024397694 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  27600 \t Train Loss:  0.01474924 \t Train Accuracy:  99.54%\nStep:  27600 \t Eval Loss:  0.023172643 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  27700 \t Train Loss:  0.01985896 \t Train Accuracy:  99.43%\nStep:  27700 \t Eval Loss:  0.024620887 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  27800 \t Train Loss:  0.019396702 \t Train Accuracy:  99.45%\nStep:  27800 \t Eval Loss:  0.023753658 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  27900 \t Train Loss:  0.022377562 \t Train Accuracy:  99.34%\nStep:  27900 \t Eval Loss:  0.019111842 \t Eval Accuracy:  99.44%\n##########################################################\nStep:  28000 \t Train Loss:  0.018731019 \t Train Accuracy:  99.44%\nStep:  28000 \t Eval Loss:  0.01951945 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  28100 \t Train Loss:  0.020588811 \t Train Accuracy:  99.37%\nStep:  28100 \t Eval Loss:  0.023724273 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  28200 \t Train Loss:  0.017847814 \t Train Accuracy:  99.46%\nStep:  28200 \t Eval Loss:  0.021965127 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  28300 \t Train Loss:  0.017932631 \t Train Accuracy:  99.44%\nStep:  28300 \t Eval Loss:  0.029761553 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  28400 \t Train Loss:  0.017863434 \t Train Accuracy:  99.43%\nStep:  28400 \t Eval Loss:  0.02175093 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  28500 \t Train Loss:  0.019766038 \t Train Accuracy:  99.33%\nStep:  28500 \t Eval Loss:  0.024602475 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  28600 \t Train Loss:  0.018700846 \t Train Accuracy:  99.44%\nStep:  28600 \t Eval Loss:  0.022735221 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  28700 \t Train Loss:  0.020823665 \t Train Accuracy:  99.38%\nStep:  28700 \t Eval Loss:  0.027110731 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  28800 \t Train Loss:  0.020726966 \t Train Accuracy:  99.28%\nStep:  28800 \t Eval Loss:  0.02252102 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  28900 \t Train Loss:  0.020474758 \t Train Accuracy:  99.39%\nStep:  28900 \t Eval Loss:  0.025524434 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  29000 \t Train Loss:  0.01841161 \t Train Accuracy:  99.41%\nStep:  29000 \t Eval Loss:  0.022643652 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  29100 \t Train Loss:  0.01687628 \t Train Accuracy:  99.49%\nStep:  29100 \t Eval Loss:  0.022780307 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  29200 \t Train Loss:  0.019282505 \t Train Accuracy:  99.35%\nStep:  29200 \t Eval Loss:  0.024039103 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  29300 \t Train Loss:  0.01731563 \t Train Accuracy:  99.43%\nStep:  29300 \t Eval Loss:  0.024092758 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  29400 \t Train Loss:  0.021319207 \t Train Accuracy:  99.32%\nStep:  29400 \t Eval Loss:  0.018980691 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  29500 \t Train Loss:  0.020627294 \t Train Accuracy:  99.38%\nStep:  29500 \t Eval Loss:  0.029336296 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  29600 \t Train Loss:  0.017221864 \t Train Accuracy:  99.49%\nStep:  29600 \t Eval Loss:  0.025615193 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  29700 \t Train Loss:  0.020916443 \t Train Accuracy:  99.38%\nStep:  29700 \t Eval Loss:  0.021690574 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  29800 \t Train Loss:  0.019156922 \t Train Accuracy:  99.41%\nStep:  29800 \t Eval Loss:  0.02229765 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  29900 \t Train Loss:  0.015123891 \t Train Accuracy:  99.46%\nStep:  29900 \t Eval Loss:  0.022295512 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  30000 \t Train Loss:  0.0175226 \t Train Accuracy:  99.49%\nStep:  30000 \t Eval Loss:  0.025150228 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  30100 \t Train Loss:  0.018172523 \t Train Accuracy:  99.44%\nStep:  30100 \t Eval Loss:  0.022684623 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  30200 \t Train Loss:  0.018694092 \t Train Accuracy:  99.48%\nStep:  30200 \t Eval Loss:  0.023656484 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  30300 \t Train Loss:  0.01757792 \t Train Accuracy:  99.49%\nStep:  30300 \t Eval Loss:  0.023370944 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  30400 \t Train Loss:  0.014411366 \t Train Accuracy:  99.55%\nStep:  30400 \t Eval Loss:  0.019726843 \t Eval Accuracy:  99.43%\n##########################################################\nStep:  30500 \t Train Loss:  0.018789466 \t Train Accuracy:  99.40%\nStep:  30500 \t Eval Loss:  0.022681177 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  30600 \t Train Loss:  0.015711345 \t Train Accuracy:  99.49%\nStep:  30600 \t Eval Loss:  0.024099786 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  30700 \t Train Loss:  0.019024009 \t Train Accuracy:  99.48%\nStep:  30700 \t Eval Loss:  0.022769695 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  30800 \t Train Loss:  0.017510511 \t Train Accuracy:  99.54%\nStep:  30800 \t Eval Loss:  0.02193524 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  30900 \t Train Loss:  0.019468172 \t Train Accuracy:  99.46%\nStep:  30900 \t Eval Loss:  0.022906387 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  31000 \t Train Loss:  0.01645932 \t Train Accuracy:  99.49%\nStep:  31000 \t Eval Loss:  0.02076626 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  31100 \t Train Loss:  0.017713407 \t Train Accuracy:  99.51%\nStep:  31100 \t Eval Loss:  0.018752314 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  31200 \t Train Loss:  0.016824678 \t Train Accuracy:  99.46%\nStep:  31200 \t Eval Loss:  0.02168316 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  31300 \t Train Loss:  0.016816467 \t Train Accuracy:  99.48%\nStep:  31300 \t Eval Loss:  0.023975167 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  31400 \t Train Loss:  0.019851044 \t Train Accuracy:  99.44%\nStep:  31400 \t Eval Loss:  0.026272321 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  31500 \t Train Loss:  0.01556376 \t Train Accuracy:  99.52%\nStep:  31500 \t Eval Loss:  0.023933519 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  31600 \t Train Loss:  0.020830043 \t Train Accuracy:  99.44%\nStep:  31600 \t Eval Loss:  0.022809247 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  31700 \t Train Loss:  0.018459309 \t Train Accuracy:  99.46%\nStep:  31700 \t Eval Loss:  0.021166634 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  31800 \t Train Loss:  0.016364342 \t Train Accuracy:  99.54%\nStep:  31800 \t Eval Loss:  0.02670126 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  31900 \t Train Loss:  0.018801633 \t Train Accuracy:  99.35%\nStep:  31900 \t Eval Loss:  0.023226963 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  32000 \t Train Loss:  0.01770395 \t Train Accuracy:  99.50%\nStep:  32000 \t Eval Loss:  0.026081163 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  32100 \t Train Loss:  0.022639038 \t Train Accuracy:  99.35%\nStep:  32100 \t Eval Loss:  0.023814607 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  32200 \t Train Loss:  0.018064722 \t Train Accuracy:  99.43%\nStep:  32200 \t Eval Loss:  0.02224048 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  32300 \t Train Loss:  0.01612185 \t Train Accuracy:  99.55%\nStep:  32300 \t Eval Loss:  0.025937626 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  32400 \t Train Loss:  0.016809385 \t Train Accuracy:  99.43%\nStep:  32400 \t Eval Loss:  0.022485994 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  32500 \t Train Loss:  0.020361993 \t Train Accuracy:  99.37%\nStep:  32500 \t Eval Loss:  0.028924543 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  32600 \t Train Loss:  0.019178253 \t Train Accuracy:  99.33%\nStep:  32600 \t Eval Loss:  0.025763044 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  32700 \t Train Loss:  0.018523013 \t Train Accuracy:  99.38%\nStep:  32700 \t Eval Loss:  0.026096214 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  32800 \t Train Loss:  0.01662817 \t Train Accuracy:  99.48%\nStep:  32800 \t Eval Loss:  0.02297929 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  32900 \t Train Loss:  0.019850152 \t Train Accuracy:  99.38%\nStep:  32900 \t Eval Loss:  0.020646509 \t Eval Accuracy:  99.43%\n##########################################################\nStep:  33000 \t Train Loss:  0.018855248 \t Train Accuracy:  99.45%\nStep:  33000 \t Eval Loss:  0.019882789 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  33100 \t Train Loss:  0.020852448 \t Train Accuracy:  99.30%\nStep:  33100 \t Eval Loss:  0.021252628 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  33200 \t Train Loss:  0.018925272 \t Train Accuracy:  99.45%\nStep:  33200 \t Eval Loss:  0.023105811 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  33300 \t Train Loss:  0.0191627 \t Train Accuracy:  99.44%\nStep:  33300 \t Eval Loss:  0.023301706 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  33400 \t Train Loss:  0.02049977 \t Train Accuracy:  99.34%\nStep:  33400 \t Eval Loss:  0.020003565 \t Eval Accuracy:  99.43%\n##########################################################\nStep:  33500 \t Train Loss:  0.017904863 \t Train Accuracy:  99.48%\nStep:  33500 \t Eval Loss:  0.025607493 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  33600 \t Train Loss:  0.020314272 \t Train Accuracy:  99.35%\nStep:  33600 \t Eval Loss:  0.022734854 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  33700 \t Train Loss:  0.015767466 \t Train Accuracy:  99.54%\nStep:  33700 \t Eval Loss:  0.02174275 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  33800 \t Train Loss:  0.01810917 \t Train Accuracy:  99.41%\nStep:  33800 \t Eval Loss:  0.020230785 \t Eval Accuracy:  99.44%\n##########################################################\nStep:  33900 \t Train Loss:  0.019534953 \t Train Accuracy:  99.40%\nStep:  33900 \t Eval Loss:  0.021274295 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  34000 \t Train Loss:  0.015340356 \t Train Accuracy:  99.45%\nStep:  34000 \t Eval Loss:  0.020862227 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  34100 \t Train Loss:  0.022474648 \t Train Accuracy:  99.40%\nStep:  34100 \t Eval Loss:  0.021821398 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  34200 \t Train Loss:  0.021298476 \t Train Accuracy:  99.38%\nStep:  34200 \t Eval Loss:  0.024744382 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  34300 \t Train Loss:  0.017187895 \t Train Accuracy:  99.54%\nStep:  34300 \t Eval Loss:  0.023065329 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  34400 \t Train Loss:  0.015768453 \t Train Accuracy:  99.51%\nStep:  34400 \t Eval Loss:  0.022758693 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  34500 \t Train Loss:  0.020684207 \t Train Accuracy:  99.39%\nStep:  34500 \t Eval Loss:  0.022452027 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  34600 \t Train Loss:  0.01841128 \t Train Accuracy:  99.45%\nStep:  34600 \t Eval Loss:  0.024395572 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  34700 \t Train Loss:  0.019002195 \t Train Accuracy:  99.48%\nStep:  34700 \t Eval Loss:  0.02068884 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  34800 \t Train Loss:  0.020737238 \t Train Accuracy:  99.35%\nStep:  34800 \t Eval Loss:  0.028809747 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  34900 \t Train Loss:  0.015849099 \t Train Accuracy:  99.51%\nStep:  34900 \t Eval Loss:  0.018197183 \t Eval Accuracy:  99.48%\n##########################################################\nStep:  35000 \t Train Loss:  0.019286973 \t Train Accuracy:  99.38%\nStep:  35000 \t Eval Loss:  0.027829235 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  35100 \t Train Loss:  0.022640135 \t Train Accuracy:  99.21%\nStep:  35100 \t Eval Loss:  0.02059482 \t Eval Accuracy:  99.45%\n##########################################################\nStep:  35200 \t Train Loss:  0.016961727 \t Train Accuracy:  99.49%\nStep:  35200 \t Eval Loss:  0.024148427 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  35300 \t Train Loss:  0.016963325 \t Train Accuracy:  99.49%\nStep:  35300 \t Eval Loss:  0.027763484 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  35400 \t Train Loss:  0.021507736 \t Train Accuracy:  99.41%\nStep:  35400 \t Eval Loss:  0.01954158 \t Eval Accuracy:  99.46%\n##########################################################\nStep:  35500 \t Train Loss:  0.021360513 \t Train Accuracy:  99.37%\nStep:  35500 \t Eval Loss:  0.025202056 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  35600 \t Train Loss:  0.017985553 \t Train Accuracy:  99.46%\nStep:  35600 \t Eval Loss:  0.025877897 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  35700 \t Train Loss:  0.01623752 \t Train Accuracy:  99.51%\nStep:  35700 \t Eval Loss:  0.022813356 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  35800 \t Train Loss:  0.018031009 \t Train Accuracy:  99.43%\nStep:  35800 \t Eval Loss:  0.022694997 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  35900 \t Train Loss:  0.02086694 \t Train Accuracy:  99.40%\nStep:  35900 \t Eval Loss:  0.02627026 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  36000 \t Train Loss:  0.017480368 \t Train Accuracy:  99.43%\nStep:  36000 \t Eval Loss:  0.027037317 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  36100 \t Train Loss:  0.017439932 \t Train Accuracy:  99.44%\nStep:  36100 \t Eval Loss:  0.022609567 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  36200 \t Train Loss:  0.016292274 \t Train Accuracy:  99.48%\nStep:  36200 \t Eval Loss:  0.022636592 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  36300 \t Train Loss:  0.017598715 \t Train Accuracy:  99.45%\nStep:  36300 \t Eval Loss:  0.022648025 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  36400 \t Train Loss:  0.016537376 \t Train Accuracy:  99.46%\nStep:  36400 \t Eval Loss:  0.025777042 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  36500 \t Train Loss:  0.014379563 \t Train Accuracy:  99.54%\nStep:  36500 \t Eval Loss:  0.020973774 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  36600 \t Train Loss:  0.013826141 \t Train Accuracy:  99.58%\nStep:  36600 \t Eval Loss:  0.02422892 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  36700 \t Train Loss:  0.016534701 \t Train Accuracy:  99.58%\nStep:  36700 \t Eval Loss:  0.022409156 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  36800 \t Train Loss:  0.016558018 \t Train Accuracy:  99.50%\nStep:  36800 \t Eval Loss:  0.025615761 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  36900 \t Train Loss:  0.0148309525 \t Train Accuracy:  99.52%\nStep:  36900 \t Eval Loss:  0.023640154 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  37000 \t Train Loss:  0.018950926 \t Train Accuracy:  99.40%\nStep:  37000 \t Eval Loss:  0.02088769 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  37100 \t Train Loss:  0.01881798 \t Train Accuracy:  99.45%\nStep:  37100 \t Eval Loss:  0.021504786 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  37200 \t Train Loss:  0.017740926 \t Train Accuracy:  99.48%\nStep:  37200 \t Eval Loss:  0.028274637 \t Eval Accuracy:  99.12%\n##########################################################\nStep:  37300 \t Train Loss:  0.016645152 \t Train Accuracy:  99.46%\nStep:  37300 \t Eval Loss:  0.024920996 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  37400 \t Train Loss:  0.016183237 \t Train Accuracy:  99.46%\nStep:  37400 \t Eval Loss:  0.024629835 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  37500 \t Train Loss:  0.018400494 \t Train Accuracy:  99.41%\nStep:  37500 \t Eval Loss:  0.022744361 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  37600 \t Train Loss:  0.015627705 \t Train Accuracy:  99.55%\nStep:  37600 \t Eval Loss:  0.023676641 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  37700 \t Train Loss:  0.017951949 \t Train Accuracy:  99.50%\nStep:  37700 \t Eval Loss:  0.022666425 \t Eval Accuracy:  99.44%\n##########################################################\nStep:  37800 \t Train Loss:  0.017923506 \t Train Accuracy:  99.49%\nStep:  37800 \t Eval Loss:  0.020286238 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  37900 \t Train Loss:  0.015092963 \t Train Accuracy:  99.56%\nStep:  37900 \t Eval Loss:  0.025379872 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  38000 \t Train Loss:  0.018081557 \t Train Accuracy:  99.38%\nStep:  38000 \t Eval Loss:  0.020964257 \t Eval Accuracy:  99.43%\n##########################################################\nStep:  38100 \t Train Loss:  0.014189605 \t Train Accuracy:  99.51%\nStep:  38100 \t Eval Loss:  0.024184238 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  38200 \t Train Loss:  0.016938973 \t Train Accuracy:  99.44%\nStep:  38200 \t Eval Loss:  0.025488913 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  38300 \t Train Loss:  0.019429652 \t Train Accuracy:  99.45%\nStep:  38300 \t Eval Loss:  0.021338444 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  38400 \t Train Loss:  0.018157937 \t Train Accuracy:  99.46%\nStep:  38400 \t Eval Loss:  0.022078205 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  38500 \t Train Loss:  0.014799891 \t Train Accuracy:  99.55%\nStep:  38500 \t Eval Loss:  0.021329125 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  38600 \t Train Loss:  0.01646818 \t Train Accuracy:  99.55%\nStep:  38600 \t Eval Loss:  0.025201755 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  38700 \t Train Loss:  0.015161401 \t Train Accuracy:  99.54%\nStep:  38700 \t Eval Loss:  0.0274143 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  38800 \t Train Loss:  0.016132373 \t Train Accuracy:  99.49%\nStep:  38800 \t Eval Loss:  0.024877053 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  38900 \t Train Loss:  0.015463292 \t Train Accuracy:  99.54%\nStep:  38900 \t Eval Loss:  0.022808852 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  39000 \t Train Loss:  0.020020891 \t Train Accuracy:  99.40%\nStep:  39000 \t Eval Loss:  0.022974022 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  39100 \t Train Loss:  0.0222669 \t Train Accuracy:  99.29%\nStep:  39100 \t Eval Loss:  0.03230892 \t Eval Accuracy:  99.08%\n##########################################################\nStep:  39200 \t Train Loss:  0.01845593 \t Train Accuracy:  99.49%\nStep:  39200 \t Eval Loss:  0.027560275 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  39300 \t Train Loss:  0.014450138 \t Train Accuracy:  99.61%\nStep:  39300 \t Eval Loss:  0.025116947 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  39400 \t Train Loss:  0.015288124 \t Train Accuracy:  99.57%\nStep:  39400 \t Eval Loss:  0.031901814 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  39500 \t Train Loss:  0.017190518 \t Train Accuracy:  99.49%\nStep:  39500 \t Eval Loss:  0.022240276 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  39600 \t Train Loss:  0.016064493 \t Train Accuracy:  99.52%\nStep:  39600 \t Eval Loss:  0.019851837 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  39700 \t Train Loss:  0.01627922 \t Train Accuracy:  99.43%\nStep:  39700 \t Eval Loss:  0.024222573 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  39800 \t Train Loss:  0.013531342 \t Train Accuracy:  99.62%\nStep:  39800 \t Eval Loss:  0.022440547 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  39900 \t Train Loss:  0.018109633 \t Train Accuracy:  99.45%\nStep:  39900 \t Eval Loss:  0.025897834 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  40000 \t Train Loss:  0.0152251385 \t Train Accuracy:  99.57%\nStep:  40000 \t Eval Loss:  0.020972352 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  40100 \t Train Loss:  0.014261033 \t Train Accuracy:  99.55%\nStep:  40100 \t Eval Loss:  0.01881301 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  40200 \t Train Loss:  0.015417534 \t Train Accuracy:  99.54%\nStep:  40200 \t Eval Loss:  0.025802612 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  40300 \t Train Loss:  0.015352049 \t Train Accuracy:  99.51%\nStep:  40300 \t Eval Loss:  0.025693975 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  40400 \t Train Loss:  0.018086644 \t Train Accuracy:  99.45%\nStep:  40400 \t Eval Loss:  0.023161175 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  40500 \t Train Loss:  0.015933633 \t Train Accuracy:  99.51%\nStep:  40500 \t Eval Loss:  0.023192171 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  40600 \t Train Loss:  0.019600635 \t Train Accuracy:  99.41%\nStep:  40600 \t Eval Loss:  0.022422422 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  40700 \t Train Loss:  0.0135788135 \t Train Accuracy:  99.55%\nStep:  40700 \t Eval Loss:  0.027437523 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  40800 \t Train Loss:  0.016355552 \t Train Accuracy:  99.55%\nStep:  40800 \t Eval Loss:  0.025729999 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  40900 \t Train Loss:  0.016667986 \t Train Accuracy:  99.52%\nStep:  40900 \t Eval Loss:  0.023783175 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  41000 \t Train Loss:  0.013376258 \t Train Accuracy:  99.57%\nStep:  41000 \t Eval Loss:  0.023156248 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  41100 \t Train Loss:  0.01740276 \t Train Accuracy:  99.51%\nStep:  41100 \t Eval Loss:  0.024457078 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  41200 \t Train Loss:  0.015939604 \t Train Accuracy:  99.52%\nStep:  41200 \t Eval Loss:  0.027064145 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  41300 \t Train Loss:  0.017632712 \t Train Accuracy:  99.43%\nStep:  41300 \t Eval Loss:  0.027751772 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  41400 \t Train Loss:  0.01851368 \t Train Accuracy:  99.43%\nStep:  41400 \t Eval Loss:  0.024372773 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  41500 \t Train Loss:  0.018859752 \t Train Accuracy:  99.46%\nStep:  41500 \t Eval Loss:  0.02572967 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  41600 \t Train Loss:  0.016375873 \t Train Accuracy:  99.51%\nStep:  41600 \t Eval Loss:  0.027163664 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  41700 \t Train Loss:  0.011649721 \t Train Accuracy:  99.63%\nStep:  41700 \t Eval Loss:  0.025420789 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  41800 \t Train Loss:  0.01679526 \t Train Accuracy:  99.49%\nStep:  41800 \t Eval Loss:  0.02619901 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  41900 \t Train Loss:  0.016382394 \t Train Accuracy:  99.45%\nStep:  41900 \t Eval Loss:  0.027030881 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  42000 \t Train Loss:  0.016268365 \t Train Accuracy:  99.50%\nStep:  42000 \t Eval Loss:  0.025900539 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  42100 \t Train Loss:  0.014835823 \t Train Accuracy:  99.52%\nStep:  42100 \t Eval Loss:  0.022649199 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  42200 \t Train Loss:  0.017389527 \t Train Accuracy:  99.51%\nStep:  42200 \t Eval Loss:  0.022972006 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  42300 \t Train Loss:  0.013484245 \t Train Accuracy:  99.61%\nStep:  42300 \t Eval Loss:  0.023290856 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  42400 \t Train Loss:  0.016158674 \t Train Accuracy:  99.51%\nStep:  42400 \t Eval Loss:  0.02225567 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  42500 \t Train Loss:  0.013880758 \t Train Accuracy:  99.55%\nStep:  42500 \t Eval Loss:  0.02666313 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  42600 \t Train Loss:  0.012188276 \t Train Accuracy:  99.69%\nStep:  42600 \t Eval Loss:  0.024101002 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  42700 \t Train Loss:  0.016997496 \t Train Accuracy:  99.46%\nStep:  42700 \t Eval Loss:  0.025484936 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  42800 \t Train Loss:  0.01759072 \t Train Accuracy:  99.40%\nStep:  42800 \t Eval Loss:  0.02556581 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  42900 \t Train Loss:  0.01659729 \t Train Accuracy:  99.55%\nStep:  42900 \t Eval Loss:  0.02229595 \t Eval Accuracy:  99.44%\n##########################################################\nStep:  43000 \t Train Loss:  0.0200405 \t Train Accuracy:  99.35%\nStep:  43000 \t Eval Loss:  0.02514132 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  43100 \t Train Loss:  0.020655416 \t Train Accuracy:  99.39%\nStep:  43100 \t Eval Loss:  0.02675338 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  43200 \t Train Loss:  0.012872586 \t Train Accuracy:  99.61%\nStep:  43200 \t Eval Loss:  0.027599905 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  43300 \t Train Loss:  0.016898429 \t Train Accuracy:  99.46%\nStep:  43300 \t Eval Loss:  0.024227705 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  43400 \t Train Loss:  0.015479176 \t Train Accuracy:  99.49%\nStep:  43400 \t Eval Loss:  0.026893254 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  43500 \t Train Loss:  0.014576771 \t Train Accuracy:  99.55%\nStep:  43500 \t Eval Loss:  0.023631971 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  43600 \t Train Loss:  0.018826991 \t Train Accuracy:  99.44%\nStep:  43600 \t Eval Loss:  0.024531549 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  43700 \t Train Loss:  0.014110291 \t Train Accuracy:  99.52%\nStep:  43700 \t Eval Loss:  0.02105332 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  43800 \t Train Loss:  0.018839903 \t Train Accuracy:  99.50%\nStep:  43800 \t Eval Loss:  0.02324979 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  43900 \t Train Loss:  0.014500892 \t Train Accuracy:  99.56%\nStep:  43900 \t Eval Loss:  0.025285777 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  44000 \t Train Loss:  0.016656514 \t Train Accuracy:  99.48%\nStep:  44000 \t Eval Loss:  0.026186548 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  44100 \t Train Loss:  0.019227091 \t Train Accuracy:  99.41%\nStep:  44100 \t Eval Loss:  0.030361546 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  44200 \t Train Loss:  0.016472328 \t Train Accuracy:  99.54%\nStep:  44200 \t Eval Loss:  0.022975352 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  44300 \t Train Loss:  0.013585309 \t Train Accuracy:  99.65%\nStep:  44300 \t Eval Loss:  0.021182295 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  44400 \t Train Loss:  0.01769434 \t Train Accuracy:  99.48%\nStep:  44400 \t Eval Loss:  0.02694439 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  44500 \t Train Loss:  0.015592816 \t Train Accuracy:  99.50%\nStep:  44500 \t Eval Loss:  0.026337873 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  44600 \t Train Loss:  0.018391827 \t Train Accuracy:  99.39%\nStep:  44600 \t Eval Loss:  0.029258959 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  44700 \t Train Loss:  0.015554024 \t Train Accuracy:  99.48%\nStep:  44700 \t Eval Loss:  0.022683736 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  44800 \t Train Loss:  0.014097249 \t Train Accuracy:  99.58%\nStep:  44800 \t Eval Loss:  0.023196299 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  44900 \t Train Loss:  0.016118469 \t Train Accuracy:  99.49%\nStep:  44900 \t Eval Loss:  0.022897605 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  45000 \t Train Loss:  0.012822271 \t Train Accuracy:  99.62%\nStep:  45000 \t Eval Loss:  0.029254446 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  45100 \t Train Loss:  0.0145075265 \t Train Accuracy:  99.52%\nStep:  45100 \t Eval Loss:  0.020347025 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  45200 \t Train Loss:  0.015416726 \t Train Accuracy:  99.56%\nStep:  45200 \t Eval Loss:  0.022656772 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  45300 \t Train Loss:  0.018168721 \t Train Accuracy:  99.43%\nStep:  45300 \t Eval Loss:  0.022286477 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  45400 \t Train Loss:  0.0113785565 \t Train Accuracy:  99.71%\nStep:  45400 \t Eval Loss:  0.023319965 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  45500 \t Train Loss:  0.011922324 \t Train Accuracy:  99.65%\nStep:  45500 \t Eval Loss:  0.021469094 \t Eval Accuracy:  99.43%\n##########################################################\nStep:  45600 \t Train Loss:  0.014800214 \t Train Accuracy:  99.52%\nStep:  45600 \t Eval Loss:  0.025645519 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  45700 \t Train Loss:  0.017945586 \t Train Accuracy:  99.45%\nStep:  45700 \t Eval Loss:  0.027660973 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  45800 \t Train Loss:  0.01578188 \t Train Accuracy:  99.52%\nStep:  45800 \t Eval Loss:  0.02461109 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  45900 \t Train Loss:  0.017244225 \t Train Accuracy:  99.44%\nStep:  45900 \t Eval Loss:  0.025002655 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  46000 \t Train Loss:  0.01733914 \t Train Accuracy:  99.39%\nStep:  46000 \t Eval Loss:  0.024157967 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  46100 \t Train Loss:  0.015887976 \t Train Accuracy:  99.52%\nStep:  46100 \t Eval Loss:  0.025239285 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  46200 \t Train Loss:  0.015615091 \t Train Accuracy:  99.49%\nStep:  46200 \t Eval Loss:  0.020996358 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  46300 \t Train Loss:  0.017303135 \t Train Accuracy:  99.55%\nStep:  46300 \t Eval Loss:  0.025703108 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  46400 \t Train Loss:  0.0156965 \t Train Accuracy:  99.51%\nStep:  46400 \t Eval Loss:  0.023310259 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  46500 \t Train Loss:  0.012317475 \t Train Accuracy:  99.63%\nStep:  46500 \t Eval Loss:  0.027494382 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  46600 \t Train Loss:  0.01501168 \t Train Accuracy:  99.54%\nStep:  46600 \t Eval Loss:  0.023599368 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  46700 \t Train Loss:  0.014103448 \t Train Accuracy:  99.58%\nStep:  46700 \t Eval Loss:  0.02419477 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  46800 \t Train Loss:  0.012237079 \t Train Accuracy:  99.60%\nStep:  46800 \t Eval Loss:  0.027158644 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  46900 \t Train Loss:  0.01840046 \t Train Accuracy:  99.46%\nStep:  46900 \t Eval Loss:  0.021931149 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  47000 \t Train Loss:  0.016965069 \t Train Accuracy:  99.50%\nStep:  47000 \t Eval Loss:  0.027245048 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  47100 \t Train Loss:  0.014354997 \t Train Accuracy:  99.56%\nStep:  47100 \t Eval Loss:  0.023783948 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  47200 \t Train Loss:  0.018680278 \t Train Accuracy:  99.43%\nStep:  47200 \t Eval Loss:  0.027850598 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  47300 \t Train Loss:  0.014711086 \t Train Accuracy:  99.54%\nStep:  47300 \t Eval Loss:  0.02330741 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  47400 \t Train Loss:  0.015066277 \t Train Accuracy:  99.52%\nStep:  47400 \t Eval Loss:  0.024990305 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  47500 \t Train Loss:  0.015772577 \t Train Accuracy:  99.57%\nStep:  47500 \t Eval Loss:  0.02469707 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  47600 \t Train Loss:  0.013354687 \t Train Accuracy:  99.63%\nStep:  47600 \t Eval Loss:  0.022387203 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  47700 \t Train Loss:  0.016262896 \t Train Accuracy:  99.54%\nStep:  47700 \t Eval Loss:  0.023950517 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  47800 \t Train Loss:  0.01399996 \t Train Accuracy:  99.56%\nStep:  47800 \t Eval Loss:  0.025162717 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  47900 \t Train Loss:  0.0141635565 \t Train Accuracy:  99.55%\nStep:  47900 \t Eval Loss:  0.030657008 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  48000 \t Train Loss:  0.01643582 \t Train Accuracy:  99.48%\nStep:  48000 \t Eval Loss:  0.022287145 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  48100 \t Train Loss:  0.01812081 \t Train Accuracy:  99.49%\nStep:  48100 \t Eval Loss:  0.024901472 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  48200 \t Train Loss:  0.0140604675 \t Train Accuracy:  99.51%\nStep:  48200 \t Eval Loss:  0.020931453 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  48300 \t Train Loss:  0.01623788 \t Train Accuracy:  99.55%\nStep:  48300 \t Eval Loss:  0.025498597 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  48400 \t Train Loss:  0.015006553 \t Train Accuracy:  99.61%\nStep:  48400 \t Eval Loss:  0.02616045 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  48500 \t Train Loss:  0.014913697 \t Train Accuracy:  99.61%\nStep:  48500 \t Eval Loss:  0.023720387 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  48600 \t Train Loss:  0.015284783 \t Train Accuracy:  99.56%\nStep:  48600 \t Eval Loss:  0.024904799 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  48700 \t Train Loss:  0.015485986 \t Train Accuracy:  99.49%\nStep:  48700 \t Eval Loss:  0.022529814 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  48800 \t Train Loss:  0.01774475 \t Train Accuracy:  99.49%\nStep:  48800 \t Eval Loss:  0.027988581 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  48900 \t Train Loss:  0.010268688 \t Train Accuracy:  99.62%\nStep:  48900 \t Eval Loss:  0.025763268 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  49000 \t Train Loss:  0.015504163 \t Train Accuracy:  99.56%\nStep:  49000 \t Eval Loss:  0.02933057 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  49100 \t Train Loss:  0.016402716 \t Train Accuracy:  99.54%\nStep:  49100 \t Eval Loss:  0.021467315 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  49200 \t Train Loss:  0.0154882055 \t Train Accuracy:  99.52%\nStep:  49200 \t Eval Loss:  0.027271947 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  49300 \t Train Loss:  0.013963027 \t Train Accuracy:  99.57%\nStep:  49300 \t Eval Loss:  0.024123773 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  49400 \t Train Loss:  0.01641001 \t Train Accuracy:  99.52%\nStep:  49400 \t Eval Loss:  0.021420501 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  49500 \t Train Loss:  0.015171345 \t Train Accuracy:  99.52%\nStep:  49500 \t Eval Loss:  0.02703946 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  49600 \t Train Loss:  0.0145525215 \t Train Accuracy:  99.51%\nStep:  49600 \t Eval Loss:  0.023536317 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  49700 \t Train Loss:  0.017258734 \t Train Accuracy:  99.55%\nStep:  49700 \t Eval Loss:  0.028097663 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  49800 \t Train Loss:  0.013212677 \t Train Accuracy:  99.63%\nStep:  49800 \t Eval Loss:  0.026617322 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  49900 \t Train Loss:  0.016415056 \t Train Accuracy:  99.51%\nStep:  49900 \t Eval Loss:  0.020130344 \t Eval Accuracy:  99.39%\nCPU times: user 1h 8min 28s, sys: 55min 8s, total: 2h 3min 37s\nWall time: 2h 12min 22s\n","output_type":"stream"}]},{"cell_type":"code","source":"# Plot loss and accuracy in subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.set_title('Loss')\nax2.set_title('Accuracy')\n\n\n\nax1.plot(all_train_losses, label='train_loss')\nax1.plot(all_eval_losses, label='eval_loss')\n\nax2.plot(all_train_accuracy, label='train_accuracy')\nax2.plot(all_test_accuracy, label='eval_accuracy')\n\nax1.legend()\nax2.legend()\nplt.show()\nplt.clf()","metadata":{"execution":{"iopub.status.busy":"2024-06-28T11:19:47.352504Z","iopub.execute_input":"2024-06-28T11:19:47.352895Z","iopub.status.idle":"2024-06-28T11:19:47.846808Z","shell.execute_reply.started":"2024-06-28T11:19:47.352861Z","shell.execute_reply":"2024-06-28T11:19:47.845896Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x500 with 2 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"@partial(jax.jit, static_argnames=(\"length\"))\ndef generate_text(rng, params, length):\n    def _scan_generate(carry, _):\n        random_key, context = carry\n        logits = model.apply(params, context)\n#         pdb.set_trace()\n        rng, rng_subkey = jax.random.split(random_key)\n        new_token = jax.random.categorical(\n          rng_subkey, logits[:, -n_tokens, :], axis=-1, shape=(1, 1)\n        )\n        context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n        print(context.shape)\n        return (rng, context), new_token\n\n    _, new_tokens = jax.lax.scan(\n    _scan_generate,\n    (rng, jnp.expand_dims(test_data[852:852+block_size], axis=0)),\n    (),\n    length=length,\n    )\n    return new_tokens","metadata":{"execution":{"iopub.status.busy":"2024-06-28T11:19:47.847942Z","iopub.execute_input":"2024-06-28T11:19:47.848196Z","iopub.status.idle":"2024-06-28T11:19:47.856183Z","shell.execute_reply.started":"2024-06-28T11:19:47.848175Z","shell.execute_reply":"2024-06-28T11:19:47.855192Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test_data[852:852+block_size]","metadata":{"execution":{"iopub.status.busy":"2024-06-28T11:19:47.857228Z","iopub.execute_input":"2024-06-28T11:19:47.857462Z","iopub.status.idle":"2024-06-28T11:19:48.448657Z","shell.execute_reply.started":"2024-06-28T11:19:47.857442Z","shell.execute_reply":"2024-06-28T11:19:48.447667Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Array([51,  6,  1, 53, 56,  1, 43, 50, 57, 43,  1, 63, 53, 59,  1, 42, 53,\n        1, 51, 43,  1, 61, 56, 53, 52, 45, 10,  0, 20, 47, 57,  1, 52, 39,\n       51, 43,  1, 47, 57,  1, 24, 47, 41, 47, 53,  6,  1, 40, 53, 56, 52,\n        1, 47, 52,  1, 25, 39, 52, 58, 59, 39,  8,  0,  0], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"i = 852\ndecode(test_data[i:i+block_size].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-06-28T11:19:48.450051Z","iopub.execute_input":"2024-06-28T11:19:48.450383Z","iopub.status.idle":"2024-06-28T11:19:48.458115Z","shell.execute_reply.started":"2024-06-28T11:19:48.450353Z","shell.execute_reply":"2024-06-28T11:19:48.457140Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'m, or else you do me wrong:\\nHis name is Licio, born in Mantua.\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"new_tokenz = 1000\nkey, subkey = jax.random.split(jax.random.PRNGKey(156))\n# key, subkey = jax.random.split(key)\n# token_gen = generate_text(jnp.zeros((1,block_size)).astype(jnp.int32), new_tokenz, {'params': state.params})\ntoken_gen = generate_text(key, params, new_tokenz)[:, 0, 0].tolist()\nprint(token_gen)\nprint('\\n')\nprint(decode(token_gen))","metadata":{"execution":{"iopub.status.busy":"2024-06-28T11:19:48.459434Z","iopub.execute_input":"2024-06-28T11:19:48.459769Z","iopub.status.idle":"2024-06-28T11:19:53.509165Z","shell.execute_reply.started":"2024-06-28T11:19:48.459742Z","shell.execute_reply":"2024-06-28T11:19:53.508251Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"(1, 64)\n[24, 13, 16, 37, 1, 31, 24, 17, 33, 18, 26, 21, 13, 52, 1, 15, 27, 18, 44, 53, 56, 42, 8, 0, 0, 19, 30, 17, 25, 21, 27, 10, 0, 14, 46, 39, 58, 2, 1, 61, 56, 43, 52, 49, 1, 57, 39, 63, 57, 1, 58, 46, 43, 56, 43, 12, 1, 58, 46, 43, 1, 53, 50, 42, 1, 41, 56, 53, 61, 52, 1, 42, 39, 63, 57, 8, 0, 27, 1, 14, 53, 50, 47, 52, 45, 40, 56, 53, 49, 43, 6, 1, 57, 47, 52, 41, 43, 1, 50, 47, 49, 43, 1, 53, 40, 43, 63, 57, 1, 40, 43, 45, 39, 52, 6, 0, 33, 50, 50, 54, 39, 56, 42, 57, 1, 53, 44, 1, 54, 43, 56, 43, 57, 57, 43, 52, 53, 53, 59, 57, 6, 1, 58, 46, 56, 39, 52, 63, 1, 47, 52, 45, 56, 47, 51, 39, 45, 43, 6, 0, 13, 52, 42, 1, 58, 46, 53, 57, 43, 1, 58, 46, 53, 59, 1, 46, 39, 57, 58, 1, 56, 47, 45, 46, 58, 1, 47, 52, 1, 40, 43, 39, 59, 58, 63, 10, 1, 53, 59, 56, 1, 55, 59, 43, 43, 52, 8, 0, 0, 26, 53, 30, 32, 20, 33, 25, 14, 17, 30, 24, 13, 26, 16, 10, 0, 26, 53, 1, 61, 53, 56, 42, 6, 1, 53, 52, 1, 39, 50, 50, 1, 58, 46, 43, 1, 17, 52, 45, 50, 39, 52, 42, 1, 41, 46, 53, 47, 57, 43, 42, 6, 1, 53, 44, 1, 63, 53, 59, 56, 1, 40, 56, 43, 39, 58, 46, 43, 57, 11, 1, 39, 52, 42, 1, 46, 43, 39, 60, 43, 52, 1, 42, 56, 53, 54, 1, 53, 52, 1, 58, 46, 63, 1, 61, 46, 47, 41, 46, 1, 58, 46, 53, 59, 1, 42, 47, 42, 57, 58, 1, 49, 47, 50, 50, 1, 58, 46, 43, 1, 51, 43, 56, 56, 47, 51, 53, 52, 45, 1, 58, 46, 43, 57, 43, 0, 21, 52, 1, 58, 46, 53, 59, 57, 39, 52, 42, 1, 51, 43, 52, 63, 1, 58, 46, 43, 47, 56, 1, 60, 39, 50, 47, 39, 52, 58, 1, 58, 56, 59, 58, 46, 58, 8, 19, 0, 28, 56, 53, 52, 53, 59, 52, 41, 43, 6, 0, 27, 56, 1, 40, 63, 1, 57, 53, 51, 43, 1, 39, 50, 50, 1, 58, 46, 43, 51, 1, 47, 52, 1, 56, 43, 1, 47, 51, 54, 43, 39, 57, 59, 56, 43, 0, 27, 44, 1, 45, 56, 43, 39, 58, 1, 42, 47, 57, 41, 46, 39, 56, 45, 43, 42, 6, 1, 39, 52, 42, 1, 44, 53, 50, 50, 53, 61, 57, 1, 51, 43, 1, 41, 59, 56, 57, 43, 1, 47, 57, 1, 42, 53, 52, 43, 8, 0, 0, 23, 21, 26, 19, 1, 17, 16, 35, 13, 30, 16, 1, 21, 34, 10, 0, 35, 46, 39, 58, 1, 47, 57, 1, 46, 47, 57, 1, 52, 39, 51, 43, 11, 0, 19, 56, 53, 61, 52, 1, 58, 61, 43, 52, 58, 63, 1, 51, 59, 56, 42, 43, 56, 1, 57, 53, 1, 46, 53, 52, 53, 59, 56, 6, 0, 32, 46, 39, 58, 1, 41, 39, 52, 1, 50, 47, 60, 43, 10, 1, 58, 46, 47, 57, 1, 47, 57, 1, 42, 47, 52, 43, 42, 1, 44, 53, 56, 1, 39, 52, 42, 1, 44, 53, 56, 43, 39, 56, 10, 0, 26, 39, 63, 6, 1, 58, 46, 56, 53, 59, 45, 46, 1, 56, 43, 44, 53, 56, 43, 6, 1, 40, 43, 57, 47, 42, 43, 1, 51, 63, 1, 57, 47, 57, 58, 43, 56, 6, 0, 21, 5, 50, 50, 1, 40, 43, 1, 63, 53, 59, 56, 1, 46, 43, 39, 60, 43, 52, 1, 54, 39, 56, 63, 1, 47, 52, 1, 45, 53, 60, 43, 56, 52, 43, 57, 58, 6, 0, 37, 53, 59, 1, 46, 39, 42, 1, 52, 53, 1, 51, 53, 56, 43, 1, 53, 44, 1, 47, 58, 8, 1, 31, 43, 43, 6, 1, 46, 43, 56, 43, 1, 52, 53, 58, 1, 58, 46, 43, 1, 41, 50, 53, 59, 42, 57, 1, 52, 53, 56, 1, 58, 46, 39, 58, 0, 20, 43, 1, 61, 39, 57, 1, 39, 50, 61, 39, 63, 1, 52, 53, 61, 1, 46, 59, 52, 1, 47, 51, 54, 53, 57, 58, 1, 43, 52, 42, 43, 56, 1, 46, 39, 58, 46, 0, 32, 46, 39, 52, 1, 58, 46, 43, 1, 57, 43, 41, 53, 52, 42, 1, 41, 59, 56, 56, 43, 52, 58, 1, 13, 42, 39, 51, 1, 58, 53, 1, 45, 53, 1, 42, 53, 61, 52, 8, 0, 0, 18, 47, 56, 57, 58, 1, 25, 59, 56, 42, 43, 56, 43, 56, 10, 0, 26, 53, 61, 6, 1, 57, 47, 40, 1, 39, 56, 47, 53, 52, 1, 58, 46, 53, 59, 1, 61, 53, 51, 43, 52, 1, 21, 1, 46, 39, 60, 43, 1, 40, 43, 43, 52, 1, 58, 53, 1, 15, 47, 58, 43, 58, 63, 10, 0, 30, 47, 41, 46, 39, 56, 42, 1, 53, 44, 44, 43, 52, 41, 43, 57, 1, 46, 39, 58, 46, 1, 57, 46, 53, 61, 1, 51, 43, 1, 44, 56, 53, 51, 1, 58, 46, 43, 1, 51, 53, 57, 58, 1, 40, 59, 57, 47, 52, 43, 57, 57, 0, 21, 1, 61, 39, 57, 1, 59, 57, 43, 1, 43, 62, 54, 43, 41, 58, 47, 53, 52, 2, 1, 61, 46, 53, 1, 57, 46, 39, 50, 50, 1, 45, 53, 1, 57, 43, 43, 1, 47, 58, 1, 54, 59, 58, 43, 6, 1, 51, 39, 63, 12, 0, 0, 14, 30, 33, 32, 33, 31, 10, 0, 18, 39, 56, 43, 61, 43, 50, 50, 6, 1, 51]\n\n\nLADY SLEUFNIAn COFford.\n\nGREMIO:\nBhat! wrenk says there? the old crown days.\nO Bolingbroke, since like obeys began,\nUllpards of peressenoous, thrany ingrimage,\nAnd those thou hast right in beauty: our queen.\n\nNoRTHUMBERLAND:\nNo word, on all the England choised, of your breathes; and heaven drop on thy which thou didst kill the merrimong these\nIn thousand meny their valiant trutht.G\nPronounce,\nOr by some all them in re impeasure\nOf great discharged, and follows me curse is done.\n\nKING EDWARD IV:\nWhat is his name;\nGrown twenty murder so honour,\nThat can live: this is dined for and forear:\nNay, through refore, beside my sister,\nI'll be your heaven pary in governest,\nYou had no more of it. See, here not the clouds nor that\nHe was alway now hun impost ender hath\nThan the second current Adam to go down.\n\nFirst Murderer:\nNow, sib arion thou women I have been to Citety:\nRichard offences hath show me from the most business\nI was use expection! who shall go see it pute, may?\n\nBRUTUS:\nFarewell, m\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}