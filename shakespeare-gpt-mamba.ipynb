{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q clu","metadata":{"id":"gS6euWNvHFye","outputId":"45b149a7-9450-439c-da67-ab8678a3b0d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt","metadata":{"id":"7jjCLfuUHFyg","outputId":"dfe048f0-dd44-40ef-edf3-2fa56558672f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from functools import partial\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom jax.nn.initializers import lecun_normal, normal\nfrom jax.numpy.linalg import eigh, inv, matrix_power\nfrom jax.scipy.signal import convolve\n\nimport torch\n\nfrom dataclasses import dataclass\n\nfrom typing import Union\n\nimport matplotlib.pyplot as plt\nimport seaborn\n\nfrom clu import metrics\nfrom flax.training import train_state  # Useful dataclass to keep train state\nfrom flax import struct                # Flax dataclasses\nimport optax                           # Common loss functions and optimizers\nfrom tqdm import tqdm","metadata":{"id":"YXSCJzupHFyh","execution":{"iopub.status.busy":"2024-05-27T08:44:21.596027Z","iopub.execute_input":"2024-05-27T08:44:21.596418Z","iopub.status.idle":"2024-05-27T08:44:25.099309Z","shell.execute_reply.started":"2024-05-27T08:44:21.596385Z","shell.execute_reply":"2024-05-27T08:44:25.098299Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# read it in to inspect it\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()","metadata":{"id":"KpJoV3KQHFyh","execution":{"iopub.status.busy":"2024-05-27T08:44:25.101077Z","iopub.execute_input":"2024-05-27T08:44:25.101511Z","iopub.status.idle":"2024-05-27T08:44:25.107287Z","shell.execute_reply.started":"2024-05-27T08:44:25.101484Z","shell.execute_reply":"2024-05-27T08:44:25.106478Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# here are all the unique characters that occur in this text\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"id":"PsWxZqyRHFyi","outputId":"b1730724-647e-45cd-edfa-97af24995830","execution":{"iopub.status.busy":"2024-05-27T08:44:25.108378Z","iopub.execute_input":"2024-05-27T08:44:25.108728Z","iopub.status.idle":"2024-05-27T08:44:25.135058Z","shell.execute_reply.started":"2024-05-27T08:44:25.108703Z","shell.execute_reply":"2024-05-27T08:44:25.134220Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n65\n","output_type":"stream"}]},{"cell_type":"code","source":"# create a mapping from characters to integers\nstoi = { ch: i for i,ch in enumerate(chars) }\nitos = { i: ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n\nprint(encode(\"hii there\"))\nprint(decode(encode(\"hii there\")))","metadata":{"id":"S-mzLOk1HFyi","outputId":"f56e2f85-5a1c-4099-87df-436ba39f4363","execution":{"iopub.status.busy":"2024-05-27T08:44:25.137089Z","iopub.execute_input":"2024-05-27T08:44:25.137369Z","iopub.status.idle":"2024-05-27T08:44:25.146648Z","shell.execute_reply.started":"2024-05-27T08:44:25.137346Z","shell.execute_reply":"2024-05-27T08:44:25.145786Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[46, 47, 47, 1, 58, 46, 43, 56, 43]\nhii there\n","output_type":"stream"}]},{"cell_type":"code","source":"data = jnp.array(encode(text), dtype=jnp.int32)\nprint(data.shape, data.dtype)\nprint(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this","metadata":{"id":"HImuqDd8HFyj","outputId":"91dcd15f-f068-4551-ad29-e6e41e52fd91","execution":{"iopub.status.busy":"2024-05-27T08:44:25.147875Z","iopub.execute_input":"2024-05-27T08:44:25.148278Z","iopub.status.idle":"2024-05-27T08:44:27.493815Z","shell.execute_reply.started":"2024-05-27T08:44:25.148247Z","shell.execute_reply":"2024-05-27T08:44:27.492871Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(1115394,) int32\n[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n  0 37 53 59  1 39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39\n 58 46 43 56  1 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47\n 57 46 12  0  0 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53\n 50 60 43 42  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47\n 56 57 58  6  1 63 53 59  1 49 52 53 61  1 15 39 47 59 57  1 25 39 56 41\n 47 59 57  1 47 57  1 41 46 47 43 44  1 43 52 43 51 63  1 58 53  1 58 46\n 43  1 54 43 53 54 50 43  8  0  0 13 50 50 10  0 35 43  1 49 52 53 61  5\n 58  6  1 61 43  1 49 52 53 61  5 58  8  0  0 18 47 56 57 58  1 15 47 58\n 47 64 43 52 10  0 24 43 58  1 59 57  1 49 47 50 50  1 46 47 51  6  1 39\n 52 42  1 61 43  5 50 50  1 46 39 60 43  1 41 53 56 52  1 39 58  1 53 59\n 56  1 53 61 52  1 54 56 47 41 43  8  0 21 57  5 58  1 39  1 60 43 56 42\n 47 41 58 12  0  0 13 50 50 10  0 26 53  1 51 53 56 43  1 58 39 50 49 47\n 52 45  1 53 52  5 58 11  1 50 43 58  1 47 58  1 40 43  1 42 53 52 43 10\n  1 39 61 39 63  6  1 39 61 39 63  2  0  0 31 43 41 53 52 42  1 15 47 58\n 47 64 43 52 10  0 27 52 43  1 61 53 56 42  6  1 45 53 53 42  1 41 47 58\n 47 64 43 52 57  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 35\n 43  1 39 56 43  1 39 41 41 53 59 52 58 43 42  1 54 53 53 56  1 41 47 58\n 47 64 43 52 57  6  1 58 46 43  1 54 39 58 56 47 41 47 39 52 57  1 45 53\n 53 42  8  0 35 46 39 58  1 39 59 58 46 53 56 47 58 63  1 57 59 56 44 43\n 47 58 57  1 53 52  1 61 53 59 50 42  1 56 43 50 47 43 60 43  1 59 57 10\n  1 47 44  1 58 46 43 63  0 61 53 59 50 42  1 63 47 43 50 42  1 59 57  1\n 40 59 58  1 58 46 43  1 57 59 54 43 56 44 50 59 47 58 63  6  1 61 46 47\n 50 43  1 47 58  1 61 43 56 43  0 61 46 53 50 43 57 53 51 43  6  1 61 43\n  1 51 47 45 46 58  1 45 59 43 57 57  1 58 46 43 63  1 56 43 50 47 43 60\n 43 42  1 59 57  1 46 59 51 39 52 43 50 63 11  0 40 59 58  1 58 46 43 63\n  1 58 46 47 52 49  1 61 43  1 39 56 43  1 58 53 53  1 42 43 39 56 10  1\n 58 46 43  1 50 43 39 52 52 43 57 57  1 58 46 39 58  0 39 44 44 50 47 41\n 58 57  1 59 57  6  1 58 46 43  1 53 40 48 43 41 58  1 53 44  1 53 59 56\n  1 51 47 57 43 56 63  6  1 47 57  1 39 57  1 39 52  0 47 52 60 43 52 58\n 53 56 63  1 58 53  1 54 39 56 58 47 41 59 50 39 56 47 57 43  1 58 46 43\n 47 56  1 39 40 59 52 42 39 52 41 43 11  1 53 59 56  0 57 59 44 44 43 56\n 39 52 41 43  1 47 57  1 39  1 45 39 47 52  1 58 53  1 58 46 43 51  1 24\n 43 58  1 59 57  1 56 43 60 43 52 45 43  1 58 46 47 57  1 61 47 58 46  0\n 53 59 56  1 54 47 49 43 57  6  1 43 56 43  1 61 43  1 40 43 41 53 51 43\n  1 56 39 49 43 57 10  1 44 53 56  1 58 46 43  1 45 53 42 57  1 49 52 53\n 61  1 21  0 57 54 43 39 49  1 58 46 47 57  1 47 52  1 46 59 52 45 43 56\n  1 44 53 56  1 40 56 43 39 42  6  1 52 53 58  1 47 52  1 58 46 47 56 57\n 58  1 44 53 56  1 56 43 60 43 52 45 43  8  0  0]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_test_split = 0.9\nn = int(train_test_split*len(data))\ntrain_data = data[:n]\ntest_data = data[n:]","metadata":{"id":"pXrAqMxRHFyj","execution":{"iopub.status.busy":"2024-05-27T08:44:27.495286Z","iopub.execute_input":"2024-05-27T08:44:27.495873Z","iopub.status.idle":"2024-05-27T08:44:27.655230Z","shell.execute_reply.started":"2024-05-27T08:44:27.495845Z","shell.execute_reply":"2024-05-27T08:44:27.654194Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"block_size = 8\ntrain_data[:block_size+1]","metadata":{"id":"ahhKyiAzHFyj","outputId":"98306c96-5082-4dfa-ba66-915051831fc8","execution":{"iopub.status.busy":"2024-05-27T08:44:27.656700Z","iopub.execute_input":"2024-05-27T08:44:27.656991Z","iopub.status.idle":"2024-05-27T08:44:27.740503Z","shell.execute_reply.started":"2024-05-27T08:44:27.656966Z","shell.execute_reply":"2024-05-27T08:44:27.739242Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Array([18, 47, 56, 57, 58,  1, 15, 47, 58], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target: {target}\")","metadata":{"id":"HIpsznQmHFyk","outputId":"be9d197b-0b79-43ed-f3a9-e74295d51c79","execution":{"iopub.status.busy":"2024-05-27T08:44:27.741941Z","iopub.execute_input":"2024-05-27T08:44:27.742339Z","iopub.status.idle":"2024-05-27T08:44:28.378058Z","shell.execute_reply.started":"2024-05-27T08:44:27.742305Z","shell.execute_reply":"2024-05-27T08:44:28.377083Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"when input is [18] the target: 47\nwhen input is [18 47] the target: 56\nwhen input is [18 47 56] the target: 57\nwhen input is [18 47 56 57] the target: 58\nwhen input is [18 47 56 57 58] the target: 1\nwhen input is [18 47 56 57 58  1] the target: 15\nwhen input is [18 47 56 57 58  1 15] the target: 47\nwhen input is [18 47 56 57 58  1 15 47] the target: 58\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 512 # how many independent sequences will we process in parallel?\nblock_size = 64 # what is the maximum context length for predictions?\nmax_iters = 10000\nlearning_rate = 1e-3\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 100\nn_embd = 256\nexpans = 3\nn_heads = 1\nchannel_size = n_embd // n_heads\nn_layers = 6\ndropout = 0.2\nconv_k_size = 3\nn_latent_dim = 16\nn_tokens = 1\n\nrng_key = jax.random.PRNGKey(1564)\n\ndynamic_slice_vmap = jax.vmap(jax.lax.dynamic_slice, in_axes=(None, 0, None))\n\n@jax.jit\ndef get_batch(random_key, data):\n    \"\"\"Prepares a random batch of training data.\n\n    Args:\n      random_key: A random seed for sampling a batch.\n      data: The complete training dataset.\n\n    Returns:\n      x: Input sequences.\n      y: Target sequences (shifted inputs).\n    \"\"\"\n    ix = jax.random.randint(\n      random_key, shape=(batch_size, 1), minval=0, maxval=len(data) - block_size\n    )\n    x = dynamic_slice_vmap(data, ix, (block_size,))\n    y = dynamic_slice_vmap(data, ix + n_tokens, (block_size,))\n    return x, y\n\nxb, yb = get_batch(rng_key, train_data)\ntrain_shape = xb.shape\nprint('inputs:')\nprint(xb.shape)\nprint(xb)\nprint('targets:')\nprint(yb.shape)\nprint(yb)\n\n# print('----')\n\n# for b in range(batch_size): # batch dimension\n#     for t in range(block_size): # time dimension\n#         context = xb[b, :t+1]\n#         target = yb[b,t]\n#         print(f\"when input is {context} the target: {target}\")","metadata":{"id":"UuAjtqPeHFyk","outputId":"6a88fb2b-b798-4ee9-9f4f-f38ce898d576","execution":{"iopub.status.busy":"2024-05-27T08:44:28.379061Z","iopub.execute_input":"2024-05-27T08:44:28.379330Z","iopub.status.idle":"2024-05-27T08:44:28.707920Z","shell.execute_reply.started":"2024-05-27T08:44:28.379300Z","shell.execute_reply":"2024-05-27T08:44:28.706906Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"inputs:\n(512, 64)\n[[33 23 17 ... 53 52 45]\n [ 0 37 53 ... 52 52 53]\n [53 52 42 ... 59 47 58]\n ...\n [52 42  1 ... 58 46  1]\n [37 53 59 ...  1 61 47]\n [17 26 34 ... 39 52  1]]\ntargets:\n(512, 64)\n[[23 17  1 ... 52 45 59]\n [37 53 59 ... 52 53 58]\n [52 42 43 ... 47 58  7]\n ...\n [42  1 63 ... 46  1 54]\n [53 59  1 ... 61 47 50]\n [26 34 27 ... 52  1 40]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Mamba Block\nDense --> Conv1D --> Silu --> SSM --> Silu -->","metadata":{"id":"yOccqzJlHFym"}},{"cell_type":"code","source":"print(xb[0])\nprint(yb[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T08:44:28.712086Z","iopub.execute_input":"2024-05-27T08:44:28.712399Z","iopub.status.idle":"2024-05-27T08:44:28.816127Z","shell.execute_reply.started":"2024-05-27T08:44:28.712372Z","shell.execute_reply":"2024-05-27T08:44:28.815162Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[33 23 17  1 27 18  1 13 33 25 17 30 24 17 10  0 18 53 56  1 43 60 43 56\n  1 51 39 63  1 51 63  1 49 52 43 43 57  1 45 56 53 61  1 58 53  1 58 46\n 43  1 43 39 56 58 46  6  0 25 63  1 58 53 52 45]\n[23 17  1 27 18  1 13 33 25 17 30 24 17 10  0 18 53 56  1 43 60 43 56  1\n 51 39 63  1 51 63  1 49 52 43 43 57  1 45 56 53 61  1 58 53  1 58 46 43\n  1 43 39 56 58 46  6  0 25 63  1 58 53 52 45 59]\n","output_type":"stream"}]},{"cell_type":"code","source":"# hidden_state = [jnp.zeros((1,n_latent_dim, n_embd * expans)) for _ in range(n_layers)]","metadata":{"execution":{"iopub.status.busy":"2024-05-27T08:44:28.817372Z","iopub.execute_input":"2024-05-27T08:44:28.817749Z","iopub.status.idle":"2024-05-27T08:44:28.821819Z","shell.execute_reply.started":"2024-05-27T08:44:28.817722Z","shell.execute_reply":"2024-05-27T08:44:28.820879Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# hidden_state[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-05-27T08:44:28.823056Z","iopub.execute_input":"2024-05-27T08:44:28.823407Z","iopub.status.idle":"2024-05-27T08:44:28.833980Z","shell.execute_reply.started":"2024-05-27T08:44:28.823377Z","shell.execute_reply":"2024-05-27T08:44:28.833142Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Mamba(nn.Module):\n\n    def setup(self):\n        emb_features = n_embd * expans\n        self.in_proj1 = nn.Dense(features=emb_features)\n        self.in_proj2 = nn.Dense(features=emb_features)\n\n        # Adjusted for Flax. Flax does not have nn.Conv1d, so you might need to reshape or use a different approach\n        self.conv1d = nn.Conv(features=emb_features,\n                              kernel_size=conv_k_size,\n                              padding=1,\n                              )\n\n        self.A = -1*self.param('A', nn.initializers.ones, (1, n_latent_dim, emb_features, 1))\n        self.B = 0.1*self.param('B', nn.initializers.ones, (1, n_latent_dim, 1, block_size))\n        self.C = self.param('C', jax.random.normal, (1, n_latent_dim, 1, block_size))\n#         self.D = self.param('D', jax.random.normal, (1, self.args.d_state, self.args.d_model, 1))\n        self.delta = self.param('delta', jax.random.normal, (1, 1,emb_features, block_size))\n\n        self.out_proj = nn.Dense(n_embd // n_heads)\n        \n        self.hidden_state = self.variable('other_variables','hidden_state', \n                                          jnp.zeros, \n                                          (1,n_latent_dim, emb_features))\n        self.rms_norm = nn.RMSNorm()\n\n    def __call__(self, embeds):\n        x = self.in_proj1(embeds)\n        x = self.conv1d(x)\n        x = jax.nn.silu(x)\n        x = x.reshape((x.shape[0],1,x.shape[2],x.shape[1]))\n        x = self.ssm(x)\n        x = x.reshape((x.shape[0],x.shape[3],x.shape[2]))\n        x = x*jax.nn.silu(self.in_proj2(embeds))\n\n        x = self.out_proj(x)\n\n        x = self.rms_norm(x)\n\n        return x\n    def discretize(self):\n        da = self.delta * self.A\n        a_ = jnp.exp(da)\n        b_ = self.B * self.delta\n        return a_, b_\n\n    def ssm(self, x):\n        y = []\n        a_, b_ = self.discretize()\n        h = 0\n        for k in range(x.shape[-1]):\n            h = a_[..., k] * h + b_[..., k] * x[..., k]\n            \n        for l in range(x.shape[-1]):\n            y.append((self.C[..., l] * h).sum(1, keepdims=True))   \n        \n        self.hidden_state.value = jax.nn.standardize(h.mean(0, keepdims=True))\n        return jnp.stack(y, -1)","metadata":{"id":"4qOdblU5HFyo","execution":{"iopub.status.busy":"2024-05-27T08:44:28.835062Z","iopub.execute_input":"2024-05-27T08:44:28.835323Z","iopub.status.idle":"2024-05-27T08:44:28.851707Z","shell.execute_reply.started":"2024-05-27T08:44:28.835301Z","shell.execute_reply":"2024-05-27T08:44:28.850778Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# class MultiHeadMamba(nn.Module):\n#     def setup(self):\n#         self.layernorm\n#         self.heads = [Mamba() for _ in range(n_heads)]\n#         self.rms_norm = nn.RMSNorm()\n\n#     def __call__(self, x):\n#         out = jnp.concatenate([h(x) for h in self.heads], axis=-1)\n#         x = self.rms_norm(out)\n#         return x","metadata":{"id":"0bH9vlLZHFyq","execution":{"iopub.status.busy":"2024-05-27T08:44:28.852872Z","iopub.execute_input":"2024-05-27T08:44:28.853203Z","iopub.status.idle":"2024-05-27T08:44:28.865413Z","shell.execute_reply.started":"2024-05-27T08:44:28.853173Z","shell.execute_reply":"2024-05-27T08:44:28.864502Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# class FeedForward(nn.Module):\n#     def setup(self):\n#         self.ffn = nn.Sequential([\n#             nn.Dense(4 * n_embd),\n#             nn.relu,\n#             nn.Dense(n_embd)]\n#         )\n#     def __call__(self, x):\n#         return self.ffn(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T08:44:28.866611Z","iopub.execute_input":"2024-05-27T08:44:28.866905Z","iopub.status.idle":"2024-05-27T08:44:28.879807Z","shell.execute_reply.started":"2024-05-27T08:44:28.866882Z","shell.execute_reply":"2024-05-27T08:44:28.878974Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# class MambaBlock(nn.Module):\n#     def setup(self):\n#         self.mamba_block = Mamba()\n#         self.ln1 = nn.RMSNorm()\n#         self.ffn = FeedForward()\n#         self.ln2 = nn.LayerNorm()\n\n#     def __call__(self, x):\n#         x = x + self.mamba_block(self.ln2(x))\n#         x = x + self.ffn(self.ln1(x))\n#         return x\n","metadata":{"id":"UiCxIjoEp2QA","execution":{"iopub.status.busy":"2024-05-27T08:44:28.880895Z","iopub.execute_input":"2024-05-27T08:44:28.881200Z","iopub.status.idle":"2024-05-27T08:44:28.890334Z","shell.execute_reply.started":"2024-05-27T08:44:28.881177Z","shell.execute_reply":"2024-05-27T08:44:28.889452Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# class MambaModel(nn.Module):\n\n#     def setup(self):\n#         self.tok_embeddings = nn.Embed(vocab_size, n_embd)\n#         self.pos_embeddings = nn.Embed(block_size, n_embd)\n#         self.ln = nn.LayerNorm()\n#         self.mamba_layers = [MambaBlock() for _ in range(n_layers)]\n#         self.preds_out = nn.Dense(vocab_size)\n\n#     def __call__(self, x, training: bool):\n#         x = self.tok_embeddings(x) + self.pos_embeddings(jnp.arange(block_size))\n# #         x = self.ln(x)\n#         for layer in self.mamba_layers:\n#             x = layer(x)\n            \n#         return self.preds_out(x)\n\n#     @jax.jit\n#     def generate(self, idx, max_new_tokens, params):\n#     # idx is (B, T) array of indices in the current context\n#         for _ in range(max_new_tokens):\n#             # crop idx to the last block_size tokens\n#             idx_cond = idx[:, -block_size:]\n#             # get the predictions\n#             logits = self.apply(params, idx_cond)\n#             # focus only on the last time step\n#             logits = logits[:, -1, :] # becomes (B, C)\n#             # apply softmax to get probabilities\n#             ##probs = tf.keras.activations.softmax(logits, dim=-1) # (B, C)\n#             # sample from the distribution\n#             idx_next = jax.random.categorical(jax.random.PRNGKey(52), logits) # (B, 1)\n#             # append sampled index to the running sequence\n#             idx = jax.numpy.expand_dims(jnp.concatenate([idx[0], idx_next], axis=0), 0) # (B, T+1)\n#     #         print(idx_next)\n#     #         print(idx)\n\n#         return idx","metadata":{"id":"y4C7OWL8HFyq","execution":{"iopub.status.busy":"2024-05-27T08:44:28.891409Z","iopub.execute_input":"2024-05-27T08:44:28.891713Z","iopub.status.idle":"2024-05-27T08:44:28.902931Z","shell.execute_reply.started":"2024-05-27T08:44:28.891690Z","shell.execute_reply":"2024-05-27T08:44:28.902110Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# model = Mamba()\n# params = model.init(jax.random.key(42), jnp.ones((1,64,256)))\n# # print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# # print(model.tabulate(jax.random.key(0), jnp.ones((1,64,256)),\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xs = model.apply(params, jnp.ones((1,64,256)), mutable=['other_variables'])\n# # # print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# xb.shape, xs[0].shape, xs[1].keys()","metadata":{"id":"wTd3jSQWHFyp","execution":{"iopub.status.busy":"2024-05-27T08:44:28.904053Z","iopub.execute_input":"2024-05-27T08:44:28.904337Z","iopub.status.idle":"2024-05-27T08:44:28.917161Z","shell.execute_reply.started":"2024-05-27T08:44:28.904314Z","shell.execute_reply":"2024-05-27T08:44:28.916234Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# print(xs[1]['other_variables']['hidden_state'].shape, xs[1]['other_variables']['hidden_state'].min(), xs[1]['other_variables']['hidden_state'].max())","metadata":{"execution":{"iopub.status.busy":"2024-05-27T08:44:28.918300Z","iopub.execute_input":"2024-05-27T08:44:28.918576Z","iopub.status.idle":"2024-05-27T08:44:28.933360Z","shell.execute_reply.started":"2024-05-27T08:44:28.918553Z","shell.execute_reply":"2024-05-27T08:44:28.932496Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# xfs = model.apply(params, 2*jnp.ones((1,64,256)), mutable=['other_variables'])\n# print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# print(xfs[1]['other_variables']['hidden_state'].shape, xfs[1]['other_variables']['hidden_state'].min(), xfs[1]['other_variables']['hidden_state'].max())","metadata":{"execution":{"iopub.status.busy":"2024-05-27T08:44:28.934407Z","iopub.execute_input":"2024-05-27T08:44:28.934762Z","iopub.status.idle":"2024-05-27T08:44:28.944664Z","shell.execute_reply.started":"2024-05-27T08:44:28.934732Z","shell.execute_reply":"2024-05-27T08:44:28.943744Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# test_model = Mamba()\n# test_params = test_model.init(jax.random.key(42), xb)\n# n_params = sum(p.size for p in jax.tree_util.tree_leaves(test_params))\n# print(f\"Total number of parameters: {n_params:_}\")\n# # print(fin_model.tabulate(jax.random.key(42), xb,\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xf = test_model.apply(test_params, xb)\n# xb.shape, xf.shape","metadata":{"id":"cm2a0nepHFyq","execution":{"iopub.status.busy":"2024-05-27T08:44:28.945595Z","iopub.execute_input":"2024-05-27T08:44:28.945875Z","iopub.status.idle":"2024-05-27T08:44:28.955286Z","shell.execute_reply.started":"2024-05-27T08:44:28.945847Z","shell.execute_reply":"2024-05-27T08:44:28.954411Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class NanoLM(nn.Module):\n    \"\"\"NanoLM model.\"\"\"\n    vocab_size: int = 65\n    num_layers: int = 6\n    num_heads: int = 8\n    head_size: int = 32\n    dropout_rate: float = 0.2\n    embed_size: int = 256\n    block_size: int = 64\n\n    @nn.compact\n    def __call__(self, x, training: bool):\n        x = nn.Embed(self.vocab_size, self.embed_size)(x) + nn.Embed(\n            self.block_size, self.embed_size\n        )(jnp.arange(self.block_size))\n        \n        for i in range(self.num_layers):\n            x_norm = nn.LayerNorm()(x)\n#             x = x + nn.MultiHeadDotProductAttention(\n#               num_heads=self.num_heads,\n#               qkv_features=self.head_size,\n#               out_features=self.head_size * self.num_heads,\n#               dropout_rate=self.dropout_rate,\n#             )(\n#               x_norm,\n#               x_norm,\n#               mask=jnp.tril(jnp.ones((x.shape[-2], x.shape[-2]))),\n#               deterministic=not training,\n#             )\n    \n            x = x + Mamba()(x_norm)\n\n#             x = x + nn.Sequential([\n#               nn.Dense(4 * self.embed_size),\n#               nn.relu,\n#               nn.Dropout(self.dropout_rate, deterministic=not training),\n#               nn.Dense(self.embed_size),\n#             ])(nn.LayerNorm()(x))\n\n        x = nn.LayerNorm()(x)\n        return nn.Dense(self.vocab_size)(x)","metadata":{"id":"zuiaFP6WHFyr","execution":{"iopub.status.busy":"2024-05-27T08:44:28.956322Z","iopub.execute_input":"2024-05-27T08:44:28.956622Z","iopub.status.idle":"2024-05-27T08:44:28.968947Z","shell.execute_reply.started":"2024-05-27T08:44:28.956577Z","shell.execute_reply":"2024-05-27T08:44:28.968088Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# key = jax.random.key(42)\n\n# # fin_model = MambaModel()\n# # fin_params = fin_model.init(key, xb, training=False)\n\n\n# fin_model = NanoLM(\n#     vocab_size=vocab_size,\n#     num_layers=n_layers,\n#     num_heads=8,\n#     head_size=32,\n#     dropout_rate=0.2,\n#     embed_size=n_embd,\n#     block_size=block_size,\n# )\n\n# fin_params = fin_model.init(\n#     {'params': key},\n#     jnp.ones((batch_size, block_size), dtype=jnp.int32),\n#     training=False\n# )\n\n# n_params = sum(p.size for p in jax.tree_util.tree_leaves(fin_params))\n# print(f\"Total number of parameters: {n_params:_}\")\n# # print(fin_model.tabulate(jax.random.key(42), xb,\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xf = fin_model.apply(fin_params, xb, training=False)[0]\n# xb.shape, xf.shape","metadata":{"id":"fnUQPyuvHFys","outputId":"f04ebf31-d67f-4488-dd5d-7fd5b20dd1ea","execution":{"iopub.status.busy":"2024-05-27T08:44:28.969887Z","iopub.execute_input":"2024-05-27T08:44:28.970123Z","iopub.status.idle":"2024-05-27T08:44:28.983844Z","shell.execute_reply.started":"2024-05-27T08:44:28.970103Z","shell.execute_reply":"2024-05-27T08:44:28.983028Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def loss_fun(params, x, y, var_params,dropout_key):\n    logits, updated_variables = model.apply({'params': params, **var_params}, x, training=True, rngs={\"dropout\": dropout_key}, mutable=['other_variables'])\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), (updated_variables, accuracy)\n\n@jax.jit\ndef eval_step(params, x, y, var_params):\n    logits, _ = model.apply({'params': params, **var_params}, x, training=False, mutable=['other_variables'])\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), accuracy","metadata":{"execution":{"iopub.status.busy":"2024-05-27T08:44:28.984955Z","iopub.execute_input":"2024-05-27T08:44:28.985250Z","iopub.status.idle":"2024-05-27T08:44:28.999925Z","shell.execute_reply.started":"2024-05-27T08:44:28.985227Z","shell.execute_reply":"2024-05-27T08:44:28.998975Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"key = jax.random.PRNGKey(42)\nkey, subkey = jax.random.split(key)\n\nmodel = NanoLM(\n    vocab_size=vocab_size,\n    num_layers=n_layers,\n    num_heads=8,\n    head_size=32,\n    dropout_rate=0.2,\n    embed_size=n_embd,\n    block_size=block_size,\n)\n\nvar_params = model.init(\n    key,\n    jnp.ones((batch_size, block_size), dtype=jnp.int32),\n    training=False,\n)\nprint(var_params.keys())\nn_params = sum(p.size for p in jax.tree_util.tree_leaves(var_params))\n\nprint(f\"Total number of parameters: {n_params:_}\")","metadata":{"id":"PKpb3864HFyt","execution":{"iopub.status.busy":"2024-05-27T08:44:29.000911Z","iopub.execute_input":"2024-05-27T08:44:29.001173Z","iopub.status.idle":"2024-05-27T08:44:39.392792Z","shell.execute_reply.started":"2024-05-27T08:44:29.001151Z","shell.execute_reply":"2024-05-27T08:44:39.391825Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"dict_keys(['params', 'other_variables'])\nTotal number of parameters: 14_680_641\n","output_type":"stream"}]},{"cell_type":"code","source":"params = var_params.pop('params')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T08:44:39.394281Z","iopub.execute_input":"2024-05-27T08:44:39.395117Z","iopub.status.idle":"2024-05-27T08:44:39.399504Z","shell.execute_reply.started":"2024-05-27T08:44:39.395079Z","shell.execute_reply":"2024-05-27T08:44:39.398591Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"var_params = jax.tree_map(lambda x: jnp.zeros_like(x), var_params)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T08:44:39.400800Z","iopub.execute_input":"2024-05-27T08:44:39.401626Z","iopub.status.idle":"2024-05-27T08:44:39.417569Z","shell.execute_reply.started":"2024-05-27T08:44:39.401591Z","shell.execute_reply":"2024-05-27T08:44:39.416779Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# decay_rate = 0.96\n# learning_rate_schedule = optax.exponential_decay(learning_rate, decay_rate, max_iters//1000)\nopt = optax.adamw(learning_rate=learning_rate)\n\nopt_state = opt.init(params)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T08:44:39.424728Z","iopub.execute_input":"2024-05-27T08:44:39.425084Z","iopub.status.idle":"2024-05-27T08:44:39.862565Z","shell.execute_reply.started":"2024-05-27T08:44:39.425061Z","shell.execute_reply":"2024-05-27T08:44:39.861508Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"%%time\n\nall_train_losses = []\nall_eval_losses = []\n\nall_train_accuracy =  []\nall_test_accuracy = []\n\n# we define one iteration of the optimizer and JIT this function\n@jax.jit\ndef step(key, params, var_params, opt_state):\n    key, subkey = jax.random.split(key)\n    xb, yb = get_batch(key, train_data)\n    (loss, aux_data), grad = jax.value_and_grad(loss_fun, has_aux=True)(params, xb, yb, var_params, subkey)\n    var_params, train_accuracy = aux_data\n    updates, opt_state = opt.update(grad, opt_state, params)\n    params = optax.apply_updates(params, updates)\n    return params, key, opt_state, loss, var_params, train_accuracy\n\n# for i in tqdm(range(max_iters)):\ncounter = 0\nloss = 10\nwhile counter<max_iters: # and loss > 1.0:\n\n    params, key, opt_state, loss, var_params, train_accuracy = step(key, params, var_params, opt_state)\n    \n\n    # once every N_FREQ_EVAL we compute loss on the validation set\n    if counter % eval_iters == 0:\n        key, subkey = jax.random.split(key)\n        eval_loss, eval_accuracy = eval_step(params, *get_batch(subkey, test_data), var_params)\n        all_train_losses.append(loss)\n        all_eval_losses.append(eval_loss)\n        all_train_accuracy.append(train_accuracy)\n        all_test_accuracy.append(eval_accuracy)\n        print('##########################################################')\n        print(f\"Step: {counter}\\t train loss: {loss}\\t train accuracy: {train_accuracy}\")\n        print(f\"Step: {counter}\\t eval loss: {eval_loss}\\t eval accuracy: {eval_accuracy}\")\n        \n    counter += 1\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-27T08:44:39.863942Z","iopub.execute_input":"2024-05-27T08:44:39.864328Z","iopub.status.idle":"2024-05-27T10:47:47.024345Z","shell.execute_reply.started":"2024-05-27T08:44:39.864294Z","shell.execute_reply":"2024-05-27T10:47:47.023295Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"2024-05-27 08:45:14.722160: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[512,768,64]{2,1,0}, u8[0]{0}) custom-call(f32[512,768,64]{2,1,0}, f32[768,768,3]{2,1,0}), window={size=3 pad=1_1}, dim_labels=bf0_oi0->bf0, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-05-27 08:45:16.762130: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.040081345s\nTrying algorithm eng0{} for conv (f32[512,768,64]{2,1,0}, u8[0]{0}) custom-call(f32[512,768,64]{2,1,0}, f32[768,768,3]{2,1,0}), window={size=3 pad=1_1}, dim_labels=bf0_oi0->bf0, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n","output_type":"stream"},{"name":"stdout","text":"##########################################################\nStep: 0\t train loss: 4.6565728187561035\t train accuracy: 0.01483154296875\nStep: 0\t eval loss: 4.555761814117432\t eval accuracy: 0.022064208984375\n##########################################################\nStep: 100\t train loss: 0.5409586429595947\t train accuracy: 0.869964599609375\nStep: 100\t eval loss: 0.5457237958908081\t eval accuracy: 0.86749267578125\n##########################################################\nStep: 200\t train loss: 0.0906335711479187\t train accuracy: 0.978851318359375\nStep: 200\t eval loss: 0.096336230635643\t eval accuracy: 0.97869873046875\n##########################################################\nStep: 300\t train loss: 0.07442846149206161\t train accuracy: 0.982757568359375\nStep: 300\t eval loss: 0.07850147783756256\t eval accuracy: 0.982025146484375\n##########################################################\nStep: 400\t train loss: 0.04991289973258972\t train accuracy: 0.98760986328125\nStep: 400\t eval loss: 0.06083737313747406\t eval accuracy: 0.9857177734375\n##########################################################\nStep: 500\t train loss: 0.044181276112794876\t train accuracy: 0.988372802734375\nStep: 500\t eval loss: 0.044981636106967926\t eval accuracy: 0.9884033203125\n##########################################################\nStep: 600\t train loss: 0.03380957245826721\t train accuracy: 0.990875244140625\nStep: 600\t eval loss: 0.03862963616847992\t eval accuracy: 0.98944091796875\n##########################################################\nStep: 700\t train loss: 0.033334821462631226\t train accuracy: 0.9906005859375\nStep: 700\t eval loss: 0.036045849323272705\t eval accuracy: 0.98980712890625\n##########################################################\nStep: 800\t train loss: 0.03338347747921944\t train accuracy: 0.9906005859375\nStep: 800\t eval loss: 0.03576241061091423\t eval accuracy: 0.990234375\n##########################################################\nStep: 900\t train loss: 0.11240898072719574\t train accuracy: 0.979583740234375\nStep: 900\t eval loss: 0.1929498314857483\t eval accuracy: 0.975067138671875\n##########################################################\nStep: 1000\t train loss: 0.05525301396846771\t train accuracy: 0.986541748046875\nStep: 1000\t eval loss: 0.060527149587869644\t eval accuracy: 0.98504638671875\n##########################################################\nStep: 1100\t train loss: 0.03234735131263733\t train accuracy: 0.991058349609375\nStep: 1100\t eval loss: 0.03798598796129227\t eval accuracy: 0.990142822265625\n##########################################################\nStep: 1200\t train loss: 0.036193203181028366\t train accuracy: 0.990386962890625\nStep: 1200\t eval loss: 0.03675445169210434\t eval accuracy: 0.99005126953125\n##########################################################\nStep: 1300\t train loss: 0.031716298311948776\t train accuracy: 0.990753173828125\nStep: 1300\t eval loss: 0.03300429508090019\t eval accuracy: 0.99053955078125\n##########################################################\nStep: 1400\t train loss: 0.02997611090540886\t train accuracy: 0.9915771484375\nStep: 1400\t eval loss: 0.03293348103761673\t eval accuracy: 0.99005126953125\n##########################################################\nStep: 1500\t train loss: 0.032057587057352066\t train accuracy: 0.990692138671875\nStep: 1500\t eval loss: 0.03193866088986397\t eval accuracy: 0.99090576171875\n##########################################################\nStep: 1600\t train loss: 0.029296934604644775\t train accuracy: 0.9913330078125\nStep: 1600\t eval loss: 0.03375949710607529\t eval accuracy: 0.990936279296875\n##########################################################\nStep: 1700\t train loss: 0.02978368103504181\t train accuracy: 0.9912109375\nStep: 1700\t eval loss: 0.03170904517173767\t eval accuracy: 0.9908447265625\n##########################################################\nStep: 1800\t train loss: 0.029818233102560043\t train accuracy: 0.991241455078125\nStep: 1800\t eval loss: 0.04008367657661438\t eval accuracy: 0.987945556640625\n##########################################################\nStep: 1900\t train loss: 0.030449971556663513\t train accuracy: 0.99127197265625\nStep: 1900\t eval loss: 0.03156055510044098\t eval accuracy: 0.991241455078125\n##########################################################\nStep: 2000\t train loss: 0.0748075544834137\t train accuracy: 0.980560302734375\nStep: 2000\t eval loss: 0.07173167914152145\t eval accuracy: 0.981201171875\n##########################################################\nStep: 2100\t train loss: 0.029459472745656967\t train accuracy: 0.99169921875\nStep: 2100\t eval loss: 0.03184914216399193\t eval accuracy: 0.99102783203125\n##########################################################\nStep: 2200\t train loss: 0.03045310452580452\t train accuracy: 0.9913330078125\nStep: 2200\t eval loss: 0.031131893396377563\t eval accuracy: 0.991302490234375\n##########################################################\nStep: 2300\t train loss: 0.029404405504465103\t train accuracy: 0.991485595703125\nStep: 2300\t eval loss: 0.03192923218011856\t eval accuracy: 0.990631103515625\n##########################################################\nStep: 2400\t train loss: 0.028862832114100456\t train accuracy: 0.9910888671875\nStep: 2400\t eval loss: 0.03026459738612175\t eval accuracy: 0.991424560546875\n##########################################################\nStep: 2500\t train loss: 0.026559880003333092\t train accuracy: 0.992156982421875\nStep: 2500\t eval loss: 0.031198054552078247\t eval accuracy: 0.990447998046875\n##########################################################\nStep: 2600\t train loss: 0.027444684877991676\t train accuracy: 0.99163818359375\nStep: 2600\t eval loss: 0.030660361051559448\t eval accuracy: 0.990814208984375\n##########################################################\nStep: 2700\t train loss: 0.027344318106770515\t train accuracy: 0.99163818359375\nStep: 2700\t eval loss: 0.030598919838666916\t eval accuracy: 0.99090576171875\n##########################################################\nStep: 2800\t train loss: 0.027665315195918083\t train accuracy: 0.991485595703125\nStep: 2800\t eval loss: 0.03095533698797226\t eval accuracy: 0.99139404296875\n##########################################################\nStep: 2900\t train loss: 0.029061786830425262\t train accuracy: 0.99163818359375\nStep: 2900\t eval loss: 0.03239307925105095\t eval accuracy: 0.990875244140625\n##########################################################\nStep: 3000\t train loss: 0.029603231698274612\t train accuracy: 0.990692138671875\nStep: 3000\t eval loss: 0.03124111331999302\t eval accuracy: 0.991058349609375\n##########################################################\nStep: 3100\t train loss: 0.030693329870700836\t train accuracy: 0.99090576171875\nStep: 3100\t eval loss: 0.03123975172638893\t eval accuracy: 0.990753173828125\n##########################################################\nStep: 3200\t train loss: 0.027701716870069504\t train accuracy: 0.991607666015625\nStep: 3200\t eval loss: 0.03126674145460129\t eval accuracy: 0.990692138671875\n##########################################################\nStep: 3300\t train loss: 0.0382007397711277\t train accuracy: 0.9888916015625\nStep: 3300\t eval loss: 0.03998319059610367\t eval accuracy: 0.9881591796875\n##########################################################\nStep: 3400\t train loss: 0.0288127139210701\t train accuracy: 0.99163818359375\nStep: 3400\t eval loss: 0.030434349551796913\t eval accuracy: 0.9915771484375\n##########################################################\nStep: 3500\t train loss: 0.027346190065145493\t train accuracy: 0.991607666015625\nStep: 3500\t eval loss: 0.0325360968708992\t eval accuracy: 0.990814208984375\n##########################################################\nStep: 3600\t train loss: 0.025762267410755157\t train accuracy: 0.99249267578125\nStep: 3600\t eval loss: 0.030646517872810364\t eval accuracy: 0.99102783203125\n##########################################################\nStep: 3700\t train loss: 0.11535303294658661\t train accuracy: 0.97235107421875\nStep: 3700\t eval loss: 0.1391431987285614\t eval accuracy: 0.968170166015625\n##########################################################\nStep: 3800\t train loss: 0.032045766711235046\t train accuracy: 0.991424560546875\nStep: 3800\t eval loss: 0.03561614826321602\t eval accuracy: 0.99017333984375\n##########################################################\nStep: 3900\t train loss: 0.028565004467964172\t train accuracy: 0.9918212890625\nStep: 3900\t eval loss: 0.030651897192001343\t eval accuracy: 0.990814208984375\n##########################################################\nStep: 4000\t train loss: 0.027843330055475235\t train accuracy: 0.99139404296875\nStep: 4000\t eval loss: 0.03189585357904434\t eval accuracy: 0.991424560546875\n##########################################################\nStep: 4100\t train loss: 0.026890195906162262\t train accuracy: 0.992340087890625\nStep: 4100\t eval loss: 0.03102671168744564\t eval accuracy: 0.99066162109375\n##########################################################\nStep: 4200\t train loss: 0.02751787379384041\t train accuracy: 0.991668701171875\nStep: 4200\t eval loss: 0.03362024575471878\t eval accuracy: 0.9908447265625\n##########################################################\nStep: 4300\t train loss: 0.02595522440969944\t train accuracy: 0.9921875\nStep: 4300\t eval loss: 0.029134253039956093\t eval accuracy: 0.991851806640625\n##########################################################\nStep: 4400\t train loss: 0.026827190071344376\t train accuracy: 0.991943359375\nStep: 4400\t eval loss: 0.030059807002544403\t eval accuracy: 0.990936279296875\n##########################################################\nStep: 4500\t train loss: 0.04312986880540848\t train accuracy: 0.988800048828125\nStep: 4500\t eval loss: 0.04580853134393692\t eval accuracy: 0.988037109375\n##########################################################\nStep: 4600\t train loss: 0.028099501505494118\t train accuracy: 0.991668701171875\nStep: 4600\t eval loss: 0.03426457196474075\t eval accuracy: 0.990875244140625\n##########################################################\nStep: 4700\t train loss: 0.029275380074977875\t train accuracy: 0.991607666015625\nStep: 4700\t eval loss: 0.030526386573910713\t eval accuracy: 0.99139404296875\n##########################################################\nStep: 4800\t train loss: 0.030519850552082062\t train accuracy: 0.99139404296875\nStep: 4800\t eval loss: 0.032052017748355865\t eval accuracy: 0.991180419921875\n##########################################################\nStep: 4900\t train loss: 0.027451608330011368\t train accuracy: 0.992034912109375\nStep: 4900\t eval loss: 0.027793070301413536\t eval accuracy: 0.992034912109375\n##########################################################\nStep: 5000\t train loss: 0.027514994144439697\t train accuracy: 0.99212646484375\nStep: 5000\t eval loss: 0.029725372791290283\t eval accuracy: 0.991302490234375\n##########################################################\nStep: 5100\t train loss: 0.027994226664304733\t train accuracy: 0.991424560546875\nStep: 5100\t eval loss: 0.03040214255452156\t eval accuracy: 0.9913330078125\n##########################################################\nStep: 5200\t train loss: 0.027734901756048203\t train accuracy: 0.991973876953125\nStep: 5200\t eval loss: 0.029562007635831833\t eval accuracy: 0.99127197265625\n##########################################################\nStep: 5300\t train loss: 0.025884589180350304\t train accuracy: 0.992095947265625\nStep: 5300\t eval loss: 0.028574135154485703\t eval accuracy: 0.99151611328125\n##########################################################\nStep: 5400\t train loss: 0.02497074007987976\t train accuracy: 0.99261474609375\nStep: 5400\t eval loss: 0.030398111790418625\t eval accuracy: 0.991485595703125\n##########################################################\nStep: 5500\t train loss: 0.028166282922029495\t train accuracy: 0.9913330078125\nStep: 5500\t eval loss: 0.0317784808576107\t eval accuracy: 0.99090576171875\n##########################################################\nStep: 5600\t train loss: 0.02609967440366745\t train accuracy: 0.99169921875\nStep: 5600\t eval loss: 0.03099595569074154\t eval accuracy: 0.9913330078125\n##########################################################\nStep: 5700\t train loss: 0.025124315172433853\t train accuracy: 0.992340087890625\nStep: 5700\t eval loss: 0.02784022130072117\t eval accuracy: 0.991729736328125\n##########################################################\nStep: 5800\t train loss: 0.025064606219530106\t train accuracy: 0.992431640625\nStep: 5800\t eval loss: 0.030619487166404724\t eval accuracy: 0.99114990234375\n##########################################################\nStep: 5900\t train loss: 0.02420915476977825\t train accuracy: 0.99261474609375\nStep: 5900\t eval loss: 0.029209118336439133\t eval accuracy: 0.991790771484375\n##########################################################\nStep: 6000\t train loss: 0.02797052450478077\t train accuracy: 0.991546630859375\nStep: 6000\t eval loss: 0.02932245470583439\t eval accuracy: 0.991058349609375\n##########################################################\nStep: 6100\t train loss: 0.038912102580070496\t train accuracy: 0.988677978515625\nStep: 6100\t eval loss: 0.042380593717098236\t eval accuracy: 0.98834228515625\n##########################################################\nStep: 6200\t train loss: 0.024948451668024063\t train accuracy: 0.99237060546875\nStep: 6200\t eval loss: 0.028811471536755562\t eval accuracy: 0.991424560546875\n##########################################################\nStep: 6300\t train loss: 0.02632848545908928\t train accuracy: 0.99237060546875\nStep: 6300\t eval loss: 0.02953571453690529\t eval accuracy: 0.991729736328125\n##########################################################\nStep: 6400\t train loss: 0.027335986495018005\t train accuracy: 0.9918212890625\nStep: 6400\t eval loss: 0.029717855155467987\t eval accuracy: 0.991363525390625\n##########################################################\nStep: 6500\t train loss: 0.025924058631062508\t train accuracy: 0.99224853515625\nStep: 6500\t eval loss: 0.030137499794363976\t eval accuracy: 0.991302490234375\n##########################################################\nStep: 6600\t train loss: 0.0261823832988739\t train accuracy: 0.99212646484375\nStep: 6600\t eval loss: 0.028303159400820732\t eval accuracy: 0.991546630859375\n##########################################################\nStep: 6700\t train loss: 0.026426298543810844\t train accuracy: 0.991943359375\nStep: 6700\t eval loss: 0.028650738298892975\t eval accuracy: 0.991851806640625\n##########################################################\nStep: 6800\t train loss: 0.025817187502980232\t train accuracy: 0.9923095703125\nStep: 6800\t eval loss: 0.030091285705566406\t eval accuracy: 0.99151611328125\n##########################################################\nStep: 6900\t train loss: 0.023531464859843254\t train accuracy: 0.9927978515625\nStep: 6900\t eval loss: 0.028094500303268433\t eval accuracy: 0.991943359375\n##########################################################\nStep: 7000\t train loss: 0.02588774636387825\t train accuracy: 0.992095947265625\nStep: 7000\t eval loss: 0.02939169481396675\t eval accuracy: 0.99139404296875\n##########################################################\nStep: 7100\t train loss: 0.02602759748697281\t train accuracy: 0.992156982421875\nStep: 7100\t eval loss: 0.029125040397047997\t eval accuracy: 0.991302490234375\n##########################################################\nStep: 7200\t train loss: 0.03969864547252655\t train accuracy: 0.988983154296875\nStep: 7200\t eval loss: 0.03852295130491257\t eval accuracy: 0.98870849609375\n##########################################################\nStep: 7300\t train loss: 0.024567384272813797\t train accuracy: 0.99261474609375\nStep: 7300\t eval loss: 0.02728034183382988\t eval accuracy: 0.99200439453125\n##########################################################\nStep: 7400\t train loss: 0.024639151990413666\t train accuracy: 0.9923095703125\nStep: 7400\t eval loss: 0.028743093833327293\t eval accuracy: 0.991729736328125\n##########################################################\nStep: 7500\t train loss: 0.06926998496055603\t train accuracy: 0.986358642578125\nStep: 7500\t eval loss: 0.12319924682378769\t eval accuracy: 0.979461669921875\n##########################################################\nStep: 7600\t train loss: 0.026053685694932938\t train accuracy: 0.99212646484375\nStep: 7600\t eval loss: 0.02958444319665432\t eval accuracy: 0.9912109375\n##########################################################\nStep: 7700\t train loss: 0.028289172798395157\t train accuracy: 0.99188232421875\nStep: 7700\t eval loss: 0.03209808096289635\t eval accuracy: 0.990509033203125\n##########################################################\nStep: 7800\t train loss: 0.024321816861629486\t train accuracy: 0.99261474609375\nStep: 7800\t eval loss: 0.030543003231287003\t eval accuracy: 0.991241455078125\n##########################################################\nStep: 7900\t train loss: 0.025487728416919708\t train accuracy: 0.99224853515625\nStep: 7900\t eval loss: 0.029869701713323593\t eval accuracy: 0.99102783203125\n##########################################################\nStep: 8000\t train loss: 0.0252972524613142\t train accuracy: 0.992431640625\nStep: 8000\t eval loss: 0.027220573276281357\t eval accuracy: 0.99200439453125\n##########################################################\nStep: 8100\t train loss: 0.025482339784502983\t train accuracy: 0.992279052734375\nStep: 8100\t eval loss: 0.02955908328294754\t eval accuracy: 0.991363525390625\n##########################################################\nStep: 8200\t train loss: 0.02564840577542782\t train accuracy: 0.992523193359375\nStep: 8200\t eval loss: 0.029253127053380013\t eval accuracy: 0.9920654296875\n##########################################################\nStep: 8300\t train loss: 0.02474226802587509\t train accuracy: 0.9921875\nStep: 8300\t eval loss: 0.02831643633544445\t eval accuracy: 0.9915771484375\n##########################################################\nStep: 8400\t train loss: 0.02631959691643715\t train accuracy: 0.991607666015625\nStep: 8400\t eval loss: 0.028618013486266136\t eval accuracy: 0.99169921875\n##########################################################\nStep: 8500\t train loss: 0.02491704747080803\t train accuracy: 0.992401123046875\nStep: 8500\t eval loss: 0.02917814441025257\t eval accuracy: 0.99169921875\n##########################################################\nStep: 8600\t train loss: 0.025594521313905716\t train accuracy: 0.992401123046875\nStep: 8600\t eval loss: 0.026842720806598663\t eval accuracy: 0.9923095703125\n##########################################################\nStep: 8700\t train loss: 0.024957533925771713\t train accuracy: 0.99212646484375\nStep: 8700\t eval loss: 0.028678379952907562\t eval accuracy: 0.99176025390625\n##########################################################\nStep: 8800\t train loss: 0.02452138438820839\t train accuracy: 0.992706298828125\nStep: 8800\t eval loss: 0.02847788855433464\t eval accuracy: 0.99151611328125\n##########################################################\nStep: 8900\t train loss: 0.02505509927868843\t train accuracy: 0.991973876953125\nStep: 8900\t eval loss: 0.028847508132457733\t eval accuracy: 0.99127197265625\n##########################################################\nStep: 9000\t train loss: 0.025024835020303726\t train accuracy: 0.992156982421875\nStep: 9000\t eval loss: 0.027720995247364044\t eval accuracy: 0.991943359375\n##########################################################\nStep: 9100\t train loss: 0.024219036102294922\t train accuracy: 0.992645263671875\nStep: 9100\t eval loss: 0.02625700645148754\t eval accuracy: 0.992095947265625\n##########################################################\nStep: 9200\t train loss: 0.026028621941804886\t train accuracy: 0.992095947265625\nStep: 9200\t eval loss: 0.02931065298616886\t eval accuracy: 0.99114990234375\n##########################################################\nStep: 9300\t train loss: 0.0749211236834526\t train accuracy: 0.980804443359375\nStep: 9300\t eval loss: 0.05938175693154335\t eval accuracy: 0.983612060546875\n##########################################################\nStep: 9400\t train loss: 0.026052657514810562\t train accuracy: 0.992279052734375\nStep: 9400\t eval loss: 0.029405342414975166\t eval accuracy: 0.991729736328125\n##########################################################\nStep: 9500\t train loss: 0.02501610666513443\t train accuracy: 0.992401123046875\nStep: 9500\t eval loss: 0.02928698994219303\t eval accuracy: 0.9918212890625\n##########################################################\nStep: 9600\t train loss: 0.02860882505774498\t train accuracy: 0.99127197265625\nStep: 9600\t eval loss: 0.030616242438554764\t eval accuracy: 0.9912109375\n##########################################################\nStep: 9700\t train loss: 0.02391429804265499\t train accuracy: 0.99267578125\nStep: 9700\t eval loss: 0.028859006240963936\t eval accuracy: 0.99200439453125\n##########################################################\nStep: 9800\t train loss: 0.02382132224738598\t train accuracy: 0.99261474609375\nStep: 9800\t eval loss: 0.028211303055286407\t eval accuracy: 0.99139404296875\n##########################################################\nStep: 9900\t train loss: 0.02471865713596344\t train accuracy: 0.9920654296875\nStep: 9900\t eval loss: 0.029523158445954323\t eval accuracy: 0.991424560546875\nCPU times: user 1h 12min 20s, sys: 50min 47s, total: 2h 3min 8s\nWall time: 2h 3min 7s\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt  # Visualization\n\n# Plot loss and accuracy in subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.set_title('Loss')\nax2.set_title('Accuracy')\n\n\n\nax1.plot(all_train_losses, label='train_loss')\nax1.plot(all_eval_losses, label='eval_loss')\n\nax2.plot(all_train_accuracy, label='train_accuracy')\nax2.plot(all_test_accuracy, label='eval_accuracy')\n\nax1.legend()\nax2.legend()\nplt.show()\nplt.clf()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:47:47.025941Z","iopub.execute_input":"2024-05-27T10:47:47.026638Z","iopub.status.idle":"2024-05-27T10:47:47.500466Z","shell.execute_reply.started":"2024-05-27T10:47:47.026598Z","shell.execute_reply":"2024-05-27T10:47:47.499601Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x500 with 2 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"@partial(jax.jit, static_argnames=(\"length\"))\ndef generate_text(rng, params, var_params, length):\n    def _scan_generate(carry, _):\n        random_key, context = carry\n        logits = model.apply({'params': params, **var_params}, context, training=False, mutable=['other_variables'])[0]\n        rng, rng_subkey = jax.random.split(random_key)\n        new_token = jax.random.categorical(\n          rng_subkey, logits[:, -n_tokens, :], axis=-1, shape=(1, 1)\n        )\n        context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n        return (rng, context), new_token\n\n    _, new_tokens = jax.lax.scan(\n    _scan_generate,\n    (rng, jnp.zeros((1, block_size), dtype=jnp.int32)),\n    (),\n    length=length,\n    )\n    return new_tokens","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:47:47.501844Z","iopub.execute_input":"2024-05-27T10:47:47.502137Z","iopub.status.idle":"2024-05-27T10:47:47.510470Z","shell.execute_reply.started":"2024-05-27T10:47:47.502112Z","shell.execute_reply":"2024-05-27T10:47:47.509549Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"new_tokenz = 1000\nkey, subkey = jax.random.split(jax.random.PRNGKey(156))\n# key, subkey = jax.random.split(key)\n# token_gen = generate_text(jnp.zeros((1,block_size)).astype(jnp.int32), new_tokenz, {'params': state.params})\ntoken_gen = generate_text(key, params, var_params, new_tokenz)[:, 0, 0].tolist()\nprint(token_gen)\nprint(decode(token_gen))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:47:47.511757Z","iopub.execute_input":"2024-05-27T10:47:47.512078Z","iopub.status.idle":"2024-05-27T10:48:09.368659Z","shell.execute_reply.started":"2024-05-27T10:47:47.512049Z","shell.execute_reply":"2024-05-27T10:48:09.367653Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"[24, 13, 30, 32, 21, 33, 31, 10, 0, 27, 6, 1, 50, 53, 56, 42, 8, 1, 14, 59, 58, 1, 60, 53, 47, 60, 47, 52, 45, 57, 6, 1, 42, 53, 1, 21, 1, 41, 39, 52, 52, 53, 58, 1, 57, 53, 56, 56, 53, 51, 1, 60, 43, 56, 63, 1, 49, 52, 53, 61, 8, 0, 27, 56, 1, 41, 50, 53, 58, 56, 47, 52, 45, 6, 0, 13, 54, 54, 50, 43, 53, 1, 58, 46, 43, 1, 41, 39, 50, 50, 1, 58, 46, 43, 0, 49, 47, 57, 50, 43, 56, 57, 1, 53, 40, 43, 63, 6, 1, 40, 53, 58, 46, 1, 58, 53, 1, 58, 46, 43, 1, 40, 56, 52, 39, 1, 46, 59, 51, 40, 43, 56, 57, 63, 8, 0, 37, 53, 59, 56, 1, 55, 59, 39, 56, 57, 1, 42, 53, 1, 51, 59, 41, 49, 51, 39, 45, 43, 6, 1, 47, 52, 60, 39, 52, 58, 10, 0, 25, 39, 56, 45, 39, 56, 1, 46, 39, 42, 1, 51, 43, 52, 8, 0, 21, 1, 41, 53, 59, 52, 58, 57, 1, 58, 46, 47, 57, 2, 0, 26, 47, 45, 46, 40, 43, 56, 58, 63, 1, 51, 53, 41, 49, 43, 42, 1, 40, 43, 44, 53, 56, 43, 1, 58, 46, 43, 1, 43, 39, 56, 56, 43, 50, 1, 53, 59, 56, 57, 43, 50, 60, 43, 57, 6, 0, 31, 58, 6, 1, 39, 57, 1, 53, 40, 46, 53, 50, 43, 6, 1, 51, 63, 1, 61, 47, 58, 46, 1, 54, 56, 43, 57, 43, 52, 45, 43, 56, 57, 1, 43, 39, 57, 58, 43, 56, 6, 1, 39, 58, 1, 40, 43, 45, 47, 52, 45, 1, 40, 39, 56, 56, 63, 8, 0, 0, 14, 17, 26, 34, 27, 24, 21, 27, 10, 0, 57, 46, 53, 61, 1, 46, 53, 53, 42, 11, 1, 45, 47, 60, 43, 1, 51, 39, 49, 43, 1, 58, 53, 1, 57, 39, 63, 6, 1, 44, 53, 56, 1, 58, 46, 53, 59, 1, 52, 53, 58, 1, 51, 43, 6, 1, 61, 46, 53, 51, 6, 1, 46, 43, 1, 61, 47, 50, 50, 1, 39, 58, 58, 43, 56, 8, 0, 0, 19, 53, 8, 0, 0, 13, 33, 32, 27, 24, 37, 15, 33, 31, 10, 0, 27, 6, 1, 57, 47, 56, 8, 1, 27, 6, 1, 46, 43, 56, 43, 1, 39, 52, 42, 1, 56, 53, 53, 50, 6, 1, 21, 1, 57, 39, 63, 1, 52, 53, 61, 1, 21, 1, 61, 47, 58, 46, 1, 40, 43, 52, 47, 58, 63, 1, 51, 39, 47, 42, 50, 63, 1, 41, 53, 52, 48, 59, 42, 45, 43, 6, 1, 57, 46, 53, 59, 50, 42, 0, 32, 47, 57, 1, 54, 39, 47, 56, 57, 1, 56, 47, 57, 58, 39, 52, 42, 57, 6, 1, 57, 58, 39, 63, 51, 43, 51, 40, 50, 43, 57, 57, 1, 58, 53, 1, 54, 50, 43, 39, 57, 43, 57, 6, 0, 19, 56, 39, 47, 52, 1, 58, 46, 43, 52, 1, 21, 1, 51, 59, 56, 42, 43, 56, 1, 21, 1, 41, 56, 53, 61, 40, 56, 47, 52, 45, 6, 1, 39, 57, 1, 58, 46, 56, 53, 39, 58, 47, 57, 44, 47, 58, 12, 1, 39, 52, 45, 43, 42, 1, 57, 46, 39, 50, 50, 1, 39, 54, 54, 43, 52, 58, 1, 44, 53, 50, 50, 53, 61, 1, 53, 59, 56, 1, 61, 39, 56, 50, 1, 58, 46, 43, 1, 54, 56, 53, 44, 53, 59, 57, 1, 47, 58, 1, 57, 47, 42, 43, 57, 6, 1, 50, 43, 58, 57, 6, 1, 52, 53, 52, 43, 6, 1, 54, 56, 43, 60, 43, 52, 1, 40, 43, 44, 53, 56, 43, 57, 10, 0, 35, 46, 63, 6, 1, 58, 46, 63, 1, 45, 53, 53, 42, 6, 1, 57, 47, 58, 6, 1, 44, 56, 53, 51, 1, 58, 46, 56, 47, 60, 43, 1, 58, 43, 50, 50, 5, 42, 0, 20, 43, 52, 56, 1, 58, 46, 50, 43, 63, 6, 0, 27, 56, 1, 61, 46, 47, 41, 46, 1, 45, 53, 50, 42, 1, 63, 53, 59, 56, 1, 54, 53, 61, 43, 56, 8, 1, 21, 1, 54, 56, 39, 63, 1, 39, 52, 63, 47, 52, 45, 52, 47, 58, 63, 6, 1, 25, 39, 57, 58, 43, 6, 1, 51, 63, 1, 50, 53, 56, 42, 8, 0, 44, 53, 56, 58, 1, 47, 52, 44, 43, 8, 1, 37, 53, 59, 8, 0, 0, 37, 27, 30, 23, 10, 0, 31, 61, 47, 44, 43, 1, 40, 59, 58, 1, 21, 1, 42, 47, 42, 1, 51, 53, 56, 43, 1, 39, 50, 41, 43, 1, 58, 46, 47, 57, 11, 1, 58, 46, 43, 47, 56, 1, 61, 53, 51, 39, 52, 43, 8, 0, 26, 53, 58, 0, 13, 52, 42, 1, 58, 46, 53, 59, 1, 61, 46, 53, 1, 46, 53, 54, 53, 59, 58, 1, 61, 47, 58, 46, 1, 54, 56, 43, 40, 50, 43, 47, 57, 43, 1, 39, 1, 55, 59, 47, 43, 58, 50, 43, 8, 0, 0, 24, 33, 15, 21, 27, 10, 0, 32, 46, 43, 56, 43, 42, 1, 44, 53, 56, 1, 39, 52, 1, 41, 39, 58, 56, 43, 39, 49, 57, 1, 51, 39, 49, 43, 1, 40, 43, 58, 61, 47, 62, 6, 1, 57, 47, 56, 8, 0, 0, 15, 24, 13, 30, 17, 26, 15, 17, 10, 0, 35, 47, 58, 46, 1, 58, 46, 43, 1, 51, 59, 57, 58, 1, 51, 43, 1, 52, 53, 58, 1, 58, 53, 1, 50, 43, 57, 59, 51, 54, 43, 58, 2, 1, 61, 46, 63, 6, 1, 52, 53, 58, 1, 40, 43, 1, 44, 50, 53, 59, 57, 1, 51, 43, 6, 1, 58]\nLARTIUS:\nO, lord. But voivings, do I cannot sorrom very know.\nOr clotring,\nAppleo the call the\nkislers obey, both to the brna humbersy.\nYour quars do muckmage, invant:\nMargar had men.\nI counts this!\nNighberty mocked before the earrel ourselves,\nSt, as obhole, my with presengers easter, at beging barry.\n\nBENVOLIO:\nshow hood; give make to say, for thou not me, whom, he will atter.\n\nGo.\n\nAUTOLYCUS:\nO, sir. O, here and rool, I say now I with benity maidly conjudge, should\nTis pairs ristands, staymembless to pleases,\nGrain then I murder I crowbring, as throatisfit? anged shall appent follow our warl the profous it sides, lets, none, preven befores:\nWhy, thy good, sit, from thrive tell'd\nHenr thley,\nOr which gold your power. I pray anyingnity, Maste, my lord.\nfort infe. You.\n\nYORK:\nSwife but I did more alce this; their womane.\nNot\nAnd thou who hopout with prebleise a quietle.\n\nLUCIO:\nThered for an catreaks make betwix, sir.\n\nCLARENCE:\nWith the must me not to lesumpet! why, not be flous me, t\n","output_type":"stream"}]},{"cell_type":"code","source":"dsfsdhfgjdg hfdgjdgjgfjhs'####################","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:48:09.369776Z","iopub.execute_input":"2024-05-27T10:48:09.370061Z","iopub.status.idle":"2024-05-27T10:48:09.375985Z","shell.execute_reply.started":"2024-05-27T10:48:09.370036Z","shell.execute_reply":"2024-05-27T10:48:09.374891Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[33], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    dsfsdhfgjdg hfdgjdgjgfjhs'####################\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"],"ename":"SyntaxError","evalue":"unterminated string literal (detected at line 1) (2630675753.py, line 1)","output_type":"error"}]},{"cell_type":"code","source":"var_params['other_variables']['Mamba_0']['hidden_state'].shape","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:48:09.376631Z","iopub.status.idle":"2024-05-27T10:48:09.376961Z","shell.execute_reply.started":"2024-05-27T10:48:09.376783Z","shell.execute_reply":"2024-05-27T10:48:09.376802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params.keys()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:48:09.377937Z","iopub.status.idle":"2024-05-27T10:48:09.378355Z","shell.execute_reply.started":"2024-05-27T10:48:09.378179Z","shell.execute_reply":"2024-05-27T10:48:09.378197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params['Dense_12']['kernel'].shape","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:48:09.379693Z","iopub.status.idle":"2024-05-27T10:48:09.380060Z","shell.execute_reply.started":"2024-05-27T10:48:09.379892Z","shell.execute_reply":"2024-05-27T10:48:09.379909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rngk = jax.random.PRNGKey(389)\nxs, ys = get_batch(rngk, train_data)\nprint(xs[0])\nprint(ys[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:48:09.381293Z","iopub.status.idle":"2024-05-27T10:48:09.381719Z","shell.execute_reply.started":"2024-05-27T10:48:09.381476Z","shell.execute_reply":"2024-05-27T10:48:09.381495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits = model.apply({'params': params, **var_params}, xs[0].reshape((1,64)), training=False, mutable=['other_variables'])[0]\nrng, rng_subkey = jax.random.split(rngk)\nfor pso in range(n_tokens):\n    new_token = jax.random.categorical(\n      rng_subkey, logits[:, -1*(n_tokens-pso), :], axis=-1, shape=(1, 1)\n    )\n    print(new_token)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:48:09.382991Z","iopub.status.idle":"2024-05-27T10:48:09.383293Z","shell.execute_reply.started":"2024-05-27T10:48:09.383143Z","shell.execute_reply":"2024-05-27T10:48:09.383155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_tok = [51,49,46,46,46,52]\nprint(decode(ys[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:48:09.384346Z","iopub.status.idle":"2024-05-27T10:48:09.384685Z","shell.execute_reply.started":"2024-05-27T10:48:09.384517Z","shell.execute_reply":"2024-05-27T10:48:09.384530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"act_tk = [60, 43, 50, 57,  1, 47]\nprint(decode(act_tk))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:48:09.385726Z","iopub.status.idle":"2024-05-27T10:48:09.386025Z","shell.execute_reply.started":"2024-05-27T10:48:09.385873Z","shell.execute_reply":"2024-05-27T10:48:09.385885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jax.nn.standardize(jnp.array([2.0,3.0,4.0]))","metadata":{"id":"Oe_GIDP2HFyt","outputId":"5d3dce16-fcc2-40b9-c49a-00a8c4013ca2","execution":{"iopub.status.busy":"2024-05-27T10:48:09.386952Z","iopub.status.idle":"2024-05-27T10:48:09.387251Z","shell.execute_reply.started":"2024-05-27T10:48:09.387102Z","shell.execute_reply":"2024-05-27T10:48:09.387114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@struct.dataclass\nclass Metrics(metrics.Collection):\n    accuracy: metrics.Accuracy\n    loss: metrics.Average.from_output('loss')","metadata":{"id":"s3nN1jOiHFyu","execution":{"iopub.status.busy":"2024-05-27T10:48:09.388920Z","iopub.status.idle":"2024-05-27T10:48:09.389249Z","shell.execute_reply.started":"2024-05-27T10:48:09.389088Z","shell.execute_reply":"2024-05-27T10:48:09.389102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainState(train_state.TrainState):\n    metrics: Metrics\n\ndef create_train_state(module, rng, learning_rate, train_shape):\n    \"\"\"Creates an initial `TrainState`.\"\"\"\n    params = module.init(rng, jnp.ones(train_shape).astype(jnp.int32), \n                         training=False)['params'] # initialize parameters by passing a template image\n    tx = optax.adamw(learning_rate)\n    return TrainState.create(\n      apply_fn=module.apply, params=params, tx=tx,\n      metrics=Metrics.empty(),\n    )","metadata":{"id":"7LLDTSFQHFyu","execution":{"iopub.status.busy":"2024-05-27T10:48:09.390574Z","iopub.status.idle":"2024-05-27T10:48:09.390900Z","shell.execute_reply.started":"2024-05-27T10:48:09.390740Z","shell.execute_reply":"2024-05-27T10:48:09.390754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TrainState.create(","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:48:09.392509Z","iopub.status.idle":"2024-05-27T10:48:09.392947Z","shell.execute_reply.started":"2024-05-27T10:48:09.392718Z","shell.execute_reply":"2024-05-27T10:48:09.392736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@jax.jit\ndef train_step(state, inputs, targets):\n    \"\"\"Train for a single step.\"\"\"\n    def loss_fn(params):\n        logits = state.apply_fn({'params': params}, inputs, training=True, \n                                rngs={\"dropout\": key})[0]\n        loss = optax.softmax_cross_entropy_with_integer_labels(\n            logits=logits, labels=targets).mean()\n        return loss\n    grad_fn = jax.grad(loss_fn)\n    grads = grad_fn(state.params)\n    state = state.apply_gradients(grads=grads)\n    return state","metadata":{"id":"zApWXUDaHFyu","execution":{"iopub.status.busy":"2024-05-27T10:48:09.394158Z","iopub.status.idle":"2024-05-27T10:48:09.394620Z","shell.execute_reply.started":"2024-05-27T10:48:09.394369Z","shell.execute_reply":"2024-05-27T10:48:09.394389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@jax.jit\ndef compute_metrics(*, state, inputs, targets):\n    logits = state.apply_fn({'params': state.params}, inputs, training=False)[0]\n    loss = optax.softmax_cross_entropy_with_integer_labels(\n        logits=logits, labels=targets).mean()\n    metric_updates = state.metrics.single_from_model_output(\n    logits=logits, labels=targets, loss=loss)\n    metrics = state.metrics.merge(metric_updates)\n    state = state.replace(metrics=metrics)\n    return state","metadata":{"id":"VzukZ4iEHFyv","execution":{"iopub.status.busy":"2024-05-27T10:48:09.396385Z","iopub.status.idle":"2024-05-27T10:48:09.396846Z","shell.execute_reply.started":"2024-05-27T10:48:09.396611Z","shell.execute_reply":"2024-05-27T10:48:09.396630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nlearning_rate = 0.005\ninit_rng = jax.random.key(0)","metadata":{"id":"ehYvMeuNHFyv","execution":{"iopub.status.busy":"2024-05-27T10:48:09.397987Z","iopub.status.idle":"2024-05-27T10:48:09.398467Z","shell.execute_reply.started":"2024-05-27T10:48:09.398221Z","shell.execute_reply":"2024-05-27T10:48:09.398238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state = create_train_state(fin_model, init_rng, learning_rate, train_shape)\ndel init_rng  # Must not be used anymore.","metadata":{"id":"D60UHLFHHFyv","execution":{"iopub.status.busy":"2024-05-27T10:48:09.400048Z","iopub.status.idle":"2024-05-27T10:48:09.400385Z","shell.execute_reply.started":"2024-05-27T10:48:09.400221Z","shell.execute_reply":"2024-05-27T10:48:09.400235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics_history = {'train_loss': [],\n                   'train_accuracy': [],\n                   'test_loss': [],\n                   'test_accuracy': []}","metadata":{"id":"Jl-9TlHEHFyv","execution":{"iopub.status.busy":"2024-05-27T10:48:09.401671Z","iopub.status.idle":"2024-05-27T10:48:09.402004Z","shell.execute_reply.started":"2024-05-27T10:48:09.401842Z","shell.execute_reply":"2024-05-27T10:48:09.401855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 442\nkey = jax.random.PRNGKey(SEED)\nloss = 10\ncounter = 0\n# for step in tqdm(range(max_iters)): # increase number of steps for good results...\nwhile counter==max_iters or loss > 1.0:\n\n      # sample a batch of data\n    xb, yb = get_batch(key, train_data)\n    state = train_step(state, xb, yb)\n    state = compute_metrics(state=state, inputs=xb, targets=yb)\n\n    key = (jax.random.split(key)[0])\n\n    if step == 0 or (step+1) % 100 == 0: # one training epoch has passed\n        for metric,value in state.metrics.compute().items(): # compute metrics\n            metrics_history[f'train_{metric}'].append(value) # record metrics\n        state = state.replace(metrics=state.metrics.empty()) # reset train_metrics for next training epoch\n\n        # Compute metrics on the test set after each training epoch\n        test_state = state\n        x_test, y_test = get_batch(key, test_data)\n    #     for test_batch in test_ds.as_numpy_iterator():\n        test_state = compute_metrics(state=test_state, inputs=x_test, targets=y_test)\n\n        for metric,value in test_state.metrics.compute().items():\n            metrics_history[f'test_{metric}'].append(value)\n\n        print(f\"train epoch: {(step+1)}, \"\n              f\"loss: {metrics_history['train_loss'][-1]}, \"\n              f\"accuracy: {metrics_history['train_accuracy'][-1] * 100}\")\n        print(f\"test epoch: {(step+1) }, \"\n          f\"loss: {metrics_history['test_loss'][-1]}, \"\n          f\"accuracy: {metrics_history['test_accuracy'][-1] * 100}\")","metadata":{"id":"CaNt9JazHFyw","outputId":"ba447ddf-9940-44a6-f4b2-d27ed78a88c2","execution":{"iopub.status.busy":"2024-05-27T10:48:09.403544Z","iopub.status.idle":"2024-05-27T10:48:09.403857Z","shell.execute_reply.started":"2024-05-27T10:48:09.403702Z","shell.execute_reply":"2024-05-27T10:48:09.403714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt  # Visualization\n\n# Plot loss and accuracy in subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.set_title('Loss')\nax2.set_title('Accuracy')\nfor dataset in ('train','test'):\n    ax1.plot(metrics_history[f'{dataset}_loss'], label=f'{dataset}_loss')\n    ax2.plot(metrics_history[f'{dataset}_accuracy'], label=f'{dataset}_accuracy')\nax1.legend()\nax2.legend()\nplt.show()\nplt.clf()","metadata":{"id":"Y40JGx1YHFyw","execution":{"iopub.status.busy":"2024-05-27T10:48:09.405414Z","iopub.status.idle":"2024-05-27T10:48:09.405780Z","shell.execute_reply.started":"2024-05-27T10:48:09.405616Z","shell.execute_reply":"2024-05-27T10:48:09.405631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlogits = fin_model.apply(fin_params, xb, training=False)[0]\nloss = optax.softmax_cross_entropy_with_integer_labels(\n            logits=logits, labels=yb).mean()\n\nprint(loss)","metadata":{"id":"7pJlFXpVHFyw","execution":{"iopub.status.busy":"2024-05-27T10:48:09.406749Z","iopub.status.idle":"2024-05-27T10:48:09.407062Z","shell.execute_reply.started":"2024-05-27T10:48:09.406901Z","shell.execute_reply":"2024-05-27T10:48:09.406914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def generate_text(idx, max_new_tokens, params):\n# # idx is (B, T) array of indices in the current context\n#     for i in range(max_new_tokens):\n#         # crop idx to the last block_size tokens\n#         idx_cond = idx[:, -block_size:]\n#         # get the predictions\n#         logits = fin_model.apply(params, idx_cond)\n#         # focus only on the last time step\n#         logits = logits[:, -1, :] # becomes (B, C)\n\n#         if i == 0:\n#             rng, rng_subkey = jax.random.split(jax.random.PRNGKey(12))\n#         else:\n#             rng, rng_subkey = jax.random.split(rng)\n\n#         idx_next = jax.random.categorical(rng_subkey, logits, axis=-1, shape=(1, 1)) # (B, 1)\n\n\n#         # append sampled index to the running sequence\n#         idx = jnp.concatenate([idx, idx_next], axis=-1) # (B, T+1)\n\n#     return idx","metadata":{"id":"9d28o-dTHFyx","execution":{"iopub.status.busy":"2024-05-27T10:48:09.408612Z","iopub.status.idle":"2024-05-27T10:48:09.408945Z","shell.execute_reply.started":"2024-05-27T10:48:09.408782Z","shell.execute_reply":"2024-05-27T10:48:09.408796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@partial(jax.jit, static_argnames=(\"self\", \"length\"))\ndef generate_text(rng, params, length):\n    def _scan_generate(carry, _):\n        random_key, context = carry\n        logits = fin_model.apply(params, context, training=False)[0]\n        rng, rng_subkey = jax.random.split(random_key)\n        new_token = jax.random.categorical(\n          rng_subkey, logits[:, -1, :], axis=-1, shape=(1, 1)\n        )\n        context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n        return (rng, context), new_token\n\n    _, new_tokens = jax.lax.scan(\n    _scan_generate,\n    (rng, jnp.zeros((1, block_size), dtype=jnp.int32)),\n    (),\n    length=length,\n    )\n    return new_tokens","metadata":{"id":"WB0og7pAHFyx","execution":{"iopub.status.busy":"2024-05-27T10:48:09.410904Z","iopub.status.idle":"2024-05-27T10:48:09.411221Z","shell.execute_reply.started":"2024-05-27T10:48:09.411066Z","shell.execute_reply":"2024-05-27T10:48:09.411079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_tokenz = 1000\nkey, subkey = jax.random.split(jax.random.PRNGKey(156))\n# key, subkey = jax.random.split(key)\n# token_gen = generate_text(jnp.zeros((1,block_size)).astype(jnp.int32), new_tokenz, {'params': state.params})\ntoken_gen = generate_text(key, {'params': state.params}, new_tokenz)[:, 0, 0].tolist()\nprint(token_gen)\nprint(decode(token_gen))","metadata":{"id":"50Vpg2lEHFyx","execution":{"iopub.status.busy":"2024-05-27T10:48:09.412351Z","iopub.status.idle":"2024-05-27T10:48:09.412699Z","shell.execute_reply.started":"2024-05-27T10:48:09.412534Z","shell.execute_reply":"2024-05-27T10:48:09.412548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdgh  fs","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:48:09.414049Z","iopub.status.idle":"2024-05-27T10:48:09.414376Z","shell.execute_reply.started":"2024-05-27T10:48:09.414215Z","shell.execute_reply":"2024-05-27T10:48:09.414228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state.params","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:48:09.416293Z","iopub.status.idle":"2024-05-27T10:48:09.416750Z","shell.execute_reply.started":"2024-05-27T10:48:09.416517Z","shell.execute_reply":"2024-05-27T10:48:09.416535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install mamba-ssm","metadata":{"id":"MOw_xjbrHFy0","execution":{"iopub.status.busy":"2024-05-27T10:48:09.417786Z","iopub.status.idle":"2024-05-27T10:48:09.418227Z","shell.execute_reply.started":"2024-05-27T10:48:09.417993Z","shell.execute_reply":"2024-05-27T10:48:09.418011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ones = lambda *size: torch.ones(*size).float().cuda()\nzeros = lambda *size: torch.zeros(*size).float().cuda()\narange = lambda n: torch.arange(n).float().cuda()\nrand = lambda size: torch.rand(*size).abs().float().cuda()\n\ndef create_torch(S = 128, Ba = 2, D = 4, N = 4):\n    x = rand((Ba, 1, D, S))\n    a = -ones((Ba, N, D, 1))\n    b = ones((Ba, N, 1, S)) * 0.1\n    c = rand((Ba, N, 1, S)) * 0.1\n    delta = rand((Ba, 1, D, S)) * 0.1\n    return x, a, b, c, delta","metadata":{"id":"W_PAnYcEOR22","execution":{"iopub.status.busy":"2024-05-27T10:48:09.419639Z","iopub.status.idle":"2024-05-27T10:48:09.420074Z","shell.execute_reply.started":"2024-05-27T10:48:09.419843Z","shell.execute_reply":"2024-05-27T10:48:09.419861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import selective_scan_cuda\n\nxx, aa, bb, cc, ddelta = create_torch()\ny_from_repo = selective_scan_cuda.fwd(xx.squeeze(1), ddelta.squeeze(1), aa[0].squeeze(-1).T, bb.squeeze(-2)[:, None, :, :], cc.squeeze(-2)[:, None, :, :], None, None, None, False)\ny_from_repo","metadata":{"id":"ykh4GTvtOrak","execution":{"iopub.status.busy":"2024-05-27T10:48:09.421187Z","iopub.status.idle":"2024-05-27T10:48:09.421567Z","shell.execute_reply.started":"2024-05-27T10:48:09.421353Z","shell.execute_reply":"2024-05-27T10:48:09.421367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discretize(a, b, delta):\n    da = delta * a\n    a_ = jnp.exp(da)\n    b_ = b * delta\n    return a_, b_\n\ndef ssm(x, a, b, c, delta):\n    \"Jax Implementation\"\n    y = []\n    h = 0\n    a_, b_ = discretize(a, b, delta)\n    for k in range(x.shape[-1]):\n        h = a_[..., k] * h + b_[..., k] * x[..., k]\n        y.append((c[..., k] * h).sum(1, keepdims=True))\n    return h, jnp.stack(y, -1)\n","metadata":{"id":"NEdG1yPNOtxU","execution":{"iopub.status.busy":"2024-05-27T10:48:09.422505Z","iopub.status.idle":"2024-05-27T10:48:09.422822Z","shell.execute_reply.started":"2024-05-27T10:48:09.422669Z","shell.execute_reply":"2024-05-27T10:48:09.422681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, y_ = ssm(xx.cpu().numpy(), aa.cpu().numpy(), bb.cpu().numpy(), cc.cpu().numpy(), ddelta.cpu().numpy())","metadata":{"id":"GEjNcZSZPIp_","execution":{"iopub.status.busy":"2024-05-27T10:48:09.424731Z","iopub.status.idle":"2024-05-27T10:48:09.425185Z","shell.execute_reply.started":"2024-05-27T10:48:09.424945Z","shell.execute_reply":"2024-05-27T10:48:09.424964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"tWlqZZOmPnYk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mamba_ssm import Mamba as Mamba_T\ntorch_mamba = Mamba_T(\n      # This module uses roughly 3 * expand * d_model^2 parameters\n      d_model=n_embd, # Model dimension d_model\n      d_state=16,  # SSM state expansion factor\n      d_conv=4,    # Local convolution width\n      expand=2,    # Block expansion factor\n)","metadata":{"id":"5RHAE_I1Pql9","execution":{"iopub.status.busy":"2024-05-27T10:48:09.426858Z","iopub.status.idle":"2024-05-27T10:48:09.427324Z","shell.execute_reply.started":"2024-05-27T10:48:09.427074Z","shell.execute_reply":"2024-05-27T10:48:09.427093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xm = x = rand((1, 1, n_embd, 32))\nxm.shape","metadata":{"id":"l9zw_M-USrDt","execution":{"iopub.status.busy":"2024-05-27T10:48:09.428251Z","iopub.status.idle":"2024-05-27T10:48:09.428704Z","shell.execute_reply.started":"2024-05-27T10:48:09.428473Z","shell.execute_reply":"2024-05-27T10:48:09.428493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_mamba(xm.squeeze(1))","metadata":{"id":"gGmA2EWlTCo0","execution":{"iopub.status.busy":"2024-05-27T10:48:09.429976Z","iopub.status.idle":"2024-05-27T10:48:09.430428Z","shell.execute_reply.started":"2024-05-27T10:48:09.430196Z","shell.execute_reply":"2024-05-27T10:48:09.430216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_mamba.in_proj","metadata":{"id":"73ek9mx9UBBl","execution":{"iopub.status.busy":"2024-05-27T10:48:09.431611Z","iopub.status.idle":"2024-05-27T10:48:09.432063Z","shell.execute_reply.started":"2024-05-27T10:48:09.431835Z","shell.execute_reply":"2024-05-27T10:48:09.431854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import CLIPTokenizer\ntokenizer_1 = CLIPTokenizer.from_pretrained('openai/clip-vit-base-patch32')","metadata":{"id":"P3l_ssIYbiYT","execution":{"iopub.status.busy":"2024-05-27T10:48:09.434157Z","iopub.status.idle":"2024-05-27T10:48:09.434620Z","shell.execute_reply.started":"2024-05-27T10:48:09.434367Z","shell.execute_reply":"2024-05-27T10:48:09.434384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenise_prompts(prompt):\n    inputs = []\n    for tokenizer in [tokenizer_1, tokenizer_2]:\n        text_inputs = tokenizer(\n            positive_prompt,\n            padding=\"max_length\",\n            max_length=tokenizer.model_max_length,\n            truncation=True,\n            return_tensors=\"np\",\n        )\n        inputs.append(text_inputs.input_ids)\n    return jnp.stack(inputs, axis=1)","metadata":{"id":"-X7hXQRMZhl3","execution":{"iopub.status.busy":"2024-05-27T10:48:09.439214Z","iopub.status.idle":"2024-05-27T10:48:09.439568Z","shell.execute_reply.started":"2024-05-27T10:48:09.439374Z","shell.execute_reply":"2024-05-27T10:48:09.439387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xm.squeeze(1).shape","metadata":{"id":"rJhKQ_Oua9Gy","execution":{"iopub.status.busy":"2024-05-27T10:48:09.440597Z","iopub.status.idle":"2024-05-27T10:48:09.440931Z","shell.execute_reply.started":"2024-05-27T10:48:09.440766Z","shell.execute_reply":"2024-05-27T10:48:09.440781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"mzkoYrSVkoJj"},"execution_count":null,"outputs":[]}]}