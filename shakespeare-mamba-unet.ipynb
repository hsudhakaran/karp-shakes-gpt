{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from functools import partial\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom jax.nn.initializers import lecun_normal, normal\nfrom jax.numpy.linalg import eigh, inv, matrix_power\nfrom jax.scipy.signal import convolve\n\nimport tensorflow_datasets as tfds\n\nimport torch\n\nfrom dataclasses import dataclass\n\nfrom typing import Union\n\nimport matplotlib.pyplot as plt\nimport seaborn\n\n# from clu import metrics\nfrom flax.training import train_state  # Useful dataclass to keep train state\nfrom flax import struct                # Flax dataclasses\nimport optax                           # Common loss functions and optimizers\nfrom tqdm import tqdm\n\nimport pdb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-01T07:27:34.257484Z","iopub.execute_input":"2024-07-01T07:27:34.258406Z","iopub.status.idle":"2024-07-01T07:27:42.285977Z","shell.execute_reply.started":"2024-07-01T07:27:34.258363Z","shell.execute_reply":"2024-07-01T07:27:42.285153Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/shak-new-input/train.txt', 'r', encoding='utf-8') as f:\n    text_train = f.read()\n    \nwith open('/kaggle/input/shak-new-input/test.txt', 'r', encoding='utf-8') as f:\n    text_validation = f.read()    ","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:27:42.287862Z","iopub.execute_input":"2024-07-01T07:27:42.288521Z","iopub.status.idle":"2024-07-01T07:27:42.310952Z","shell.execute_reply.started":"2024-07-01T07:27:42.288494Z","shell.execute_reply":"2024-07-01T07:27:42.310021Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# here are all the unique characters that occur in this text\nchars = sorted(list(set(text_train+text_validation)))\n# chars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:27:42.312125Z","iopub.execute_input":"2024-07-01T07:27:42.312780Z","iopub.status.idle":"2024-07-01T07:27:42.335201Z","shell.execute_reply.started":"2024-07-01T07:27:42.312749Z","shell.execute_reply":"2024-07-01T07:27:42.334356Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n65\n","output_type":"stream"}]},{"cell_type":"code","source":"# create a mapping from characters to integers\nstoi = { ch: i for i,ch in enumerate(chars) }\nitos = { i: ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n\nprint(encode(\"hii there\"))\nprint(decode(encode(\"hii there\")))","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:27:42.337889Z","iopub.execute_input":"2024-07-01T07:27:42.338313Z","iopub.status.idle":"2024-07-01T07:27:42.346699Z","shell.execute_reply.started":"2024-07-01T07:27:42.338281Z","shell.execute_reply":"2024-07-01T07:27:42.345855Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[46, 47, 47, 1, 58, 46, 43, 56, 43]\nhii there\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = jnp.array(encode(text_train), dtype=jnp.int32)\ntest_data = jnp.array(encode(text_validation), dtype=jnp.int32)\nblock_size = 8\ntrain_data[:block_size+1]","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:27:42.347764Z","iopub.execute_input":"2024-07-01T07:27:42.348463Z","iopub.status.idle":"2024-07-01T07:27:45.242058Z","shell.execute_reply.started":"2024-07-01T07:27:42.348438Z","shell.execute_reply":"2024-07-01T07:27:45.241044Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Array([18, 47, 56, 57, 58,  1, 15, 47, 58], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target: {target}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:27:45.243170Z","iopub.execute_input":"2024-07-01T07:27:45.243533Z","iopub.status.idle":"2024-07-01T07:27:45.725142Z","shell.execute_reply.started":"2024-07-01T07:27:45.243506Z","shell.execute_reply":"2024-07-01T07:27:45.724044Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"when input is [18] the target: 47\nwhen input is [18 47] the target: 56\nwhen input is [18 47 56] the target: 57\nwhen input is [18 47 56 57] the target: 58\nwhen input is [18 47 56 57 58] the target: 1\nwhen input is [18 47 56 57 58  1] the target: 15\nwhen input is [18 47 56 57 58  1 15] the target: 47\nwhen input is [18 47 56 57 58  1 15 47] the target: 58\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 128 # how many independent sequences will we process in parallel?\nblock_size = 64 # what is the maximum context length for predictions?\nseq_size = block_size//8\n\nnum_layers = 5\n\nmax_iters = 50000\nlearning_rate = 5e-4\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 100\nn_embd = 32\nexpans = 2\nhidden_dim = n_embd*expans*4\nconv_k_size = 3\nn_latent_dim = 16\nn_tokens = 1\n\nrng_key = jax.random.PRNGKey(1564)\n\ndynamic_slice_vmap = jax.vmap(jax.lax.dynamic_slice, in_axes=(None, 0, None))\n\n@jax.jit\ndef get_batch(random_key, data):\n    \"\"\"Prepares a random batch of training data.\n\n    Args:\n      random_key: A random seed for sampling a batch.\n      data: The complete training dataset.\n\n    Returns:\n      x: Input sequences.\n      y: Target sequences (shifted inputs).\n    \"\"\"\n    ix = jax.random.randint(\n      random_key, shape=(batch_size, 1), minval=0, maxval=len(data) - block_size\n    )\n    x = dynamic_slice_vmap(data, ix, (block_size,))\n    y = dynamic_slice_vmap(data, ix + n_tokens, (block_size,))\n    return x, y\n\nxb, yb = get_batch(rng_key, train_data)\ntrain_shape = xb.shape\nprint('inputs:')\nprint(xb.shape)\nprint(xb)\nprint('targets:')\nprint(yb.shape)\nprint(yb)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:27:45.726454Z","iopub.execute_input":"2024-07-01T07:27:45.726755Z","iopub.status.idle":"2024-07-01T07:27:46.012413Z","shell.execute_reply.started":"2024-07-01T07:27:45.726730Z","shell.execute_reply":"2024-07-01T07:27:46.011448Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"inputs:\n(128, 64)\n[[12  0  0 ... 53 42  1]\n [ 1 44 39 ... 56  1 45]\n [56 57  8 ... 10  0 17]\n ...\n [54 53 53 ... 17 17 26]\n [59 58 58 ... 16 21 33]\n [50  1 57 ... 47 58  1]]\ntargets:\n(128, 64)\n[[ 0  0 15 ... 42  1 40]\n [44 39 56 ...  1 45 56]\n [57  8  0 ...  0 17 47]\n ...\n [53 53 56 ... 17 26  1]\n [58 58 43 ... 21 33 31]\n [ 1 57 53 ... 58  1 40]]\n","output_type":"stream"}]},{"cell_type":"code","source":"class S6_Unet(nn.Module):\n    \n    @nn.compact\n    def __call__(self, x):\n        \n        conv1 = jax.nn.silu(nn.Conv(features=n_embd*expans, kernel_size=conv_k_size,padding=1)(x))\n        \n        max_pool1 = nn.max_pool(conv1 , window_shape=(2,), strides=(2,), padding='valid')\n        max_pool1_ind = (conv1 == jnp.repeat(max_pool1 , repeats=2, axis=1)).astype(jnp.int32)\n        \n        conv2 = jax.nn.silu(nn.Conv(features=n_embd*expans*2, kernel_size=conv_k_size,padding=1)(max_pool1))\n    \n        max_pool2 = nn.max_pool(conv2 , window_shape=(2,), strides=(2,), padding='valid')\n        max_pool2_ind = (conv2 == jnp.repeat(max_pool2 , repeats=2, axis=1)).astype(jnp.int32)   \n        \n        conv3 = jax.nn.silu(nn.Conv(features=n_embd*expans*4, kernel_size=conv_k_size,padding=1)(max_pool2))\n    \n        max_pool3 = nn.max_pool(conv3 , window_shape=(2,), strides=(2,), padding='valid')\n        max_pool3_ind = (conv3 == jnp.repeat(max_pool3 , repeats=2, axis=1)).astype(jnp.int32)\n        \n        A = -1*self.param('A', nn.initializers.ones, (1, n_latent_dim, hidden_dim, 1))\n        B = 0.1*self.param('B', nn.initializers.ones, (1, n_latent_dim, 1, seq_size))\n        C = 0.09*self.param('C', jax.random.normal, (1, n_latent_dim, 1, seq_size))\n        D = 0.1*self.param('D', jax.random.normal, (1, 1,hidden_dim, seq_size))\n        delta = 0.05*self.param('delta', jax.random.normal, (1, 1, hidden_dim, seq_size))\n        \n        x = nn.RMSNorm()(jnp.expand_dims(jnp.transpose(max_pool3,(0,2,1)), axis=1))\n        x = self.ssm(x, A, B, C, D, delta)\n        x = jnp.transpose(x[:,0,:,:],(0,2,1))\n        ###############\n        uconv3 = jnp.repeat(x, repeats=2, axis=1)*jnp.concatenate([max_pool3_ind[:,1:,:],jnp.ones((max_pool3_ind.shape[0],1,max_pool3_ind.shape[-1]))], axis=1)\n        \n        cat_conv3 = jnp.concatenate([conv3, uconv3], axis=-1)\n        conv4 = jax.nn.silu(nn.Conv(features=cat_conv3.shape[-1]//2, kernel_size=conv_k_size,padding=1)(cat_conv3))\n        \n        conv3T = nn.ConvTranspose(conv4.shape[-1]//2, kernel_size = 3, padding = 1)(conv4)\n        ###############\n        uconv2 = jnp.repeat(conv3T, repeats=2, axis=1)*jnp.concatenate([max_pool2_ind[:,1:,:],jnp.ones((max_pool2_ind.shape[0],1,max_pool2_ind.shape[-1]))], axis=1)\n        \n        cat_conv2 = jnp.concatenate([conv2, uconv2], axis=-1)\n        conv5 = jax.nn.silu(nn.Conv(features=cat_conv2.shape[-1]//2, kernel_size=conv_k_size,padding=1)(cat_conv2))\n        \n        conv2T = nn.ConvTranspose(conv5.shape[-1]//2, kernel_size = 3, padding = 1)(conv5)\n        \n        ###############\n        uconv1 = jnp.repeat(conv2T, repeats=2, axis=1)*jnp.concatenate([max_pool1_ind[:,1:,:],jnp.ones((max_pool1_ind.shape[0],1,max_pool1_ind.shape[-1]))], axis=1)\n        \n        cat_conv1 = jnp.concatenate([conv1, uconv1], axis=-1)\n        conv6 = jax.nn.silu(nn.Conv(features=cat_conv1.shape[-1]//2, kernel_size=conv_k_size,padding=1)(cat_conv1))\n        \n        conv1T = nn.ConvTranspose(conv6.shape[-1]//2, kernel_size = 3, padding = 1)(conv6)\n        ##############\n#         pdb.set_trace()\n        \n                \n#         first_uconv = jnp.repeat(max_pool1, repeats=2, axis=1)*max_pool1_ind\n        \n        \n        return conv1T\n    \n    def discretize(self, A, B, delta):\n        da = delta * A\n        a_ = jnp.exp(da)\n        b_ = B * delta\n        return a_, b_\n\n    def ssm(self, x, A, B, C, D, delta):\n        a_, b_ = self.discretize(A, B, delta)\n        h = 0\n        for k in range(x.shape[-1]):\n            h = a_[..., k] * h + b_[..., k] * x[..., k]\n#         _, N, D, S = a_.shape\n#         indices = jnp.tril(jnp.ones((S-1,S-1))) \n#         indices = jnp.expand_dims(a_[...,1:],axis=4)*jnp.expand_dims(indices, axis=(0,1,2)) + jnp.expand_dims(jnp.triu(jnp.ones((S-1,S-1)),1), axis=(0,1,2))\n#         indices = (jnp.concatenate((indices, jnp.ones((1,N,D,S-1,1))), axis=-1)).prod(axis=-2)\n#         h = (indices*(b_*x)).sum(axis=-1)\n\n        y = ((C * jax.lax.expand_dims(h,[3])).sum(1, keepdims=True) + D*x)\n        \n#         self.hidden_state.value = jax.nn.standardize(h.mean(0, keepdims=True))\n        return y    \n                ","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:27:46.013911Z","iopub.execute_input":"2024-07-01T07:27:46.014215Z","iopub.status.idle":"2024-07-01T07:27:46.040369Z","shell.execute_reply.started":"2024-07-01T07:27:46.014190Z","shell.execute_reply":"2024-07-01T07:27:46.039351Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class LLM_Model(nn.Module):\n    \n    @nn.compact\n    def __call__(self, x):\n        x = nn.Embed(vocab_size, n_embd)(x) + nn.Embed(block_size, n_embd)(jnp.arange(block_size))\n    \n        for _ in range(num_layers):\n            x = x + S6_Unet()(nn.RMSNorm()(x))\n            \n        x = S6_Unet()(nn.RMSNorm()(x)) * jnp.concatenate([x[:,1:,:],jnp.ones((x.shape[0],1,x.shape[-1]))], axis=1)\n        \n        x = nn.Dense(vocab_size)(nn.RMSNorm()(x))\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:27:46.041609Z","iopub.execute_input":"2024-07-01T07:27:46.041892Z","iopub.status.idle":"2024-07-01T07:27:46.054576Z","shell.execute_reply.started":"2024-07-01T07:27:46.041869Z","shell.execute_reply":"2024-07-01T07:27:46.053750Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def loss_fun(params, x, y, dropout_key):\n    logits = model.apply(params, x)\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), accuracy\n\n@jax.jit\ndef eval_step(params, x, y):\n    logits = model.apply(params, x)\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), accuracy","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:27:46.057714Z","iopub.execute_input":"2024-07-01T07:27:46.058048Z","iopub.status.idle":"2024-07-01T07:27:46.065042Z","shell.execute_reply.started":"2024-07-01T07:27:46.058013Z","shell.execute_reply":"2024-07-01T07:27:46.064150Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"key = jax.random.PRNGKey(42)\n# x = jnp.expand_dims(xb[0],axis=0)\nx = xb\n\nmodel = LLM_Model()\n\nparams = model.init(jax.random.PRNGKey(45),x)\nprint(params.keys())\nn_params = sum(p.size for p in jax.tree_util.tree_leaves(params))\n\nprint(f\"Total number of parameters: {n_params:_}\")\n\noutput = model.apply(params, x)\nprint(output.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:27:46.066047Z","iopub.execute_input":"2024-07-01T07:27:46.066354Z","iopub.status.idle":"2024-07-01T07:27:56.428038Z","shell.execute_reply.started":"2024-07-01T07:27:46.066331Z","shell.execute_reply":"2024-07-01T07:27:56.426963Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"dict_keys(['params'])\nTotal number of parameters: 4_708_817\n(128, 64, 65)\n","output_type":"stream"}]},{"cell_type":"code","source":"opt = optax.adamw(learning_rate=learning_rate)\n\nopt_state = opt.init(params)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:27:56.429399Z","iopub.execute_input":"2024-07-01T07:27:56.429843Z","iopub.status.idle":"2024-07-01T07:27:56.776337Z","shell.execute_reply.started":"2024-07-01T07:27:56.429810Z","shell.execute_reply":"2024-07-01T07:27:56.775507Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"%%time\n\nall_train_losses = []\nall_eval_losses = []\n\nall_train_accuracy =  []\nall_test_accuracy = []\n\n# we define one iteration of the optimizer and JIT this function\n@jax.jit\ndef step(key, params, opt_state):\n    key, subkey = jax.random.split(key)\n    xb, yb = get_batch(key, train_data)\n    (loss, train_accuracy), grad = jax.value_and_grad(loss_fun, has_aux=True)(params, xb, yb, subkey)\n    updates, opt_state = opt.update(grad, opt_state, params)\n    params = optax.apply_updates(params, updates)\n    return params, key, opt_state, loss, train_accuracy\n\n# for i in tqdm(range(max_iters)):\ncounter = 0\nloss = 10\nwhile counter<max_iters: # and loss > 1.0:\n\n    params, key, opt_state, loss, train_accuracy = step(key, params, opt_state)\n    \n\n    # once every N_FREQ_EVAL we compute loss on the validation set\n    if counter % eval_iters == 0:\n        key, subkey = jax.random.split(key)\n        eval_loss, eval_accuracy = eval_step(params, *get_batch(subkey, test_data))\n        all_train_losses.append(loss)\n        all_eval_losses.append(eval_loss)\n        all_train_accuracy.append(train_accuracy)\n        all_test_accuracy.append(eval_accuracy)\n        print('##########################################################')\n        print(\"Step: \", counter,\"\\t Train Loss: \", loss,\"\\t Train Accuracy: \", format(train_accuracy, \".2%\"))\n        print(\"Step: \", counter,\"\\t Eval Loss: \", eval_loss,\"\\t Eval Accuracy: \", format(eval_accuracy, \".2%\"))\n        \n    counter += 1\n        ","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:27:56.777424Z","iopub.execute_input":"2024-07-01T07:27:56.777692Z","iopub.status.idle":"2024-07-01T07:52:55.144606Z","shell.execute_reply.started":"2024-07-01T07:27:56.777669Z","shell.execute_reply":"2024-07-01T07:52:55.143583Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"##########################################################\nStep:  0 \t Train Loss:  4.6010942 \t Train Accuracy:  2.16%\nStep:  0 \t Eval Loss:  4.2062483 \t Eval Accuracy:  5.22%\n##########################################################\nStep:  100 \t Train Loss:  0.53406346 \t Train Accuracy:  94.58%\nStep:  100 \t Eval Loss:  0.5194996 \t Eval Accuracy:  94.51%\n##########################################################\nStep:  200 \t Train Loss:  0.20450541 \t Train Accuracy:  98.44%\nStep:  200 \t Eval Loss:  0.21151614 \t Eval Accuracy:  98.40%\n##########################################################\nStep:  300 \t Train Loss:  0.1182656 \t Train Accuracy:  98.80%\nStep:  300 \t Eval Loss:  0.1271469 \t Eval Accuracy:  98.84%\n##########################################################\nStep:  400 \t Train Loss:  0.08908148 \t Train Accuracy:  98.86%\nStep:  400 \t Eval Loss:  0.09425921 \t Eval Accuracy:  98.77%\n##########################################################\nStep:  500 \t Train Loss:  0.0666136 \t Train Accuracy:  99.02%\nStep:  500 \t Eval Loss:  0.07277365 \t Eval Accuracy:  98.85%\n##########################################################\nStep:  600 \t Train Loss:  0.061096337 \t Train Accuracy:  98.90%\nStep:  600 \t Eval Loss:  0.061655954 \t Eval Accuracy:  98.94%\n##########################################################\nStep:  700 \t Train Loss:  0.05296432 \t Train Accuracy:  99.06%\nStep:  700 \t Eval Loss:  0.055973455 \t Eval Accuracy:  98.89%\n##########################################################\nStep:  800 \t Train Loss:  0.04806605 \t Train Accuracy:  99.08%\nStep:  800 \t Eval Loss:  0.052052036 \t Eval Accuracy:  98.93%\n##########################################################\nStep:  900 \t Train Loss:  0.04394648 \t Train Accuracy:  99.04%\nStep:  900 \t Eval Loss:  0.04561469 \t Eval Accuracy:  99.02%\n##########################################################\nStep:  1000 \t Train Loss:  0.041346535 \t Train Accuracy:  99.15%\nStep:  1000 \t Eval Loss:  0.045056365 \t Eval Accuracy:  99.00%\n##########################################################\nStep:  1100 \t Train Loss:  0.03859783 \t Train Accuracy:  99.18%\nStep:  1100 \t Eval Loss:  0.04474072 \t Eval Accuracy:  99.00%\n##########################################################\nStep:  1200 \t Train Loss:  0.04248887 \t Train Accuracy:  99.01%\nStep:  1200 \t Eval Loss:  0.03988488 \t Eval Accuracy:  98.95%\n##########################################################\nStep:  1300 \t Train Loss:  0.04096576 \t Train Accuracy:  98.97%\nStep:  1300 \t Eval Loss:  0.038620766 \t Eval Accuracy:  99.08%\n##########################################################\nStep:  1400 \t Train Loss:  0.040088177 \t Train Accuracy:  99.01%\nStep:  1400 \t Eval Loss:  0.038842242 \t Eval Accuracy:  99.04%\n##########################################################\nStep:  1500 \t Train Loss:  0.03509972 \t Train Accuracy:  99.13%\nStep:  1500 \t Eval Loss:  0.034744773 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  1600 \t Train Loss:  0.03701972 \t Train Accuracy:  99.07%\nStep:  1600 \t Eval Loss:  0.04089247 \t Eval Accuracy:  99.04%\n##########################################################\nStep:  1700 \t Train Loss:  0.03693759 \t Train Accuracy:  99.08%\nStep:  1700 \t Eval Loss:  0.037044227 \t Eval Accuracy:  99.05%\n##########################################################\nStep:  1800 \t Train Loss:  0.03399434 \t Train Accuracy:  99.13%\nStep:  1800 \t Eval Loss:  0.03688474 \t Eval Accuracy:  98.97%\n##########################################################\nStep:  1900 \t Train Loss:  0.033771336 \t Train Accuracy:  99.11%\nStep:  1900 \t Eval Loss:  0.03746252 \t Eval Accuracy:  98.96%\n##########################################################\nStep:  2000 \t Train Loss:  0.036370244 \t Train Accuracy:  99.01%\nStep:  2000 \t Eval Loss:  0.033753186 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  2100 \t Train Loss:  0.02964592 \t Train Accuracy:  99.15%\nStep:  2100 \t Eval Loss:  0.034921784 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  2200 \t Train Loss:  0.035786882 \t Train Accuracy:  99.01%\nStep:  2200 \t Eval Loss:  0.032766942 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  2300 \t Train Loss:  0.032561716 \t Train Accuracy:  99.17%\nStep:  2300 \t Eval Loss:  0.034713976 \t Eval Accuracy:  98.97%\n##########################################################\nStep:  2400 \t Train Loss:  0.030011235 \t Train Accuracy:  99.16%\nStep:  2400 \t Eval Loss:  0.031535793 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  2500 \t Train Loss:  0.028465133 \t Train Accuracy:  99.24%\nStep:  2500 \t Eval Loss:  0.034246676 \t Eval Accuracy:  99.12%\n##########################################################\nStep:  2600 \t Train Loss:  0.03192249 \t Train Accuracy:  99.22%\nStep:  2600 \t Eval Loss:  0.034157813 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  2700 \t Train Loss:  0.028406318 \t Train Accuracy:  99.19%\nStep:  2700 \t Eval Loss:  0.03446186 \t Eval Accuracy:  99.08%\n##########################################################\nStep:  2800 \t Train Loss:  0.032597855 \t Train Accuracy:  99.07%\nStep:  2800 \t Eval Loss:  0.03299412 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  2900 \t Train Loss:  0.0291081 \t Train Accuracy:  99.24%\nStep:  2900 \t Eval Loss:  0.029008357 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  3000 \t Train Loss:  0.029028952 \t Train Accuracy:  99.18%\nStep:  3000 \t Eval Loss:  0.03335373 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  3100 \t Train Loss:  0.030801632 \t Train Accuracy:  99.16%\nStep:  3100 \t Eval Loss:  0.031867534 \t Eval Accuracy:  99.08%\n##########################################################\nStep:  3200 \t Train Loss:  0.030774044 \t Train Accuracy:  99.13%\nStep:  3200 \t Eval Loss:  0.031045593 \t Eval Accuracy:  99.05%\n##########################################################\nStep:  3300 \t Train Loss:  0.030918624 \t Train Accuracy:  99.17%\nStep:  3300 \t Eval Loss:  0.02969978 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  3400 \t Train Loss:  0.025077993 \t Train Accuracy:  99.28%\nStep:  3400 \t Eval Loss:  0.022823848 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  3500 \t Train Loss:  0.02921277 \t Train Accuracy:  99.12%\nStep:  3500 \t Eval Loss:  0.033987556 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  3600 \t Train Loss:  0.032203123 \t Train Accuracy:  99.13%\nStep:  3600 \t Eval Loss:  0.027452057 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  3700 \t Train Loss:  0.029707087 \t Train Accuracy:  99.17%\nStep:  3700 \t Eval Loss:  0.030691553 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  3800 \t Train Loss:  0.02793228 \t Train Accuracy:  99.26%\nStep:  3800 \t Eval Loss:  0.032487247 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  3900 \t Train Loss:  0.025824655 \t Train Accuracy:  99.29%\nStep:  3900 \t Eval Loss:  0.029496979 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  4000 \t Train Loss:  0.028116776 \t Train Accuracy:  99.23%\nStep:  4000 \t Eval Loss:  0.030071419 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  4100 \t Train Loss:  0.02806903 \t Train Accuracy:  99.26%\nStep:  4100 \t Eval Loss:  0.032923356 \t Eval Accuracy:  99.07%\n##########################################################\nStep:  4200 \t Train Loss:  0.029039426 \t Train Accuracy:  99.12%\nStep:  4200 \t Eval Loss:  0.032531593 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  4300 \t Train Loss:  0.025595613 \t Train Accuracy:  99.26%\nStep:  4300 \t Eval Loss:  0.027722966 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  4400 \t Train Loss:  0.03137897 \t Train Accuracy:  99.11%\nStep:  4400 \t Eval Loss:  0.030456662 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  4500 \t Train Loss:  0.027792025 \t Train Accuracy:  99.18%\nStep:  4500 \t Eval Loss:  0.029495578 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  4600 \t Train Loss:  0.03096634 \t Train Accuracy:  99.16%\nStep:  4600 \t Eval Loss:  0.025993876 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  4700 \t Train Loss:  0.024366353 \t Train Accuracy:  99.32%\nStep:  4700 \t Eval Loss:  0.030950729 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  4800 \t Train Loss:  0.026235443 \t Train Accuracy:  99.24%\nStep:  4800 \t Eval Loss:  0.029942833 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  4900 \t Train Loss:  0.024799071 \t Train Accuracy:  99.29%\nStep:  4900 \t Eval Loss:  0.027103694 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  5000 \t Train Loss:  0.025191508 \t Train Accuracy:  99.26%\nStep:  5000 \t Eval Loss:  0.032496847 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  5100 \t Train Loss:  0.02801802 \t Train Accuracy:  99.21%\nStep:  5100 \t Eval Loss:  0.030626372 \t Eval Accuracy:  99.07%\n##########################################################\nStep:  5200 \t Train Loss:  0.024638193 \t Train Accuracy:  99.32%\nStep:  5200 \t Eval Loss:  0.027534015 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  5300 \t Train Loss:  0.027285531 \t Train Accuracy:  99.22%\nStep:  5300 \t Eval Loss:  0.031465173 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  5400 \t Train Loss:  0.028755251 \t Train Accuracy:  99.28%\nStep:  5400 \t Eval Loss:  0.027859993 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  5500 \t Train Loss:  0.026205892 \t Train Accuracy:  99.24%\nStep:  5500 \t Eval Loss:  0.02677826 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  5600 \t Train Loss:  0.02743819 \t Train Accuracy:  99.24%\nStep:  5600 \t Eval Loss:  0.028347425 \t Eval Accuracy:  99.08%\n##########################################################\nStep:  5700 \t Train Loss:  0.025569575 \t Train Accuracy:  99.26%\nStep:  5700 \t Eval Loss:  0.028100103 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  5800 \t Train Loss:  0.022679605 \t Train Accuracy:  99.35%\nStep:  5800 \t Eval Loss:  0.027129846 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  5900 \t Train Loss:  0.027764939 \t Train Accuracy:  99.12%\nStep:  5900 \t Eval Loss:  0.029880188 \t Eval Accuracy:  99.06%\n##########################################################\nStep:  6000 \t Train Loss:  0.030523108 \t Train Accuracy:  99.15%\nStep:  6000 \t Eval Loss:  0.028469041 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  6100 \t Train Loss:  0.02429251 \t Train Accuracy:  99.30%\nStep:  6100 \t Eval Loss:  0.029546693 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  6200 \t Train Loss:  0.028376732 \t Train Accuracy:  99.17%\nStep:  6200 \t Eval Loss:  0.026122306 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  6300 \t Train Loss:  0.021565856 \t Train Accuracy:  99.37%\nStep:  6300 \t Eval Loss:  0.027378105 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  6400 \t Train Loss:  0.023645394 \t Train Accuracy:  99.35%\nStep:  6400 \t Eval Loss:  0.031586256 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  6500 \t Train Loss:  0.026742231 \t Train Accuracy:  99.24%\nStep:  6500 \t Eval Loss:  0.027543211 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  6600 \t Train Loss:  0.028077936 \t Train Accuracy:  99.15%\nStep:  6600 \t Eval Loss:  0.026316814 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  6700 \t Train Loss:  0.020523002 \t Train Accuracy:  99.40%\nStep:  6700 \t Eval Loss:  0.027855996 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  6800 \t Train Loss:  0.024034299 \t Train Accuracy:  99.27%\nStep:  6800 \t Eval Loss:  0.025627043 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  6900 \t Train Loss:  0.027010694 \t Train Accuracy:  99.18%\nStep:  6900 \t Eval Loss:  0.026957907 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  7000 \t Train Loss:  0.028451089 \t Train Accuracy:  99.17%\nStep:  7000 \t Eval Loss:  0.030008862 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  7100 \t Train Loss:  0.025648601 \t Train Accuracy:  99.26%\nStep:  7100 \t Eval Loss:  0.026643999 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  7200 \t Train Loss:  0.027956933 \t Train Accuracy:  99.22%\nStep:  7200 \t Eval Loss:  0.029886834 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  7300 \t Train Loss:  0.022575483 \t Train Accuracy:  99.27%\nStep:  7300 \t Eval Loss:  0.028321974 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  7400 \t Train Loss:  0.02557081 \t Train Accuracy:  99.30%\nStep:  7400 \t Eval Loss:  0.023920441 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  7500 \t Train Loss:  0.025689155 \t Train Accuracy:  99.24%\nStep:  7500 \t Eval Loss:  0.026378307 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  7600 \t Train Loss:  0.024877174 \t Train Accuracy:  99.27%\nStep:  7600 \t Eval Loss:  0.025261093 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  7700 \t Train Loss:  0.025162946 \t Train Accuracy:  99.30%\nStep:  7700 \t Eval Loss:  0.023493491 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  7800 \t Train Loss:  0.028385257 \t Train Accuracy:  99.26%\nStep:  7800 \t Eval Loss:  0.028352853 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  7900 \t Train Loss:  0.023703404 \t Train Accuracy:  99.30%\nStep:  7900 \t Eval Loss:  0.023725566 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  8000 \t Train Loss:  0.025671033 \t Train Accuracy:  99.27%\nStep:  8000 \t Eval Loss:  0.025069682 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  8100 \t Train Loss:  0.024815911 \t Train Accuracy:  99.24%\nStep:  8100 \t Eval Loss:  0.027084466 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  8200 \t Train Loss:  0.021662932 \t Train Accuracy:  99.37%\nStep:  8200 \t Eval Loss:  0.026215587 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  8300 \t Train Loss:  0.025480077 \t Train Accuracy:  99.24%\nStep:  8300 \t Eval Loss:  0.028082747 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  8400 \t Train Loss:  0.023160078 \t Train Accuracy:  99.33%\nStep:  8400 \t Eval Loss:  0.02443861 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  8500 \t Train Loss:  0.025700372 \t Train Accuracy:  99.24%\nStep:  8500 \t Eval Loss:  0.023989044 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  8600 \t Train Loss:  0.023828208 \t Train Accuracy:  99.30%\nStep:  8600 \t Eval Loss:  0.029121414 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  8700 \t Train Loss:  0.023429051 \t Train Accuracy:  99.34%\nStep:  8700 \t Eval Loss:  0.02765609 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  8800 \t Train Loss:  0.025443904 \t Train Accuracy:  99.32%\nStep:  8800 \t Eval Loss:  0.025091551 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  8900 \t Train Loss:  0.02228427 \t Train Accuracy:  99.24%\nStep:  8900 \t Eval Loss:  0.02711029 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  9000 \t Train Loss:  0.02496291 \t Train Accuracy:  99.27%\nStep:  9000 \t Eval Loss:  0.026909996 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  9100 \t Train Loss:  0.026070414 \t Train Accuracy:  99.22%\nStep:  9100 \t Eval Loss:  0.022021528 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  9200 \t Train Loss:  0.023784574 \t Train Accuracy:  99.30%\nStep:  9200 \t Eval Loss:  0.023404721 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  9300 \t Train Loss:  0.026958242 \t Train Accuracy:  99.13%\nStep:  9300 \t Eval Loss:  0.026531804 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  9400 \t Train Loss:  0.024562616 \t Train Accuracy:  99.27%\nStep:  9400 \t Eval Loss:  0.028270721 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  9500 \t Train Loss:  0.023056133 \t Train Accuracy:  99.29%\nStep:  9500 \t Eval Loss:  0.025082886 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  9600 \t Train Loss:  0.024256732 \t Train Accuracy:  99.26%\nStep:  9600 \t Eval Loss:  0.025689043 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  9700 \t Train Loss:  0.02210171 \t Train Accuracy:  99.33%\nStep:  9700 \t Eval Loss:  0.025274497 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  9800 \t Train Loss:  0.022809193 \t Train Accuracy:  99.35%\nStep:  9800 \t Eval Loss:  0.025558503 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  9900 \t Train Loss:  0.02788113 \t Train Accuracy:  99.08%\nStep:  9900 \t Eval Loss:  0.023306595 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  10000 \t Train Loss:  0.026307702 \t Train Accuracy:  99.23%\nStep:  10000 \t Eval Loss:  0.025655972 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  10100 \t Train Loss:  0.020959415 \t Train Accuracy:  99.39%\nStep:  10100 \t Eval Loss:  0.028021269 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  10200 \t Train Loss:  0.024786424 \t Train Accuracy:  99.33%\nStep:  10200 \t Eval Loss:  0.022482561 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  10300 \t Train Loss:  0.02676731 \t Train Accuracy:  99.24%\nStep:  10300 \t Eval Loss:  0.025757581 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  10400 \t Train Loss:  0.018531036 \t Train Accuracy:  99.43%\nStep:  10400 \t Eval Loss:  0.025567766 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  10500 \t Train Loss:  0.025756834 \t Train Accuracy:  99.21%\nStep:  10500 \t Eval Loss:  0.026188951 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  10600 \t Train Loss:  0.02755402 \t Train Accuracy:  99.21%\nStep:  10600 \t Eval Loss:  0.024976414 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  10700 \t Train Loss:  0.023383472 \t Train Accuracy:  99.32%\nStep:  10700 \t Eval Loss:  0.026614279 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  10800 \t Train Loss:  0.021557456 \t Train Accuracy:  99.30%\nStep:  10800 \t Eval Loss:  0.022107735 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  10900 \t Train Loss:  0.023513205 \t Train Accuracy:  99.28%\nStep:  10900 \t Eval Loss:  0.022408843 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  11000 \t Train Loss:  0.025582168 \t Train Accuracy:  99.19%\nStep:  11000 \t Eval Loss:  0.027097452 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  11100 \t Train Loss:  0.025263768 \t Train Accuracy:  99.21%\nStep:  11100 \t Eval Loss:  0.026565392 \t Eval Accuracy:  99.12%\n##########################################################\nStep:  11200 \t Train Loss:  0.024186803 \t Train Accuracy:  99.24%\nStep:  11200 \t Eval Loss:  0.02552027 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  11300 \t Train Loss:  0.022381734 \t Train Accuracy:  99.30%\nStep:  11300 \t Eval Loss:  0.021026004 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  11400 \t Train Loss:  0.019951703 \t Train Accuracy:  99.41%\nStep:  11400 \t Eval Loss:  0.025219724 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  11500 \t Train Loss:  0.020735929 \t Train Accuracy:  99.37%\nStep:  11500 \t Eval Loss:  0.02623193 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  11600 \t Train Loss:  0.024754528 \t Train Accuracy:  99.24%\nStep:  11600 \t Eval Loss:  0.022585083 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  11700 \t Train Loss:  0.025284698 \t Train Accuracy:  99.27%\nStep:  11700 \t Eval Loss:  0.02347653 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  11800 \t Train Loss:  0.023268906 \t Train Accuracy:  99.35%\nStep:  11800 \t Eval Loss:  0.029791728 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  11900 \t Train Loss:  0.0264992 \t Train Accuracy:  99.22%\nStep:  11900 \t Eval Loss:  0.028870583 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  12000 \t Train Loss:  0.021253414 \t Train Accuracy:  99.29%\nStep:  12000 \t Eval Loss:  0.022548698 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  12100 \t Train Loss:  0.020234846 \t Train Accuracy:  99.40%\nStep:  12100 \t Eval Loss:  0.026996544 \t Eval Accuracy:  99.11%\n##########################################################\nStep:  12200 \t Train Loss:  0.023544043 \t Train Accuracy:  99.24%\nStep:  12200 \t Eval Loss:  0.023185905 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  12300 \t Train Loss:  0.023454748 \t Train Accuracy:  99.27%\nStep:  12300 \t Eval Loss:  0.027917018 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  12400 \t Train Loss:  0.026431398 \t Train Accuracy:  99.27%\nStep:  12400 \t Eval Loss:  0.027339092 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  12500 \t Train Loss:  0.02531032 \t Train Accuracy:  99.29%\nStep:  12500 \t Eval Loss:  0.02725631 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  12600 \t Train Loss:  0.021511978 \t Train Accuracy:  99.38%\nStep:  12600 \t Eval Loss:  0.024359992 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  12700 \t Train Loss:  0.025853354 \t Train Accuracy:  99.21%\nStep:  12700 \t Eval Loss:  0.025328096 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  12800 \t Train Loss:  0.022982331 \t Train Accuracy:  99.28%\nStep:  12800 \t Eval Loss:  0.020133775 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  12900 \t Train Loss:  0.023241924 \t Train Accuracy:  99.30%\nStep:  12900 \t Eval Loss:  0.026219454 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  13000 \t Train Loss:  0.02446419 \t Train Accuracy:  99.32%\nStep:  13000 \t Eval Loss:  0.02252224 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  13100 \t Train Loss:  0.02370997 \t Train Accuracy:  99.32%\nStep:  13100 \t Eval Loss:  0.024761662 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  13200 \t Train Loss:  0.0262817 \t Train Accuracy:  99.16%\nStep:  13200 \t Eval Loss:  0.027380362 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  13300 \t Train Loss:  0.022438647 \t Train Accuracy:  99.30%\nStep:  13300 \t Eval Loss:  0.02225126 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  13400 \t Train Loss:  0.02361009 \t Train Accuracy:  99.30%\nStep:  13400 \t Eval Loss:  0.022588113 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  13500 \t Train Loss:  0.018813122 \t Train Accuracy:  99.40%\nStep:  13500 \t Eval Loss:  0.023038406 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  13600 \t Train Loss:  0.02436925 \t Train Accuracy:  99.22%\nStep:  13600 \t Eval Loss:  0.026594542 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  13700 \t Train Loss:  0.025477026 \t Train Accuracy:  99.27%\nStep:  13700 \t Eval Loss:  0.023132917 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  13800 \t Train Loss:  0.01878082 \t Train Accuracy:  99.48%\nStep:  13800 \t Eval Loss:  0.022765394 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  13900 \t Train Loss:  0.023267262 \t Train Accuracy:  99.32%\nStep:  13900 \t Eval Loss:  0.023959013 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  14000 \t Train Loss:  0.025665855 \t Train Accuracy:  99.24%\nStep:  14000 \t Eval Loss:  0.022972122 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  14100 \t Train Loss:  0.02336839 \t Train Accuracy:  99.34%\nStep:  14100 \t Eval Loss:  0.023634141 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  14200 \t Train Loss:  0.023682393 \t Train Accuracy:  99.28%\nStep:  14200 \t Eval Loss:  0.025929727 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  14300 \t Train Loss:  0.023140244 \t Train Accuracy:  99.35%\nStep:  14300 \t Eval Loss:  0.026024994 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  14400 \t Train Loss:  0.022955775 \t Train Accuracy:  99.32%\nStep:  14400 \t Eval Loss:  0.024690226 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  14500 \t Train Loss:  0.02313742 \t Train Accuracy:  99.35%\nStep:  14500 \t Eval Loss:  0.028436959 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  14600 \t Train Loss:  0.023737669 \t Train Accuracy:  99.30%\nStep:  14600 \t Eval Loss:  0.02269173 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  14700 \t Train Loss:  0.023707125 \t Train Accuracy:  99.30%\nStep:  14700 \t Eval Loss:  0.02143335 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  14800 \t Train Loss:  0.024445638 \t Train Accuracy:  99.26%\nStep:  14800 \t Eval Loss:  0.027617354 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  14900 \t Train Loss:  0.023861876 \t Train Accuracy:  99.24%\nStep:  14900 \t Eval Loss:  0.028199045 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  15000 \t Train Loss:  0.025225107 \t Train Accuracy:  99.27%\nStep:  15000 \t Eval Loss:  0.028640207 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  15100 \t Train Loss:  0.024111256 \t Train Accuracy:  99.30%\nStep:  15100 \t Eval Loss:  0.024073597 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  15200 \t Train Loss:  0.02424527 \t Train Accuracy:  99.29%\nStep:  15200 \t Eval Loss:  0.025741505 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  15300 \t Train Loss:  0.02283832 \t Train Accuracy:  99.29%\nStep:  15300 \t Eval Loss:  0.021857627 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  15400 \t Train Loss:  0.022266064 \t Train Accuracy:  99.35%\nStep:  15400 \t Eval Loss:  0.025811438 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  15500 \t Train Loss:  0.024843164 \t Train Accuracy:  99.23%\nStep:  15500 \t Eval Loss:  0.018711045 \t Eval Accuracy:  99.44%\n##########################################################\nStep:  15600 \t Train Loss:  0.0251301 \t Train Accuracy:  99.24%\nStep:  15600 \t Eval Loss:  0.027749114 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  15700 \t Train Loss:  0.024839398 \t Train Accuracy:  99.29%\nStep:  15700 \t Eval Loss:  0.02545287 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  15800 \t Train Loss:  0.020698331 \t Train Accuracy:  99.37%\nStep:  15800 \t Eval Loss:  0.025221251 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  15900 \t Train Loss:  0.024381824 \t Train Accuracy:  99.27%\nStep:  15900 \t Eval Loss:  0.024933014 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  16000 \t Train Loss:  0.020899424 \t Train Accuracy:  99.32%\nStep:  16000 \t Eval Loss:  0.023288617 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  16100 \t Train Loss:  0.020936195 \t Train Accuracy:  99.38%\nStep:  16100 \t Eval Loss:  0.025552034 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  16200 \t Train Loss:  0.023594957 \t Train Accuracy:  99.24%\nStep:  16200 \t Eval Loss:  0.025939435 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  16300 \t Train Loss:  0.022676706 \t Train Accuracy:  99.35%\nStep:  16300 \t Eval Loss:  0.025379997 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  16400 \t Train Loss:  0.020535724 \t Train Accuracy:  99.37%\nStep:  16400 \t Eval Loss:  0.026126841 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  16500 \t Train Loss:  0.024578817 \t Train Accuracy:  99.26%\nStep:  16500 \t Eval Loss:  0.022824798 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  16600 \t Train Loss:  0.024957169 \t Train Accuracy:  99.23%\nStep:  16600 \t Eval Loss:  0.026376538 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  16700 \t Train Loss:  0.021539163 \t Train Accuracy:  99.30%\nStep:  16700 \t Eval Loss:  0.026554454 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  16800 \t Train Loss:  0.024073076 \t Train Accuracy:  99.28%\nStep:  16800 \t Eval Loss:  0.027415996 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  16900 \t Train Loss:  0.020264456 \t Train Accuracy:  99.27%\nStep:  16900 \t Eval Loss:  0.022643637 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  17000 \t Train Loss:  0.026342932 \t Train Accuracy:  99.21%\nStep:  17000 \t Eval Loss:  0.023719052 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  17100 \t Train Loss:  0.02460507 \t Train Accuracy:  99.19%\nStep:  17100 \t Eval Loss:  0.023365617 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  17200 \t Train Loss:  0.022178482 \t Train Accuracy:  99.38%\nStep:  17200 \t Eval Loss:  0.02368131 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  17300 \t Train Loss:  0.020819861 \t Train Accuracy:  99.37%\nStep:  17300 \t Eval Loss:  0.026146976 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  17400 \t Train Loss:  0.025581574 \t Train Accuracy:  99.28%\nStep:  17400 \t Eval Loss:  0.02724495 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  17500 \t Train Loss:  0.01977898 \t Train Accuracy:  99.43%\nStep:  17500 \t Eval Loss:  0.02490108 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  17600 \t Train Loss:  0.021784013 \t Train Accuracy:  99.38%\nStep:  17600 \t Eval Loss:  0.027737647 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  17700 \t Train Loss:  0.024730898 \t Train Accuracy:  99.32%\nStep:  17700 \t Eval Loss:  0.02318294 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  17800 \t Train Loss:  0.02514299 \t Train Accuracy:  99.24%\nStep:  17800 \t Eval Loss:  0.027587526 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  17900 \t Train Loss:  0.024552612 \t Train Accuracy:  99.18%\nStep:  17900 \t Eval Loss:  0.022030968 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  18000 \t Train Loss:  0.022252925 \t Train Accuracy:  99.38%\nStep:  18000 \t Eval Loss:  0.024662916 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  18100 \t Train Loss:  0.024085246 \t Train Accuracy:  99.30%\nStep:  18100 \t Eval Loss:  0.023061292 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  18200 \t Train Loss:  0.020647481 \t Train Accuracy:  99.43%\nStep:  18200 \t Eval Loss:  0.025778275 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  18300 \t Train Loss:  0.023599835 \t Train Accuracy:  99.29%\nStep:  18300 \t Eval Loss:  0.021950567 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  18400 \t Train Loss:  0.021830967 \t Train Accuracy:  99.29%\nStep:  18400 \t Eval Loss:  0.024597958 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  18500 \t Train Loss:  0.025069715 \t Train Accuracy:  99.28%\nStep:  18500 \t Eval Loss:  0.026274726 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  18600 \t Train Loss:  0.023037575 \t Train Accuracy:  99.27%\nStep:  18600 \t Eval Loss:  0.029227853 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  18700 \t Train Loss:  0.021468531 \t Train Accuracy:  99.33%\nStep:  18700 \t Eval Loss:  0.023990486 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  18800 \t Train Loss:  0.021517042 \t Train Accuracy:  99.40%\nStep:  18800 \t Eval Loss:  0.025771126 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  18900 \t Train Loss:  0.02445396 \t Train Accuracy:  99.30%\nStep:  18900 \t Eval Loss:  0.023735557 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  19000 \t Train Loss:  0.020138722 \t Train Accuracy:  99.35%\nStep:  19000 \t Eval Loss:  0.028030962 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  19100 \t Train Loss:  0.025133846 \t Train Accuracy:  99.23%\nStep:  19100 \t Eval Loss:  0.024143634 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  19200 \t Train Loss:  0.020961544 \t Train Accuracy:  99.38%\nStep:  19200 \t Eval Loss:  0.021081574 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  19300 \t Train Loss:  0.025252575 \t Train Accuracy:  99.24%\nStep:  19300 \t Eval Loss:  0.021621725 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  19400 \t Train Loss:  0.023894155 \t Train Accuracy:  99.26%\nStep:  19400 \t Eval Loss:  0.023629572 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  19500 \t Train Loss:  0.021466862 \t Train Accuracy:  99.35%\nStep:  19500 \t Eval Loss:  0.026909111 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  19600 \t Train Loss:  0.021328155 \t Train Accuracy:  99.29%\nStep:  19600 \t Eval Loss:  0.022456914 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  19700 \t Train Loss:  0.02585274 \t Train Accuracy:  99.21%\nStep:  19700 \t Eval Loss:  0.025157122 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  19800 \t Train Loss:  0.02303523 \t Train Accuracy:  99.21%\nStep:  19800 \t Eval Loss:  0.023075145 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  19900 \t Train Loss:  0.018110823 \t Train Accuracy:  99.46%\nStep:  19900 \t Eval Loss:  0.025544418 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  20000 \t Train Loss:  0.0179025 \t Train Accuracy:  99.46%\nStep:  20000 \t Eval Loss:  0.021155294 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  20100 \t Train Loss:  0.022073995 \t Train Accuracy:  99.30%\nStep:  20100 \t Eval Loss:  0.028426172 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  20200 \t Train Loss:  0.021842591 \t Train Accuracy:  99.30%\nStep:  20200 \t Eval Loss:  0.024728512 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  20300 \t Train Loss:  0.022524782 \t Train Accuracy:  99.29%\nStep:  20300 \t Eval Loss:  0.020836627 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  20400 \t Train Loss:  0.022654433 \t Train Accuracy:  99.29%\nStep:  20400 \t Eval Loss:  0.023835618 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  20500 \t Train Loss:  0.023692997 \t Train Accuracy:  99.27%\nStep:  20500 \t Eval Loss:  0.025432868 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  20600 \t Train Loss:  0.021530824 \t Train Accuracy:  99.30%\nStep:  20600 \t Eval Loss:  0.02556945 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  20700 \t Train Loss:  0.020978453 \t Train Accuracy:  99.37%\nStep:  20700 \t Eval Loss:  0.021398336 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  20800 \t Train Loss:  0.020446636 \t Train Accuracy:  99.32%\nStep:  20800 \t Eval Loss:  0.027093744 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  20900 \t Train Loss:  0.02045343 \t Train Accuracy:  99.34%\nStep:  20900 \t Eval Loss:  0.02429119 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  21000 \t Train Loss:  0.020275129 \t Train Accuracy:  99.33%\nStep:  21000 \t Eval Loss:  0.022987796 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  21100 \t Train Loss:  0.02337924 \t Train Accuracy:  99.18%\nStep:  21100 \t Eval Loss:  0.025550531 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  21200 \t Train Loss:  0.022385538 \t Train Accuracy:  99.32%\nStep:  21200 \t Eval Loss:  0.026883215 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  21300 \t Train Loss:  0.02502966 \t Train Accuracy:  99.28%\nStep:  21300 \t Eval Loss:  0.02378507 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  21400 \t Train Loss:  0.024270024 \t Train Accuracy:  99.27%\nStep:  21400 \t Eval Loss:  0.027869405 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  21500 \t Train Loss:  0.023228168 \t Train Accuracy:  99.28%\nStep:  21500 \t Eval Loss:  0.025268588 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  21600 \t Train Loss:  0.022044597 \t Train Accuracy:  99.35%\nStep:  21600 \t Eval Loss:  0.02121857 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  21700 \t Train Loss:  0.018514773 \t Train Accuracy:  99.43%\nStep:  21700 \t Eval Loss:  0.022382397 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  21800 \t Train Loss:  0.02324359 \t Train Accuracy:  99.32%\nStep:  21800 \t Eval Loss:  0.02125717 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  21900 \t Train Loss:  0.022589121 \t Train Accuracy:  99.35%\nStep:  21900 \t Eval Loss:  0.025252357 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  22000 \t Train Loss:  0.02541681 \t Train Accuracy:  99.19%\nStep:  22000 \t Eval Loss:  0.02858596 \t Eval Accuracy:  99.08%\n##########################################################\nStep:  22100 \t Train Loss:  0.020944875 \t Train Accuracy:  99.28%\nStep:  22100 \t Eval Loss:  0.022753619 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  22200 \t Train Loss:  0.022263307 \t Train Accuracy:  99.34%\nStep:  22200 \t Eval Loss:  0.022780485 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  22300 \t Train Loss:  0.021892173 \t Train Accuracy:  99.39%\nStep:  22300 \t Eval Loss:  0.02190422 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  22400 \t Train Loss:  0.022804158 \t Train Accuracy:  99.29%\nStep:  22400 \t Eval Loss:  0.026903577 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  22500 \t Train Loss:  0.023093246 \t Train Accuracy:  99.29%\nStep:  22500 \t Eval Loss:  0.021777656 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  22600 \t Train Loss:  0.019721128 \t Train Accuracy:  99.33%\nStep:  22600 \t Eval Loss:  0.022556746 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  22700 \t Train Loss:  0.023429947 \t Train Accuracy:  99.21%\nStep:  22700 \t Eval Loss:  0.027592178 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  22800 \t Train Loss:  0.020948952 \t Train Accuracy:  99.27%\nStep:  22800 \t Eval Loss:  0.022703819 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  22900 \t Train Loss:  0.022961916 \t Train Accuracy:  99.29%\nStep:  22900 \t Eval Loss:  0.02245853 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  23000 \t Train Loss:  0.022277992 \t Train Accuracy:  99.23%\nStep:  23000 \t Eval Loss:  0.026040021 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  23100 \t Train Loss:  0.02264443 \t Train Accuracy:  99.27%\nStep:  23100 \t Eval Loss:  0.02518115 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  23200 \t Train Loss:  0.025312733 \t Train Accuracy:  99.21%\nStep:  23200 \t Eval Loss:  0.0233703 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  23300 \t Train Loss:  0.021400008 \t Train Accuracy:  99.34%\nStep:  23300 \t Eval Loss:  0.021419592 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  23400 \t Train Loss:  0.0210273 \t Train Accuracy:  99.37%\nStep:  23400 \t Eval Loss:  0.027301718 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  23500 \t Train Loss:  0.022690859 \t Train Accuracy:  99.26%\nStep:  23500 \t Eval Loss:  0.028337244 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  23600 \t Train Loss:  0.025503445 \t Train Accuracy:  99.22%\nStep:  23600 \t Eval Loss:  0.025020972 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  23700 \t Train Loss:  0.022759238 \t Train Accuracy:  99.37%\nStep:  23700 \t Eval Loss:  0.02028809 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  23800 \t Train Loss:  0.023651093 \t Train Accuracy:  99.29%\nStep:  23800 \t Eval Loss:  0.025762733 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  23900 \t Train Loss:  0.024137188 \t Train Accuracy:  99.34%\nStep:  23900 \t Eval Loss:  0.023446158 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  24000 \t Train Loss:  0.022695385 \t Train Accuracy:  99.28%\nStep:  24000 \t Eval Loss:  0.021342173 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  24100 \t Train Loss:  0.024439927 \t Train Accuracy:  99.23%\nStep:  24100 \t Eval Loss:  0.023117622 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  24200 \t Train Loss:  0.023585632 \t Train Accuracy:  99.29%\nStep:  24200 \t Eval Loss:  0.024849918 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  24300 \t Train Loss:  0.0192355 \t Train Accuracy:  99.40%\nStep:  24300 \t Eval Loss:  0.027094418 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  24400 \t Train Loss:  0.020225115 \t Train Accuracy:  99.38%\nStep:  24400 \t Eval Loss:  0.026185313 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  24500 \t Train Loss:  0.024605067 \t Train Accuracy:  99.30%\nStep:  24500 \t Eval Loss:  0.024283687 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  24600 \t Train Loss:  0.02114713 \t Train Accuracy:  99.35%\nStep:  24600 \t Eval Loss:  0.021007374 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  24700 \t Train Loss:  0.021959035 \t Train Accuracy:  99.37%\nStep:  24700 \t Eval Loss:  0.022774445 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  24800 \t Train Loss:  0.022248257 \t Train Accuracy:  99.39%\nStep:  24800 \t Eval Loss:  0.024766698 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  24900 \t Train Loss:  0.021339905 \t Train Accuracy:  99.30%\nStep:  24900 \t Eval Loss:  0.025183752 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  25000 \t Train Loss:  0.022853242 \t Train Accuracy:  99.24%\nStep:  25000 \t Eval Loss:  0.022886489 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  25100 \t Train Loss:  0.022075793 \t Train Accuracy:  99.34%\nStep:  25100 \t Eval Loss:  0.022451615 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  25200 \t Train Loss:  0.020574423 \t Train Accuracy:  99.43%\nStep:  25200 \t Eval Loss:  0.023003293 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  25300 \t Train Loss:  0.01969355 \t Train Accuracy:  99.34%\nStep:  25300 \t Eval Loss:  0.026580736 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  25400 \t Train Loss:  0.01958953 \t Train Accuracy:  99.37%\nStep:  25400 \t Eval Loss:  0.01998407 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  25500 \t Train Loss:  0.019262029 \t Train Accuracy:  99.33%\nStep:  25500 \t Eval Loss:  0.024197448 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  25600 \t Train Loss:  0.020470418 \t Train Accuracy:  99.30%\nStep:  25600 \t Eval Loss:  0.018091284 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  25700 \t Train Loss:  0.021379886 \t Train Accuracy:  99.37%\nStep:  25700 \t Eval Loss:  0.028017733 \t Eval Accuracy:  99.15%\n##########################################################\nStep:  25800 \t Train Loss:  0.018946677 \t Train Accuracy:  99.45%\nStep:  25800 \t Eval Loss:  0.026591456 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  25900 \t Train Loss:  0.021884145 \t Train Accuracy:  99.27%\nStep:  25900 \t Eval Loss:  0.028538361 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  26000 \t Train Loss:  0.024163868 \t Train Accuracy:  99.30%\nStep:  26000 \t Eval Loss:  0.026159994 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  26100 \t Train Loss:  0.022558123 \t Train Accuracy:  99.37%\nStep:  26100 \t Eval Loss:  0.021552404 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  26200 \t Train Loss:  0.022231523 \t Train Accuracy:  99.26%\nStep:  26200 \t Eval Loss:  0.022458222 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  26300 \t Train Loss:  0.019838419 \t Train Accuracy:  99.41%\nStep:  26300 \t Eval Loss:  0.022523161 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  26400 \t Train Loss:  0.020373976 \t Train Accuracy:  99.32%\nStep:  26400 \t Eval Loss:  0.021581395 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  26500 \t Train Loss:  0.022260528 \t Train Accuracy:  99.26%\nStep:  26500 \t Eval Loss:  0.024642851 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  26600 \t Train Loss:  0.023457829 \t Train Accuracy:  99.24%\nStep:  26600 \t Eval Loss:  0.021876263 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  26700 \t Train Loss:  0.022738045 \t Train Accuracy:  99.30%\nStep:  26700 \t Eval Loss:  0.023613159 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  26800 \t Train Loss:  0.024476608 \t Train Accuracy:  99.22%\nStep:  26800 \t Eval Loss:  0.023867384 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  26900 \t Train Loss:  0.019176392 \t Train Accuracy:  99.41%\nStep:  26900 \t Eval Loss:  0.024851039 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  27000 \t Train Loss:  0.018900309 \t Train Accuracy:  99.44%\nStep:  27000 \t Eval Loss:  0.023591973 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  27100 \t Train Loss:  0.020833272 \t Train Accuracy:  99.35%\nStep:  27100 \t Eval Loss:  0.019711882 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  27200 \t Train Loss:  0.023301158 \t Train Accuracy:  99.23%\nStep:  27200 \t Eval Loss:  0.020968342 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  27300 \t Train Loss:  0.019999944 \t Train Accuracy:  99.43%\nStep:  27300 \t Eval Loss:  0.026352596 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  27400 \t Train Loss:  0.022756284 \t Train Accuracy:  99.32%\nStep:  27400 \t Eval Loss:  0.021436244 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  27500 \t Train Loss:  0.021530233 \t Train Accuracy:  99.35%\nStep:  27500 \t Eval Loss:  0.024516346 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  27600 \t Train Loss:  0.017122652 \t Train Accuracy:  99.43%\nStep:  27600 \t Eval Loss:  0.023210783 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  27700 \t Train Loss:  0.02050874 \t Train Accuracy:  99.39%\nStep:  27700 \t Eval Loss:  0.023394046 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  27800 \t Train Loss:  0.021957021 \t Train Accuracy:  99.32%\nStep:  27800 \t Eval Loss:  0.02316177 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  27900 \t Train Loss:  0.023908146 \t Train Accuracy:  99.35%\nStep:  27900 \t Eval Loss:  0.018983804 \t Eval Accuracy:  99.46%\n##########################################################\nStep:  28000 \t Train Loss:  0.020259567 \t Train Accuracy:  99.37%\nStep:  28000 \t Eval Loss:  0.019048054 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  28100 \t Train Loss:  0.022442192 \t Train Accuracy:  99.37%\nStep:  28100 \t Eval Loss:  0.025191246 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  28200 \t Train Loss:  0.020062089 \t Train Accuracy:  99.35%\nStep:  28200 \t Eval Loss:  0.021659773 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  28300 \t Train Loss:  0.020066403 \t Train Accuracy:  99.35%\nStep:  28300 \t Eval Loss:  0.02613449 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  28400 \t Train Loss:  0.01938598 \t Train Accuracy:  99.41%\nStep:  28400 \t Eval Loss:  0.023434745 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  28500 \t Train Loss:  0.022231705 \t Train Accuracy:  99.33%\nStep:  28500 \t Eval Loss:  0.02528613 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  28600 \t Train Loss:  0.022030268 \t Train Accuracy:  99.33%\nStep:  28600 \t Eval Loss:  0.022980668 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  28700 \t Train Loss:  0.022624414 \t Train Accuracy:  99.29%\nStep:  28700 \t Eval Loss:  0.026709046 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  28800 \t Train Loss:  0.022267334 \t Train Accuracy:  99.29%\nStep:  28800 \t Eval Loss:  0.023913117 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  28900 \t Train Loss:  0.021442514 \t Train Accuracy:  99.37%\nStep:  28900 \t Eval Loss:  0.02778909 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  29000 \t Train Loss:  0.020162437 \t Train Accuracy:  99.35%\nStep:  29000 \t Eval Loss:  0.021552736 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  29100 \t Train Loss:  0.017387306 \t Train Accuracy:  99.44%\nStep:  29100 \t Eval Loss:  0.023640884 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  29200 \t Train Loss:  0.02174297 \t Train Accuracy:  99.33%\nStep:  29200 \t Eval Loss:  0.023362953 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  29300 \t Train Loss:  0.018866286 \t Train Accuracy:  99.40%\nStep:  29300 \t Eval Loss:  0.02422066 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  29400 \t Train Loss:  0.024722043 \t Train Accuracy:  99.22%\nStep:  29400 \t Eval Loss:  0.0192938 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  29500 \t Train Loss:  0.021775736 \t Train Accuracy:  99.33%\nStep:  29500 \t Eval Loss:  0.02817733 \t Eval Accuracy:  99.16%\n##########################################################\nStep:  29600 \t Train Loss:  0.01911682 \t Train Accuracy:  99.41%\nStep:  29600 \t Eval Loss:  0.025198944 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  29700 \t Train Loss:  0.022683507 \t Train Accuracy:  99.32%\nStep:  29700 \t Eval Loss:  0.021467663 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  29800 \t Train Loss:  0.022471879 \t Train Accuracy:  99.35%\nStep:  29800 \t Eval Loss:  0.02234941 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  29900 \t Train Loss:  0.017939983 \t Train Accuracy:  99.38%\nStep:  29900 \t Eval Loss:  0.02292268 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  30000 \t Train Loss:  0.019716632 \t Train Accuracy:  99.45%\nStep:  30000 \t Eval Loss:  0.025725987 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  30100 \t Train Loss:  0.019099664 \t Train Accuracy:  99.41%\nStep:  30100 \t Eval Loss:  0.022300825 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  30200 \t Train Loss:  0.021895656 \t Train Accuracy:  99.30%\nStep:  30200 \t Eval Loss:  0.024358109 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  30300 \t Train Loss:  0.020610314 \t Train Accuracy:  99.37%\nStep:  30300 \t Eval Loss:  0.02482403 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  30400 \t Train Loss:  0.017809905 \t Train Accuracy:  99.45%\nStep:  30400 \t Eval Loss:  0.020149782 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  30500 \t Train Loss:  0.020390505 \t Train Accuracy:  99.35%\nStep:  30500 \t Eval Loss:  0.021028427 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  30600 \t Train Loss:  0.017335713 \t Train Accuracy:  99.43%\nStep:  30600 \t Eval Loss:  0.023249473 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  30700 \t Train Loss:  0.020195547 \t Train Accuracy:  99.45%\nStep:  30700 \t Eval Loss:  0.022177447 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  30800 \t Train Loss:  0.01911921 \t Train Accuracy:  99.38%\nStep:  30800 \t Eval Loss:  0.02431374 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  30900 \t Train Loss:  0.022185132 \t Train Accuracy:  99.38%\nStep:  30900 \t Eval Loss:  0.02355265 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  31000 \t Train Loss:  0.018240435 \t Train Accuracy:  99.46%\nStep:  31000 \t Eval Loss:  0.02115918 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  31100 \t Train Loss:  0.020901915 \t Train Accuracy:  99.40%\nStep:  31100 \t Eval Loss:  0.01838126 \t Eval Accuracy:  99.45%\n##########################################################\nStep:  31200 \t Train Loss:  0.018562332 \t Train Accuracy:  99.35%\nStep:  31200 \t Eval Loss:  0.02265186 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  31300 \t Train Loss:  0.019649336 \t Train Accuracy:  99.37%\nStep:  31300 \t Eval Loss:  0.023844006 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  31400 \t Train Loss:  0.021525644 \t Train Accuracy:  99.40%\nStep:  31400 \t Eval Loss:  0.026216477 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  31500 \t Train Loss:  0.020583883 \t Train Accuracy:  99.43%\nStep:  31500 \t Eval Loss:  0.023274679 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  31600 \t Train Loss:  0.023672827 \t Train Accuracy:  99.32%\nStep:  31600 \t Eval Loss:  0.024575673 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  31700 \t Train Loss:  0.021394337 \t Train Accuracy:  99.29%\nStep:  31700 \t Eval Loss:  0.021731611 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  31800 \t Train Loss:  0.019084468 \t Train Accuracy:  99.39%\nStep:  31800 \t Eval Loss:  0.025059514 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  31900 \t Train Loss:  0.021351904 \t Train Accuracy:  99.35%\nStep:  31900 \t Eval Loss:  0.022126008 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  32000 \t Train Loss:  0.020787586 \t Train Accuracy:  99.35%\nStep:  32000 \t Eval Loss:  0.02541447 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  32100 \t Train Loss:  0.024491254 \t Train Accuracy:  99.27%\nStep:  32100 \t Eval Loss:  0.022937225 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  32200 \t Train Loss:  0.02097568 \t Train Accuracy:  99.32%\nStep:  32200 \t Eval Loss:  0.020686442 \t Eval Accuracy:  99.43%\n##########################################################\nStep:  32300 \t Train Loss:  0.020186342 \t Train Accuracy:  99.35%\nStep:  32300 \t Eval Loss:  0.025636692 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  32400 \t Train Loss:  0.021176312 \t Train Accuracy:  99.33%\nStep:  32400 \t Eval Loss:  0.023674814 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  32500 \t Train Loss:  0.022665925 \t Train Accuracy:  99.33%\nStep:  32500 \t Eval Loss:  0.026450422 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  32600 \t Train Loss:  0.02083703 \t Train Accuracy:  99.33%\nStep:  32600 \t Eval Loss:  0.025665537 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  32700 \t Train Loss:  0.020510517 \t Train Accuracy:  99.33%\nStep:  32700 \t Eval Loss:  0.02806344 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  32800 \t Train Loss:  0.020113477 \t Train Accuracy:  99.37%\nStep:  32800 \t Eval Loss:  0.021486271 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  32900 \t Train Loss:  0.020133935 \t Train Accuracy:  99.39%\nStep:  32900 \t Eval Loss:  0.02249502 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  33000 \t Train Loss:  0.020189913 \t Train Accuracy:  99.44%\nStep:  33000 \t Eval Loss:  0.020964928 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  33100 \t Train Loss:  0.024498139 \t Train Accuracy:  99.27%\nStep:  33100 \t Eval Loss:  0.022709655 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  33200 \t Train Loss:  0.02002522 \t Train Accuracy:  99.38%\nStep:  33200 \t Eval Loss:  0.021503702 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  33300 \t Train Loss:  0.022356793 \t Train Accuracy:  99.33%\nStep:  33300 \t Eval Loss:  0.021848045 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  33400 \t Train Loss:  0.023369845 \t Train Accuracy:  99.28%\nStep:  33400 \t Eval Loss:  0.019555472 \t Eval Accuracy:  99.43%\n##########################################################\nStep:  33500 \t Train Loss:  0.020158745 \t Train Accuracy:  99.44%\nStep:  33500 \t Eval Loss:  0.02521382 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  33600 \t Train Loss:  0.023141038 \t Train Accuracy:  99.30%\nStep:  33600 \t Eval Loss:  0.023279712 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  33700 \t Train Loss:  0.02073023 \t Train Accuracy:  99.35%\nStep:  33700 \t Eval Loss:  0.019639147 \t Eval Accuracy:  99.44%\n##########################################################\nStep:  33800 \t Train Loss:  0.020939628 \t Train Accuracy:  99.41%\nStep:  33800 \t Eval Loss:  0.022953644 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  33900 \t Train Loss:  0.022313498 \t Train Accuracy:  99.34%\nStep:  33900 \t Eval Loss:  0.022437992 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  34000 \t Train Loss:  0.017845042 \t Train Accuracy:  99.38%\nStep:  34000 \t Eval Loss:  0.019618645 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  34100 \t Train Loss:  0.023870144 \t Train Accuracy:  99.24%\nStep:  34100 \t Eval Loss:  0.0215003 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  34200 \t Train Loss:  0.021728419 \t Train Accuracy:  99.33%\nStep:  34200 \t Eval Loss:  0.023407523 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  34300 \t Train Loss:  0.020355625 \t Train Accuracy:  99.39%\nStep:  34300 \t Eval Loss:  0.023617363 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  34400 \t Train Loss:  0.019917022 \t Train Accuracy:  99.40%\nStep:  34400 \t Eval Loss:  0.022603877 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  34500 \t Train Loss:  0.022501282 \t Train Accuracy:  99.33%\nStep:  34500 \t Eval Loss:  0.021781286 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  34600 \t Train Loss:  0.020233568 \t Train Accuracy:  99.39%\nStep:  34600 \t Eval Loss:  0.026014555 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  34700 \t Train Loss:  0.020242177 \t Train Accuracy:  99.35%\nStep:  34700 \t Eval Loss:  0.02064899 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  34800 \t Train Loss:  0.022184009 \t Train Accuracy:  99.32%\nStep:  34800 \t Eval Loss:  0.028715106 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  34900 \t Train Loss:  0.017941434 \t Train Accuracy:  99.45%\nStep:  34900 \t Eval Loss:  0.01955819 \t Eval Accuracy:  99.45%\n##########################################################\nStep:  35000 \t Train Loss:  0.021320831 \t Train Accuracy:  99.40%\nStep:  35000 \t Eval Loss:  0.027693545 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  35100 \t Train Loss:  0.02491108 \t Train Accuracy:  99.19%\nStep:  35100 \t Eval Loss:  0.01948674 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  35200 \t Train Loss:  0.020571372 \t Train Accuracy:  99.43%\nStep:  35200 \t Eval Loss:  0.023414778 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  35300 \t Train Loss:  0.018655565 \t Train Accuracy:  99.43%\nStep:  35300 \t Eval Loss:  0.027078185 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  35400 \t Train Loss:  0.023648418 \t Train Accuracy:  99.30%\nStep:  35400 \t Eval Loss:  0.020445853 \t Eval Accuracy:  99.43%\n##########################################################\nStep:  35500 \t Train Loss:  0.025245385 \t Train Accuracy:  99.19%\nStep:  35500 \t Eval Loss:  0.02691685 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  35600 \t Train Loss:  0.020969693 \t Train Accuracy:  99.39%\nStep:  35600 \t Eval Loss:  0.026091453 \t Eval Accuracy:  99.21%\n##########################################################\nStep:  35700 \t Train Loss:  0.019582078 \t Train Accuracy:  99.34%\nStep:  35700 \t Eval Loss:  0.022191666 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  35800 \t Train Loss:  0.02090653 \t Train Accuracy:  99.44%\nStep:  35800 \t Eval Loss:  0.021201702 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  35900 \t Train Loss:  0.02332904 \t Train Accuracy:  99.33%\nStep:  35900 \t Eval Loss:  0.023947213 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  36000 \t Train Loss:  0.021667823 \t Train Accuracy:  99.26%\nStep:  36000 \t Eval Loss:  0.024743468 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  36100 \t Train Loss:  0.02093561 \t Train Accuracy:  99.37%\nStep:  36100 \t Eval Loss:  0.022742646 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  36200 \t Train Loss:  0.01815684 \t Train Accuracy:  99.45%\nStep:  36200 \t Eval Loss:  0.02315339 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  36300 \t Train Loss:  0.020180926 \t Train Accuracy:  99.35%\nStep:  36300 \t Eval Loss:  0.022520699 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  36400 \t Train Loss:  0.018584644 \t Train Accuracy:  99.39%\nStep:  36400 \t Eval Loss:  0.025619423 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  36500 \t Train Loss:  0.017886294 \t Train Accuracy:  99.44%\nStep:  36500 \t Eval Loss:  0.020503737 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  36600 \t Train Loss:  0.017911877 \t Train Accuracy:  99.43%\nStep:  36600 \t Eval Loss:  0.022051457 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  36700 \t Train Loss:  0.022468075 \t Train Accuracy:  99.38%\nStep:  36700 \t Eval Loss:  0.021676518 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  36800 \t Train Loss:  0.019323882 \t Train Accuracy:  99.39%\nStep:  36800 \t Eval Loss:  0.025437143 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  36900 \t Train Loss:  0.019478276 \t Train Accuracy:  99.39%\nStep:  36900 \t Eval Loss:  0.024221014 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  37000 \t Train Loss:  0.021530462 \t Train Accuracy:  99.35%\nStep:  37000 \t Eval Loss:  0.019248242 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  37100 \t Train Loss:  0.022176325 \t Train Accuracy:  99.35%\nStep:  37100 \t Eval Loss:  0.022027303 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  37200 \t Train Loss:  0.020405967 \t Train Accuracy:  99.37%\nStep:  37200 \t Eval Loss:  0.026245203 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  37300 \t Train Loss:  0.019602519 \t Train Accuracy:  99.35%\nStep:  37300 \t Eval Loss:  0.022655355 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  37400 \t Train Loss:  0.019653589 \t Train Accuracy:  99.43%\nStep:  37400 \t Eval Loss:  0.023732133 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  37500 \t Train Loss:  0.021356082 \t Train Accuracy:  99.30%\nStep:  37500 \t Eval Loss:  0.02199541 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  37600 \t Train Loss:  0.018002857 \t Train Accuracy:  99.46%\nStep:  37600 \t Eval Loss:  0.021761347 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  37700 \t Train Loss:  0.019785125 \t Train Accuracy:  99.44%\nStep:  37700 \t Eval Loss:  0.02219448 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  37800 \t Train Loss:  0.019926284 \t Train Accuracy:  99.38%\nStep:  37800 \t Eval Loss:  0.02017026 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  37900 \t Train Loss:  0.020516707 \t Train Accuracy:  99.39%\nStep:  37900 \t Eval Loss:  0.024941646 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  38000 \t Train Loss:  0.021380745 \t Train Accuracy:  99.29%\nStep:  38000 \t Eval Loss:  0.019995395 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  38100 \t Train Loss:  0.0183524 \t Train Accuracy:  99.46%\nStep:  38100 \t Eval Loss:  0.0241927 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  38200 \t Train Loss:  0.020183453 \t Train Accuracy:  99.35%\nStep:  38200 \t Eval Loss:  0.027460065 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  38300 \t Train Loss:  0.023460377 \t Train Accuracy:  99.34%\nStep:  38300 \t Eval Loss:  0.020977138 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  38400 \t Train Loss:  0.02187546 \t Train Accuracy:  99.33%\nStep:  38400 \t Eval Loss:  0.022935458 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  38500 \t Train Loss:  0.019287184 \t Train Accuracy:  99.41%\nStep:  38500 \t Eval Loss:  0.019980485 \t Eval Accuracy:  99.43%\n##########################################################\nStep:  38600 \t Train Loss:  0.020916412 \t Train Accuracy:  99.44%\nStep:  38600 \t Eval Loss:  0.02478122 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  38700 \t Train Loss:  0.018730737 \t Train Accuracy:  99.43%\nStep:  38700 \t Eval Loss:  0.028226469 \t Eval Accuracy:  99.10%\n##########################################################\nStep:  38800 \t Train Loss:  0.018119358 \t Train Accuracy:  99.37%\nStep:  38800 \t Eval Loss:  0.024352666 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  38900 \t Train Loss:  0.019002208 \t Train Accuracy:  99.41%\nStep:  38900 \t Eval Loss:  0.022125687 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  39000 \t Train Loss:  0.023476074 \t Train Accuracy:  99.32%\nStep:  39000 \t Eval Loss:  0.021845978 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  39100 \t Train Loss:  0.025068747 \t Train Accuracy:  99.24%\nStep:  39100 \t Eval Loss:  0.027922496 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  39200 \t Train Loss:  0.021785576 \t Train Accuracy:  99.30%\nStep:  39200 \t Eval Loss:  0.024493817 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  39300 \t Train Loss:  0.01720788 \t Train Accuracy:  99.50%\nStep:  39300 \t Eval Loss:  0.024681458 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  39400 \t Train Loss:  0.02175609 \t Train Accuracy:  99.33%\nStep:  39400 \t Eval Loss:  0.02994558 \t Eval Accuracy:  99.13%\n##########################################################\nStep:  39500 \t Train Loss:  0.019845754 \t Train Accuracy:  99.35%\nStep:  39500 \t Eval Loss:  0.023670536 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  39600 \t Train Loss:  0.019711375 \t Train Accuracy:  99.38%\nStep:  39600 \t Eval Loss:  0.01935801 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  39700 \t Train Loss:  0.018845119 \t Train Accuracy:  99.34%\nStep:  39700 \t Eval Loss:  0.023166386 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  39800 \t Train Loss:  0.018220657 \t Train Accuracy:  99.41%\nStep:  39800 \t Eval Loss:  0.022457507 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  39900 \t Train Loss:  0.021392671 \t Train Accuracy:  99.29%\nStep:  39900 \t Eval Loss:  0.027693935 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  40000 \t Train Loss:  0.020264309 \t Train Accuracy:  99.39%\nStep:  40000 \t Eval Loss:  0.020346822 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  40100 \t Train Loss:  0.018733386 \t Train Accuracy:  99.35%\nStep:  40100 \t Eval Loss:  0.018671926 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  40200 \t Train Loss:  0.017974354 \t Train Accuracy:  99.43%\nStep:  40200 \t Eval Loss:  0.023897335 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  40300 \t Train Loss:  0.019520469 \t Train Accuracy:  99.37%\nStep:  40300 \t Eval Loss:  0.026370233 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  40400 \t Train Loss:  0.020748116 \t Train Accuracy:  99.26%\nStep:  40400 \t Eval Loss:  0.022067307 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  40500 \t Train Loss:  0.019654224 \t Train Accuracy:  99.40%\nStep:  40500 \t Eval Loss:  0.022649372 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  40600 \t Train Loss:  0.023552597 \t Train Accuracy:  99.29%\nStep:  40600 \t Eval Loss:  0.023866035 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  40700 \t Train Loss:  0.016903779 \t Train Accuracy:  99.50%\nStep:  40700 \t Eval Loss:  0.02399902 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  40800 \t Train Loss:  0.02052152 \t Train Accuracy:  99.32%\nStep:  40800 \t Eval Loss:  0.025793912 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  40900 \t Train Loss:  0.018623166 \t Train Accuracy:  99.39%\nStep:  40900 \t Eval Loss:  0.022025742 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  41000 \t Train Loss:  0.017547969 \t Train Accuracy:  99.46%\nStep:  41000 \t Eval Loss:  0.023001717 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  41100 \t Train Loss:  0.019937988 \t Train Accuracy:  99.44%\nStep:  41100 \t Eval Loss:  0.024188055 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  41200 \t Train Loss:  0.018981103 \t Train Accuracy:  99.34%\nStep:  41200 \t Eval Loss:  0.025411688 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  41300 \t Train Loss:  0.021010177 \t Train Accuracy:  99.34%\nStep:  41300 \t Eval Loss:  0.025545448 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  41400 \t Train Loss:  0.022515677 \t Train Accuracy:  99.29%\nStep:  41400 \t Eval Loss:  0.02464257 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  41500 \t Train Loss:  0.023887534 \t Train Accuracy:  99.32%\nStep:  41500 \t Eval Loss:  0.024307061 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  41600 \t Train Loss:  0.022722904 \t Train Accuracy:  99.30%\nStep:  41600 \t Eval Loss:  0.025799405 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  41700 \t Train Loss:  0.016896263 \t Train Accuracy:  99.49%\nStep:  41700 \t Eval Loss:  0.025367223 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  41800 \t Train Loss:  0.02243546 \t Train Accuracy:  99.35%\nStep:  41800 \t Eval Loss:  0.022296714 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  41900 \t Train Loss:  0.019375645 \t Train Accuracy:  99.34%\nStep:  41900 \t Eval Loss:  0.024369568 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  42000 \t Train Loss:  0.018794397 \t Train Accuracy:  99.45%\nStep:  42000 \t Eval Loss:  0.025778238 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  42100 \t Train Loss:  0.018000234 \t Train Accuracy:  99.44%\nStep:  42100 \t Eval Loss:  0.023862952 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  42200 \t Train Loss:  0.023228934 \t Train Accuracy:  99.23%\nStep:  42200 \t Eval Loss:  0.024396896 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  42300 \t Train Loss:  0.019298304 \t Train Accuracy:  99.43%\nStep:  42300 \t Eval Loss:  0.022779524 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  42400 \t Train Loss:  0.021269219 \t Train Accuracy:  99.38%\nStep:  42400 \t Eval Loss:  0.02165709 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  42500 \t Train Loss:  0.015727999 \t Train Accuracy:  99.46%\nStep:  42500 \t Eval Loss:  0.026643056 \t Eval Accuracy:  99.17%\n##########################################################\nStep:  42600 \t Train Loss:  0.015430069 \t Train Accuracy:  99.57%\nStep:  42600 \t Eval Loss:  0.022707751 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  42700 \t Train Loss:  0.020642325 \t Train Accuracy:  99.37%\nStep:  42700 \t Eval Loss:  0.023697063 \t Eval Accuracy:  99.19%\n##########################################################\nStep:  42800 \t Train Loss:  0.023231907 \t Train Accuracy:  99.28%\nStep:  42800 \t Eval Loss:  0.025268242 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  42900 \t Train Loss:  0.021253498 \t Train Accuracy:  99.37%\nStep:  42900 \t Eval Loss:  0.019589102 \t Eval Accuracy:  99.43%\n##########################################################\nStep:  43000 \t Train Loss:  0.023089428 \t Train Accuracy:  99.27%\nStep:  43000 \t Eval Loss:  0.024592962 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  43100 \t Train Loss:  0.025683664 \t Train Accuracy:  99.23%\nStep:  43100 \t Eval Loss:  0.025521614 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  43200 \t Train Loss:  0.017345939 \t Train Accuracy:  99.46%\nStep:  43200 \t Eval Loss:  0.024469737 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  43300 \t Train Loss:  0.019338598 \t Train Accuracy:  99.37%\nStep:  43300 \t Eval Loss:  0.023171116 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  43400 \t Train Loss:  0.01983481 \t Train Accuracy:  99.35%\nStep:  43400 \t Eval Loss:  0.024956752 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  43500 \t Train Loss:  0.021147348 \t Train Accuracy:  99.32%\nStep:  43500 \t Eval Loss:  0.022047536 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  43600 \t Train Loss:  0.021511363 \t Train Accuracy:  99.35%\nStep:  43600 \t Eval Loss:  0.023301875 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  43700 \t Train Loss:  0.017700382 \t Train Accuracy:  99.41%\nStep:  43700 \t Eval Loss:  0.021104805 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  43800 \t Train Loss:  0.023173656 \t Train Accuracy:  99.37%\nStep:  43800 \t Eval Loss:  0.01955669 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  43900 \t Train Loss:  0.01840574 \t Train Accuracy:  99.44%\nStep:  43900 \t Eval Loss:  0.024038482 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  44000 \t Train Loss:  0.021846969 \t Train Accuracy:  99.28%\nStep:  44000 \t Eval Loss:  0.024736552 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  44100 \t Train Loss:  0.023111675 \t Train Accuracy:  99.32%\nStep:  44100 \t Eval Loss:  0.027243074 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  44200 \t Train Loss:  0.020049565 \t Train Accuracy:  99.45%\nStep:  44200 \t Eval Loss:  0.021542283 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  44300 \t Train Loss:  0.017697528 \t Train Accuracy:  99.45%\nStep:  44300 \t Eval Loss:  0.02279155 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  44400 \t Train Loss:  0.02290688 \t Train Accuracy:  99.17%\nStep:  44400 \t Eval Loss:  0.025980588 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  44500 \t Train Loss:  0.0202141 \t Train Accuracy:  99.37%\nStep:  44500 \t Eval Loss:  0.024229042 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  44600 \t Train Loss:  0.021238312 \t Train Accuracy:  99.28%\nStep:  44600 \t Eval Loss:  0.02666764 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  44700 \t Train Loss:  0.018697541 \t Train Accuracy:  99.46%\nStep:  44700 \t Eval Loss:  0.022726987 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  44800 \t Train Loss:  0.01884387 \t Train Accuracy:  99.41%\nStep:  44800 \t Eval Loss:  0.019654667 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  44900 \t Train Loss:  0.020360578 \t Train Accuracy:  99.40%\nStep:  44900 \t Eval Loss:  0.020739438 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  45000 \t Train Loss:  0.016249247 \t Train Accuracy:  99.48%\nStep:  45000 \t Eval Loss:  0.025910743 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  45100 \t Train Loss:  0.0169848 \t Train Accuracy:  99.48%\nStep:  45100 \t Eval Loss:  0.019556906 \t Eval Accuracy:  99.41%\n##########################################################\nStep:  45200 \t Train Loss:  0.018938826 \t Train Accuracy:  99.45%\nStep:  45200 \t Eval Loss:  0.022768982 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  45300 \t Train Loss:  0.023019444 \t Train Accuracy:  99.28%\nStep:  45300 \t Eval Loss:  0.020639297 \t Eval Accuracy:  99.49%\n##########################################################\nStep:  45400 \t Train Loss:  0.01653983 \t Train Accuracy:  99.46%\nStep:  45400 \t Eval Loss:  0.022410387 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  45500 \t Train Loss:  0.016532864 \t Train Accuracy:  99.48%\nStep:  45500 \t Eval Loss:  0.022325814 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  45600 \t Train Loss:  0.019259999 \t Train Accuracy:  99.43%\nStep:  45600 \t Eval Loss:  0.021997873 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  45700 \t Train Loss:  0.021000829 \t Train Accuracy:  99.34%\nStep:  45700 \t Eval Loss:  0.026986975 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  45800 \t Train Loss:  0.01965858 \t Train Accuracy:  99.41%\nStep:  45800 \t Eval Loss:  0.021630373 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  45900 \t Train Loss:  0.02209559 \t Train Accuracy:  99.30%\nStep:  45900 \t Eval Loss:  0.022601668 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  46000 \t Train Loss:  0.019501816 \t Train Accuracy:  99.38%\nStep:  46000 \t Eval Loss:  0.021194201 \t Eval Accuracy:  99.39%\n##########################################################\nStep:  46100 \t Train Loss:  0.020265633 \t Train Accuracy:  99.38%\nStep:  46100 \t Eval Loss:  0.023506438 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  46200 \t Train Loss:  0.022552779 \t Train Accuracy:  99.34%\nStep:  46200 \t Eval Loss:  0.020992456 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  46300 \t Train Loss:  0.021451421 \t Train Accuracy:  99.29%\nStep:  46300 \t Eval Loss:  0.023115389 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  46400 \t Train Loss:  0.021767586 \t Train Accuracy:  99.40%\nStep:  46400 \t Eval Loss:  0.023601653 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  46500 \t Train Loss:  0.017324846 \t Train Accuracy:  99.44%\nStep:  46500 \t Eval Loss:  0.024885895 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  46600 \t Train Loss:  0.020531867 \t Train Accuracy:  99.44%\nStep:  46600 \t Eval Loss:  0.021397196 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  46700 \t Train Loss:  0.017851796 \t Train Accuracy:  99.49%\nStep:  46700 \t Eval Loss:  0.02172254 \t Eval Accuracy:  99.37%\n##########################################################\nStep:  46800 \t Train Loss:  0.017557615 \t Train Accuracy:  99.45%\nStep:  46800 \t Eval Loss:  0.02702567 \t Eval Accuracy:  99.22%\n##########################################################\nStep:  46900 \t Train Loss:  0.02208754 \t Train Accuracy:  99.26%\nStep:  46900 \t Eval Loss:  0.021284962 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  47000 \t Train Loss:  0.020316385 \t Train Accuracy:  99.40%\nStep:  47000 \t Eval Loss:  0.024930086 \t Eval Accuracy:  99.30%\n##########################################################\nStep:  47100 \t Train Loss:  0.019873794 \t Train Accuracy:  99.40%\nStep:  47100 \t Eval Loss:  0.021102697 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  47200 \t Train Loss:  0.022956364 \t Train Accuracy:  99.30%\nStep:  47200 \t Eval Loss:  0.025528057 \t Eval Accuracy:  99.27%\n##########################################################\nStep:  47300 \t Train Loss:  0.020406393 \t Train Accuracy:  99.38%\nStep:  47300 \t Eval Loss:  0.021871414 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  47400 \t Train Loss:  0.01943856 \t Train Accuracy:  99.40%\nStep:  47400 \t Eval Loss:  0.022224393 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  47500 \t Train Loss:  0.020097498 \t Train Accuracy:  99.43%\nStep:  47500 \t Eval Loss:  0.025821332 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  47600 \t Train Loss:  0.018394958 \t Train Accuracy:  99.45%\nStep:  47600 \t Eval Loss:  0.022013169 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  47700 \t Train Loss:  0.02254484 \t Train Accuracy:  99.38%\nStep:  47700 \t Eval Loss:  0.020234425 \t Eval Accuracy:  99.38%\n##########################################################\nStep:  47800 \t Train Loss:  0.02217168 \t Train Accuracy:  99.28%\nStep:  47800 \t Eval Loss:  0.024764042 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  47900 \t Train Loss:  0.020433862 \t Train Accuracy:  99.27%\nStep:  47900 \t Eval Loss:  0.026191728 \t Eval Accuracy:  99.18%\n##########################################################\nStep:  48000 \t Train Loss:  0.020432308 \t Train Accuracy:  99.34%\nStep:  48000 \t Eval Loss:  0.02125441 \t Eval Accuracy:  99.43%\n##########################################################\nStep:  48100 \t Train Loss:  0.023442797 \t Train Accuracy:  99.28%\nStep:  48100 \t Eval Loss:  0.026714686 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  48200 \t Train Loss:  0.020096466 \t Train Accuracy:  99.39%\nStep:  48200 \t Eval Loss:  0.022159465 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  48300 \t Train Loss:  0.020469202 \t Train Accuracy:  99.32%\nStep:  48300 \t Eval Loss:  0.023728166 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  48400 \t Train Loss:  0.020433307 \t Train Accuracy:  99.38%\nStep:  48400 \t Eval Loss:  0.02588963 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  48500 \t Train Loss:  0.017734403 \t Train Accuracy:  99.44%\nStep:  48500 \t Eval Loss:  0.022106191 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  48600 \t Train Loss:  0.02010601 \t Train Accuracy:  99.41%\nStep:  48600 \t Eval Loss:  0.023411617 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  48700 \t Train Loss:  0.021442972 \t Train Accuracy:  99.33%\nStep:  48700 \t Eval Loss:  0.020505212 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  48800 \t Train Loss:  0.022060454 \t Train Accuracy:  99.28%\nStep:  48800 \t Eval Loss:  0.023266613 \t Eval Accuracy:  99.34%\n##########################################################\nStep:  48900 \t Train Loss:  0.015623229 \t Train Accuracy:  99.46%\nStep:  48900 \t Eval Loss:  0.02434652 \t Eval Accuracy:  99.26%\n##########################################################\nStep:  49000 \t Train Loss:  0.019359298 \t Train Accuracy:  99.41%\nStep:  49000 \t Eval Loss:  0.027564194 \t Eval Accuracy:  99.23%\n##########################################################\nStep:  49100 \t Train Loss:  0.021834096 \t Train Accuracy:  99.37%\nStep:  49100 \t Eval Loss:  0.021171408 \t Eval Accuracy:  99.35%\n##########################################################\nStep:  49200 \t Train Loss:  0.020656794 \t Train Accuracy:  99.39%\nStep:  49200 \t Eval Loss:  0.023614261 \t Eval Accuracy:  99.33%\n##########################################################\nStep:  49300 \t Train Loss:  0.019524477 \t Train Accuracy:  99.40%\nStep:  49300 \t Eval Loss:  0.023545133 \t Eval Accuracy:  99.29%\n##########################################################\nStep:  49400 \t Train Loss:  0.022148762 \t Train Accuracy:  99.33%\nStep:  49400 \t Eval Loss:  0.02241289 \t Eval Accuracy:  99.40%\n##########################################################\nStep:  49500 \t Train Loss:  0.019587185 \t Train Accuracy:  99.38%\nStep:  49500 \t Eval Loss:  0.027522694 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  49600 \t Train Loss:  0.017971477 \t Train Accuracy:  99.35%\nStep:  49600 \t Eval Loss:  0.022509847 \t Eval Accuracy:  99.32%\n##########################################################\nStep:  49700 \t Train Loss:  0.019897427 \t Train Accuracy:  99.39%\nStep:  49700 \t Eval Loss:  0.02428809 \t Eval Accuracy:  99.24%\n##########################################################\nStep:  49800 \t Train Loss:  0.018255051 \t Train Accuracy:  99.51%\nStep:  49800 \t Eval Loss:  0.024355683 \t Eval Accuracy:  99.28%\n##########################################################\nStep:  49900 \t Train Loss:  0.021693889 \t Train Accuracy:  99.35%\nStep:  49900 \t Eval Loss:  0.019467184 \t Eval Accuracy:  99.39%\nCPU times: user 16min 40s, sys: 8min 4s, total: 24min 44s\nWall time: 24min 58s\n","output_type":"stream"}]},{"cell_type":"code","source":"# Plot loss and accuracy in subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.set_title('Loss')\nax2.set_title('Accuracy')\n\n\n\nax1.plot(all_train_losses, label='train_loss')\nax1.plot(all_eval_losses, label='eval_loss')\n\nax2.plot(all_train_accuracy, label='train_accuracy')\nax2.plot(all_test_accuracy, label='eval_accuracy')\n\nax1.legend()\nax2.legend()\nplt.show()\nplt.clf()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:52:55.145874Z","iopub.execute_input":"2024-07-01T07:52:55.146176Z","iopub.status.idle":"2024-07-01T07:52:55.667481Z","shell.execute_reply.started":"2024-07-01T07:52:55.146150Z","shell.execute_reply":"2024-07-01T07:52:55.666504Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x500 with 2 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"@partial(jax.jit, static_argnames=(\"length\"))\ndef generate_text(rng, params, length):\n    def _scan_generate(carry, _):\n        random_key, context = carry\n        logits = model.apply(params, context)\n#         pdb.set_trace()\n        rng, rng_subkey = jax.random.split(random_key)\n        new_token = jax.random.categorical(\n          rng_subkey, logits[:, -n_tokens, :], axis=-1, shape=(1, 1)\n        )\n        context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n        print(context.shape)\n        return (rng, context), new_token\n\n    _, new_tokens = jax.lax.scan(\n    _scan_generate,\n    (rng, jnp.expand_dims(test_data[852:852+block_size], axis=0)),\n    (),\n    length=length,\n    )\n    return new_tokens","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:52:55.668676Z","iopub.execute_input":"2024-07-01T07:52:55.668965Z","iopub.status.idle":"2024-07-01T07:52:55.676735Z","shell.execute_reply.started":"2024-07-01T07:52:55.668941Z","shell.execute_reply":"2024-07-01T07:52:55.675563Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_data[852:852+block_size]","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:52:55.677947Z","iopub.execute_input":"2024-07-01T07:52:55.678731Z","iopub.status.idle":"2024-07-01T07:52:55.753303Z","shell.execute_reply.started":"2024-07-01T07:52:55.678697Z","shell.execute_reply":"2024-07-01T07:52:55.752415Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Array([51,  6,  1, 53, 56,  1, 43, 50, 57, 43,  1, 63, 53, 59,  1, 42, 53,\n        1, 51, 43,  1, 61, 56, 53, 52, 45, 10,  0, 20, 47, 57,  1, 52, 39,\n       51, 43,  1, 47, 57,  1, 24, 47, 41, 47, 53,  6,  1, 40, 53, 56, 52,\n        1, 47, 52,  1, 25, 39, 52, 58, 59, 39,  8,  0,  0], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"i = 852\ndecode(test_data[i:i+block_size].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:52:55.754488Z","iopub.execute_input":"2024-07-01T07:52:55.755484Z","iopub.status.idle":"2024-07-01T07:52:55.761715Z","shell.execute_reply.started":"2024-07-01T07:52:55.755456Z","shell.execute_reply":"2024-07-01T07:52:55.760851Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'m, or else you do me wrong:\\nHis name is Licio, born in Mantua.\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"new_tokenz = 1000\nkey, subkey = jax.random.split(jax.random.PRNGKey(156))\n# key, subkey = jax.random.split(key)\n# token_gen = generate_text(jnp.zeros((1,block_size)).astype(jnp.int32), new_tokenz, {'params': state.params})\ntoken_gen = generate_text(key, params, new_tokenz)[:, 0, 0].tolist()\nprint(token_gen)\nprint('\\n')\nprint(decode(token_gen))","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:52:55.762878Z","iopub.execute_input":"2024-07-01T07:52:55.763149Z","iopub.status.idle":"2024-07-01T07:53:01.526502Z","shell.execute_reply.started":"2024-07-01T07:52:55.763127Z","shell.execute_reply":"2024-07-01T07:53:01.525564Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"(1, 64)\n[24, 33, 15, 21, 27, 10, 0, 21, 5, 50, 50, 1, 50, 53, 60, 43, 1, 18, 56, 53, 51, 1, 60, 47, 56, 58, 59, 43, 8, 0, 0, 31, 43, 41, 53, 52, 42, 1, 31, 43, 56, 60, 47, 52, 45, 51, 39, 52, 10, 0, 35, 46, 43, 56, 43, 1, 47, 57, 1, 58, 46, 43, 1, 56, 43, 57, 58, 1, 39, 52, 42, 1, 57, 53, 59, 52, 42, 1, 57, 53, 51, 43, 58, 46, 47, 52, 45, 1, 58, 41, 53, 58, 46, 43, 56, 0, 14, 56, 47, 52, 45, 1, 58, 53, 1, 56, 39, 45, 43, 1, 53, 44, 1, 42, 43, 39, 58, 46, 11, 1, 39, 52, 42, 1, 61, 43, 39, 56, 1, 58, 46, 43, 57, 43, 1, 39, 56, 51, 57, 6, 0, 32, 47, 50, 50, 1, 47, 58, 1, 54, 50, 43, 39, 57, 59, 52, 45, 12, 1, 21, 44, 1, 63, 53, 59, 1, 51, 47, 52, 43, 1, 47, 57, 1, 61, 46, 39, 58, 1, 43, 60, 47, 50, 57, 43, 42, 8, 0, 13, 52, 42, 1, 50, 43, 58, 1, 46, 47, 51, 1, 47, 52, 1, 40, 43, 1, 58, 53, 1, 51, 63, 1, 39, 44, 58, 43, 56, 1, 44, 53, 56, 1, 58, 46, 43, 1, 50, 47, 49, 43, 0, 27, 5, 1, 1, 54, 56, 39, 63, 1, 63, 53, 59, 6, 1, 39, 52, 42, 1, 39, 42, 60, 53, 41, 46, 5, 42, 1, 59, 52, 56, 53, 53, 44, 5, 42, 6, 1, 39, 52, 42, 1, 40, 43, 1, 59, 58, 57, 11, 0, 37, 53, 59, 56, 1, 61, 53, 56, 58, 46, 1, 47, 57, 1, 39, 1, 41, 56, 39, 44, 58, 1, 53, 44, 44, 1, 51, 63, 1, 58, 53, 52, 45, 59, 43, 57, 6, 0, 13, 52, 42, 1, 58, 46, 53, 59, 45, 46, 1, 51, 39, 56, 56, 47, 43, 42, 1, 53, 44, 1, 51, 63, 1, 57, 53, 52, 1, 51, 53, 56, 52, 47, 52, 45, 1, 40, 43, 43, 42, 0, 35, 47, 58, 46, 47, 52, 1, 46, 47, 51, 1, 46, 39, 58, 46, 1, 58, 58, 43, 57, 54, 43, 41, 58, 53, 56, 1, 63, 53, 59, 1, 46, 39, 60, 43, 1, 41, 56, 53, 61, 52, 12, 0, 14, 59, 58, 1, 63, 43, 57, 58, 1, 58, 46, 53, 59, 6, 0, 33, 52, 50, 43, 57, 57, 1, 21, 1, 57, 46, 53, 59, 50, 42, 1, 52, 53, 58, 1, 46, 53, 61, 1, 59, 52, 52, 53, 58, 1, 58, 53, 53, 6, 0, 18, 53, 56, 1, 41, 53, 51, 43, 1, 58, 53, 1, 30, 53, 51, 43, 10, 1, 39, 52, 1, 47, 57, 1, 58, 46, 47, 57, 1, 41, 56, 47, 51, 8, 0, 0, 28, 13, 33, 24, 21, 26, 19, 10, 0, 20, 43, 56, 43, 1, 41, 53, 51, 43, 57, 1, 59, 57, 6, 0, 13, 52, 42, 1, 41, 53, 51, 43, 1, 51, 39, 56, 56, 47, 44, 44, 6, 1, 51, 59, 56, 42, 43, 56, 1, 21, 1, 52, 43, 55, 59, 43, 57, 58, 1, 51, 39, 56, 49, 57, 6, 0, 33, 52, 41, 50, 43, 57, 58, 1, 46, 47, 58, 46, 43, 56, 6, 1, 58, 46, 39, 52, 1, 21, 1, 44, 43, 39, 56, 1, 53, 59, 58, 1, 53, 52, 43, 1, 39, 1, 40, 53, 56, 52, 6, 0, 32, 46, 39, 58, 1, 61, 39, 57, 1, 58, 46, 53, 59, 1, 57, 47, 56, 6, 1, 47, 52, 58, 43, 56, 56, 59, 57, 1, 39, 52, 42, 1, 52, 53, 58, 1, 61, 47, 58, 46, 1, 58, 46, 43, 43, 0, 5, 32, 61, 39, 57, 1, 58, 46, 53, 59, 1, 45, 39, 56, 42, 43, 52, 1, 59, 54, 53, 52, 1, 63, 53, 59, 56, 1, 45, 39, 57, 46, 8, 0, 0, 24, 13, 16, 37, 1, 13, 26, 26, 17, 10, 0, 35, 46, 39, 58, 1, 42, 53, 50, 42, 1, 51, 39, 49, 43, 1, 59, 57, 1, 39, 50, 50, 1, 51, 39, 49, 43, 1, 44, 53, 56, 1, 51, 63, 1, 57, 54, 43, 43, 41, 46, 0, 33, 54, 53, 52, 1, 46, 47, 57, 1, 54, 39, 56, 58, 63, 6, 1, 53, 56, 1, 28, 53, 51, 44, 56, 43, 43, 1, 42, 43, 39, 42, 6, 1, 61, 43, 1, 61, 47, 42, 53, 61, 8, 0, 0, 31, 21, 15, 17, 26, 27, 24, 17, 10, 0, 16, 53, 1, 63, 53, 59, 56, 1, 55, 59, 43, 43, 52, 1, 45, 56, 53, 61, 57, 1, 39, 58, 1, 58, 46, 43, 1, 45, 56, 47, 43, 44, 1, 58, 53, 8, 0, 0, 16, 33, 23, 17, 1, 34, 21, 26, 15, 17, 26, 32, 21, 27, 10, 0, 14, 43, 47, 53, 52, 1, 61, 46, 53, 1, 46, 39, 42, 1, 58, 53, 1, 57, 43, 43, 1, 46, 47, 57, 1, 40, 50, 53, 47, 42, 43, 56, 1, 15, 50, 39, 56, 43, 52, 41, 43, 8, 0, 0, 24, 33, 15, 21, 27, 10, 0, 32, 46, 39, 58, 1, 42, 53, 1, 63, 53, 59, 1, 43, 60, 43, 52, 1, 56, 43, 58, 59, 56, 52, 51, 43, 52, 58, 1, 40, 59, 58, 1, 58, 46, 43, 1, 57, 43, 62, 58, 1, 57, 53, 59, 52, 42, 1, 43, 62, 54, 56, 47, 52, 45, 57, 1, 57, 46, 39, 50, 50, 1, 40, 43, 1, 15, 50, 47, 44, 44, 53, 56, 42, 1, 41, 53, 51, 43, 57, 58, 6, 1, 46, 53, 51, 43, 6, 1, 39, 52, 42, 1, 58, 43, 50, 50, 1, 51, 43, 6, 1, 58, 46, 39, 58, 5, 57, 1, 58]\n\n\nLUCIO:\nI'll love From virtue.\n\nSecond Servingman:\nWhere is the rest and sound something tcother\nBring to rage of death; and wear these arms,\nTill it pleasung? If you mine is what evilsed.\nAnd let him in be to my after for the like\nO'  pray you, and advoch'd unroof'd, and be uts;\nYour worth is a craft off my tongues,\nAnd though married of my son morning beed\nWithin him hath ttespector you have crown?\nBut yest thou,\nUnless I should not how unnot too,\nFor come to Rome: an is this crim.\n\nPAULING:\nHere comes us,\nAnd come marriff, murder I nequest marks,\nUnclest hither, than I fear out one a born,\nThat was thou sir, interrus and not with thee\n'Twas thou garden upon your gash.\n\nLADY ANNE:\nWhat dold make us all make for my speech\nUpon his party, or Pomfree dead, we widow.\n\nSICENOLE:\nDo your queen grows at the grief to.\n\nDUKE VINCENTIO:\nBeion who had to see his bloider Clarence.\n\nLUCIO:\nThat do you even returnment but the sext sound exprings shall be Clifford comest, home, and tell me, that's t\n","output_type":"stream"}]},{"cell_type":"code","source":"params['params'].keys()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:53:01.527810Z","iopub.execute_input":"2024-07-01T07:53:01.528177Z","iopub.status.idle":"2024-07-01T07:53:01.534060Z","shell.execute_reply.started":"2024-07-01T07:53:01.528148Z","shell.execute_reply":"2024-07-01T07:53:01.533058Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"dict_keys(['Dense_0', 'Embed_0', 'Embed_1', 'RMSNorm_0', 'RMSNorm_1', 'RMSNorm_2', 'RMSNorm_3', 'RMSNorm_4', 'RMSNorm_5', 'RMSNorm_6', 'S6_Unet_0', 'S6_Unet_1', 'S6_Unet_2', 'S6_Unet_3', 'S6_Unet_4', 'S6_Unet_5'])"},"metadata":{}}]},{"cell_type":"code","source":"var_params = {'params':{}}","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:53:01.535259Z","iopub.execute_input":"2024-07-01T07:53:01.535814Z","iopub.status.idle":"2024-07-01T07:53:01.546338Z","shell.execute_reply.started":"2024-07-01T07:53:01.535789Z","shell.execute_reply":"2024-07-01T07:53:01.545477Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"var_params['params']['Conv_0'] = params['params']['Conv_0']","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:53:01.547415Z","iopub.execute_input":"2024-07-01T07:53:01.547676Z","iopub.status.idle":"2024-07-01T07:53:02.056498Z","shell.execute_reply.started":"2024-07-01T07:53:01.547654Z","shell.execute_reply":"2024-07-01T07:53:02.055275Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m var_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConv_0\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mConv_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n","\u001b[0;31mKeyError\u001b[0m: 'Conv_0'"],"ename":"KeyError","evalue":"'Conv_0'","output_type":"error"}]},{"cell_type":"code","source":"for key in params['params'].keys():\n    \n    n_params = sum(p.size for p in jax.tree_util.tree_leaves(params['params'][key]))\n\n    print(f\"Total number of parameters in {key}: {n_params:_}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:53:02.057407Z","iopub.status.idle":"2024-07-01T07:53:02.057750Z","shell.execute_reply.started":"2024-07-01T07:53:02.057584Z","shell.execute_reply":"2024-07-01T07:53:02.057598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}