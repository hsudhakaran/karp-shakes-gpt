{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q clu","metadata":{"id":"gS6euWNvHFye","outputId":"45b149a7-9450-439c-da67-ab8678a3b0d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt","metadata":{"id":"7jjCLfuUHFyg","outputId":"dfe048f0-dd44-40ef-edf3-2fa56558672f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from functools import partial\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom jax.nn.initializers import lecun_normal, normal\nfrom jax.numpy.linalg import eigh, inv, matrix_power\nfrom jax.scipy.signal import convolve\n\nimport torch\n\nfrom dataclasses import dataclass\n\nfrom typing import Union\n\nimport matplotlib.pyplot as plt\nimport seaborn\n\nfrom clu import metrics\nfrom flax.training import train_state  # Useful dataclass to keep train state\nfrom flax import struct                # Flax dataclasses\nimport optax                           # Common loss functions and optimizers\nfrom tqdm import tqdm","metadata":{"id":"YXSCJzupHFyh","execution":{"iopub.status.busy":"2024-05-27T06:45:16.434481Z","iopub.execute_input":"2024-05-27T06:45:16.435400Z","iopub.status.idle":"2024-05-27T06:45:19.899932Z","shell.execute_reply.started":"2024-05-27T06:45:16.435366Z","shell.execute_reply":"2024-05-27T06:45:19.899097Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# read it in to inspect it\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()","metadata":{"id":"KpJoV3KQHFyh","execution":{"iopub.status.busy":"2024-05-27T06:45:19.901460Z","iopub.execute_input":"2024-05-27T06:45:19.901860Z","iopub.status.idle":"2024-05-27T06:45:19.907937Z","shell.execute_reply.started":"2024-05-27T06:45:19.901834Z","shell.execute_reply":"2024-05-27T06:45:19.907079Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# here are all the unique characters that occur in this text\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"id":"PsWxZqyRHFyi","outputId":"b1730724-647e-45cd-edfa-97af24995830","execution":{"iopub.status.busy":"2024-05-27T06:45:19.909198Z","iopub.execute_input":"2024-05-27T06:45:19.909822Z","iopub.status.idle":"2024-05-27T06:45:19.932902Z","shell.execute_reply.started":"2024-05-27T06:45:19.909788Z","shell.execute_reply":"2024-05-27T06:45:19.931975Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n65\n","output_type":"stream"}]},{"cell_type":"code","source":"# create a mapping from characters to integers\nstoi = { ch: i for i,ch in enumerate(chars) }\nitos = { i: ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n\nprint(encode(\"hii there\"))\nprint(decode(encode(\"hii there\")))","metadata":{"id":"S-mzLOk1HFyi","outputId":"f56e2f85-5a1c-4099-87df-436ba39f4363","execution":{"iopub.status.busy":"2024-05-27T06:45:19.934954Z","iopub.execute_input":"2024-05-27T06:45:19.935437Z","iopub.status.idle":"2024-05-27T06:45:19.943037Z","shell.execute_reply.started":"2024-05-27T06:45:19.935411Z","shell.execute_reply":"2024-05-27T06:45:19.942129Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[46, 47, 47, 1, 58, 46, 43, 56, 43]\nhii there\n","output_type":"stream"}]},{"cell_type":"code","source":"data = jnp.array(encode(text), dtype=jnp.int32)\nprint(data.shape, data.dtype)\nprint(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this","metadata":{"id":"HImuqDd8HFyj","outputId":"91dcd15f-f068-4551-ad29-e6e41e52fd91","execution":{"iopub.status.busy":"2024-05-27T06:45:19.944258Z","iopub.execute_input":"2024-05-27T06:45:19.945102Z","iopub.status.idle":"2024-05-27T06:45:22.296625Z","shell.execute_reply.started":"2024-05-27T06:45:19.945030Z","shell.execute_reply":"2024-05-27T06:45:22.295669Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(1115394,) int32\n[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n  0 37 53 59  1 39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39\n 58 46 43 56  1 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47\n 57 46 12  0  0 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53\n 50 60 43 42  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47\n 56 57 58  6  1 63 53 59  1 49 52 53 61  1 15 39 47 59 57  1 25 39 56 41\n 47 59 57  1 47 57  1 41 46 47 43 44  1 43 52 43 51 63  1 58 53  1 58 46\n 43  1 54 43 53 54 50 43  8  0  0 13 50 50 10  0 35 43  1 49 52 53 61  5\n 58  6  1 61 43  1 49 52 53 61  5 58  8  0  0 18 47 56 57 58  1 15 47 58\n 47 64 43 52 10  0 24 43 58  1 59 57  1 49 47 50 50  1 46 47 51  6  1 39\n 52 42  1 61 43  5 50 50  1 46 39 60 43  1 41 53 56 52  1 39 58  1 53 59\n 56  1 53 61 52  1 54 56 47 41 43  8  0 21 57  5 58  1 39  1 60 43 56 42\n 47 41 58 12  0  0 13 50 50 10  0 26 53  1 51 53 56 43  1 58 39 50 49 47\n 52 45  1 53 52  5 58 11  1 50 43 58  1 47 58  1 40 43  1 42 53 52 43 10\n  1 39 61 39 63  6  1 39 61 39 63  2  0  0 31 43 41 53 52 42  1 15 47 58\n 47 64 43 52 10  0 27 52 43  1 61 53 56 42  6  1 45 53 53 42  1 41 47 58\n 47 64 43 52 57  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 35\n 43  1 39 56 43  1 39 41 41 53 59 52 58 43 42  1 54 53 53 56  1 41 47 58\n 47 64 43 52 57  6  1 58 46 43  1 54 39 58 56 47 41 47 39 52 57  1 45 53\n 53 42  8  0 35 46 39 58  1 39 59 58 46 53 56 47 58 63  1 57 59 56 44 43\n 47 58 57  1 53 52  1 61 53 59 50 42  1 56 43 50 47 43 60 43  1 59 57 10\n  1 47 44  1 58 46 43 63  0 61 53 59 50 42  1 63 47 43 50 42  1 59 57  1\n 40 59 58  1 58 46 43  1 57 59 54 43 56 44 50 59 47 58 63  6  1 61 46 47\n 50 43  1 47 58  1 61 43 56 43  0 61 46 53 50 43 57 53 51 43  6  1 61 43\n  1 51 47 45 46 58  1 45 59 43 57 57  1 58 46 43 63  1 56 43 50 47 43 60\n 43 42  1 59 57  1 46 59 51 39 52 43 50 63 11  0 40 59 58  1 58 46 43 63\n  1 58 46 47 52 49  1 61 43  1 39 56 43  1 58 53 53  1 42 43 39 56 10  1\n 58 46 43  1 50 43 39 52 52 43 57 57  1 58 46 39 58  0 39 44 44 50 47 41\n 58 57  1 59 57  6  1 58 46 43  1 53 40 48 43 41 58  1 53 44  1 53 59 56\n  1 51 47 57 43 56 63  6  1 47 57  1 39 57  1 39 52  0 47 52 60 43 52 58\n 53 56 63  1 58 53  1 54 39 56 58 47 41 59 50 39 56 47 57 43  1 58 46 43\n 47 56  1 39 40 59 52 42 39 52 41 43 11  1 53 59 56  0 57 59 44 44 43 56\n 39 52 41 43  1 47 57  1 39  1 45 39 47 52  1 58 53  1 58 46 43 51  1 24\n 43 58  1 59 57  1 56 43 60 43 52 45 43  1 58 46 47 57  1 61 47 58 46  0\n 53 59 56  1 54 47 49 43 57  6  1 43 56 43  1 61 43  1 40 43 41 53 51 43\n  1 56 39 49 43 57 10  1 44 53 56  1 58 46 43  1 45 53 42 57  1 49 52 53\n 61  1 21  0 57 54 43 39 49  1 58 46 47 57  1 47 52  1 46 59 52 45 43 56\n  1 44 53 56  1 40 56 43 39 42  6  1 52 53 58  1 47 52  1 58 46 47 56 57\n 58  1 44 53 56  1 56 43 60 43 52 45 43  8  0  0]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_test_split = 0.9\nn = int(train_test_split*len(data))\ntrain_data = data[:n]\ntest_data = data[n:]","metadata":{"id":"pXrAqMxRHFyj","execution":{"iopub.status.busy":"2024-05-27T06:45:22.297730Z","iopub.execute_input":"2024-05-27T06:45:22.298017Z","iopub.status.idle":"2024-05-27T06:45:22.455333Z","shell.execute_reply.started":"2024-05-27T06:45:22.297985Z","shell.execute_reply":"2024-05-27T06:45:22.454436Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"block_size = 8\ntrain_data[:block_size+1]","metadata":{"id":"ahhKyiAzHFyj","outputId":"98306c96-5082-4dfa-ba66-915051831fc8","execution":{"iopub.status.busy":"2024-05-27T06:45:22.456532Z","iopub.execute_input":"2024-05-27T06:45:22.456885Z","iopub.status.idle":"2024-05-27T06:45:22.541222Z","shell.execute_reply.started":"2024-05-27T06:45:22.456854Z","shell.execute_reply":"2024-05-27T06:45:22.540167Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Array([18, 47, 56, 57, 58,  1, 15, 47, 58], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target: {target}\")","metadata":{"id":"HIpsznQmHFyk","outputId":"be9d197b-0b79-43ed-f3a9-e74295d51c79","execution":{"iopub.status.busy":"2024-05-27T06:45:22.542546Z","iopub.execute_input":"2024-05-27T06:45:22.542914Z","iopub.status.idle":"2024-05-27T06:45:23.169527Z","shell.execute_reply.started":"2024-05-27T06:45:22.542884Z","shell.execute_reply":"2024-05-27T06:45:23.168496Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"when input is [18] the target: 47\nwhen input is [18 47] the target: 56\nwhen input is [18 47 56] the target: 57\nwhen input is [18 47 56 57] the target: 58\nwhen input is [18 47 56 57 58] the target: 1\nwhen input is [18 47 56 57 58  1] the target: 15\nwhen input is [18 47 56 57 58  1 15] the target: 47\nwhen input is [18 47 56 57 58  1 15 47] the target: 58\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 128 # how many independent sequences will we process in parallel?\nblock_size = 64 # what is the maximum context length for predictions?\nmax_iters = 10000\nlearning_rate = 1e-3\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 100\nn_embd = 384\nexpans = 2\nn_heads = 1\nchannel_size = n_embd // n_heads\nn_layers = 6\ndropout = 0.2\nconv_k_size = 3\nn_latent_dim = 16\nn_tokens = 1\n\nrng_key = jax.random.PRNGKey(1564)\n\ndynamic_slice_vmap = jax.vmap(jax.lax.dynamic_slice, in_axes=(None, 0, None))\n\n@jax.jit\ndef get_batch(random_key, data):\n    \"\"\"Prepares a random batch of training data.\n\n    Args:\n      random_key: A random seed for sampling a batch.\n      data: The complete training dataset.\n\n    Returns:\n      x: Input sequences.\n      y: Target sequences (shifted inputs).\n    \"\"\"\n    ix = jax.random.randint(\n      random_key, shape=(batch_size, 1), minval=0, maxval=len(data) - block_size\n    )\n    x = dynamic_slice_vmap(data, ix, (block_size,))\n    y = dynamic_slice_vmap(data, ix + n_tokens, (block_size,))\n    return x, y\n\nxb, yb = get_batch(rng_key, train_data)\ntrain_shape = xb.shape\nprint('inputs:')\nprint(xb.shape)\nprint(xb)\nprint('targets:')\nprint(yb.shape)\nprint(yb)\n\n# print('----')\n\n# for b in range(batch_size): # batch dimension\n#     for t in range(block_size): # time dimension\n#         context = xb[b, :t+1]\n#         target = yb[b,t]\n#         print(f\"when input is {context} the target: {target}\")","metadata":{"id":"UuAjtqPeHFyk","outputId":"6a88fb2b-b798-4ee9-9f4f-f38ce898d576","execution":{"iopub.status.busy":"2024-05-27T06:45:23.170692Z","iopub.execute_input":"2024-05-27T06:45:23.171008Z","iopub.status.idle":"2024-05-27T06:45:23.507095Z","shell.execute_reply.started":"2024-05-27T06:45:23.170981Z","shell.execute_reply":"2024-05-27T06:45:23.506015Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"inputs:\n(128, 64)\n[[ 1 63 53 ... 40 63  1]\n [43  1 52 ... 46 39 42]\n [63  1 45 ... 50  1 61]\n ...\n [46 47 41 ... 58 43  1]\n [ 1 61 43 ... 53 59  1]\n [49  1 58 ... 53 61  1]]\ntargets:\n(128, 64)\n[[63 53 59 ... 63  1 58]\n [ 1 52 43 ... 39 42  1]\n [ 1 45 53 ...  1 61 43]\n ...\n [47 41 46 ... 43  1 47]\n [61 43  5 ... 59  1 42]\n [ 1 58 46 ... 61  1 52]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Mamba Block\nDense --> Conv1D --> Silu --> SSM --> Silu -->","metadata":{"id":"yOccqzJlHFym"}},{"cell_type":"code","source":"print(xb[0])\nprint(yb[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:45:23.511612Z","iopub.execute_input":"2024-05-27T06:45:23.511934Z","iopub.status.idle":"2024-05-27T06:45:23.616745Z","shell.execute_reply.started":"2024-05-27T06:45:23.511907Z","shell.execute_reply":"2024-05-27T06:45:23.615755Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[ 1 63 53 59 56 57  8  0  0 24 17 27 26 32 17 31 10  0 13  1 52 43 57 58\n  1 53 44  1 58 56 39 47 58 53 56 57  2  0  0 13 26 32 21 19 27 26 33 31\n 10  0 21  1 39 51  1 52 53 52 43  6  1 40 63  1]\n[63 53 59 56 57  8  0  0 24 17 27 26 32 17 31 10  0 13  1 52 43 57 58  1\n 53 44  1 58 56 39 47 58 53 56 57  2  0  0 13 26 32 21 19 27 26 33 31 10\n  0 21  1 39 51  1 52 53 52 43  6  1 40 63  1 58]\n","output_type":"stream"}]},{"cell_type":"code","source":"# hidden_state = [jnp.zeros((1,n_latent_dim, n_embd * expans)) for _ in range(n_layers)]","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:45:23.617785Z","iopub.execute_input":"2024-05-27T06:45:23.618060Z","iopub.status.idle":"2024-05-27T06:45:23.622096Z","shell.execute_reply.started":"2024-05-27T06:45:23.618036Z","shell.execute_reply":"2024-05-27T06:45:23.621116Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# hidden_state[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:45:23.623290Z","iopub.execute_input":"2024-05-27T06:45:23.623650Z","iopub.status.idle":"2024-05-27T06:45:23.632266Z","shell.execute_reply.started":"2024-05-27T06:45:23.623582Z","shell.execute_reply":"2024-05-27T06:45:23.631359Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Mamba(nn.Module):\n\n    def setup(self):\n        emb_features = n_embd * expans\n        self.in_proj1 = nn.Dense(features=emb_features)\n        self.in_proj2 = nn.Dense(features=emb_features)\n\n        # Adjusted for Flax. Flax does not have nn.Conv1d, so you might need to reshape or use a different approach\n        self.conv1d = nn.Conv(features=emb_features,\n                              kernel_size=conv_k_size,\n                              padding=1,\n                              )\n\n        self.A = -1*self.param('A', nn.initializers.ones, (1, n_latent_dim, emb_features, 1))\n        self.B = 0.1*self.param('B', nn.initializers.ones, (1, n_latent_dim, 1, block_size))\n        self.C = self.param('C', jax.random.normal, (1, n_latent_dim, 1, block_size))\n#         self.D = self.param('D', jax.random.normal, (1, self.args.d_state, self.args.d_model, 1))\n        self.delta = self.param('delta', jax.random.normal, (1, 1,emb_features, block_size))\n\n        self.out_proj = nn.Dense(n_embd // n_heads)\n        \n        self.hidden_state = self.variable('other_variables','hidden_state', \n                                          jnp.zeros, \n                                          (1,n_latent_dim, emb_features))\n        self.rms_norm = nn.RMSNorm()\n\n    def __call__(self, embeds):\n        x = self.in_proj1(embeds)\n        x = self.conv1d(x)\n        x = jax.nn.silu(x)\n        x = x.reshape((x.shape[0],1,x.shape[2],x.shape[1]))\n        x = self.ssm(x)\n        x = x.reshape((x.shape[0],x.shape[3],x.shape[2]))\n        x = x*jax.nn.silu(self.in_proj2(embeds))\n\n        x = self.out_proj(x)\n\n        x = self.rms_norm(x)\n\n        return x\n    def discretize(self):\n        da = self.delta * self.A\n        a_ = jnp.exp(da)\n        b_ = self.B * self.delta\n        return a_, b_\n\n    def ssm(self, x):\n        y = []\n        a_, b_ = self.discretize()\n        h = 0\n        for k in range(x.shape[-1]):\n            h = a_[..., k] * h + b_[..., k] * x[..., k]\n            \n        for l in range(x.shape[-1]):\n            y.append((self.C[..., l] * h).sum(1, keepdims=True))     \n        \n        self.hidden_state.value = jax.nn.standardize(h.mean(0, keepdims=True))\n        return jnp.stack(y, -1)","metadata":{"id":"4qOdblU5HFyo","execution":{"iopub.status.busy":"2024-05-27T06:45:23.633582Z","iopub.execute_input":"2024-05-27T06:45:23.633896Z","iopub.status.idle":"2024-05-27T06:45:23.649765Z","shell.execute_reply.started":"2024-05-27T06:45:23.633873Z","shell.execute_reply":"2024-05-27T06:45:23.648803Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# class MultiHeadMamba(nn.Module):\n#     def setup(self):\n#         self.layernorm\n#         self.heads = [Mamba() for _ in range(n_heads)]\n#         self.rms_norm = nn.RMSNorm()\n\n#     def __call__(self, x):\n#         out = jnp.concatenate([h(x) for h in self.heads], axis=-1)\n#         x = self.rms_norm(out)\n#         return x","metadata":{"id":"0bH9vlLZHFyq","execution":{"iopub.status.busy":"2024-05-27T06:45:23.651022Z","iopub.execute_input":"2024-05-27T06:45:23.651631Z","iopub.status.idle":"2024-05-27T06:45:23.661957Z","shell.execute_reply.started":"2024-05-27T06:45:23.651584Z","shell.execute_reply":"2024-05-27T06:45:23.661177Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# class FeedForward(nn.Module):\n#     def setup(self):\n#         self.ffn = nn.Sequential([\n#             nn.Dense(4 * n_embd),\n#             nn.relu,\n#             nn.Dense(n_embd)]\n#         )\n#     def __call__(self, x):\n#         return self.ffn(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:45:23.663003Z","iopub.execute_input":"2024-05-27T06:45:23.663269Z","iopub.status.idle":"2024-05-27T06:45:23.674531Z","shell.execute_reply.started":"2024-05-27T06:45:23.663238Z","shell.execute_reply":"2024-05-27T06:45:23.673773Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# class MambaBlock(nn.Module):\n#     def setup(self):\n#         self.mamba_block = Mamba()\n#         self.ln1 = nn.RMSNorm()\n#         self.ffn = FeedForward()\n#         self.ln2 = nn.LayerNorm()\n\n#     def __call__(self, x):\n#         x = x + self.mamba_block(self.ln2(x))\n#         x = x + self.ffn(self.ln1(x))\n#         return x\n","metadata":{"id":"UiCxIjoEp2QA","execution":{"iopub.status.busy":"2024-05-27T06:45:23.675578Z","iopub.execute_input":"2024-05-27T06:45:23.676069Z","iopub.status.idle":"2024-05-27T06:45:23.684383Z","shell.execute_reply.started":"2024-05-27T06:45:23.676045Z","shell.execute_reply":"2024-05-27T06:45:23.683448Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# class MambaModel(nn.Module):\n\n#     def setup(self):\n#         self.tok_embeddings = nn.Embed(vocab_size, n_embd)\n#         self.pos_embeddings = nn.Embed(block_size, n_embd)\n#         self.ln = nn.LayerNorm()\n#         self.mamba_layers = [MambaBlock() for _ in range(n_layers)]\n#         self.preds_out = nn.Dense(vocab_size)\n\n#     def __call__(self, x, training: bool):\n#         x = self.tok_embeddings(x) + self.pos_embeddings(jnp.arange(block_size))\n# #         x = self.ln(x)\n#         for layer in self.mamba_layers:\n#             x = layer(x)\n            \n#         return self.preds_out(x)\n\n#     @jax.jit\n#     def generate(self, idx, max_new_tokens, params):\n#     # idx is (B, T) array of indices in the current context\n#         for _ in range(max_new_tokens):\n#             # crop idx to the last block_size tokens\n#             idx_cond = idx[:, -block_size:]\n#             # get the predictions\n#             logits = self.apply(params, idx_cond)\n#             # focus only on the last time step\n#             logits = logits[:, -1, :] # becomes (B, C)\n#             # apply softmax to get probabilities\n#             ##probs = tf.keras.activations.softmax(logits, dim=-1) # (B, C)\n#             # sample from the distribution\n#             idx_next = jax.random.categorical(jax.random.PRNGKey(52), logits) # (B, 1)\n#             # append sampled index to the running sequence\n#             idx = jax.numpy.expand_dims(jnp.concatenate([idx[0], idx_next], axis=0), 0) # (B, T+1)\n#     #         print(idx_next)\n#     #         print(idx)\n\n#         return idx","metadata":{"id":"y4C7OWL8HFyq","execution":{"iopub.status.busy":"2024-05-27T06:45:23.685397Z","iopub.execute_input":"2024-05-27T06:45:23.685665Z","iopub.status.idle":"2024-05-27T06:45:23.695715Z","shell.execute_reply.started":"2024-05-27T06:45:23.685642Z","shell.execute_reply":"2024-05-27T06:45:23.694832Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# model = Mamba()\n# params = model.init(jax.random.key(42), jnp.ones((1,64,256)))\n# # print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# # print(model.tabulate(jax.random.key(0), jnp.ones((1,64,256)),\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xs = model.apply(params, jnp.ones((1,64,256)), mutable=['other_variables'])\n# # # print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# xb.shape, xs[0].shape, xs[1].keys()","metadata":{"id":"wTd3jSQWHFyp","execution":{"iopub.status.busy":"2024-05-27T06:45:23.696582Z","iopub.execute_input":"2024-05-27T06:45:23.696867Z","iopub.status.idle":"2024-05-27T06:45:23.708981Z","shell.execute_reply.started":"2024-05-27T06:45:23.696833Z","shell.execute_reply":"2024-05-27T06:45:23.708079Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# print(xs[1]['other_variables']['hidden_state'].shape, xs[1]['other_variables']['hidden_state'].min(), xs[1]['other_variables']['hidden_state'].max())","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:45:23.710246Z","iopub.execute_input":"2024-05-27T06:45:23.710618Z","iopub.status.idle":"2024-05-27T06:45:23.722539Z","shell.execute_reply.started":"2024-05-27T06:45:23.710569Z","shell.execute_reply":"2024-05-27T06:45:23.721605Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# xfs = model.apply(params, 2*jnp.ones((1,64,256)), mutable=['other_variables'])\n# print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# print(xfs[1]['other_variables']['hidden_state'].shape, xfs[1]['other_variables']['hidden_state'].min(), xfs[1]['other_variables']['hidden_state'].max())","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:45:23.723922Z","iopub.execute_input":"2024-05-27T06:45:23.724520Z","iopub.status.idle":"2024-05-27T06:45:23.732578Z","shell.execute_reply.started":"2024-05-27T06:45:23.724478Z","shell.execute_reply":"2024-05-27T06:45:23.731826Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# test_model = Mamba()\n# test_params = test_model.init(jax.random.key(42), xb)\n# n_params = sum(p.size for p in jax.tree_util.tree_leaves(test_params))\n# print(f\"Total number of parameters: {n_params:_}\")\n# # print(fin_model.tabulate(jax.random.key(42), xb,\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xf = test_model.apply(test_params, xb)\n# xb.shape, xf.shape","metadata":{"id":"cm2a0nepHFyq","execution":{"iopub.status.busy":"2024-05-27T06:45:23.733958Z","iopub.execute_input":"2024-05-27T06:45:23.734320Z","iopub.status.idle":"2024-05-27T06:45:23.742387Z","shell.execute_reply.started":"2024-05-27T06:45:23.734255Z","shell.execute_reply":"2024-05-27T06:45:23.741515Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class NanoLM(nn.Module):\n    \"\"\"NanoLM model.\"\"\"\n    vocab_size: int = 65\n    num_layers: int = 6\n    num_heads: int = 8\n    head_size: int = 32\n    dropout_rate: float = 0.2\n    embed_size: int = 256\n    block_size: int = 64\n\n    @nn.compact\n    def __call__(self, x, training: bool):\n        x = nn.Embed(self.vocab_size, self.embed_size)(x) + nn.Embed(\n            self.block_size, self.embed_size\n        )(jnp.arange(self.block_size))\n        \n        for i in range(self.num_layers):\n            x_norm = nn.LayerNorm()(x)\n#             x = x + nn.MultiHeadDotProductAttention(\n#               num_heads=self.num_heads,\n#               qkv_features=self.head_size,\n#               out_features=self.head_size * self.num_heads,\n#               dropout_rate=self.dropout_rate,\n#             )(\n#               x_norm,\n#               x_norm,\n#               mask=jnp.tril(jnp.ones((x.shape[-2], x.shape[-2]))),\n#               deterministic=not training,\n#             )\n    \n            x = x + Mamba()(x_norm)\n\n#             x = x + nn.Sequential([\n#               nn.Dense(4 * self.embed_size),\n#               nn.relu,\n#               nn.Dropout(self.dropout_rate, deterministic=not training),\n#               nn.Dense(self.embed_size),\n#             ])(nn.LayerNorm()(x))\n\n        x = nn.LayerNorm()(x)\n        return nn.Dense(self.vocab_size)(x)","metadata":{"id":"zuiaFP6WHFyr","execution":{"iopub.status.busy":"2024-05-27T06:45:23.743506Z","iopub.execute_input":"2024-05-27T06:45:23.743836Z","iopub.status.idle":"2024-05-27T06:45:23.754447Z","shell.execute_reply.started":"2024-05-27T06:45:23.743812Z","shell.execute_reply":"2024-05-27T06:45:23.753649Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# key = jax.random.key(42)\n\n# # fin_model = MambaModel()\n# # fin_params = fin_model.init(key, xb, training=False)\n\n\n# fin_model = NanoLM(\n#     vocab_size=vocab_size,\n#     num_layers=n_layers,\n#     num_heads=8,\n#     head_size=32,\n#     dropout_rate=0.2,\n#     embed_size=n_embd,\n#     block_size=block_size,\n# )\n\n# fin_params = fin_model.init(\n#     {'params': key},\n#     jnp.ones((batch_size, block_size), dtype=jnp.int32),\n#     training=False\n# )\n\n# n_params = sum(p.size for p in jax.tree_util.tree_leaves(fin_params))\n# print(f\"Total number of parameters: {n_params:_}\")\n# # print(fin_model.tabulate(jax.random.key(42), xb,\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xf = fin_model.apply(fin_params, xb, training=False)[0]\n# xb.shape, xf.shape","metadata":{"id":"fnUQPyuvHFys","outputId":"f04ebf31-d67f-4488-dd5d-7fd5b20dd1ea","execution":{"iopub.status.busy":"2024-05-27T06:45:23.755504Z","iopub.execute_input":"2024-05-27T06:45:23.755855Z","iopub.status.idle":"2024-05-27T06:45:23.768063Z","shell.execute_reply.started":"2024-05-27T06:45:23.755830Z","shell.execute_reply":"2024-05-27T06:45:23.767306Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def loss_fun(params, x, y, var_params,dropout_key):\n    logits, updated_variables = model.apply({'params': params, **var_params}, x, training=True, rngs={\"dropout\": dropout_key}, mutable=['other_variables'])\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), (updated_variables, accuracy)\n\n@jax.jit\ndef eval_step(params, x, y, var_params):\n    logits, _ = model.apply({'params': params, **var_params}, x, training=False, mutable=['other_variables'])\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), accuracy","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:45:23.769081Z","iopub.execute_input":"2024-05-27T06:45:23.769341Z","iopub.status.idle":"2024-05-27T06:45:23.781996Z","shell.execute_reply.started":"2024-05-27T06:45:23.769318Z","shell.execute_reply":"2024-05-27T06:45:23.781245Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"key = jax.random.PRNGKey(42)\nkey, subkey = jax.random.split(key)\n\nmodel = NanoLM(\n    vocab_size=vocab_size,\n    num_layers=n_layers,\n    num_heads=8,\n    head_size=32,\n    dropout_rate=0.2,\n    embed_size=n_embd,\n    block_size=block_size,\n)\n\nvar_params = model.init(\n    key,\n    jnp.ones((batch_size, block_size), dtype=jnp.int32),\n    training=False,\n)\nprint(var_params.keys())\nn_params = sum(p.size for p in jax.tree_util.tree_leaves(var_params))\n\nprint(f\"Total number of parameters: {n_params:_}\")","metadata":{"id":"PKpb3864HFyt","execution":{"iopub.status.busy":"2024-05-27T06:45:23.783047Z","iopub.execute_input":"2024-05-27T06:45:23.783312Z","iopub.status.idle":"2024-05-27T06:45:32.981532Z","shell.execute_reply.started":"2024-05-27T06:45:23.783288Z","shell.execute_reply":"2024-05-27T06:45:32.980576Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"dict_keys(['params', 'other_variables'])\nTotal number of parameters: 7_450_689\n","output_type":"stream"}]},{"cell_type":"code","source":"params = var_params.pop('params')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:45:32.982901Z","iopub.execute_input":"2024-05-27T06:45:32.983647Z","iopub.status.idle":"2024-05-27T06:45:32.987958Z","shell.execute_reply.started":"2024-05-27T06:45:32.983577Z","shell.execute_reply":"2024-05-27T06:45:32.987051Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"var_params = jax.tree_map(lambda x: jnp.zeros_like(x), var_params)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:45:32.989201Z","iopub.execute_input":"2024-05-27T06:45:32.989574Z","iopub.status.idle":"2024-05-27T06:45:33.004987Z","shell.execute_reply.started":"2024-05-27T06:45:32.989542Z","shell.execute_reply":"2024-05-27T06:45:33.004066Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# decay_rate = 0.96\n# learning_rate_schedule = optax.exponential_decay(learning_rate, decay_rate, max_iters//1000)\nopt = optax.adamw(learning_rate=learning_rate)\n\nopt_state = opt.init(params)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:45:33.012973Z","iopub.execute_input":"2024-05-27T06:45:33.013288Z","iopub.status.idle":"2024-05-27T06:45:33.390874Z","shell.execute_reply.started":"2024-05-27T06:45:33.013264Z","shell.execute_reply":"2024-05-27T06:45:33.389991Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"%%time\n\nall_train_losses = []\nall_eval_losses = []\n\nall_train_accuracy =  []\nall_test_accuracy = []\n\n# we define one iteration of the optimizer and JIT this function\n@jax.jit\ndef step(key, params, var_params, opt_state):\n    key, subkey = jax.random.split(key)\n    xb, yb = get_batch(key, train_data)\n    (loss, aux_data), grad = jax.value_and_grad(loss_fun, has_aux=True)(params, xb, yb, var_params, subkey)\n    var_params, train_accuracy = aux_data\n    updates, opt_state = opt.update(grad, opt_state, params)\n    params = optax.apply_updates(params, updates)\n    return params, key, opt_state, loss, var_params, train_accuracy\n\n# for i in tqdm(range(max_iters)):\ncounter = 0\nloss = 10\nwhile counter<max_iters: # and loss > 1.0:\n\n    params, key, opt_state, loss, var_params, train_accuracy = step(key, params, var_params, opt_state)\n    \n\n    # once every N_FREQ_EVAL we compute loss on the validation set\n    if counter % eval_iters == 0:\n        key, subkey = jax.random.split(key)\n        eval_loss, eval_accuracy = eval_step(params, *get_batch(subkey, test_data), var_params)\n        all_train_losses.append(loss)\n        all_eval_losses.append(eval_loss)\n        all_train_accuracy.append(train_accuracy)\n        all_test_accuracy.append(eval_accuracy)\n        print('##########################################################')\n        print(f\"Step: {counter}\\t train loss: {loss}\\t train accuracy: {train_accuracy}\")\n        print(f\"Step: {counter}\\t eval loss: {eval_loss}\\t eval accuracy: {eval_accuracy}\")\n        \n    counter += 1\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:45:33.392046Z","iopub.execute_input":"2024-05-27T06:45:33.392406Z","iopub.status.idle":"2024-05-27T07:06:57.263186Z","shell.execute_reply.started":"2024-05-27T06:45:33.392374Z","shell.execute_reply":"2024-05-27T07:06:57.262140Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"##########################################################\nStep: 0\t train loss: 4.6652421951293945\t train accuracy: 0.0164794921875\nStep: 0\t eval loss: 4.582863807678223\t eval accuracy: 0.0186767578125\n##########################################################\nStep: 100\t train loss: 1.3436217308044434\t train accuracy: 0.6663818359375\nStep: 100\t eval loss: 1.3116658926010132\t eval accuracy: 0.671875\n##########################################################\nStep: 200\t train loss: 0.31666362285614014\t train accuracy: 0.9259033203125\nStep: 200\t eval loss: 0.3357149064540863\t eval accuracy: 0.924072265625\n##########################################################\nStep: 300\t train loss: 0.13645046949386597\t train accuracy: 0.9674072265625\nStep: 300\t eval loss: 0.13832038640975952\t eval accuracy: 0.968505859375\n##########################################################\nStep: 400\t train loss: 0.07383321970701218\t train accuracy: 0.9842529296875\nStep: 400\t eval loss: 0.0682372897863388\t eval accuracy: 0.9844970703125\n##########################################################\nStep: 500\t train loss: 0.054378755390644073\t train accuracy: 0.98583984375\nStep: 500\t eval loss: 0.05294819921255112\t eval accuracy: 0.9866943359375\n##########################################################\nStep: 600\t train loss: 0.050938498228788376\t train accuracy: 0.98779296875\nStep: 600\t eval loss: 0.052078977227211\t eval accuracy: 0.9862060546875\n##########################################################\nStep: 700\t train loss: 0.06380070000886917\t train accuracy: 0.9852294921875\nStep: 700\t eval loss: 0.06172652542591095\t eval accuracy: 0.9844970703125\n##########################################################\nStep: 800\t train loss: 0.04113774746656418\t train accuracy: 0.9901123046875\nStep: 800\t eval loss: 0.04307301342487335\t eval accuracy: 0.988037109375\n##########################################################\nStep: 900\t train loss: 0.04216132313013077\t train accuracy: 0.9884033203125\nStep: 900\t eval loss: 0.039785679429769516\t eval accuracy: 0.9896240234375\n##########################################################\nStep: 1000\t train loss: 0.040006913244724274\t train accuracy: 0.9893798828125\nStep: 1000\t eval loss: 0.04603397846221924\t eval accuracy: 0.9879150390625\n##########################################################\nStep: 1100\t train loss: 0.04030181095004082\t train accuracy: 0.9892578125\nStep: 1100\t eval loss: 0.03743913024663925\t eval accuracy: 0.9893798828125\n##########################################################\nStep: 1200\t train loss: 0.058736369013786316\t train accuracy: 0.9854736328125\nStep: 1200\t eval loss: 0.06656775623559952\t eval accuracy: 0.98291015625\n##########################################################\nStep: 1300\t train loss: 0.04267450422048569\t train accuracy: 0.988037109375\nStep: 1300\t eval loss: 0.042369186878204346\t eval accuracy: 0.98974609375\n##########################################################\nStep: 1400\t train loss: 0.04495815932750702\t train accuracy: 0.9879150390625\nStep: 1400\t eval loss: 0.038941264152526855\t eval accuracy: 0.9903564453125\n##########################################################\nStep: 1500\t train loss: 0.035054728388786316\t train accuracy: 0.989013671875\nStep: 1500\t eval loss: 0.035922661423683167\t eval accuracy: 0.9898681640625\n##########################################################\nStep: 1600\t train loss: 0.03744201362133026\t train accuracy: 0.9903564453125\nStep: 1600\t eval loss: 0.037067919969558716\t eval accuracy: 0.9893798828125\n##########################################################\nStep: 1700\t train loss: 0.03687591478228569\t train accuracy: 0.9891357421875\nStep: 1700\t eval loss: 0.03535394370555878\t eval accuracy: 0.989013671875\n##########################################################\nStep: 1800\t train loss: 0.034999292343854904\t train accuracy: 0.990234375\nStep: 1800\t eval loss: 0.042336806654930115\t eval accuracy: 0.9879150390625\n##########################################################\nStep: 1900\t train loss: 0.07040198892354965\t train accuracy: 0.9827880859375\nStep: 1900\t eval loss: 0.06039334833621979\t eval accuracy: 0.9840087890625\n##########################################################\nStep: 2000\t train loss: 0.036174677312374115\t train accuracy: 0.9893798828125\nStep: 2000\t eval loss: 0.03786104544997215\t eval accuracy: 0.9896240234375\n##########################################################\nStep: 2100\t train loss: 0.0341547355055809\t train accuracy: 0.990478515625\nStep: 2100\t eval loss: 0.036508917808532715\t eval accuracy: 0.9901123046875\n##########################################################\nStep: 2200\t train loss: 0.03194592520594597\t train accuracy: 0.990966796875\nStep: 2200\t eval loss: 0.035993002355098724\t eval accuracy: 0.9898681640625\n##########################################################\nStep: 2300\t train loss: 0.03433171659708023\t train accuracy: 0.9901123046875\nStep: 2300\t eval loss: 0.03353511169552803\t eval accuracy: 0.990234375\n##########################################################\nStep: 2400\t train loss: 0.03678881749510765\t train accuracy: 0.988525390625\nStep: 2400\t eval loss: 0.034377433359622955\t eval accuracy: 0.9910888671875\n##########################################################\nStep: 2500\t train loss: 0.03508617356419563\t train accuracy: 0.9901123046875\nStep: 2500\t eval loss: 0.036793094128370285\t eval accuracy: 0.9888916015625\n##########################################################\nStep: 2600\t train loss: 0.03455342352390289\t train accuracy: 0.98974609375\nStep: 2600\t eval loss: 0.030729472637176514\t eval accuracy: 0.9908447265625\n##########################################################\nStep: 2700\t train loss: 0.045303866267204285\t train accuracy: 0.9873046875\nStep: 2700\t eval loss: 0.055368565022945404\t eval accuracy: 0.9849853515625\n##########################################################\nStep: 2800\t train loss: 0.03284137696027756\t train accuracy: 0.99072265625\nStep: 2800\t eval loss: 0.03697580471634865\t eval accuracy: 0.990234375\n##########################################################\nStep: 2900\t train loss: 0.03370016813278198\t train accuracy: 0.9898681640625\nStep: 2900\t eval loss: 0.03833041340112686\t eval accuracy: 0.989501953125\n##########################################################\nStep: 3000\t train loss: 0.03931747376918793\t train accuracy: 0.9888916015625\nStep: 3000\t eval loss: 0.045756541192531586\t eval accuracy: 0.9871826171875\n##########################################################\nStep: 3100\t train loss: 0.029642846435308456\t train accuracy: 0.9908447265625\nStep: 3100\t eval loss: 0.040554992854595184\t eval accuracy: 0.9886474609375\n##########################################################\nStep: 3200\t train loss: 0.03933453932404518\t train accuracy: 0.9886474609375\nStep: 3200\t eval loss: 0.04414815828204155\t eval accuracy: 0.9864501953125\n##########################################################\nStep: 3300\t train loss: 0.03228868544101715\t train accuracy: 0.9906005859375\nStep: 3300\t eval loss: 0.03441786766052246\t eval accuracy: 0.990478515625\n##########################################################\nStep: 3400\t train loss: 0.03376134857535362\t train accuracy: 0.98974609375\nStep: 3400\t eval loss: 0.042144954204559326\t eval accuracy: 0.9892578125\n##########################################################\nStep: 3500\t train loss: 0.031520213931798935\t train accuracy: 0.99072265625\nStep: 3500\t eval loss: 0.03935672342777252\t eval accuracy: 0.9891357421875\n##########################################################\nStep: 3600\t train loss: 0.032225102186203\t train accuracy: 0.990966796875\nStep: 3600\t eval loss: 0.03739548474550247\t eval accuracy: 0.9892578125\n##########################################################\nStep: 3700\t train loss: 0.03190474957227707\t train accuracy: 0.9901123046875\nStep: 3700\t eval loss: 0.032868705689907074\t eval accuracy: 0.9898681640625\n##########################################################\nStep: 3800\t train loss: 0.030807560309767723\t train accuracy: 0.9915771484375\nStep: 3800\t eval loss: 0.033712685108184814\t eval accuracy: 0.990478515625\n##########################################################\nStep: 3900\t train loss: 0.03448641300201416\t train accuracy: 0.990478515625\nStep: 3900\t eval loss: 0.03354072570800781\t eval accuracy: 0.990478515625\n##########################################################\nStep: 4000\t train loss: 0.030346553772687912\t train accuracy: 0.9913330078125\nStep: 4000\t eval loss: 0.03155631572008133\t eval accuracy: 0.99072265625\n##########################################################\nStep: 4100\t train loss: 0.029701560735702515\t train accuracy: 0.9910888671875\nStep: 4100\t eval loss: 0.0318136103451252\t eval accuracy: 0.9903564453125\n##########################################################\nStep: 4200\t train loss: 0.05733315646648407\t train accuracy: 0.9830322265625\nStep: 4200\t eval loss: 0.061989523470401764\t eval accuracy: 0.9825439453125\n##########################################################\nStep: 4300\t train loss: 0.028592385351657867\t train accuracy: 0.991943359375\nStep: 4300\t eval loss: 0.03609539568424225\t eval accuracy: 0.98974609375\n##########################################################\nStep: 4400\t train loss: 0.03295455127954483\t train accuracy: 0.9903564453125\nStep: 4400\t eval loss: 0.033556677401065826\t eval accuracy: 0.9892578125\n##########################################################\nStep: 4500\t train loss: 0.03298105672001839\t train accuracy: 0.9903564453125\nStep: 4500\t eval loss: 0.03982459753751755\t eval accuracy: 0.988525390625\n##########################################################\nStep: 4600\t train loss: 0.029050936922430992\t train accuracy: 0.9918212890625\nStep: 4600\t eval loss: 0.03476611152291298\t eval accuracy: 0.9901123046875\n##########################################################\nStep: 4700\t train loss: 0.0281478650867939\t train accuracy: 0.991943359375\nStep: 4700\t eval loss: 0.03153284639120102\t eval accuracy: 0.9906005859375\n##########################################################\nStep: 4800\t train loss: 0.02757820300757885\t train accuracy: 0.9921875\nStep: 4800\t eval loss: 0.0344843789935112\t eval accuracy: 0.990478515625\n##########################################################\nStep: 4900\t train loss: 0.031139083206653595\t train accuracy: 0.9903564453125\nStep: 4900\t eval loss: 0.03371318057179451\t eval accuracy: 0.9906005859375\n##########################################################\nStep: 5000\t train loss: 0.029794011265039444\t train accuracy: 0.9906005859375\nStep: 5000\t eval loss: 0.031209450215101242\t eval accuracy: 0.991455078125\n##########################################################\nStep: 5100\t train loss: 0.03342726081609726\t train accuracy: 0.990966796875\nStep: 5100\t eval loss: 0.03233030065894127\t eval accuracy: 0.98974609375\n##########################################################\nStep: 5200\t train loss: 0.04047833010554314\t train accuracy: 0.989501953125\nStep: 5200\t eval loss: 0.039978887885808945\t eval accuracy: 0.9892578125\n##########################################################\nStep: 5300\t train loss: 0.04348866641521454\t train accuracy: 0.988037109375\nStep: 5300\t eval loss: 0.04893539473414421\t eval accuracy: 0.9862060546875\n##########################################################\nStep: 5400\t train loss: 0.030050121247768402\t train accuracy: 0.9912109375\nStep: 5400\t eval loss: 0.03602280467748642\t eval accuracy: 0.9898681640625\n##########################################################\nStep: 5500\t train loss: 0.03207976371049881\t train accuracy: 0.990478515625\nStep: 5500\t eval loss: 0.0336887426674366\t eval accuracy: 0.989013671875\n##########################################################\nStep: 5600\t train loss: 0.028959598392248154\t train accuracy: 0.991455078125\nStep: 5600\t eval loss: 0.03222556412220001\t eval accuracy: 0.990478515625\n##########################################################\nStep: 5700\t train loss: 0.03559207171201706\t train accuracy: 0.989013671875\nStep: 5700\t eval loss: 0.03360215201973915\t eval accuracy: 0.9908447265625\n##########################################################\nStep: 5800\t train loss: 0.031131727620959282\t train accuracy: 0.991455078125\nStep: 5800\t eval loss: 0.03523009270429611\t eval accuracy: 0.9906005859375\n##########################################################\nStep: 5900\t train loss: 0.029112346470355988\t train accuracy: 0.9912109375\nStep: 5900\t eval loss: 0.03552093729376793\t eval accuracy: 0.9906005859375\n##########################################################\nStep: 6000\t train loss: 0.029769208282232285\t train accuracy: 0.991943359375\nStep: 6000\t eval loss: 0.03668108582496643\t eval accuracy: 0.990234375\n##########################################################\nStep: 6100\t train loss: 0.024371720850467682\t train accuracy: 0.992431640625\nStep: 6100\t eval loss: 0.03200841695070267\t eval accuracy: 0.98974609375\n##########################################################\nStep: 6200\t train loss: 0.030279451981186867\t train accuracy: 0.9908447265625\nStep: 6200\t eval loss: 0.04089703410863876\t eval accuracy: 0.9876708984375\n##########################################################\nStep: 6300\t train loss: 0.04337731748819351\t train accuracy: 0.9886474609375\nStep: 6300\t eval loss: 0.04260005056858063\t eval accuracy: 0.9893798828125\n##########################################################\nStep: 6400\t train loss: 0.029585866257548332\t train accuracy: 0.9912109375\nStep: 6400\t eval loss: 0.03288683295249939\t eval accuracy: 0.990966796875\n##########################################################\nStep: 6500\t train loss: 0.03072512522339821\t train accuracy: 0.990478515625\nStep: 6500\t eval loss: 0.03346966207027435\t eval accuracy: 0.989990234375\n##########################################################\nStep: 6600\t train loss: 0.03224489837884903\t train accuracy: 0.99072265625\nStep: 6600\t eval loss: 0.031970128417015076\t eval accuracy: 0.990478515625\n##########################################################\nStep: 6700\t train loss: 0.03184106945991516\t train accuracy: 0.9906005859375\nStep: 6700\t eval loss: 0.03948076441884041\t eval accuracy: 0.988525390625\n##########################################################\nStep: 6800\t train loss: 0.03563413769006729\t train accuracy: 0.9898681640625\nStep: 6800\t eval loss: 0.03200073912739754\t eval accuracy: 0.990478515625\n##########################################################\nStep: 6900\t train loss: 0.03262939676642418\t train accuracy: 0.9903564453125\nStep: 6900\t eval loss: 0.03217025846242905\t eval accuracy: 0.9901123046875\n##########################################################\nStep: 7000\t train loss: 0.029730822890996933\t train accuracy: 0.990966796875\nStep: 7000\t eval loss: 0.029531417414546013\t eval accuracy: 0.9913330078125\n##########################################################\nStep: 7100\t train loss: 0.029633115977048874\t train accuracy: 0.9910888671875\nStep: 7100\t eval loss: 0.033866118639707565\t eval accuracy: 0.9901123046875\n##########################################################\nStep: 7200\t train loss: 0.029532071202993393\t train accuracy: 0.991455078125\nStep: 7200\t eval loss: 0.03688672557473183\t eval accuracy: 0.9892578125\n##########################################################\nStep: 7300\t train loss: 0.028325185179710388\t train accuracy: 0.9910888671875\nStep: 7300\t eval loss: 0.039106812328100204\t eval accuracy: 0.9893798828125\n##########################################################\nStep: 7400\t train loss: 0.030725417658686638\t train accuracy: 0.990478515625\nStep: 7400\t eval loss: 0.0314783975481987\t eval accuracy: 0.9903564453125\n##########################################################\nStep: 7500\t train loss: 0.0318327434360981\t train accuracy: 0.9910888671875\nStep: 7500\t eval loss: 0.03695886582136154\t eval accuracy: 0.9888916015625\n##########################################################\nStep: 7600\t train loss: 0.05319654941558838\t train accuracy: 0.9842529296875\nStep: 7600\t eval loss: 0.057375263422727585\t eval accuracy: 0.98291015625\n##########################################################\nStep: 7700\t train loss: 0.03743433952331543\t train accuracy: 0.9893798828125\nStep: 7700\t eval loss: 0.03632538020610809\t eval accuracy: 0.989990234375\n##########################################################\nStep: 7800\t train loss: 0.03016091138124466\t train accuracy: 0.9901123046875\nStep: 7800\t eval loss: 0.03435954451560974\t eval accuracy: 0.9892578125\n##########################################################\nStep: 7900\t train loss: 0.027833886444568634\t train accuracy: 0.9915771484375\nStep: 7900\t eval loss: 0.031082261353731155\t eval accuracy: 0.9915771484375\n##########################################################\nStep: 8000\t train loss: 0.02765899896621704\t train accuracy: 0.99267578125\nStep: 8000\t eval loss: 0.028420420363545418\t eval accuracy: 0.991943359375\n##########################################################\nStep: 8100\t train loss: 0.028601916506886482\t train accuracy: 0.9915771484375\nStep: 8100\t eval loss: 0.031104132533073425\t eval accuracy: 0.99072265625\n##########################################################\nStep: 8200\t train loss: 0.02773291990160942\t train accuracy: 0.9921875\nStep: 8200\t eval loss: 0.03180244192481041\t eval accuracy: 0.9901123046875\n##########################################################\nStep: 8300\t train loss: 0.034959953278303146\t train accuracy: 0.990478515625\nStep: 8300\t eval loss: 0.033265627920627594\t eval accuracy: 0.9908447265625\n##########################################################\nStep: 8400\t train loss: 0.031549274921417236\t train accuracy: 0.9913330078125\nStep: 8400\t eval loss: 0.03034001775085926\t eval accuracy: 0.99169921875\n##########################################################\nStep: 8500\t train loss: 0.027990002185106277\t train accuracy: 0.99169921875\nStep: 8500\t eval loss: 0.031070370227098465\t eval accuracy: 0.991455078125\n##########################################################\nStep: 8600\t train loss: 0.029022935777902603\t train accuracy: 0.9915771484375\nStep: 8600\t eval loss: 0.03053857386112213\t eval accuracy: 0.991455078125\n##########################################################\nStep: 8700\t train loss: 0.049795374274253845\t train accuracy: 0.9898681640625\nStep: 8700\t eval loss: 0.03782951831817627\t eval accuracy: 0.99072265625\n##########################################################\nStep: 8800\t train loss: 0.03424351289868355\t train accuracy: 0.989990234375\nStep: 8800\t eval loss: 0.03528602421283722\t eval accuracy: 0.9901123046875\n##########################################################\nStep: 8900\t train loss: 0.030912112444639206\t train accuracy: 0.990478515625\nStep: 8900\t eval loss: 0.03454805165529251\t eval accuracy: 0.9898681640625\n##########################################################\nStep: 9000\t train loss: 0.027843192219734192\t train accuracy: 0.9920654296875\nStep: 9000\t eval loss: 0.03303774446249008\t eval accuracy: 0.990478515625\n##########################################################\nStep: 9100\t train loss: 0.03155123442411423\t train accuracy: 0.990966796875\nStep: 9100\t eval loss: 0.0344218835234642\t eval accuracy: 0.9903564453125\n##########################################################\nStep: 9200\t train loss: 0.034138619899749756\t train accuracy: 0.9908447265625\nStep: 9200\t eval loss: 0.032096926122903824\t eval accuracy: 0.990966796875\n##########################################################\nStep: 9300\t train loss: 0.02622903510928154\t train accuracy: 0.991943359375\nStep: 9300\t eval loss: 0.028077999129891396\t eval accuracy: 0.990966796875\n##########################################################\nStep: 9400\t train loss: 0.029522666707634926\t train accuracy: 0.9910888671875\nStep: 9400\t eval loss: 0.030545514076948166\t eval accuracy: 0.9901123046875\n##########################################################\nStep: 9500\t train loss: 0.03173583000898361\t train accuracy: 0.9913330078125\nStep: 9500\t eval loss: 0.028904438018798828\t eval accuracy: 0.991943359375\n##########################################################\nStep: 9600\t train loss: 0.03891301155090332\t train accuracy: 0.9896240234375\nStep: 9600\t eval loss: 0.038683198392391205\t eval accuracy: 0.9896240234375\n##########################################################\nStep: 9700\t train loss: 0.03398483246564865\t train accuracy: 0.9906005859375\nStep: 9700\t eval loss: 0.0396321602165699\t eval accuracy: 0.9891357421875\n##########################################################\nStep: 9800\t train loss: 0.032824087888002396\t train accuracy: 0.991455078125\nStep: 9800\t eval loss: 0.031330712139606476\t eval accuracy: 0.9910888671875\n##########################################################\nStep: 9900\t train loss: 0.028182847425341606\t train accuracy: 0.991455078125\nStep: 9900\t eval loss: 0.030981872230768204\t eval accuracy: 0.9912109375\nCPU times: user 13min 49s, sys: 7min 37s, total: 21min 26s\nWall time: 21min 23s\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt  # Visualization\n\n# Plot loss and accuracy in subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.set_title('Loss')\nax2.set_title('Accuracy')\n\n\n\nax1.plot(all_train_losses, label='train_loss')\nax1.plot(all_eval_losses, label='eval_loss')\n\nax2.plot(all_train_accuracy, label='train_accuracy')\nax2.plot(all_test_accuracy, label='eval_accuracy')\n\nax1.legend()\nax2.legend()\nplt.show()\nplt.clf()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:06:57.264393Z","iopub.execute_input":"2024-05-27T07:06:57.264712Z","iopub.status.idle":"2024-05-27T07:06:57.755011Z","shell.execute_reply.started":"2024-05-27T07:06:57.264686Z","shell.execute_reply":"2024-05-27T07:06:57.754066Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x500 with 2 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"@partial(jax.jit, static_argnames=(\"length\"))\ndef generate_text(rng, params, var_params, length):\n    def _scan_generate(carry, _):\n        random_key, context = carry\n        logits = model.apply({'params': params, **var_params}, context, training=False, mutable=['other_variables'])[0]\n        rng, rng_subkey = jax.random.split(random_key)\n        new_token = jax.random.categorical(\n          rng_subkey, logits[:, -n_tokens, :], axis=-1, shape=(1, 1)\n        )\n        context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n        return (rng, context), new_token\n\n    _, new_tokens = jax.lax.scan(\n    _scan_generate,\n    (rng, jnp.zeros((1, block_size), dtype=jnp.int32)),\n    (),\n    length=length,\n    )\n    return new_tokens","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:06:57.756225Z","iopub.execute_input":"2024-05-27T07:06:57.756519Z","iopub.status.idle":"2024-05-27T07:06:57.765382Z","shell.execute_reply.started":"2024-05-27T07:06:57.756494Z","shell.execute_reply":"2024-05-27T07:06:57.764423Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"new_tokenz = 1000\nkey, subkey = jax.random.split(jax.random.PRNGKey(156))\n# key, subkey = jax.random.split(key)\n# token_gen = generate_text(jnp.zeros((1,block_size)).astype(jnp.int32), new_tokenz, {'params': state.params})\ntoken_gen = generate_text(key, params, var_params, new_tokenz)[:, 0, 0].tolist()\nprint(token_gen)\nprint(decode(token_gen))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:06:57.767487Z","iopub.execute_input":"2024-05-27T07:06:57.767814Z","iopub.status.idle":"2024-05-27T07:07:20.356188Z","shell.execute_reply.started":"2024-05-27T07:06:57.767789Z","shell.execute_reply":"2024-05-27T07:07:20.355172Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"[24, 33, 15, 21, 27, 10, 0, 21, 5, 50, 50, 53, 50, 52, 1, 52, 53, 1, 51, 39, 63, 1, 60, 53, 60, 43, 56, 43, 57, 2, 0, 0, 28, 50, 39, 63, 1, 58, 46, 39, 58, 1, 21, 1, 61, 53, 56, 42, 57, 1, 58, 53, 1, 44, 39, 59, 52, 58, 1, 58, 53, 1, 50, 47, 54, 1, 57, 53, 8, 0, 0, 24, 13, 30, 16, 1, 16, 21, 27, 10, 0, 15, 53, 51, 43, 6, 1, 47, 58, 1, 58, 53, 1, 59, 57, 46, 6, 0, 25, 39, 56, 57, 43, 50, 44, 47, 41, 43, 1, 40, 53, 63, 57, 1, 40, 53, 59, 50, 50, 7, 44, 43, 46, 57, 1, 63, 53, 59, 1, 39, 54, 54, 47, 52, 43, 1, 53, 44, 1, 46, 53, 52, 47, 64, 59, 57, 47, 41, 46, 1, 51, 63, 41, 49, 1, 58, 53, 12, 0, 21, 44, 1, 60, 39, 47, 58, 63, 1, 46, 39, 54, 47, 41, 58, 1, 46, 39, 42, 1, 39, 56, 52, 43, 57, 43, 1, 47, 52, 1, 40, 43, 1, 50, 47, 60, 47, 52, 45, 1, 58, 47, 51, 43, 1, 42, 56, 43, 39, 58, 1, 46, 43, 39, 56, 57, 1, 40, 43, 1, 53, 44, 44, 1, 58, 46, 43, 1, 43, 39, 56, 56, 43, 50, 47, 53, 52, 1, 39, 50, 50, 1, 58, 53, 50, 42, 47, 52, 45, 6, 1, 42, 53, 53, 58, 46, 1, 21, 1, 59, 47, 56, 42, 6, 1, 52, 53, 58, 1, 39, 50, 50, 1, 40, 43, 1, 59, 52, 57, 39, 56, 56, 47, 52, 43, 1, 61, 53, 39, 58, 46, 1, 47, 45, 52, 39, 42, 1, 40, 39, 56, 56, 63, 8, 0, 0, 14, 17, 26, 34, 27, 24, 33, 18, 10, 0, 57, 46, 53, 61, 1, 53, 44, 1, 63, 53, 59, 56, 1, 39, 51, 39, 56, 6, 0, 32, 53, 1, 50, 43, 57, 1, 58, 56, 39, 44, 21, 1, 39, 51, 1, 53, 44, 1, 52, 53, 58, 1, 51, 43, 6, 1, 61, 39, 41, 43, 6, 1, 46, 43, 39, 56, 6, 1, 51, 39, 63, 1, 40, 43, 57, 54, 43, 56, 47, 53, 46, 43, 56, 56, 53, 52, 12, 0, 0, 28, 13, 33, 24, 17, 32, 10, 0, 35, 39, 56, 61, 47, 50, 50, 57, 6, 1, 58, 46, 43, 52, 6, 0, 33, 56, 56, 53, 61, 1, 42, 53, 61, 43, 56, 1, 58, 53, 1, 46, 39, 52, 45, 43, 1, 58, 46, 43, 1, 43, 52, 42, 57, 2, 1, 35, 39, 58, 47, 57, 46, 1, 41, 53, 52, 42, 1, 42, 59, 43, 1, 49, 47, 52, 41, 43, 1, 53, 52, 1, 47, 57, 1, 54, 39, 59, 45, 43, 1, 56, 47, 57, 41, 39, 52, 50, 59, 40, 1, 39, 58, 1, 57, 51, 43, 51, 43, 52, 41, 43, 50, 1, 58, 53, 1, 54, 50, 43, 39, 52, 57, 1, 40, 53, 63, 57, 6, 1, 53, 52, 43, 1, 42, 43, 39, 58, 47, 53, 59, 57, 1, 40, 47, 58, 47, 53, 52, 1, 50, 59, 40, 50, 47, 52, 45, 6, 1, 39, 1, 42, 53, 58, 46, 1, 50, 53, 56, 42, 10, 1, 58, 46, 43, 1, 63, 53, 59, 1, 42, 39, 56, 47, 43, 44, 44, 43, 42, 1, 42, 53, 59, 52, 42, 53, 52, 43, 1, 39, 1, 56, 59, 57, 58, 1, 46, 43, 39, 56, 58, 57, 1, 39, 52, 42, 1, 44, 53, 59, 50, 50, 47, 56, 43, 57, 1, 40, 56, 43, 39, 58, 1, 57, 59, 57, 39, 57, 1, 39, 52, 42, 1, 61, 47, 58, 46, 43, 56, 1, 39, 40, 58, 56, 39, 52, 41, 63, 10, 0, 35, 46, 63, 6, 0, 32, 46, 63, 1, 45, 53, 59, 52, 58, 43, 57, 58, 1, 46, 39, 50, 50, 1, 57, 46, 53, 59, 56, 1, 57, 54, 43, 56, 43, 47, 57, 53, 59, 40, 58, 1, 52, 53, 1, 42, 43, 50, 39, 63, 6, 0, 13, 1, 51, 39, 49, 43, 1, 46, 43, 56, 1, 50, 43, 39, 57, 59, 1, 53, 52, 43, 1, 58, 46, 39, 58, 1, 54, 56, 39, 63, 1, 58, 46, 39, 58, 5, 57, 1, 50, 39, 51, 43, 44, 43, 57, 1, 39, 1, 28, 53, 58, 46, 6, 1, 45, 56, 39, 54, 50, 43, 1, 44, 47, 58, 63, 1, 47, 52, 44, 43, 1, 45, 47, 60, 43, 8, 0, 0, 5, 32, 47, 57, 1, 41, 53, 51, 47, 52, 45, 59, 43, 1, 46, 43, 1, 44, 53, 56, 6, 1, 46, 53, 61, 6, 1, 39, 50, 41, 53, 52, 58, 63, 1, 42, 39, 63, 8, 1, 34, 39, 56, 47, 52, 49, 57, 1, 46, 43, 39, 60, 43, 1, 41, 39, 50, 58, 1, 46, 43, 5, 53, 51, 1, 39, 52, 42, 1, 46, 53, 54, 53, 53, 44, 1, 63, 53, 59, 1, 46, 43, 1, 58, 43, 50, 50, 47, 39, 50, 1, 39, 1, 55, 59, 47, 50, 43, 1, 43, 52, 42, 6, 1, 44, 53, 50, 59, 58, 39, 58, 59, 56, 43, 1, 42, 53, 59, 58, 6, 1, 39, 52, 42, 1, 51, 63, 1, 41, 53, 52, 57, 43, 51, 57, 1, 46, 39, 57, 43, 1, 47, 52, 1, 44, 43, 43, 50, 63, 1, 41, 53, 59, 52, 41, 43, 1, 43, 62, 54, 56, 47, 51, 47, 57, 43, 2, 1, 61, 47, 58, 46, 1, 58, 63, 1, 51, 43, 1, 52, 39, 48, 43, 58, 41, 46, 1, 21, 57, 59, 51, 54, 43, 56, 51, 6, 1, 53, 59, 58, 46, 52, 43, 41, 58, 57, 1, 39, 44, 44, 43, 58, 57, 1, 51, 43, 6, 0, 35]\nLUCIO:\nI'lloln no may voveres!\n\nPlay that I words to faunt to lip so.\n\nLARD DIO:\nCome, it to ush,\nMarselfice boys boull-fehs you appine of honizusich myck to?\nIf vaity hapict had arnese in be living time dreat hears be off the earrelion all tolding, dooth I uird, not all be unsarrine woath ignad barry.\n\nBENVOLUF:\nshow of your amar,\nTo les trafI am of not me, wace, hear, may besperioherron?\n\nPAULET:\nWarwills, then,\nUrrow dower to hange the ends! Watish cond due kince on is pauge riscanlub at smemencel to pleans boys, one deatious bition lubling, a doth lord: the you darieffed doundone a rust hearts and foullires breat susas and wither abtrancy:\nWhy,\nThy gountest hall shour spereisoubt no delay,\nA make her leasu one that pray that's lamefes a Poth, graple fity infe give.\n\n'Tis comingue he for, how, alconty day. Varinks heave calt he'om and hopoof you he tellial a quile end, folutature dout, and my consems hase in feely counce exprimise! with ty me najetch Isumperm, outhnects affets me,\nW\n","output_type":"stream"}]},{"cell_type":"code","source":"dsfsdhfgjdg hfdgjdgjgfjhs'####################","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:07:20.357727Z","iopub.execute_input":"2024-05-27T07:07:20.358249Z","iopub.status.idle":"2024-05-27T07:07:20.364320Z","shell.execute_reply.started":"2024-05-27T07:07:20.358211Z","shell.execute_reply":"2024-05-27T07:07:20.363072Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[33], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    dsfsdhfgjdg hfdgjdgjgfjhs'####################\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"],"ename":"SyntaxError","evalue":"unterminated string literal (detected at line 1) (2630675753.py, line 1)","output_type":"error"}]},{"cell_type":"code","source":"var_params['other_variables']['Mamba_0']['hidden_state'].shape","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:07:20.365097Z","iopub.status.idle":"2024-05-27T07:07:20.365455Z","shell.execute_reply.started":"2024-05-27T07:07:20.365264Z","shell.execute_reply":"2024-05-27T07:07:20.365277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params.keys()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:07:20.367277Z","iopub.status.idle":"2024-05-27T07:07:20.367700Z","shell.execute_reply.started":"2024-05-27T07:07:20.367459Z","shell.execute_reply":"2024-05-27T07:07:20.367473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params['Dense_12']['kernel'].shape","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:07:20.369184Z","iopub.status.idle":"2024-05-27T07:07:20.369583Z","shell.execute_reply.started":"2024-05-27T07:07:20.369359Z","shell.execute_reply":"2024-05-27T07:07:20.369373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rngk = jax.random.PRNGKey(389)\nxs, ys = get_batch(rngk, train_data)\nprint(xs[0])\nprint(ys[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:07:20.371425Z","iopub.status.idle":"2024-05-27T07:07:20.372127Z","shell.execute_reply.started":"2024-05-27T07:07:20.371841Z","shell.execute_reply":"2024-05-27T07:07:20.371865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits = model.apply({'params': params, **var_params}, xs[0].reshape((1,64)), training=False, mutable=['other_variables'])[0]\nrng, rng_subkey = jax.random.split(rngk)\nfor pso in range(n_tokens):\n    new_token = jax.random.categorical(\n      rng_subkey, logits[:, -1*(n_tokens-pso), :], axis=-1, shape=(1, 1)\n    )\n    print(new_token)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:07:20.373887Z","iopub.status.idle":"2024-05-27T07:07:20.374581Z","shell.execute_reply.started":"2024-05-27T07:07:20.374316Z","shell.execute_reply":"2024-05-27T07:07:20.374338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_tok = [51,49,46,46,46,52]\nprint(decode(ys[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:07:20.375919Z","iopub.status.idle":"2024-05-27T07:07:20.376367Z","shell.execute_reply.started":"2024-05-27T07:07:20.376137Z","shell.execute_reply":"2024-05-27T07:07:20.376155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"act_tk = [60, 43, 50, 57,  1, 47]\nprint(decode(act_tk))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:07:20.377666Z","iopub.status.idle":"2024-05-27T07:07:20.378113Z","shell.execute_reply.started":"2024-05-27T07:07:20.377881Z","shell.execute_reply":"2024-05-27T07:07:20.377900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jax.nn.standardize(jnp.array([2.0,3.0,4.0]))","metadata":{"id":"Oe_GIDP2HFyt","outputId":"5d3dce16-fcc2-40b9-c49a-00a8c4013ca2","execution":{"iopub.status.busy":"2024-05-27T07:07:20.379540Z","iopub.status.idle":"2024-05-27T07:07:20.380020Z","shell.execute_reply.started":"2024-05-27T07:07:20.379781Z","shell.execute_reply":"2024-05-27T07:07:20.379801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@struct.dataclass\nclass Metrics(metrics.Collection):\n    accuracy: metrics.Accuracy\n    loss: metrics.Average.from_output('loss')","metadata":{"id":"s3nN1jOiHFyu","execution":{"iopub.status.busy":"2024-05-27T07:07:20.381543Z","iopub.status.idle":"2024-05-27T07:07:20.382053Z","shell.execute_reply.started":"2024-05-27T07:07:20.381779Z","shell.execute_reply":"2024-05-27T07:07:20.381814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainState(train_state.TrainState):\n    metrics: Metrics\n\ndef create_train_state(module, rng, learning_rate, train_shape):\n    \"\"\"Creates an initial `TrainState`.\"\"\"\n    params = module.init(rng, jnp.ones(train_shape).astype(jnp.int32), \n                         training=False)['params'] # initialize parameters by passing a template image\n    tx = optax.adamw(learning_rate)\n    return TrainState.create(\n      apply_fn=module.apply, params=params, tx=tx,\n      metrics=Metrics.empty(),\n    )","metadata":{"id":"7LLDTSFQHFyu","execution":{"iopub.status.busy":"2024-05-27T07:07:20.383381Z","iopub.status.idle":"2024-05-27T07:07:20.383727Z","shell.execute_reply.started":"2024-05-27T07:07:20.383540Z","shell.execute_reply":"2024-05-27T07:07:20.383552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TrainState.create(","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:07:20.385358Z","iopub.status.idle":"2024-05-27T07:07:20.385705Z","shell.execute_reply.started":"2024-05-27T07:07:20.385522Z","shell.execute_reply":"2024-05-27T07:07:20.385534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@jax.jit\ndef train_step(state, inputs, targets):\n    \"\"\"Train for a single step.\"\"\"\n    def loss_fn(params):\n        logits = state.apply_fn({'params': params}, inputs, training=True, \n                                rngs={\"dropout\": key})[0]\n        loss = optax.softmax_cross_entropy_with_integer_labels(\n            logits=logits, labels=targets).mean()\n        return loss\n    grad_fn = jax.grad(loss_fn)\n    grads = grad_fn(state.params)\n    state = state.apply_gradients(grads=grads)\n    return state","metadata":{"id":"zApWXUDaHFyu","execution":{"iopub.status.busy":"2024-05-27T07:07:20.386905Z","iopub.status.idle":"2024-05-27T07:07:20.387250Z","shell.execute_reply.started":"2024-05-27T07:07:20.387088Z","shell.execute_reply":"2024-05-27T07:07:20.387102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@jax.jit\ndef compute_metrics(*, state, inputs, targets):\n    logits = state.apply_fn({'params': state.params}, inputs, training=False)[0]\n    loss = optax.softmax_cross_entropy_with_integer_labels(\n        logits=logits, labels=targets).mean()\n    metric_updates = state.metrics.single_from_model_output(\n    logits=logits, labels=targets, loss=loss)\n    metrics = state.metrics.merge(metric_updates)\n    state = state.replace(metrics=metrics)\n    return state","metadata":{"id":"VzukZ4iEHFyv","execution":{"iopub.status.busy":"2024-05-27T07:07:20.388853Z","iopub.status.idle":"2024-05-27T07:07:20.389180Z","shell.execute_reply.started":"2024-05-27T07:07:20.389017Z","shell.execute_reply":"2024-05-27T07:07:20.389030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nlearning_rate = 0.005\ninit_rng = jax.random.key(0)","metadata":{"id":"ehYvMeuNHFyv","execution":{"iopub.status.busy":"2024-05-27T07:07:20.390063Z","iopub.status.idle":"2024-05-27T07:07:20.390360Z","shell.execute_reply.started":"2024-05-27T07:07:20.390211Z","shell.execute_reply":"2024-05-27T07:07:20.390223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state = create_train_state(fin_model, init_rng, learning_rate, train_shape)\ndel init_rng  # Must not be used anymore.","metadata":{"id":"D60UHLFHHFyv","execution":{"iopub.status.busy":"2024-05-27T07:07:20.391636Z","iopub.status.idle":"2024-05-27T07:07:20.392000Z","shell.execute_reply.started":"2024-05-27T07:07:20.391821Z","shell.execute_reply":"2024-05-27T07:07:20.391836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics_history = {'train_loss': [],\n                   'train_accuracy': [],\n                   'test_loss': [],\n                   'test_accuracy': []}","metadata":{"id":"Jl-9TlHEHFyv","execution":{"iopub.status.busy":"2024-05-27T07:07:20.393102Z","iopub.status.idle":"2024-05-27T07:07:20.393404Z","shell.execute_reply.started":"2024-05-27T07:07:20.393252Z","shell.execute_reply":"2024-05-27T07:07:20.393265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 442\nkey = jax.random.PRNGKey(SEED)\nloss = 10\ncounter = 0\n# for step in tqdm(range(max_iters)): # increase number of steps for good results...\nwhile counter==max_iters or loss > 1.0:\n\n      # sample a batch of data\n    xb, yb = get_batch(key, train_data)\n    state = train_step(state, xb, yb)\n    state = compute_metrics(state=state, inputs=xb, targets=yb)\n\n    key = (jax.random.split(key)[0])\n\n    if step == 0 or (step+1) % 100 == 0: # one training epoch has passed\n        for metric,value in state.metrics.compute().items(): # compute metrics\n            metrics_history[f'train_{metric}'].append(value) # record metrics\n        state = state.replace(metrics=state.metrics.empty()) # reset train_metrics for next training epoch\n\n        # Compute metrics on the test set after each training epoch\n        test_state = state\n        x_test, y_test = get_batch(key, test_data)\n    #     for test_batch in test_ds.as_numpy_iterator():\n        test_state = compute_metrics(state=test_state, inputs=x_test, targets=y_test)\n\n        for metric,value in test_state.metrics.compute().items():\n            metrics_history[f'test_{metric}'].append(value)\n\n        print(f\"train epoch: {(step+1)}, \"\n              f\"loss: {metrics_history['train_loss'][-1]}, \"\n              f\"accuracy: {metrics_history['train_accuracy'][-1] * 100}\")\n        print(f\"test epoch: {(step+1) }, \"\n          f\"loss: {metrics_history['test_loss'][-1]}, \"\n          f\"accuracy: {metrics_history['test_accuracy'][-1] * 100}\")","metadata":{"id":"CaNt9JazHFyw","outputId":"ba447ddf-9940-44a6-f4b2-d27ed78a88c2","execution":{"iopub.status.busy":"2024-05-27T07:07:20.395557Z","iopub.status.idle":"2024-05-27T07:07:20.396028Z","shell.execute_reply.started":"2024-05-27T07:07:20.395797Z","shell.execute_reply":"2024-05-27T07:07:20.395816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt  # Visualization\n\n# Plot loss and accuracy in subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.set_title('Loss')\nax2.set_title('Accuracy')\nfor dataset in ('train','test'):\n    ax1.plot(metrics_history[f'{dataset}_loss'], label=f'{dataset}_loss')\n    ax2.plot(metrics_history[f'{dataset}_accuracy'], label=f'{dataset}_accuracy')\nax1.legend()\nax2.legend()\nplt.show()\nplt.clf()","metadata":{"id":"Y40JGx1YHFyw","execution":{"iopub.status.busy":"2024-05-27T07:07:20.397059Z","iopub.status.idle":"2024-05-27T07:07:20.397499Z","shell.execute_reply.started":"2024-05-27T07:07:20.397273Z","shell.execute_reply":"2024-05-27T07:07:20.397292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlogits = fin_model.apply(fin_params, xb, training=False)[0]\nloss = optax.softmax_cross_entropy_with_integer_labels(\n            logits=logits, labels=yb).mean()\n\nprint(loss)","metadata":{"id":"7pJlFXpVHFyw","execution":{"iopub.status.busy":"2024-05-27T07:07:20.398974Z","iopub.status.idle":"2024-05-27T07:07:20.399413Z","shell.execute_reply.started":"2024-05-27T07:07:20.399184Z","shell.execute_reply":"2024-05-27T07:07:20.399203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def generate_text(idx, max_new_tokens, params):\n# # idx is (B, T) array of indices in the current context\n#     for i in range(max_new_tokens):\n#         # crop idx to the last block_size tokens\n#         idx_cond = idx[:, -block_size:]\n#         # get the predictions\n#         logits = fin_model.apply(params, idx_cond)\n#         # focus only on the last time step\n#         logits = logits[:, -1, :] # becomes (B, C)\n\n#         if i == 0:\n#             rng, rng_subkey = jax.random.split(jax.random.PRNGKey(12))\n#         else:\n#             rng, rng_subkey = jax.random.split(rng)\n\n#         idx_next = jax.random.categorical(rng_subkey, logits, axis=-1, shape=(1, 1)) # (B, 1)\n\n\n#         # append sampled index to the running sequence\n#         idx = jnp.concatenate([idx, idx_next], axis=-1) # (B, T+1)\n\n#     return idx","metadata":{"id":"9d28o-dTHFyx","execution":{"iopub.status.busy":"2024-05-27T07:07:20.400753Z","iopub.status.idle":"2024-05-27T07:07:20.401195Z","shell.execute_reply.started":"2024-05-27T07:07:20.400963Z","shell.execute_reply":"2024-05-27T07:07:20.400981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@partial(jax.jit, static_argnames=(\"self\", \"length\"))\ndef generate_text(rng, params, length):\n    def _scan_generate(carry, _):\n        random_key, context = carry\n        logits = fin_model.apply(params, context, training=False)[0]\n        rng, rng_subkey = jax.random.split(random_key)\n        new_token = jax.random.categorical(\n          rng_subkey, logits[:, -1, :], axis=-1, shape=(1, 1)\n        )\n        context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n        return (rng, context), new_token\n\n    _, new_tokens = jax.lax.scan(\n    _scan_generate,\n    (rng, jnp.zeros((1, block_size), dtype=jnp.int32)),\n    (),\n    length=length,\n    )\n    return new_tokens","metadata":{"id":"WB0og7pAHFyx","execution":{"iopub.status.busy":"2024-05-27T07:07:20.402524Z","iopub.status.idle":"2024-05-27T07:07:20.402930Z","shell.execute_reply.started":"2024-05-27T07:07:20.402746Z","shell.execute_reply":"2024-05-27T07:07:20.402761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_tokenz = 1000\nkey, subkey = jax.random.split(jax.random.PRNGKey(156))\n# key, subkey = jax.random.split(key)\n# token_gen = generate_text(jnp.zeros((1,block_size)).astype(jnp.int32), new_tokenz, {'params': state.params})\ntoken_gen = generate_text(key, {'params': state.params}, new_tokenz)[:, 0, 0].tolist()\nprint(token_gen)\nprint(decode(token_gen))","metadata":{"id":"50Vpg2lEHFyx","execution":{"iopub.status.busy":"2024-05-27T07:07:20.404492Z","iopub.status.idle":"2024-05-27T07:07:20.404860Z","shell.execute_reply.started":"2024-05-27T07:07:20.404695Z","shell.execute_reply":"2024-05-27T07:07:20.404709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdgh  fs","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:07:20.406721Z","iopub.status.idle":"2024-05-27T07:07:20.407075Z","shell.execute_reply.started":"2024-05-27T07:07:20.406894Z","shell.execute_reply":"2024-05-27T07:07:20.406907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state.params","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:07:20.408216Z","iopub.status.idle":"2024-05-27T07:07:20.408534Z","shell.execute_reply.started":"2024-05-27T07:07:20.408373Z","shell.execute_reply":"2024-05-27T07:07:20.408385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install mamba-ssm","metadata":{"id":"MOw_xjbrHFy0","execution":{"iopub.status.busy":"2024-05-27T07:07:20.409897Z","iopub.status.idle":"2024-05-27T07:07:20.410377Z","shell.execute_reply.started":"2024-05-27T07:07:20.410132Z","shell.execute_reply":"2024-05-27T07:07:20.410151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ones = lambda *size: torch.ones(*size).float().cuda()\nzeros = lambda *size: torch.zeros(*size).float().cuda()\narange = lambda n: torch.arange(n).float().cuda()\nrand = lambda size: torch.rand(*size).abs().float().cuda()\n\ndef create_torch(S = 128, Ba = 2, D = 4, N = 4):\n    x = rand((Ba, 1, D, S))\n    a = -ones((Ba, N, D, 1))\n    b = ones((Ba, N, 1, S)) * 0.1\n    c = rand((Ba, N, 1, S)) * 0.1\n    delta = rand((Ba, 1, D, S)) * 0.1\n    return x, a, b, c, delta","metadata":{"id":"W_PAnYcEOR22","execution":{"iopub.status.busy":"2024-05-27T07:07:20.412235Z","iopub.status.idle":"2024-05-27T07:07:20.412762Z","shell.execute_reply.started":"2024-05-27T07:07:20.412472Z","shell.execute_reply":"2024-05-27T07:07:20.412493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import selective_scan_cuda\n\nxx, aa, bb, cc, ddelta = create_torch()\ny_from_repo = selective_scan_cuda.fwd(xx.squeeze(1), ddelta.squeeze(1), aa[0].squeeze(-1).T, bb.squeeze(-2)[:, None, :, :], cc.squeeze(-2)[:, None, :, :], None, None, None, False)\ny_from_repo","metadata":{"id":"ykh4GTvtOrak","execution":{"iopub.status.busy":"2024-05-27T07:07:20.413963Z","iopub.status.idle":"2024-05-27T07:07:20.414402Z","shell.execute_reply.started":"2024-05-27T07:07:20.414175Z","shell.execute_reply":"2024-05-27T07:07:20.414193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discretize(a, b, delta):\n    da = delta * a\n    a_ = jnp.exp(da)\n    b_ = b * delta\n    return a_, b_\n\ndef ssm(x, a, b, c, delta):\n    \"Jax Implementation\"\n    y = []\n    h = 0\n    a_, b_ = discretize(a, b, delta)\n    for k in range(x.shape[-1]):\n        h = a_[..., k] * h + b_[..., k] * x[..., k]\n        y.append((c[..., k] * h).sum(1, keepdims=True))\n    return h, jnp.stack(y, -1)\n","metadata":{"id":"NEdG1yPNOtxU","execution":{"iopub.status.busy":"2024-05-27T07:07:20.416480Z","iopub.status.idle":"2024-05-27T07:07:20.416967Z","shell.execute_reply.started":"2024-05-27T07:07:20.416724Z","shell.execute_reply":"2024-05-27T07:07:20.416745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, y_ = ssm(xx.cpu().numpy(), aa.cpu().numpy(), bb.cpu().numpy(), cc.cpu().numpy(), ddelta.cpu().numpy())","metadata":{"id":"GEjNcZSZPIp_","execution":{"iopub.status.busy":"2024-05-27T07:07:20.418200Z","iopub.status.idle":"2024-05-27T07:07:20.418721Z","shell.execute_reply.started":"2024-05-27T07:07:20.418421Z","shell.execute_reply":"2024-05-27T07:07:20.418440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"tWlqZZOmPnYk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mamba_ssm import Mamba as Mamba_T\ntorch_mamba = Mamba_T(\n      # This module uses roughly 3 * expand * d_model^2 parameters\n      d_model=n_embd, # Model dimension d_model\n      d_state=16,  # SSM state expansion factor\n      d_conv=4,    # Local convolution width\n      expand=2,    # Block expansion factor\n)","metadata":{"id":"5RHAE_I1Pql9","execution":{"iopub.status.busy":"2024-05-27T07:07:20.420192Z","iopub.status.idle":"2024-05-27T07:07:20.420507Z","shell.execute_reply.started":"2024-05-27T07:07:20.420346Z","shell.execute_reply":"2024-05-27T07:07:20.420358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xm = x = rand((1, 1, n_embd, 32))\nxm.shape","metadata":{"id":"l9zw_M-USrDt","execution":{"iopub.status.busy":"2024-05-27T07:07:20.421989Z","iopub.status.idle":"2024-05-27T07:07:20.422334Z","shell.execute_reply.started":"2024-05-27T07:07:20.422161Z","shell.execute_reply":"2024-05-27T07:07:20.422176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_mamba(xm.squeeze(1))","metadata":{"id":"gGmA2EWlTCo0","execution":{"iopub.status.busy":"2024-05-27T07:07:20.423579Z","iopub.status.idle":"2024-05-27T07:07:20.423936Z","shell.execute_reply.started":"2024-05-27T07:07:20.423774Z","shell.execute_reply":"2024-05-27T07:07:20.423788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_mamba.in_proj","metadata":{"id":"73ek9mx9UBBl","execution":{"iopub.status.busy":"2024-05-27T07:07:20.424891Z","iopub.status.idle":"2024-05-27T07:07:20.425191Z","shell.execute_reply.started":"2024-05-27T07:07:20.425040Z","shell.execute_reply":"2024-05-27T07:07:20.425052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import CLIPTokenizer\ntokenizer_1 = CLIPTokenizer.from_pretrained('openai/clip-vit-base-patch32')","metadata":{"id":"P3l_ssIYbiYT","execution":{"iopub.status.busy":"2024-05-27T07:07:20.426154Z","iopub.status.idle":"2024-05-27T07:07:20.426475Z","shell.execute_reply.started":"2024-05-27T07:07:20.426316Z","shell.execute_reply":"2024-05-27T07:07:20.426330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenise_prompts(prompt):\n    inputs = []\n    for tokenizer in [tokenizer_1, tokenizer_2]:\n        text_inputs = tokenizer(\n            positive_prompt,\n            padding=\"max_length\",\n            max_length=tokenizer.model_max_length,\n            truncation=True,\n            return_tensors=\"np\",\n        )\n        inputs.append(text_inputs.input_ids)\n    return jnp.stack(inputs, axis=1)","metadata":{"id":"-X7hXQRMZhl3","execution":{"iopub.status.busy":"2024-05-27T07:07:20.427771Z","iopub.status.idle":"2024-05-27T07:07:20.428109Z","shell.execute_reply.started":"2024-05-27T07:07:20.427945Z","shell.execute_reply":"2024-05-27T07:07:20.427959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xm.squeeze(1).shape","metadata":{"id":"rJhKQ_Oua9Gy","execution":{"iopub.status.busy":"2024-05-27T07:07:20.429535Z","iopub.status.idle":"2024-05-27T07:07:20.429949Z","shell.execute_reply.started":"2024-05-27T07:07:20.429758Z","shell.execute_reply":"2024-05-27T07:07:20.429774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"mzkoYrSVkoJj"},"execution_count":null,"outputs":[]}]}