{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q clu","metadata":{"id":"gS6euWNvHFye","outputId":"45b149a7-9450-439c-da67-ab8678a3b0d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt","metadata":{"id":"7jjCLfuUHFyg","outputId":"dfe048f0-dd44-40ef-edf3-2fa56558672f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from functools import partial\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom jax.nn.initializers import lecun_normal, normal\nfrom jax.numpy.linalg import eigh, inv, matrix_power\nfrom jax.scipy.signal import convolve\n\nimport torch\n\nfrom dataclasses import dataclass\n\nfrom typing import Union\n\nimport matplotlib.pyplot as plt\nimport seaborn\n\nfrom clu import metrics\nfrom flax.training import train_state  # Useful dataclass to keep train state\nfrom flax import struct                # Flax dataclasses\nimport optax                           # Common loss functions and optimizers\nfrom tqdm import tqdm","metadata":{"id":"YXSCJzupHFyh","execution":{"iopub.status.busy":"2024-05-22T09:50:04.004686Z","iopub.execute_input":"2024-05-22T09:50:04.005018Z","iopub.status.idle":"2024-05-22T09:50:07.535622Z","shell.execute_reply.started":"2024-05-22T09:50:04.004991Z","shell.execute_reply":"2024-05-22T09:50:07.534747Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# read it in to inspect it\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()","metadata":{"id":"KpJoV3KQHFyh","execution":{"iopub.status.busy":"2024-05-22T09:50:07.537590Z","iopub.execute_input":"2024-05-22T09:50:07.538040Z","iopub.status.idle":"2024-05-22T09:50:07.544328Z","shell.execute_reply.started":"2024-05-22T09:50:07.538003Z","shell.execute_reply":"2024-05-22T09:50:07.543380Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# here are all the unique characters that occur in this text\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"id":"PsWxZqyRHFyi","outputId":"b1730724-647e-45cd-edfa-97af24995830","execution":{"iopub.status.busy":"2024-05-22T09:50:07.545573Z","iopub.execute_input":"2024-05-22T09:50:07.545874Z","iopub.status.idle":"2024-05-22T09:50:07.573971Z","shell.execute_reply.started":"2024-05-22T09:50:07.545843Z","shell.execute_reply":"2024-05-22T09:50:07.573040Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n65\n","output_type":"stream"}]},{"cell_type":"code","source":"# create a mapping from characters to integers\nstoi = { ch: i for i,ch in enumerate(chars) }\nitos = { i: ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n\nprint(encode(\"hii there\"))\nprint(decode(encode(\"hii there\")))","metadata":{"id":"S-mzLOk1HFyi","outputId":"f56e2f85-5a1c-4099-87df-436ba39f4363","execution":{"iopub.status.busy":"2024-05-22T09:50:07.575302Z","iopub.execute_input":"2024-05-22T09:50:07.575637Z","iopub.status.idle":"2024-05-22T09:50:07.585423Z","shell.execute_reply.started":"2024-05-22T09:50:07.575604Z","shell.execute_reply":"2024-05-22T09:50:07.584553Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[46, 47, 47, 1, 58, 46, 43, 56, 43]\nhii there\n","output_type":"stream"}]},{"cell_type":"code","source":"data = jnp.array(encode(text), dtype=jnp.int32)\nprint(data.shape, data.dtype)\nprint(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this","metadata":{"id":"HImuqDd8HFyj","outputId":"91dcd15f-f068-4551-ad29-e6e41e52fd91","execution":{"iopub.status.busy":"2024-05-22T09:50:07.588927Z","iopub.execute_input":"2024-05-22T09:50:07.589412Z","iopub.status.idle":"2024-05-22T09:50:09.934218Z","shell.execute_reply.started":"2024-05-22T09:50:07.589378Z","shell.execute_reply":"2024-05-22T09:50:09.933185Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(1115394,) int32\n[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n  0 37 53 59  1 39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39\n 58 46 43 56  1 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47\n 57 46 12  0  0 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53\n 50 60 43 42  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47\n 56 57 58  6  1 63 53 59  1 49 52 53 61  1 15 39 47 59 57  1 25 39 56 41\n 47 59 57  1 47 57  1 41 46 47 43 44  1 43 52 43 51 63  1 58 53  1 58 46\n 43  1 54 43 53 54 50 43  8  0  0 13 50 50 10  0 35 43  1 49 52 53 61  5\n 58  6  1 61 43  1 49 52 53 61  5 58  8  0  0 18 47 56 57 58  1 15 47 58\n 47 64 43 52 10  0 24 43 58  1 59 57  1 49 47 50 50  1 46 47 51  6  1 39\n 52 42  1 61 43  5 50 50  1 46 39 60 43  1 41 53 56 52  1 39 58  1 53 59\n 56  1 53 61 52  1 54 56 47 41 43  8  0 21 57  5 58  1 39  1 60 43 56 42\n 47 41 58 12  0  0 13 50 50 10  0 26 53  1 51 53 56 43  1 58 39 50 49 47\n 52 45  1 53 52  5 58 11  1 50 43 58  1 47 58  1 40 43  1 42 53 52 43 10\n  1 39 61 39 63  6  1 39 61 39 63  2  0  0 31 43 41 53 52 42  1 15 47 58\n 47 64 43 52 10  0 27 52 43  1 61 53 56 42  6  1 45 53 53 42  1 41 47 58\n 47 64 43 52 57  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 35\n 43  1 39 56 43  1 39 41 41 53 59 52 58 43 42  1 54 53 53 56  1 41 47 58\n 47 64 43 52 57  6  1 58 46 43  1 54 39 58 56 47 41 47 39 52 57  1 45 53\n 53 42  8  0 35 46 39 58  1 39 59 58 46 53 56 47 58 63  1 57 59 56 44 43\n 47 58 57  1 53 52  1 61 53 59 50 42  1 56 43 50 47 43 60 43  1 59 57 10\n  1 47 44  1 58 46 43 63  0 61 53 59 50 42  1 63 47 43 50 42  1 59 57  1\n 40 59 58  1 58 46 43  1 57 59 54 43 56 44 50 59 47 58 63  6  1 61 46 47\n 50 43  1 47 58  1 61 43 56 43  0 61 46 53 50 43 57 53 51 43  6  1 61 43\n  1 51 47 45 46 58  1 45 59 43 57 57  1 58 46 43 63  1 56 43 50 47 43 60\n 43 42  1 59 57  1 46 59 51 39 52 43 50 63 11  0 40 59 58  1 58 46 43 63\n  1 58 46 47 52 49  1 61 43  1 39 56 43  1 58 53 53  1 42 43 39 56 10  1\n 58 46 43  1 50 43 39 52 52 43 57 57  1 58 46 39 58  0 39 44 44 50 47 41\n 58 57  1 59 57  6  1 58 46 43  1 53 40 48 43 41 58  1 53 44  1 53 59 56\n  1 51 47 57 43 56 63  6  1 47 57  1 39 57  1 39 52  0 47 52 60 43 52 58\n 53 56 63  1 58 53  1 54 39 56 58 47 41 59 50 39 56 47 57 43  1 58 46 43\n 47 56  1 39 40 59 52 42 39 52 41 43 11  1 53 59 56  0 57 59 44 44 43 56\n 39 52 41 43  1 47 57  1 39  1 45 39 47 52  1 58 53  1 58 46 43 51  1 24\n 43 58  1 59 57  1 56 43 60 43 52 45 43  1 58 46 47 57  1 61 47 58 46  0\n 53 59 56  1 54 47 49 43 57  6  1 43 56 43  1 61 43  1 40 43 41 53 51 43\n  1 56 39 49 43 57 10  1 44 53 56  1 58 46 43  1 45 53 42 57  1 49 52 53\n 61  1 21  0 57 54 43 39 49  1 58 46 47 57  1 47 52  1 46 59 52 45 43 56\n  1 44 53 56  1 40 56 43 39 42  6  1 52 53 58  1 47 52  1 58 46 47 56 57\n 58  1 44 53 56  1 56 43 60 43 52 45 43  8  0  0]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_test_split = 0.9\nn = int(train_test_split*len(data))\ntrain_data = data[:n]\ntest_data = data[n:]","metadata":{"id":"pXrAqMxRHFyj","execution":{"iopub.status.busy":"2024-05-22T09:50:09.935250Z","iopub.execute_input":"2024-05-22T09:50:09.935529Z","iopub.status.idle":"2024-05-22T09:50:10.089351Z","shell.execute_reply.started":"2024-05-22T09:50:09.935504Z","shell.execute_reply":"2024-05-22T09:50:10.088222Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"block_size = 8\ntrain_data[:block_size+1]","metadata":{"id":"ahhKyiAzHFyj","outputId":"98306c96-5082-4dfa-ba66-915051831fc8","execution":{"iopub.status.busy":"2024-05-22T09:50:10.091251Z","iopub.execute_input":"2024-05-22T09:50:10.091541Z","iopub.status.idle":"2024-05-22T09:50:10.175137Z","shell.execute_reply.started":"2024-05-22T09:50:10.091515Z","shell.execute_reply":"2024-05-22T09:50:10.174167Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Array([18, 47, 56, 57, 58,  1, 15, 47, 58], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target: {target}\")","metadata":{"id":"HIpsznQmHFyk","outputId":"be9d197b-0b79-43ed-f3a9-e74295d51c79","execution":{"iopub.status.busy":"2024-05-22T09:50:10.176386Z","iopub.execute_input":"2024-05-22T09:50:10.176689Z","iopub.status.idle":"2024-05-22T09:50:10.792522Z","shell.execute_reply.started":"2024-05-22T09:50:10.176663Z","shell.execute_reply":"2024-05-22T09:50:10.791564Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"when input is [18] the target: 47\nwhen input is [18 47] the target: 56\nwhen input is [18 47 56] the target: 57\nwhen input is [18 47 56 57] the target: 58\nwhen input is [18 47 56 57 58] the target: 1\nwhen input is [18 47 56 57 58  1] the target: 15\nwhen input is [18 47 56 57 58  1 15] the target: 47\nwhen input is [18 47 56 57 58  1 15 47] the target: 58\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 128 # how many independent sequences will we process in parallel?\nblock_size = 64 # what is the maximum context length for predictions?\nmax_iters = 1000\nlearning_rate = 5e-4\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 100\nn_embd = 256\nexpans = 2\nn_heads = 1\nchannel_size = n_embd // n_heads\nn_layers = 4\ndropout = 0.2\nconv_k_size = 3\nn_latent_dim = 16\n\nrng_key = jax.random.PRNGKey(1564)\n\ndynamic_slice_vmap = jax.vmap(jax.lax.dynamic_slice, in_axes=(None, 0, None))\n\n@jax.jit\ndef get_batch(random_key, data):\n    \"\"\"Prepares a random batch of training data.\n\n    Args:\n      random_key: A random seed for sampling a batch.\n      data: The complete training dataset.\n\n    Returns:\n      x: Input sequences.\n      y: Target sequences (shifted inputs).\n    \"\"\"\n    ix = jax.random.randint(\n      random_key, shape=(batch_size, 1), minval=0, maxval=len(data) - block_size\n    )\n    x = dynamic_slice_vmap(data, ix, (block_size,))\n    y = dynamic_slice_vmap(data, ix + 1, (block_size,))\n    return x, y\n\nxb, yb = get_batch(rng_key, train_data)\ntrain_shape = xb.shape\nprint('inputs:')\nprint(xb.shape)\nprint(xb)\nprint('targets:')\nprint(yb.shape)\nprint(yb)\n\n# print('----')\n\n# for b in range(batch_size): # batch dimension\n#     for t in range(block_size): # time dimension\n#         context = xb[b, :t+1]\n#         target = yb[b,t]\n#         print(f\"when input is {context} the target: {target}\")","metadata":{"id":"UuAjtqPeHFyk","outputId":"6a88fb2b-b798-4ee9-9f4f-f38ce898d576","execution":{"iopub.status.busy":"2024-05-22T09:50:10.794055Z","iopub.execute_input":"2024-05-22T09:50:10.794410Z","iopub.status.idle":"2024-05-22T09:50:11.116378Z","shell.execute_reply.started":"2024-05-22T09:50:10.794380Z","shell.execute_reply":"2024-05-22T09:50:11.115325Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"inputs:\n(64, 256)\n[[63  1 49 ... 59 58 46]\n [57  0 13 ... 43 45  1]\n [58  1 58 ... 58 53  1]\n ...\n [53 59 40 ... 53 56 42]\n [47 56 57 ... 54 10  5]\n [ 1 21  1 ... 27 10  0]]\ntargets:\n(64, 256)\n[[ 1 49 52 ... 58 46  6]\n [ 0 13 56 ... 45  1 53]\n [ 1 58 53 ... 53  1 44]\n ...\n [59 40 58 ... 56 42 10]\n [56 57 58 ... 10  5  1]\n [21  1 44 ... 10  0 19]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Mamba Block\nDense --> Conv1D --> Silu --> SSM --> Silu -->","metadata":{"id":"yOccqzJlHFym"}},{"cell_type":"code","source":"hidden_state = [jnp.zeros((1,n_latent_dim, n_embd * expans)) for _ in range(n_layers)]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:50:11.117860Z","iopub.execute_input":"2024-05-22T09:50:11.118174Z","iopub.status.idle":"2024-05-22T09:50:11.212020Z","shell.execute_reply.started":"2024-05-22T09:50:11.118136Z","shell.execute_reply":"2024-05-22T09:50:11.211216Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"hidden_state[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:50:11.213089Z","iopub.execute_input":"2024-05-22T09:50:11.213397Z","iopub.status.idle":"2024-05-22T09:50:11.219431Z","shell.execute_reply.started":"2024-05-22T09:50:11.213372Z","shell.execute_reply":"2024-05-22T09:50:11.218406Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(1, 16, 768)"},"metadata":{}}]},{"cell_type":"code","source":"class Mamba(nn.Module):\n\n    def setup(self):\n        emb_features = n_embd * expans\n        self.in_proj1 = nn.Dense(features=emb_features)\n        self.in_proj2 = nn.Dense(features=emb_features)\n\n        # Adjusted for Flax. Flax does not have nn.Conv1d, so you might need to reshape or use a different approach\n        self.conv1d = nn.Conv(features=emb_features,\n                              kernel_size=conv_k_size,\n                              padding=1,\n                              )\n\n        self.A = -1*self.param('A', nn.initializers.ones, (1, n_latent_dim, emb_features, 1))\n        self.B = 0.1*self.param('B', nn.initializers.ones, (1, n_latent_dim, 1, block_size))\n        self.C = self.param('C', jax.random.normal, (1, n_latent_dim, 1, block_size))\n#         self.D = self.param('D', jax.random.normal, (1, self.args.d_state, self.args.d_model, 1))\n        self.delta = self.param('delta', jax.random.normal, (1, 1,emb_features, block_size))\n\n        self.out_proj = nn.Dense(n_embd // n_heads)\n        \n        self.hidden_state = self.variable('other_variables','hidden_state', \n                                          jnp.zeros, \n                                          (1,n_latent_dim, emb_features))\n        self.rms_norm = nn.RMSNorm()\n\n    def __call__(self, embeds):\n        x = self.in_proj1(embeds)\n        x = self.conv1d(x)\n        x = jax.nn.silu(x)\n        x = x.reshape((x.shape[0],1,x.shape[2],x.shape[1]))\n        x = self.ssm(x)\n        x = x.reshape((x.shape[0],x.shape[3],x.shape[2]))\n        x = x*jax.nn.silu(self.in_proj2(embeds))\n\n        x = self.out_proj(x)\n\n        x = self.rms_norm(x)\n\n        return x\n    def discretize(self):\n        da = self.delta * self.A\n        a_ = jnp.exp(da)\n        b_ = self.B * self.delta\n        return a_, b_\n\n    def ssm(self, x):\n        y = []\n        a_, b_ = self.discretize()\n        for k in range(x.shape[-1]):\n            h = a_[..., k] * self.hidden_state.value + b_[..., k] * x[..., k]\n            y.append((self.C[..., k] * h).sum(1, keepdims=True))     \n        \n        self.hidden_state.value = jax.nn.standardize(h.mean(0, keepdims=True))\n        return jnp.stack(y, -1)","metadata":{"id":"4qOdblU5HFyo","execution":{"iopub.status.busy":"2024-05-22T09:50:11.220903Z","iopub.execute_input":"2024-05-22T09:50:11.221280Z","iopub.status.idle":"2024-05-22T09:50:11.242777Z","shell.execute_reply.started":"2024-05-22T09:50:11.221246Z","shell.execute_reply":"2024-05-22T09:50:11.241663Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# class MultiHeadMamba(nn.Module):\n#     def setup(self):\n#         self.layernorm\n#         self.heads = [Mamba() for _ in range(n_heads)]\n#         self.rms_norm = nn.RMSNorm()\n\n#     def __call__(self, x):\n#         out = jnp.concatenate([h(x) for h in self.heads], axis=-1)\n#         x = self.rms_norm(out)\n#         return x","metadata":{"id":"0bH9vlLZHFyq","execution":{"iopub.status.busy":"2024-05-22T09:50:11.244229Z","iopub.execute_input":"2024-05-22T09:50:11.244493Z","iopub.status.idle":"2024-05-22T09:50:11.255326Z","shell.execute_reply.started":"2024-05-22T09:50:11.244470Z","shell.execute_reply":"2024-05-22T09:50:11.254381Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# class FeedForward(nn.Module):\n#     def setup(self):\n#         self.ffn = nn.Sequential([\n#             nn.Dense(4 * n_embd),\n#             nn.relu,\n#             nn.Dense(n_embd)]\n#         )\n#     def __call__(self, x):\n#         return self.ffn(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:50:11.260322Z","iopub.execute_input":"2024-05-22T09:50:11.260587Z","iopub.status.idle":"2024-05-22T09:50:11.267752Z","shell.execute_reply.started":"2024-05-22T09:50:11.260564Z","shell.execute_reply":"2024-05-22T09:50:11.266824Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# class MambaBlock(nn.Module):\n#     def setup(self):\n#         self.mamba_block = Mamba()\n#         self.ln1 = nn.RMSNorm()\n#         self.ffn = FeedForward()\n#         self.ln2 = nn.LayerNorm()\n\n#     def __call__(self, x):\n#         x = x + self.mamba_block(self.ln2(x))\n#         x = x + self.ffn(self.ln1(x))\n#         return x\n","metadata":{"id":"UiCxIjoEp2QA","execution":{"iopub.status.busy":"2024-05-22T09:50:11.268903Z","iopub.execute_input":"2024-05-22T09:50:11.269221Z","iopub.status.idle":"2024-05-22T09:50:11.276959Z","shell.execute_reply.started":"2024-05-22T09:50:11.269196Z","shell.execute_reply":"2024-05-22T09:50:11.275946Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# class MambaModel(nn.Module):\n\n#     def setup(self):\n#         self.tok_embeddings = nn.Embed(vocab_size, n_embd)\n#         self.pos_embeddings = nn.Embed(block_size, n_embd)\n#         self.ln = nn.LayerNorm()\n#         self.mamba_layers = [MambaBlock() for _ in range(n_layers)]\n#         self.preds_out = nn.Dense(vocab_size)\n\n#     def __call__(self, x, training: bool):\n#         x = self.tok_embeddings(x) + self.pos_embeddings(jnp.arange(block_size))\n# #         x = self.ln(x)\n#         for layer in self.mamba_layers:\n#             x = layer(x)\n            \n#         return self.preds_out(x)\n\n#     @jax.jit\n#     def generate(self, idx, max_new_tokens, params):\n#     # idx is (B, T) array of indices in the current context\n#         for _ in range(max_new_tokens):\n#             # crop idx to the last block_size tokens\n#             idx_cond = idx[:, -block_size:]\n#             # get the predictions\n#             logits = self.apply(params, idx_cond)\n#             # focus only on the last time step\n#             logits = logits[:, -1, :] # becomes (B, C)\n#             # apply softmax to get probabilities\n#             ##probs = tf.keras.activations.softmax(logits, dim=-1) # (B, C)\n#             # sample from the distribution\n#             idx_next = jax.random.categorical(jax.random.PRNGKey(52), logits) # (B, 1)\n#             # append sampled index to the running sequence\n#             idx = jax.numpy.expand_dims(jnp.concatenate([idx[0], idx_next], axis=0), 0) # (B, T+1)\n#     #         print(idx_next)\n#     #         print(idx)\n\n#         return idx","metadata":{"id":"y4C7OWL8HFyq","execution":{"iopub.status.busy":"2024-05-22T09:50:11.278132Z","iopub.execute_input":"2024-05-22T09:50:11.278444Z","iopub.status.idle":"2024-05-22T09:50:11.286987Z","shell.execute_reply.started":"2024-05-22T09:50:11.278421Z","shell.execute_reply":"2024-05-22T09:50:11.286130Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# model = Mamba()\n# params = model.init(jax.random.key(42), jnp.ones((1,64,256)))\n# # print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# # print(model.tabulate(jax.random.key(0), jnp.ones((1,64,256)),\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xs = model.apply(params, jnp.ones((1,64,256)), mutable=['other_variables'])\n# # # print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# xb.shape, xs[0].shape, xs[1].keys()","metadata":{"id":"wTd3jSQWHFyp","execution":{"iopub.status.busy":"2024-05-22T09:50:11.287968Z","iopub.execute_input":"2024-05-22T09:50:11.288253Z","iopub.status.idle":"2024-05-22T09:50:11.299354Z","shell.execute_reply.started":"2024-05-22T09:50:11.288225Z","shell.execute_reply":"2024-05-22T09:50:11.298442Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# print(xs[1]['other_variables']['hidden_state'].shape, xs[1]['other_variables']['hidden_state'].min(), xs[1]['other_variables']['hidden_state'].max())","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:50:11.300444Z","iopub.execute_input":"2024-05-22T09:50:11.300718Z","iopub.status.idle":"2024-05-22T09:50:11.311809Z","shell.execute_reply.started":"2024-05-22T09:50:11.300685Z","shell.execute_reply":"2024-05-22T09:50:11.310891Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# xfs = model.apply(params, 2*jnp.ones((1,64,256)), mutable=['other_variables'])\n# print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# print(xfs[1]['other_variables']['hidden_state'].shape, xfs[1]['other_variables']['hidden_state'].min(), xfs[1]['other_variables']['hidden_state'].max())","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:50:11.312873Z","iopub.execute_input":"2024-05-22T09:50:11.313133Z","iopub.status.idle":"2024-05-22T09:50:11.321095Z","shell.execute_reply.started":"2024-05-22T09:50:11.313104Z","shell.execute_reply":"2024-05-22T09:50:11.320274Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# test_model = Mamba()\n# test_params = test_model.init(jax.random.key(42), xb)\n# n_params = sum(p.size for p in jax.tree_util.tree_leaves(test_params))\n# print(f\"Total number of parameters: {n_params:_}\")\n# # print(fin_model.tabulate(jax.random.key(42), xb,\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xf = test_model.apply(test_params, xb)\n# xb.shape, xf.shape","metadata":{"id":"cm2a0nepHFyq","execution":{"iopub.status.busy":"2024-05-22T09:50:11.322338Z","iopub.execute_input":"2024-05-22T09:50:11.322604Z","iopub.status.idle":"2024-05-22T09:50:11.330236Z","shell.execute_reply.started":"2024-05-22T09:50:11.322582Z","shell.execute_reply":"2024-05-22T09:50:11.329331Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class NanoLM(nn.Module):\n    \"\"\"NanoLM model.\"\"\"\n    vocab_size: int = 65\n    num_layers: int = 6\n    num_heads: int = 8\n    head_size: int = 32\n    dropout_rate: float = 0.2\n    embed_size: int = 256\n    block_size: int = 64\n\n    @nn.compact\n    def __call__(self, x, training: bool):\n        x = nn.Embed(self.vocab_size, self.embed_size)(x) + nn.Embed(\n            self.block_size, self.embed_size\n        )(jnp.arange(self.block_size))\n        \n        for i in range(self.num_layers):\n            x_norm = nn.LayerNorm()(x)\n#             x = x + nn.MultiHeadDotProductAttention(\n#               num_heads=self.num_heads,\n#               qkv_features=self.head_size,\n#               out_features=self.head_size * self.num_heads,\n#               dropout_rate=self.dropout_rate,\n#             )(\n#               x_norm,\n#               x_norm,\n#               mask=jnp.tril(jnp.ones((x.shape[-2], x.shape[-2]))),\n#               deterministic=not training,\n#             )\n            x_mamba = Mamba()(x_norm)\n    \n            x = x + x_mamba\n\n            x = x + nn.Sequential([\n              nn.Dense(4 * self.embed_size),\n              nn.relu,\n              nn.Dropout(self.dropout_rate, deterministic=not training),\n              nn.Dense(self.embed_size),\n            ])(nn.LayerNorm()(x))\n\n        x = nn.LayerNorm()(x)\n        return nn.Dense(self.vocab_size)(x)","metadata":{"id":"zuiaFP6WHFyr","execution":{"iopub.status.busy":"2024-05-22T09:50:11.331578Z","iopub.execute_input":"2024-05-22T09:50:11.331842Z","iopub.status.idle":"2024-05-22T09:50:11.342438Z","shell.execute_reply.started":"2024-05-22T09:50:11.331819Z","shell.execute_reply":"2024-05-22T09:50:11.341307Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# key = jax.random.key(42)\n\n# # fin_model = MambaModel()\n# # fin_params = fin_model.init(key, xb, training=False)\n\n\n# fin_model = NanoLM(\n#     vocab_size=vocab_size,\n#     num_layers=n_layers,\n#     num_heads=8,\n#     head_size=32,\n#     dropout_rate=0.2,\n#     embed_size=n_embd,\n#     block_size=block_size,\n# )\n\n# fin_params = fin_model.init(\n#     {'params': key},\n#     jnp.ones((batch_size, block_size), dtype=jnp.int32),\n#     training=False\n# )\n\n# n_params = sum(p.size for p in jax.tree_util.tree_leaves(fin_params))\n# print(f\"Total number of parameters: {n_params:_}\")\n# # print(fin_model.tabulate(jax.random.key(42), xb,\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xf = fin_model.apply(fin_params, xb, training=False)[0]\n# xb.shape, xf.shape","metadata":{"id":"fnUQPyuvHFys","outputId":"f04ebf31-d67f-4488-dd5d-7fd5b20dd1ea","execution":{"iopub.status.busy":"2024-05-22T09:50:11.343363Z","iopub.execute_input":"2024-05-22T09:50:11.343617Z","iopub.status.idle":"2024-05-22T09:50:11.355713Z","shell.execute_reply.started":"2024-05-22T09:50:11.343589Z","shell.execute_reply":"2024-05-22T09:50:11.354897Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def loss_fun(params, x, y, var_params,dropout_key):\n    logits, updated_variables = model.apply({'params': params, **var_params}, x, training=True, rngs={\"dropout\": dropout_key}, mutable=['other_variables'])\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), (updated_variables, accuracy)\n\n@jax.jit\ndef eval_step(params, x, y, var_params):\n    logits, _ = model.apply({'params': params, **var_params}, x, training=False, mutable=['other_variables'])\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), accuracy","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:50:11.356853Z","iopub.execute_input":"2024-05-22T09:50:11.357150Z","iopub.status.idle":"2024-05-22T09:50:11.369031Z","shell.execute_reply.started":"2024-05-22T09:50:11.357126Z","shell.execute_reply":"2024-05-22T09:50:11.368130Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"key = jax.random.PRNGKey(42)\nkey, subkey = jax.random.split(key)\n\nmodel = NanoLM(\n    vocab_size=vocab_size,\n    num_layers=n_layers,\n    num_heads=8,\n    head_size=32,\n    dropout_rate=0.2,\n    embed_size=n_embd,\n    block_size=block_size,\n)\n\nvar_params = model.init(\n    key,\n    jnp.ones((batch_size, block_size), dtype=jnp.int32),\n    training=False,\n)\nprint(var_params.keys())\nn_params = sum(p.size for p in jax.tree_util.tree_leaves(var_params))\n\nprint(f\"Total number of parameters: {n_params:_}\")","metadata":{"id":"PKpb3864HFyt","execution":{"iopub.status.busy":"2024-05-22T09:50:11.370144Z","iopub.execute_input":"2024-05-22T09:50:11.370450Z","iopub.status.idle":"2024-05-22T09:50:22.447957Z","shell.execute_reply.started":"2024-05-22T09:50:11.370427Z","shell.execute_reply":"2024-05-22T09:50:22.446958Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"dict_keys(['params', 'other_variables'])\nTotal number of parameters: 8_288_577\n","output_type":"stream"}]},{"cell_type":"code","source":"params = var_params.pop('params')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:50:22.449739Z","iopub.execute_input":"2024-05-22T09:50:22.450299Z","iopub.status.idle":"2024-05-22T09:50:22.454819Z","shell.execute_reply.started":"2024-05-22T09:50:22.450262Z","shell.execute_reply":"2024-05-22T09:50:22.453951Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"var_params = jax.tree_map(lambda x: jnp.zeros_like(x), var_params)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:50:22.456375Z","iopub.execute_input":"2024-05-22T09:50:22.456955Z","iopub.status.idle":"2024-05-22T09:50:22.470030Z","shell.execute_reply.started":"2024-05-22T09:50:22.456920Z","shell.execute_reply":"2024-05-22T09:50:22.469090Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"opt = optax.adamw(learning_rate=learning_rate)\n\nopt_state = opt.init(params)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:50:22.471279Z","iopub.execute_input":"2024-05-22T09:50:22.471621Z","iopub.status.idle":"2024-05-22T09:50:22.911100Z","shell.execute_reply.started":"2024-05-22T09:50:22.471589Z","shell.execute_reply":"2024-05-22T09:50:22.910092Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"%%time\n\nall_train_losses = []\nall_eval_losses = []\n\nall_train_accuracy =  []\nall_test_accuracy = []\n\n# we define one iteration of the optimizer and JIT this function\n@jax.jit\ndef step(key, params, var_params, opt_state):\n    key, subkey = jax.random.split(key)\n    xb, yb = get_batch(key, train_data)\n    (loss, aux_data), grad = jax.value_and_grad(loss_fun, has_aux=True)(params, xb, yb, var_params, subkey)\n    var_params, train_accuracy = aux_data\n    updates, opt_state = opt.update(grad, opt_state, params)\n    params = optax.apply_updates(params, updates)\n    return params, key, opt_state, loss, var_params, train_accuracy\n\nfor i in tqdm(range(max_iters)):\n\n    params, key, opt_state, loss, var_params, train_accuracy = step(key, params, var_params, opt_state)\n    \n\n    # once every N_FREQ_EVAL we compute loss on the validation set\n    if i % eval_iters == 0:\n        key, subkey = jax.random.split(key)\n        eval_loss, eval_accuracy = eval_step(params, *get_batch(subkey, test_data), var_params)\n        all_train_losses.append(loss)\n        all_eval_losses.append(eval_loss)\n        all_train_accuracy.append(train_accuracy)\n        all_test_accuracy.append(eval_accuracy)\n        print(f\"Step: {i}\\t train loss: {loss}\\t eval loss: {eval_loss}\")\n        print(f\"Step: {i}\\t train accuracy: {train_accuracy}\\t eval accuracy: {eval_accuracy}\")\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:50:22.912322Z","iopub.execute_input":"2024-05-22T09:50:22.912613Z","iopub.status.idle":"2024-05-22T09:57:04.698244Z","shell.execute_reply.started":"2024-05-22T09:50:22.912586Z","shell.execute_reply":"2024-05-22T09:57:04.696822Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"  0%|          | 0/1000 [00:00<?, ?it/s]2024-05-22 09:51:07.283216: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[64,768,256]{2,1,0}, u8[0]{0}) custom-call(f32[64,768,256]{2,1,0}, f32[768,768,3]{2,1,0}), window={size=3 pad=1_1}, dim_labels=bf0_oi0->bf0, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-05-22 09:51:07.813842: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.530810914s\nTrying algorithm eng0{} for conv (f32[64,768,256]{2,1,0}, u8[0]{0}) custom-call(f32[64,768,256]{2,1,0}, f32[768,768,3]{2,1,0}), window={size=3 pad=1_1}, dim_labels=bf0_oi0->bf0, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n  0%|          | 1/1000 [02:37<43:47:36, 157.81s/it]","output_type":"stream"},{"name":"stdout","text":"Step: 0\t train loss: 4.606764316558838\t eval loss: 3.948723316192627\nStep: 0\t train accuracy: 0.0147705078125\t eval accuracy: 0.12933349609375\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 101/1000 [03:02<10:19,  1.45it/s]  ","output_type":"stream"},{"name":"stdout","text":"Step: 100\t train loss: 0.020649179816246033\t eval loss: 0.0187660101801157\nStep: 100\t train accuracy: 0.99609375\t eval accuracy: 0.9962158203125\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 201/1000 [03:26<09:09,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Step: 200\t train loss: 0.012719116173684597\t eval loss: 0.011734808795154095\nStep: 200\t train accuracy: 0.99676513671875\t eval accuracy: 0.99737548828125\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 301/1000 [03:51<08:00,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Step: 300\t train loss: 0.010982471518218517\t eval loss: 0.010319935157895088\nStep: 300\t train accuracy: 0.9969482421875\t eval accuracy: 0.9971923828125\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 401/1000 [04:16<06:53,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Step: 400\t train loss: 0.010300607420504093\t eval loss: 0.009193019941449165\nStep: 400\t train accuracy: 0.9969482421875\t eval accuracy: 0.99786376953125\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 501/1000 [04:40<05:43,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Step: 500\t train loss: 0.010094580240547657\t eval loss: 0.009157761000096798\nStep: 500\t train accuracy: 0.9969482421875\t eval accuracy: 0.99737548828125\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 601/1000 [05:05<04:35,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Step: 600\t train loss: 0.009972636587917805\t eval loss: 0.008674390614032745\nStep: 600\t train accuracy: 0.9970703125\t eval accuracy: 0.99749755859375\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 701/1000 [05:29<03:26,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Step: 700\t train loss: 0.009942932985723019\t eval loss: 0.009607291780412197\nStep: 700\t train accuracy: 0.99755859375\t eval accuracy: 0.99737548828125\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 801/1000 [05:54<02:16,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Step: 800\t train loss: 0.00893580261617899\t eval loss: 0.008704669773578644\nStep: 800\t train accuracy: 0.99755859375\t eval accuracy: 0.9974365234375\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 901/1000 [06:18<01:08,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Step: 900\t train loss: 0.009074140340089798\t eval loss: 0.008442873135209084\nStep: 900\t train accuracy: 0.9974365234375\t eval accuracy: 0.997314453125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1000/1000 [06:41<00:00,  2.49it/s]","output_type":"stream"},{"name":"stdout","text":"CPU times: user 4min 54s, sys: 1min 41s, total: 6min 36s\nWall time: 6min 41s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt  # Visualization\n\n# Plot loss and accuracy in subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.set_title('Loss')\nax2.set_title('Accuracy')\n\n\n\nax1.plot(all_train_losses, label='train_loss')\nax1.plot(all_eval_losses[f'{dataset}_accuracy'], label='eval_loss')\n\nax2.plot(all_train_accuracy, label='train_accuracy')\nax2.plot(all_test_accuracy[f'{dataset}_accuracy'], label='eval_accuracy')\n\nax1.legend()\nax2.legend()\nplt.show()\nplt.clf()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@partial(jax.jit, static_argnames=(\"length\"))\ndef generate_text(rng, params, var_params, length):\n    def _scan_generate(carry, _):\n        random_key, context = carry\n        logits = model.apply({'params': params, **var_params}, context, training=False, mutable=['other_variables'])[0]\n        rng, rng_subkey = jax.random.split(random_key)\n        new_token = jax.random.categorical(\n          rng_subkey, logits[:, -1, :], axis=-1, shape=(1, 1)\n        )\n        context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n        return (rng, context), new_token\n\n    _, new_tokens = jax.lax.scan(\n    _scan_generate,\n    (rng, jnp.zeros((1, block_size), dtype=jnp.int32)),\n    (),\n    length=length,\n    )\n    return new_tokens","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:00:18.842867Z","iopub.execute_input":"2024-05-22T10:00:18.843268Z","iopub.status.idle":"2024-05-22T10:00:18.852027Z","shell.execute_reply.started":"2024-05-22T10:00:18.843234Z","shell.execute_reply":"2024-05-22T10:00:18.851073Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"new_tokenz = 1000\nkey, subkey = jax.random.split(jax.random.PRNGKey(156))\n# key, subkey = jax.random.split(key)\n# token_gen = generate_text(jnp.zeros((1,block_size)).astype(jnp.int32), new_tokenz, {'params': state.params})\ntoken_gen = generate_text(key, params, var_params, new_tokenz)[:, 0, 0].tolist()\nprint(token_gen)\nprint(decode(token_gen))","metadata":{"execution":{"iopub.status.busy":"2024-05-22T10:00:52.799881Z","iopub.execute_input":"2024-05-22T10:00:52.800286Z","iopub.status.idle":"2024-05-22T10:01:21.000529Z","shell.execute_reply.started":"2024-05-22T10:00:52.800252Z","shell.execute_reply":"2024-05-22T10:01:20.999504Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"[24, 39, 47, 50, 50, 1, 51, 47, 58, 43, 61, 53, 50, 52, 1, 57, 47, 42, 1, 57, 63, 1, 60, 47, 60, 43, 56, 43, 57, 57, 1, 50, 59, 58, 46, 0, 13, 58, 57, 6, 0, 30, 21, 13, 26, 19, 17, 10, 0, 32, 46, 43, 43, 44, 58, 6, 1, 58, 53, 1, 58, 46, 63, 10, 0, 32, 46, 63, 8, 0, 0, 24, 53, 61, 6, 0, 16, 33, 17, 26, 53, 61, 58, 0, 25, 63, 1, 47, 58, 41, 46, 39, 60, 43, 0, 46, 43, 56, 50, 47, 56, 57, 43, 50, 50, 1, 39, 57, 1, 40, 53, 51, 43, 1, 58, 53, 1, 58, 46, 43, 1, 40, 46, 52, 1, 63, 39, 59, 54, 43, 43, 43, 57, 1, 63, 53, 59, 57, 6, 0, 18, 53, 49, 1, 46, 39, 60, 43, 8, 0, 31, 10, 0, 26, 59, 58, 1, 57, 39, 60, 47, 52, 42, 57, 8, 0, 0, 18, 39, 63, 6, 1, 51, 63, 1, 46, 39, 42, 57, 43, 56, 52, 45, 57, 43, 42, 1, 40, 59, 58, 43, 57, 43, 63, 1, 51, 39, 56, 42, 57, 47, 52, 45, 57, 1, 61, 47, 58, 46, 1, 46, 43, 39, 58, 43, 42, 6, 1, 44, 53, 56, 60, 47, 43, 1, 58, 53, 43, 8, 0, 0, 34, 27, 20, 27, 26, 13, 27, 26, 32, 17, 10, 0, 33, 57, 58, 1, 45, 53, 39, 42, 1, 57, 58, 46, 59, 57, 1, 59, 47, 51, 42, 6, 1, 52, 53, 58, 1, 54, 56, 43, 57, 1, 58, 46, 1, 58, 46, 39, 56, 58, 1, 58, 46, 43, 56, 43, 39, 58, 1, 57, 47, 45, 52, 53, 58, 1, 40, 39, 56, 56, 63, 8, 0, 0, 24, 17, 26, 21, 10, 0, 25, 20, 24, 27, 33, 15, 10, 0, 21, 1, 37, 53, 63, 1, 42, 56, 47, 58, 46, 39, 51, 6, 0, 32, 53, 1, 50, 43, 43, 1, 58, 47, 56, 44, 21, 26, 19, 32, 17, 26, 17, 10, 0, 30, 27, 26, 17, 26, 17, 10, 0, 21, 1, 43, 6, 1, 46, 47, 51, 6, 1, 39, 51, 1, 39, 58, 58, 43, 63, 8, 0, 0, 19, 53, 8, 0, 0, 18, 53, 52, 12, 7, 51, 43, 1, 58, 56, 53, 40, 2, 1, 57, 58, 39, 63, 1, 63, 39, 57, 54, 43, 52, 42, 1, 39, 52, 42, 1, 21, 1, 1, 39, 51, 43, 6, 0, 26, 59, 45, 46, 52, 8, 0, 0, 21, 57, 8, 0, 0, 14, 59, 58, 43, 52, 1, 57, 63, 1, 51, 63, 6, 1, 50, 39, 47, 56, 1, 52, 39, 42, 10, 0, 20, 39, 49, 57, 6, 1, 56, 43, 1, 51, 63, 1, 57, 58, 6, 1, 59, 57, 51, 1, 56, 47, 53, 52, 57, 6, 0, 32, 46, 63, 1, 58, 46, 57, 51, 1, 51, 39, 57, 8, 0, 0, 23, 21, 17, 24, 1, 57, 46, 39, 52, 42, 57, 6, 0, 19, 56, 47, 47, 52, 1, 58, 46, 43, 52, 1, 63, 47, 58, 1, 63, 53, 59, 1, 58, 47, 51, 43, 56, 50, 63, 2, 0, 26, 53, 51, 6, 1, 39, 1, 57, 58, 1, 56, 47, 50, 6, 0, 32, 46, 43, 6, 1, 63, 53, 59, 45, 46, 58, 1, 57, 43, 58, 43, 56, 1, 39, 54, 43, 42, 57, 6, 1, 39, 52, 42, 43, 57, 39, 63, 1, 50, 39, 63, 6, 1, 58, 46, 56, 59, 58, 1, 39, 52, 54, 43, 44, 53, 56, 42, 57, 47, 56, 46, 47, 57, 1, 61, 43, 39, 58, 1, 57, 1, 57, 59, 43, 1, 39, 52, 1, 45, 47, 60, 43, 56, 43, 57, 1, 58, 46, 58, 5, 1, 54, 39, 57, 10, 0, 20, 39, 63, 8, 0, 0, 31, 46, 43, 45, 43, 57, 49, 47, 43, 57, 43, 58, 6, 0, 50, 43, 1, 57, 47, 58, 46, 56, 47, 57, 54, 53, 58, 1, 47, 57, 1, 30, 63, 1, 61, 52, 6, 1, 52, 53, 50, 42, 1, 57, 54, 43, 56, 1, 57, 46, 43, 39, 57, 43, 1, 51, 39, 56, 1, 63, 59, 1, 58, 53, 1, 41, 47, 43, 52, 8, 0, 0, 26, 59, 58, 1, 58, 46, 39, 51, 43, 52, 6, 1, 52, 53, 58, 44, 43, 57, 1, 32, 53, 1, 58, 46, 43, 56, 43, 43, 56, 42, 6, 1, 51, 39, 44, 44, 6, 0, 32, 46, 39, 44, 43, 8, 0, 0, 23, 21, 26, 17, 31, 10, 0, 31, 39, 59, 56, 51, 1, 57, 58, 43, 59, 58, 1, 46, 39, 58, 1, 42, 47, 56, 41, 46, 1, 46, 43, 1, 50, 39, 41, 43, 52, 45, 6, 1, 42, 39, 63, 8, 0, 28, 27, 26, 17, 0, 26, 59, 41, 46, 43, 8, 0, 26, 53, 58, 0, 13, 52, 1, 46, 43, 47, 53, 42, 1, 39, 52, 51, 47, 58, 53, 1, 57, 53, 51, 63, 1, 44, 39, 56, 42, 6, 1, 58, 46, 6, 1, 47, 57, 43, 56, 1, 57, 39, 39, 56, 58, 39, 50, 43, 58, 39, 56, 43, 44, 43, 6, 1, 39, 39, 58, 46, 1, 58, 61, 43, 57, 6, 1, 39, 1, 39, 52, 1, 41, 39, 58, 1, 46, 39, 50, 57, 1, 51, 39, 49, 43, 1, 40, 59, 58, 1, 46, 39, 50, 50, 1, 46, 47, 57, 1, 57, 39, 59, 56, 1, 63, 43, 58, 1, 57, 47, 50, 50, 1, 44, 53, 1, 61, 47, 58, 1, 32, 46, 63, 1, 51, 43, 1, 1, 58, 5, 43, 59, 41, 46, 53, 59, 56, 59, 51, 54, 43, 1, 51, 39, 63, 1, 63, 53, 59, 52, 58, 43, 61, 52, 1, 39, 44, 43, 42, 1, 57, 39, 63, 5, 57, 58, 1]\nLaill mitewoln sid sy viveress luth\nAts,\nRIANGE:\nTheeft, to thy:\nThy.\n\nLow,\nDUENowt\nMy itchave\nherlirsell as bome to the bhn yaupeees yous,\nFok have.\nS:\nNut savinds.\n\nFay, my hadserngsed butesey mardsings with heated, forvie toe.\n\nVOHONAONTE:\nUst goad sthus uimd, not pres th thart thereat signot barry.\n\nLENI:\nMHLOUC:\nI Yoy dritham,\nTo lee tirfINGTENE:\nRONENE:\nI e, him, am attey.\n\nGo.\n\nFon?-me trob! stay yaspend and I  ame,\nNughn.\n\nIs.\n\nButen sy my, lair nad:\nHaks, re my st, usm rions,\nThy thsm mas.\n\nKIEL shands,\nGriin then yit you timerly!\nNom, a st ril,\nThe, yought seter apeds, andesay lay, thrut anpefordsirhis weat s sue an giveres tht' pas:\nHay.\n\nShegeskieset,\nle sithrispot is Ry wn, nold sper shease mar yu to cien.\n\nNut thamen, notfes To thereerd, maff,\nThafe.\n\nKINES:\nSaurm steut hat dirch he laceng, day.\nPONE\nNuche.\nNot\nAn heiod anmito somy fard, th, iser saartaletarefe, aath twes, a an cat hals make but hall his saur yet sill fo wit Thy me  t'euchourumpe may yountewn afed say'st \n","output_type":"stream"}]},{"cell_type":"code","source":"dsfsdhfgjdg hfdgjdgjgfjhs'####################","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:57:04.699759Z","iopub.execute_input":"2024-05-22T09:57:04.700060Z","iopub.status.idle":"2024-05-22T09:57:04.710722Z","shell.execute_reply.started":"2024-05-22T09:57:04.700031Z","shell.execute_reply":"2024-05-22T09:57:04.707000Z"},"trusted":true},"execution_count":29,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[29], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    dsfsdhfgjdg hfdgjdgjgfjhs'####################\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"],"ename":"SyntaxError","evalue":"unterminated string literal (detected at line 1) (2630675753.py, line 1)","output_type":"error"}]},{"cell_type":"code","source":"jax.nn.standardize(jnp.array([2.0,3.0,4.0]))","metadata":{"id":"Oe_GIDP2HFyt","outputId":"5d3dce16-fcc2-40b9-c49a-00a8c4013ca2","execution":{"iopub.status.busy":"2024-05-22T09:57:04.712640Z","iopub.status.idle":"2024-05-22T09:57:04.714011Z","shell.execute_reply.started":"2024-05-22T09:57:04.713708Z","shell.execute_reply":"2024-05-22T09:57:04.713731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@struct.dataclass\nclass Metrics(metrics.Collection):\n    accuracy: metrics.Accuracy\n    loss: metrics.Average.from_output('loss')","metadata":{"id":"s3nN1jOiHFyu","execution":{"iopub.status.busy":"2024-05-22T09:57:04.715476Z","iopub.status.idle":"2024-05-22T09:57:04.715796Z","shell.execute_reply.started":"2024-05-22T09:57:04.715633Z","shell.execute_reply":"2024-05-22T09:57:04.715645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainState(train_state.TrainState):\n    metrics: Metrics\n\ndef create_train_state(module, rng, learning_rate, train_shape):\n    \"\"\"Creates an initial `TrainState`.\"\"\"\n    params = module.init(rng, jnp.ones(train_shape).astype(jnp.int32), \n                         training=False)['params'] # initialize parameters by passing a template image\n    tx = optax.adamw(learning_rate)\n    return TrainState.create(\n      apply_fn=module.apply, params=params, tx=tx,\n      metrics=Metrics.empty(),\n    )","metadata":{"id":"7LLDTSFQHFyu","execution":{"iopub.status.busy":"2024-05-22T09:57:04.717323Z","iopub.status.idle":"2024-05-22T09:57:04.718128Z","shell.execute_reply.started":"2024-05-22T09:57:04.717795Z","shell.execute_reply":"2024-05-22T09:57:04.717819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TrainState.create(","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:57:04.719552Z","iopub.status.idle":"2024-05-22T09:57:04.719892Z","shell.execute_reply.started":"2024-05-22T09:57:04.719721Z","shell.execute_reply":"2024-05-22T09:57:04.719736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@jax.jit\ndef train_step(state, inputs, targets):\n    \"\"\"Train for a single step.\"\"\"\n    def loss_fn(params):\n        logits = state.apply_fn({'params': params}, inputs, training=True, \n                                rngs={\"dropout\": key})[0]\n        loss = optax.softmax_cross_entropy_with_integer_labels(\n            logits=logits, labels=targets).mean()\n        return loss\n    grad_fn = jax.grad(loss_fn)\n    grads = grad_fn(state.params)\n    state = state.apply_gradients(grads=grads)\n    return state","metadata":{"id":"zApWXUDaHFyu","execution":{"iopub.status.busy":"2024-05-22T09:57:04.721528Z","iopub.status.idle":"2024-05-22T09:57:04.721920Z","shell.execute_reply.started":"2024-05-22T09:57:04.721735Z","shell.execute_reply":"2024-05-22T09:57:04.721751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@jax.jit\ndef compute_metrics(*, state, inputs, targets):\n    logits = state.apply_fn({'params': state.params}, inputs, training=False)[0]\n    loss = optax.softmax_cross_entropy_with_integer_labels(\n        logits=logits, labels=targets).mean()\n    metric_updates = state.metrics.single_from_model_output(\n    logits=logits, labels=targets, loss=loss)\n    metrics = state.metrics.merge(metric_updates)\n    state = state.replace(metrics=metrics)\n    return state","metadata":{"id":"VzukZ4iEHFyv","execution":{"iopub.status.busy":"2024-05-22T09:57:04.723343Z","iopub.status.idle":"2024-05-22T09:57:04.723727Z","shell.execute_reply.started":"2024-05-22T09:57:04.723558Z","shell.execute_reply":"2024-05-22T09:57:04.723572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nlearning_rate = 0.005\ninit_rng = jax.random.key(0)","metadata":{"id":"ehYvMeuNHFyv","execution":{"iopub.status.busy":"2024-05-22T09:57:04.724877Z","iopub.status.idle":"2024-05-22T09:57:04.725235Z","shell.execute_reply.started":"2024-05-22T09:57:04.725044Z","shell.execute_reply":"2024-05-22T09:57:04.725059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state = create_train_state(fin_model, init_rng, learning_rate, train_shape)\ndel init_rng  # Must not be used anymore.","metadata":{"id":"D60UHLFHHFyv","execution":{"iopub.status.busy":"2024-05-22T09:57:04.726331Z","iopub.status.idle":"2024-05-22T09:57:04.726675Z","shell.execute_reply.started":"2024-05-22T09:57:04.726505Z","shell.execute_reply":"2024-05-22T09:57:04.726525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics_history = {'train_loss': [],\n                   'train_accuracy': [],\n                   'test_loss': [],\n                   'test_accuracy': []}","metadata":{"id":"Jl-9TlHEHFyv","execution":{"iopub.status.busy":"2024-05-22T09:57:04.728105Z","iopub.status.idle":"2024-05-22T09:57:04.728554Z","shell.execute_reply.started":"2024-05-22T09:57:04.728373Z","shell.execute_reply":"2024-05-22T09:57:04.728392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 442\nkey = jax.random.PRNGKey(SEED)\nfor step in tqdm(range(max_iters)): # increase number of steps for good results...\n\n      # sample a batch of data\n    xb, yb = get_batch(key, train_data)\n    state = train_step(state, xb, yb)\n    state = compute_metrics(state=state, inputs=xb, targets=yb)\n\n    key = (jax.random.split(key)[0])\n\n    if step == 0 or (step+1) % 100 == 0: # one training epoch has passed\n        for metric,value in state.metrics.compute().items(): # compute metrics\n            metrics_history[f'train_{metric}'].append(value) # record metrics\n        state = state.replace(metrics=state.metrics.empty()) # reset train_metrics for next training epoch\n\n        # Compute metrics on the test set after each training epoch\n        test_state = state\n        x_test, y_test = get_batch(key, test_data)\n    #     for test_batch in test_ds.as_numpy_iterator():\n        test_state = compute_metrics(state=test_state, inputs=x_test, targets=y_test)\n\n        for metric,value in test_state.metrics.compute().items():\n            metrics_history[f'test_{metric}'].append(value)\n\n        print(f\"train epoch: {(step+1)}, \"\n              f\"loss: {metrics_history['train_loss'][-1]}, \"\n              f\"accuracy: {metrics_history['train_accuracy'][-1] * 100}\")\n        print(f\"test epoch: {(step+1) }, \"\n          f\"loss: {metrics_history['test_loss'][-1]}, \"\n          f\"accuracy: {metrics_history['test_accuracy'][-1] * 100}\")","metadata":{"id":"CaNt9JazHFyw","outputId":"ba447ddf-9940-44a6-f4b2-d27ed78a88c2","execution":{"iopub.status.busy":"2024-05-22T09:57:04.729832Z","iopub.status.idle":"2024-05-22T09:57:04.730193Z","shell.execute_reply.started":"2024-05-22T09:57:04.730002Z","shell.execute_reply":"2024-05-22T09:57:04.730017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt  # Visualization\n\n# Plot loss and accuracy in subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.set_title('Loss')\nax2.set_title('Accuracy')\nfor dataset in ('train','test'):\n    ax1.plot(metrics_history[f'{dataset}_loss'], label=f'{dataset}_loss')\n    ax2.plot(metrics_history[f'{dataset}_accuracy'], label=f'{dataset}_accuracy')\nax1.legend()\nax2.legend()\nplt.show()\nplt.clf()","metadata":{"id":"Y40JGx1YHFyw","execution":{"iopub.status.busy":"2024-05-22T09:57:04.731482Z","iopub.status.idle":"2024-05-22T09:57:04.731823Z","shell.execute_reply.started":"2024-05-22T09:57:04.731659Z","shell.execute_reply":"2024-05-22T09:57:04.731674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlogits = fin_model.apply(fin_params, xb, training=False)[0]\nloss = optax.softmax_cross_entropy_with_integer_labels(\n            logits=logits, labels=yb).mean()\n\nprint(loss)","metadata":{"id":"7pJlFXpVHFyw","execution":{"iopub.status.busy":"2024-05-22T09:57:04.732992Z","iopub.status.idle":"2024-05-22T09:57:04.733851Z","shell.execute_reply.started":"2024-05-22T09:57:04.733527Z","shell.execute_reply":"2024-05-22T09:57:04.733553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def generate_text(idx, max_new_tokens, params):\n# # idx is (B, T) array of indices in the current context\n#     for i in range(max_new_tokens):\n#         # crop idx to the last block_size tokens\n#         idx_cond = idx[:, -block_size:]\n#         # get the predictions\n#         logits = fin_model.apply(params, idx_cond)\n#         # focus only on the last time step\n#         logits = logits[:, -1, :] # becomes (B, C)\n\n#         if i == 0:\n#             rng, rng_subkey = jax.random.split(jax.random.PRNGKey(12))\n#         else:\n#             rng, rng_subkey = jax.random.split(rng)\n\n#         idx_next = jax.random.categorical(rng_subkey, logits, axis=-1, shape=(1, 1)) # (B, 1)\n\n\n#         # append sampled index to the running sequence\n#         idx = jnp.concatenate([idx, idx_next], axis=-1) # (B, T+1)\n\n#     return idx","metadata":{"id":"9d28o-dTHFyx","execution":{"iopub.status.busy":"2024-05-22T09:57:04.735477Z","iopub.status.idle":"2024-05-22T09:57:04.735821Z","shell.execute_reply.started":"2024-05-22T09:57:04.735657Z","shell.execute_reply":"2024-05-22T09:57:04.735671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@partial(jax.jit, static_argnames=(\"self\", \"length\"))\ndef generate_text(rng, params, length):\n    def _scan_generate(carry, _):\n        random_key, context = carry\n        logits = fin_model.apply(params, context, training=False)[0]\n        rng, rng_subkey = jax.random.split(random_key)\n        new_token = jax.random.categorical(\n          rng_subkey, logits[:, -1, :], axis=-1, shape=(1, 1)\n        )\n        context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n        return (rng, context), new_token\n\n    _, new_tokens = jax.lax.scan(\n    _scan_generate,\n    (rng, jnp.zeros((1, block_size), dtype=jnp.int32)),\n    (),\n    length=length,\n    )\n    return new_tokens","metadata":{"id":"WB0og7pAHFyx","execution":{"iopub.status.busy":"2024-05-22T09:57:04.737082Z","iopub.status.idle":"2024-05-22T09:57:04.737451Z","shell.execute_reply.started":"2024-05-22T09:57:04.737283Z","shell.execute_reply":"2024-05-22T09:57:04.737298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_tokenz = 1000\nkey, subkey = jax.random.split(jax.random.PRNGKey(156))\n# key, subkey = jax.random.split(key)\n# token_gen = generate_text(jnp.zeros((1,block_size)).astype(jnp.int32), new_tokenz, {'params': state.params})\ntoken_gen = generate_text(key, {'params': state.params}, new_tokenz)[:, 0, 0].tolist()\nprint(token_gen)\nprint(decode(token_gen))","metadata":{"id":"50Vpg2lEHFyx","execution":{"iopub.status.busy":"2024-05-22T09:57:04.738707Z","iopub.status.idle":"2024-05-22T09:57:04.739042Z","shell.execute_reply.started":"2024-05-22T09:57:04.738879Z","shell.execute_reply":"2024-05-22T09:57:04.738893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdgh  fs","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:57:04.740297Z","iopub.status.idle":"2024-05-22T09:57:04.740641Z","shell.execute_reply.started":"2024-05-22T09:57:04.740471Z","shell.execute_reply":"2024-05-22T09:57:04.740485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state.params","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:57:04.742595Z","iopub.status.idle":"2024-05-22T09:57:04.742927Z","shell.execute_reply.started":"2024-05-22T09:57:04.742766Z","shell.execute_reply":"2024-05-22T09:57:04.742780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install mamba-ssm","metadata":{"id":"MOw_xjbrHFy0","execution":{"iopub.status.busy":"2024-05-22T09:57:04.744174Z","iopub.status.idle":"2024-05-22T09:57:04.744520Z","shell.execute_reply.started":"2024-05-22T09:57:04.744350Z","shell.execute_reply":"2024-05-22T09:57:04.744365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ones = lambda *size: torch.ones(*size).float().cuda()\nzeros = lambda *size: torch.zeros(*size).float().cuda()\narange = lambda n: torch.arange(n).float().cuda()\nrand = lambda size: torch.rand(*size).abs().float().cuda()\n\ndef create_torch(S = 128, Ba = 2, D = 4, N = 4):\n    x = rand((Ba, 1, D, S))\n    a = -ones((Ba, N, D, 1))\n    b = ones((Ba, N, 1, S)) * 0.1\n    c = rand((Ba, N, 1, S)) * 0.1\n    delta = rand((Ba, 1, D, S)) * 0.1\n    return x, a, b, c, delta","metadata":{"id":"W_PAnYcEOR22","execution":{"iopub.status.busy":"2024-05-22T09:57:04.745878Z","iopub.status.idle":"2024-05-22T09:57:04.746755Z","shell.execute_reply.started":"2024-05-22T09:57:04.746417Z","shell.execute_reply":"2024-05-22T09:57:04.746442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import selective_scan_cuda\n\nxx, aa, bb, cc, ddelta = create_torch()\ny_from_repo = selective_scan_cuda.fwd(xx.squeeze(1), ddelta.squeeze(1), aa[0].squeeze(-1).T, bb.squeeze(-2)[:, None, :, :], cc.squeeze(-2)[:, None, :, :], None, None, None, False)\ny_from_repo","metadata":{"id":"ykh4GTvtOrak","execution":{"iopub.status.busy":"2024-05-22T09:57:04.748099Z","iopub.status.idle":"2024-05-22T09:57:04.748463Z","shell.execute_reply.started":"2024-05-22T09:57:04.748297Z","shell.execute_reply":"2024-05-22T09:57:04.748312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discretize(a, b, delta):\n    da = delta * a\n    a_ = jnp.exp(da)\n    b_ = b * delta\n    return a_, b_\n\ndef ssm(x, a, b, c, delta):\n    \"Jax Implementation\"\n    y = []\n    h = 0\n    a_, b_ = discretize(a, b, delta)\n    for k in range(x.shape[-1]):\n        h = a_[..., k] * h + b_[..., k] * x[..., k]\n        y.append((c[..., k] * h).sum(1, keepdims=True))\n    return h, jnp.stack(y, -1)\n","metadata":{"id":"NEdG1yPNOtxU","execution":{"iopub.status.busy":"2024-05-22T09:57:04.749735Z","iopub.status.idle":"2024-05-22T09:57:04.750069Z","shell.execute_reply.started":"2024-05-22T09:57:04.749905Z","shell.execute_reply":"2024-05-22T09:57:04.749919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, y_ = ssm(xx.cpu().numpy(), aa.cpu().numpy(), bb.cpu().numpy(), cc.cpu().numpy(), ddelta.cpu().numpy())","metadata":{"id":"GEjNcZSZPIp_","execution":{"iopub.status.busy":"2024-05-22T09:57:04.751328Z","iopub.status.idle":"2024-05-22T09:57:04.751666Z","shell.execute_reply.started":"2024-05-22T09:57:04.751496Z","shell.execute_reply":"2024-05-22T09:57:04.751510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"tWlqZZOmPnYk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mamba_ssm import Mamba as Mamba_T\ntorch_mamba = Mamba_T(\n      # This module uses roughly 3 * expand * d_model^2 parameters\n      d_model=n_embd, # Model dimension d_model\n      d_state=16,  # SSM state expansion factor\n      d_conv=4,    # Local convolution width\n      expand=2,    # Block expansion factor\n)","metadata":{"id":"5RHAE_I1Pql9","execution":{"iopub.status.busy":"2024-05-22T09:57:04.753004Z","iopub.status.idle":"2024-05-22T09:57:04.753685Z","shell.execute_reply.started":"2024-05-22T09:57:04.753494Z","shell.execute_reply":"2024-05-22T09:57:04.753513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xm = x = rand((1, 1, n_embd, 32))\nxm.shape","metadata":{"id":"l9zw_M-USrDt","execution":{"iopub.status.busy":"2024-05-22T09:57:04.759239Z","iopub.status.idle":"2024-05-22T09:57:04.759586Z","shell.execute_reply.started":"2024-05-22T09:57:04.759413Z","shell.execute_reply":"2024-05-22T09:57:04.759428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_mamba(xm.squeeze(1))","metadata":{"id":"gGmA2EWlTCo0","execution":{"iopub.status.busy":"2024-05-22T09:57:04.760867Z","iopub.status.idle":"2024-05-22T09:57:04.761234Z","shell.execute_reply.started":"2024-05-22T09:57:04.761044Z","shell.execute_reply":"2024-05-22T09:57:04.761059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_mamba.in_proj","metadata":{"id":"73ek9mx9UBBl","execution":{"iopub.status.busy":"2024-05-22T09:57:04.762364Z","iopub.status.idle":"2024-05-22T09:57:04.762688Z","shell.execute_reply.started":"2024-05-22T09:57:04.762528Z","shell.execute_reply":"2024-05-22T09:57:04.762542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"P3l_ssIYbiYT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_mamba_repo = mamba_inner_fn()","metadata":{"id":"-X7hXQRMZhl3","execution":{"iopub.status.busy":"2024-05-22T09:57:04.763635Z","iopub.status.idle":"2024-05-22T09:57:04.763960Z","shell.execute_reply.started":"2024-05-22T09:57:04.763798Z","shell.execute_reply":"2024-05-22T09:57:04.763812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xm.squeeze(1).shape","metadata":{"id":"rJhKQ_Oua9Gy","execution":{"iopub.status.busy":"2024-05-22T09:57:04.765478Z","iopub.status.idle":"2024-05-22T09:57:04.765819Z","shell.execute_reply.started":"2024-05-22T09:57:04.765656Z","shell.execute_reply":"2024-05-22T09:57:04.765671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"mzkoYrSVkoJj"},"execution_count":null,"outputs":[]}]}