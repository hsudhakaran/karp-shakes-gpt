{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q clu","metadata":{"id":"gS6euWNvHFye","outputId":"45b149a7-9450-439c-da67-ab8678a3b0d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt","metadata":{"id":"7jjCLfuUHFyg","outputId":"dfe048f0-dd44-40ef-edf3-2fa56558672f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from functools import partial\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom jax.nn.initializers import lecun_normal, normal\nfrom jax.numpy.linalg import eigh, inv, matrix_power\nfrom jax.scipy.signal import convolve\n\nimport torch\n\nfrom dataclasses import dataclass\n\nfrom typing import Union\n\nimport matplotlib.pyplot as plt\nimport seaborn\n\nfrom clu import metrics\nfrom flax.training import train_state  # Useful dataclass to keep train state\nfrom flax import struct                # Flax dataclasses\nimport optax                           # Common loss functions and optimizers\nfrom tqdm import tqdm","metadata":{"id":"YXSCJzupHFyh","execution":{"iopub.status.busy":"2024-05-27T10:51:00.323483Z","iopub.execute_input":"2024-05-27T10:51:00.324149Z","iopub.status.idle":"2024-05-27T10:51:03.697172Z","shell.execute_reply.started":"2024-05-27T10:51:00.324118Z","shell.execute_reply":"2024-05-27T10:51:03.696115Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# read it in to inspect it\nwith open('input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()","metadata":{"id":"KpJoV3KQHFyh","execution":{"iopub.status.busy":"2024-05-27T10:51:03.699050Z","iopub.execute_input":"2024-05-27T10:51:03.699489Z","iopub.status.idle":"2024-05-27T10:51:03.705528Z","shell.execute_reply.started":"2024-05-27T10:51:03.699434Z","shell.execute_reply":"2024-05-27T10:51:03.704641Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# here are all the unique characters that occur in this text\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"id":"PsWxZqyRHFyi","outputId":"b1730724-647e-45cd-edfa-97af24995830","execution":{"iopub.status.busy":"2024-05-27T10:51:03.706756Z","iopub.execute_input":"2024-05-27T10:51:03.707029Z","iopub.status.idle":"2024-05-27T10:51:03.730963Z","shell.execute_reply.started":"2024-05-27T10:51:03.706999Z","shell.execute_reply":"2024-05-27T10:51:03.730187Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n65\n","output_type":"stream"}]},{"cell_type":"code","source":"# create a mapping from characters to integers\nstoi = { ch: i for i,ch in enumerate(chars) }\nitos = { i: ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\ndecode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n\nprint(encode(\"hii there\"))\nprint(decode(encode(\"hii there\")))","metadata":{"id":"S-mzLOk1HFyi","outputId":"f56e2f85-5a1c-4099-87df-436ba39f4363","execution":{"iopub.status.busy":"2024-05-27T10:51:03.732967Z","iopub.execute_input":"2024-05-27T10:51:03.733254Z","iopub.status.idle":"2024-05-27T10:51:03.741449Z","shell.execute_reply.started":"2024-05-27T10:51:03.733231Z","shell.execute_reply":"2024-05-27T10:51:03.740604Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[46, 47, 47, 1, 58, 46, 43, 56, 43]\nhii there\n","output_type":"stream"}]},{"cell_type":"code","source":"data = jnp.array(encode(text), dtype=jnp.int32)\nprint(data.shape, data.dtype)\nprint(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this","metadata":{"id":"HImuqDd8HFyj","outputId":"91dcd15f-f068-4551-ad29-e6e41e52fd91","execution":{"iopub.status.busy":"2024-05-27T10:51:03.742543Z","iopub.execute_input":"2024-05-27T10:51:03.742803Z","iopub.status.idle":"2024-05-27T10:51:06.046830Z","shell.execute_reply.started":"2024-05-27T10:51:03.742780Z","shell.execute_reply":"2024-05-27T10:51:06.045829Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(1115394,) int32\n[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n  0 37 53 59  1 39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39\n 58 46 43 56  1 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47\n 57 46 12  0  0 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53\n 50 60 43 42  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47\n 56 57 58  6  1 63 53 59  1 49 52 53 61  1 15 39 47 59 57  1 25 39 56 41\n 47 59 57  1 47 57  1 41 46 47 43 44  1 43 52 43 51 63  1 58 53  1 58 46\n 43  1 54 43 53 54 50 43  8  0  0 13 50 50 10  0 35 43  1 49 52 53 61  5\n 58  6  1 61 43  1 49 52 53 61  5 58  8  0  0 18 47 56 57 58  1 15 47 58\n 47 64 43 52 10  0 24 43 58  1 59 57  1 49 47 50 50  1 46 47 51  6  1 39\n 52 42  1 61 43  5 50 50  1 46 39 60 43  1 41 53 56 52  1 39 58  1 53 59\n 56  1 53 61 52  1 54 56 47 41 43  8  0 21 57  5 58  1 39  1 60 43 56 42\n 47 41 58 12  0  0 13 50 50 10  0 26 53  1 51 53 56 43  1 58 39 50 49 47\n 52 45  1 53 52  5 58 11  1 50 43 58  1 47 58  1 40 43  1 42 53 52 43 10\n  1 39 61 39 63  6  1 39 61 39 63  2  0  0 31 43 41 53 52 42  1 15 47 58\n 47 64 43 52 10  0 27 52 43  1 61 53 56 42  6  1 45 53 53 42  1 41 47 58\n 47 64 43 52 57  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 35\n 43  1 39 56 43  1 39 41 41 53 59 52 58 43 42  1 54 53 53 56  1 41 47 58\n 47 64 43 52 57  6  1 58 46 43  1 54 39 58 56 47 41 47 39 52 57  1 45 53\n 53 42  8  0 35 46 39 58  1 39 59 58 46 53 56 47 58 63  1 57 59 56 44 43\n 47 58 57  1 53 52  1 61 53 59 50 42  1 56 43 50 47 43 60 43  1 59 57 10\n  1 47 44  1 58 46 43 63  0 61 53 59 50 42  1 63 47 43 50 42  1 59 57  1\n 40 59 58  1 58 46 43  1 57 59 54 43 56 44 50 59 47 58 63  6  1 61 46 47\n 50 43  1 47 58  1 61 43 56 43  0 61 46 53 50 43 57 53 51 43  6  1 61 43\n  1 51 47 45 46 58  1 45 59 43 57 57  1 58 46 43 63  1 56 43 50 47 43 60\n 43 42  1 59 57  1 46 59 51 39 52 43 50 63 11  0 40 59 58  1 58 46 43 63\n  1 58 46 47 52 49  1 61 43  1 39 56 43  1 58 53 53  1 42 43 39 56 10  1\n 58 46 43  1 50 43 39 52 52 43 57 57  1 58 46 39 58  0 39 44 44 50 47 41\n 58 57  1 59 57  6  1 58 46 43  1 53 40 48 43 41 58  1 53 44  1 53 59 56\n  1 51 47 57 43 56 63  6  1 47 57  1 39 57  1 39 52  0 47 52 60 43 52 58\n 53 56 63  1 58 53  1 54 39 56 58 47 41 59 50 39 56 47 57 43  1 58 46 43\n 47 56  1 39 40 59 52 42 39 52 41 43 11  1 53 59 56  0 57 59 44 44 43 56\n 39 52 41 43  1 47 57  1 39  1 45 39 47 52  1 58 53  1 58 46 43 51  1 24\n 43 58  1 59 57  1 56 43 60 43 52 45 43  1 58 46 47 57  1 61 47 58 46  0\n 53 59 56  1 54 47 49 43 57  6  1 43 56 43  1 61 43  1 40 43 41 53 51 43\n  1 56 39 49 43 57 10  1 44 53 56  1 58 46 43  1 45 53 42 57  1 49 52 53\n 61  1 21  0 57 54 43 39 49  1 58 46 47 57  1 47 52  1 46 59 52 45 43 56\n  1 44 53 56  1 40 56 43 39 42  6  1 52 53 58  1 47 52  1 58 46 47 56 57\n 58  1 44 53 56  1 56 43 60 43 52 45 43  8  0  0]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_test_split = 0.9\nn = int(train_test_split*len(data))\ntrain_data = data[:n]\ntest_data = data[n:]","metadata":{"id":"pXrAqMxRHFyj","execution":{"iopub.status.busy":"2024-05-27T10:51:06.048082Z","iopub.execute_input":"2024-05-27T10:51:06.048504Z","iopub.status.idle":"2024-05-27T10:51:06.211234Z","shell.execute_reply.started":"2024-05-27T10:51:06.048466Z","shell.execute_reply":"2024-05-27T10:51:06.210328Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"block_size = 8\ntrain_data[:block_size+1]","metadata":{"id":"ahhKyiAzHFyj","outputId":"98306c96-5082-4dfa-ba66-915051831fc8","execution":{"iopub.status.busy":"2024-05-27T10:51:06.212430Z","iopub.execute_input":"2024-05-27T10:51:06.212786Z","iopub.status.idle":"2024-05-27T10:51:06.295809Z","shell.execute_reply.started":"2024-05-27T10:51:06.212759Z","shell.execute_reply":"2024-05-27T10:51:06.294778Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Array([18, 47, 56, 57, 58,  1, 15, 47, 58], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target: {target}\")","metadata":{"id":"HIpsznQmHFyk","outputId":"be9d197b-0b79-43ed-f3a9-e74295d51c79","execution":{"iopub.status.busy":"2024-05-27T10:51:06.297157Z","iopub.execute_input":"2024-05-27T10:51:06.297617Z","iopub.status.idle":"2024-05-27T10:51:06.937023Z","shell.execute_reply.started":"2024-05-27T10:51:06.297569Z","shell.execute_reply":"2024-05-27T10:51:06.936137Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"when input is [18] the target: 47\nwhen input is [18 47] the target: 56\nwhen input is [18 47 56] the target: 57\nwhen input is [18 47 56 57] the target: 58\nwhen input is [18 47 56 57 58] the target: 1\nwhen input is [18 47 56 57 58  1] the target: 15\nwhen input is [18 47 56 57 58  1 15] the target: 47\nwhen input is [18 47 56 57 58  1 15 47] the target: 58\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 512 # how many independent sequences will we process in parallel?\nblock_size = 64 # what is the maximum context length for predictions?\nmax_iters = 10000\nlearning_rate = 1e-3\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 100\nn_embd = 256\nexpans = 3\nn_heads = 1\nchannel_size = n_embd // n_heads\nn_layers = 6\ndropout = 0.2\nconv_k_size = 3\nn_latent_dim = 16\nn_tokens = 1\n\nrng_key = jax.random.PRNGKey(1564)\n\ndynamic_slice_vmap = jax.vmap(jax.lax.dynamic_slice, in_axes=(None, 0, None))\n\n@jax.jit\ndef get_batch(random_key, data):\n    \"\"\"Prepares a random batch of training data.\n\n    Args:\n      random_key: A random seed for sampling a batch.\n      data: The complete training dataset.\n\n    Returns:\n      x: Input sequences.\n      y: Target sequences (shifted inputs).\n    \"\"\"\n    ix = jax.random.randint(\n      random_key, shape=(batch_size, 1), minval=0, maxval=len(data) - block_size\n    )\n    x = dynamic_slice_vmap(data, ix, (block_size,))\n    y = dynamic_slice_vmap(data, ix + n_tokens, (block_size,))\n    return x, y\n\nxb, yb = get_batch(rng_key, train_data)\ntrain_shape = xb.shape\nprint('inputs:')\nprint(xb.shape)\nprint(xb)\nprint('targets:')\nprint(yb.shape)\nprint(yb)\n\n# print('----')\n\n# for b in range(batch_size): # batch dimension\n#     for t in range(block_size): # time dimension\n#         context = xb[b, :t+1]\n#         target = yb[b,t]\n#         print(f\"when input is {context} the target: {target}\")","metadata":{"id":"UuAjtqPeHFyk","outputId":"6a88fb2b-b798-4ee9-9f4f-f38ce898d576","execution":{"iopub.status.busy":"2024-05-27T10:51:06.938284Z","iopub.execute_input":"2024-05-27T10:51:06.938588Z","iopub.status.idle":"2024-05-27T10:51:07.266658Z","shell.execute_reply.started":"2024-05-27T10:51:06.938564Z","shell.execute_reply":"2024-05-27T10:51:07.265561Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"inputs:\n(512, 64)\n[[33 23 17 ... 53 52 45]\n [ 0 37 53 ... 52 52 53]\n [53 52 42 ... 59 47 58]\n ...\n [52 42  1 ... 58 46  1]\n [37 53 59 ...  1 61 47]\n [17 26 34 ... 39 52  1]]\ntargets:\n(512, 64)\n[[23 17  1 ... 52 45 59]\n [37 53 59 ... 52 53 58]\n [52 42 43 ... 47 58  7]\n ...\n [42  1 63 ... 46  1 54]\n [53 59  1 ... 61 47 50]\n [26 34 27 ... 52  1 40]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Mamba Block\nDense --> Conv1D --> Silu --> SSM --> Silu -->","metadata":{"id":"yOccqzJlHFym"}},{"cell_type":"code","source":"print(xb[0])\nprint(yb[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:51:07.270051Z","iopub.execute_input":"2024-05-27T10:51:07.270337Z","iopub.status.idle":"2024-05-27T10:51:07.367903Z","shell.execute_reply.started":"2024-05-27T10:51:07.270314Z","shell.execute_reply":"2024-05-27T10:51:07.366885Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[33 23 17  1 27 18  1 13 33 25 17 30 24 17 10  0 18 53 56  1 43 60 43 56\n  1 51 39 63  1 51 63  1 49 52 43 43 57  1 45 56 53 61  1 58 53  1 58 46\n 43  1 43 39 56 58 46  6  0 25 63  1 58 53 52 45]\n[23 17  1 27 18  1 13 33 25 17 30 24 17 10  0 18 53 56  1 43 60 43 56  1\n 51 39 63  1 51 63  1 49 52 43 43 57  1 45 56 53 61  1 58 53  1 58 46 43\n  1 43 39 56 58 46  6  0 25 63  1 58 53 52 45 59]\n","output_type":"stream"}]},{"cell_type":"code","source":"# hidden_state = [jnp.zeros((1,n_latent_dim, n_embd * expans)) for _ in range(n_layers)]","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:51:07.369090Z","iopub.execute_input":"2024-05-27T10:51:07.369382Z","iopub.status.idle":"2024-05-27T10:51:07.373776Z","shell.execute_reply.started":"2024-05-27T10:51:07.369358Z","shell.execute_reply":"2024-05-27T10:51:07.372795Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# hidden_state[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:51:07.374831Z","iopub.execute_input":"2024-05-27T10:51:07.375108Z","iopub.status.idle":"2024-05-27T10:51:07.383774Z","shell.execute_reply.started":"2024-05-27T10:51:07.375074Z","shell.execute_reply":"2024-05-27T10:51:07.382980Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Mamba(nn.Module):\n\n    def setup(self):\n        emb_features = n_embd * expans\n        self.in_proj1 = nn.Dense(features=emb_features)\n        self.in_proj2 = nn.Dense(features=emb_features)\n\n        # Adjusted for Flax. Flax does not have nn.Conv1d, so you might need to reshape or use a different approach\n        self.conv1d = nn.Conv(features=emb_features,\n                              kernel_size=conv_k_size,\n                              padding=1,\n                              )\n\n        self.A = -1*self.param('A', nn.initializers.ones, (1, n_latent_dim, emb_features, 1))\n        self.B = 0.1*self.param('B', nn.initializers.ones, (1, n_latent_dim, 1, block_size))\n        self.C = self.param('C', jax.random.normal, (1, n_latent_dim, 1, block_size))\n#         self.D = self.param('D', jax.random.normal, (1, self.args.d_state, self.args.d_model, 1))\n        self.delta = self.param('delta', jax.random.normal, (1, 1,emb_features, block_size))\n\n        self.out_proj = nn.Dense(n_embd // n_heads)\n        \n        self.hidden_state = self.variable('other_variables','hidden_state', \n                                          jnp.zeros, \n                                          (1,n_latent_dim, emb_features))\n        self.rms_norm = nn.RMSNorm()\n\n    def __call__(self, embeds):\n        x = self.in_proj1(embeds)\n        x = self.conv1d(x)\n        x = jax.nn.silu(x)\n        x = x.reshape((x.shape[0],1,x.shape[2],x.shape[1]))\n        x = self.ssm(x)\n        x = x.reshape((x.shape[0],x.shape[3],x.shape[2]))\n        x = x*jax.nn.silu(self.in_proj2(embeds))\n\n        x = self.out_proj(x)\n\n        x = self.rms_norm(x)\n\n        return x\n    def discretize(self):\n        da = self.delta * self.A\n        a_ = jnp.exp(da)\n        b_ = self.B * self.delta\n        return a_, b_\n\n    def ssm(self, x):\n        y = []\n        a_, b_ = self.discretize()\n        h = 0\n        for k in range(x.shape[-1]):\n            h = a_[..., k] * h + b_[..., k] * x[..., k]\n            \n#         for l in range(x.shape[-1]):\n            y.append((self.C[..., k] * h).sum(1, keepdims=True))   \n        \n        self.hidden_state.value = jax.nn.standardize(h.mean(0, keepdims=True))\n        return jnp.stack(y, -1)","metadata":{"id":"4qOdblU5HFyo","execution":{"iopub.status.busy":"2024-05-27T10:51:07.384709Z","iopub.execute_input":"2024-05-27T10:51:07.384940Z","iopub.status.idle":"2024-05-27T10:51:07.400818Z","shell.execute_reply.started":"2024-05-27T10:51:07.384920Z","shell.execute_reply":"2024-05-27T10:51:07.399902Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# class MultiHeadMamba(nn.Module):\n#     def setup(self):\n#         self.layernorm\n#         self.heads = [Mamba() for _ in range(n_heads)]\n#         self.rms_norm = nn.RMSNorm()\n\n#     def __call__(self, x):\n#         out = jnp.concatenate([h(x) for h in self.heads], axis=-1)\n#         x = self.rms_norm(out)\n#         return x","metadata":{"id":"0bH9vlLZHFyq","execution":{"iopub.status.busy":"2024-05-27T10:51:07.401911Z","iopub.execute_input":"2024-05-27T10:51:07.402708Z","iopub.status.idle":"2024-05-27T10:51:07.413379Z","shell.execute_reply.started":"2024-05-27T10:51:07.402676Z","shell.execute_reply":"2024-05-27T10:51:07.412477Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# class FeedForward(nn.Module):\n#     def setup(self):\n#         self.ffn = nn.Sequential([\n#             nn.Dense(4 * n_embd),\n#             nn.relu,\n#             nn.Dense(n_embd)]\n#         )\n#     def __call__(self, x):\n#         return self.ffn(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:51:07.414755Z","iopub.execute_input":"2024-05-27T10:51:07.414999Z","iopub.status.idle":"2024-05-27T10:51:07.426102Z","shell.execute_reply.started":"2024-05-27T10:51:07.414978Z","shell.execute_reply":"2024-05-27T10:51:07.425239Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# class MambaBlock(nn.Module):\n#     def setup(self):\n#         self.mamba_block = Mamba()\n#         self.ln1 = nn.RMSNorm()\n#         self.ffn = FeedForward()\n#         self.ln2 = nn.LayerNorm()\n\n#     def __call__(self, x):\n#         x = x + self.mamba_block(self.ln2(x))\n#         x = x + self.ffn(self.ln1(x))\n#         return x\n","metadata":{"id":"UiCxIjoEp2QA","execution":{"iopub.status.busy":"2024-05-27T10:51:07.427433Z","iopub.execute_input":"2024-05-27T10:51:07.427762Z","iopub.status.idle":"2024-05-27T10:51:07.435100Z","shell.execute_reply.started":"2024-05-27T10:51:07.427734Z","shell.execute_reply":"2024-05-27T10:51:07.434292Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# class MambaModel(nn.Module):\n\n#     def setup(self):\n#         self.tok_embeddings = nn.Embed(vocab_size, n_embd)\n#         self.pos_embeddings = nn.Embed(block_size, n_embd)\n#         self.ln = nn.LayerNorm()\n#         self.mamba_layers = [MambaBlock() for _ in range(n_layers)]\n#         self.preds_out = nn.Dense(vocab_size)\n\n#     def __call__(self, x, training: bool):\n#         x = self.tok_embeddings(x) + self.pos_embeddings(jnp.arange(block_size))\n# #         x = self.ln(x)\n#         for layer in self.mamba_layers:\n#             x = layer(x)\n            \n#         return self.preds_out(x)\n\n#     @jax.jit\n#     def generate(self, idx, max_new_tokens, params):\n#     # idx is (B, T) array of indices in the current context\n#         for _ in range(max_new_tokens):\n#             # crop idx to the last block_size tokens\n#             idx_cond = idx[:, -block_size:]\n#             # get the predictions\n#             logits = self.apply(params, idx_cond)\n#             # focus only on the last time step\n#             logits = logits[:, -1, :] # becomes (B, C)\n#             # apply softmax to get probabilities\n#             ##probs = tf.keras.activations.softmax(logits, dim=-1) # (B, C)\n#             # sample from the distribution\n#             idx_next = jax.random.categorical(jax.random.PRNGKey(52), logits) # (B, 1)\n#             # append sampled index to the running sequence\n#             idx = jax.numpy.expand_dims(jnp.concatenate([idx[0], idx_next], axis=0), 0) # (B, T+1)\n#     #         print(idx_next)\n#     #         print(idx)\n\n#         return idx","metadata":{"id":"y4C7OWL8HFyq","execution":{"iopub.status.busy":"2024-05-27T10:51:07.436183Z","iopub.execute_input":"2024-05-27T10:51:07.436494Z","iopub.status.idle":"2024-05-27T10:51:07.445770Z","shell.execute_reply.started":"2024-05-27T10:51:07.436466Z","shell.execute_reply":"2024-05-27T10:51:07.444939Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# model = Mamba()\n# params = model.init(jax.random.key(42), jnp.ones((1,64,256)))\n# # print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# # print(model.tabulate(jax.random.key(0), jnp.ones((1,64,256)),\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xs = model.apply(params, jnp.ones((1,64,256)), mutable=['other_variables'])\n# # # print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# xb.shape, xs[0].shape, xs[1].keys()","metadata":{"id":"wTd3jSQWHFyp","execution":{"iopub.status.busy":"2024-05-27T10:51:07.446871Z","iopub.execute_input":"2024-05-27T10:51:07.447160Z","iopub.status.idle":"2024-05-27T10:51:07.457932Z","shell.execute_reply.started":"2024-05-27T10:51:07.447136Z","shell.execute_reply":"2024-05-27T10:51:07.457004Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# print(xs[1]['other_variables']['hidden_state'].shape, xs[1]['other_variables']['hidden_state'].min(), xs[1]['other_variables']['hidden_state'].max())","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:51:07.458929Z","iopub.execute_input":"2024-05-27T10:51:07.459184Z","iopub.status.idle":"2024-05-27T10:51:07.470315Z","shell.execute_reply.started":"2024-05-27T10:51:07.459163Z","shell.execute_reply":"2024-05-27T10:51:07.469639Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# xfs = model.apply(params, 2*jnp.ones((1,64,256)), mutable=['other_variables'])\n# print(params['other_variables']['hidden_state'].shape, params['other_variables']['hidden_state'].min(), params['other_variables']['hidden_state'].max())\n# print(xfs[1]['other_variables']['hidden_state'].shape, xfs[1]['other_variables']['hidden_state'].min(), xfs[1]['other_variables']['hidden_state'].max())","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:51:07.471409Z","iopub.execute_input":"2024-05-27T10:51:07.471983Z","iopub.status.idle":"2024-05-27T10:51:07.479312Z","shell.execute_reply.started":"2024-05-27T10:51:07.471951Z","shell.execute_reply":"2024-05-27T10:51:07.478458Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# test_model = Mamba()\n# test_params = test_model.init(jax.random.key(42), xb)\n# n_params = sum(p.size for p in jax.tree_util.tree_leaves(test_params))\n# print(f\"Total number of parameters: {n_params:_}\")\n# # print(fin_model.tabulate(jax.random.key(42), xb,\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xf = test_model.apply(test_params, xb)\n# xb.shape, xf.shape","metadata":{"id":"cm2a0nepHFyq","execution":{"iopub.status.busy":"2024-05-27T10:51:07.480319Z","iopub.execute_input":"2024-05-27T10:51:07.480660Z","iopub.status.idle":"2024-05-27T10:51:07.488615Z","shell.execute_reply.started":"2024-05-27T10:51:07.480630Z","shell.execute_reply":"2024-05-27T10:51:07.487806Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class NanoLM(nn.Module):\n    \"\"\"NanoLM model.\"\"\"\n    vocab_size: int = 65\n    num_layers: int = 6\n    num_heads: int = 8\n    head_size: int = 32\n    dropout_rate: float = 0.2\n    embed_size: int = 256\n    block_size: int = 64\n\n    @nn.compact\n    def __call__(self, x, training: bool):\n        x = nn.Embed(self.vocab_size, self.embed_size)(x) + nn.Embed(\n            self.block_size, self.embed_size\n        )(jnp.arange(self.block_size))\n        \n        for i in range(self.num_layers):\n            x_norm = nn.LayerNorm()(x)\n#             x = x + nn.MultiHeadDotProductAttention(\n#               num_heads=self.num_heads,\n#               qkv_features=self.head_size,\n#               out_features=self.head_size * self.num_heads,\n#               dropout_rate=self.dropout_rate,\n#             )(\n#               x_norm,\n#               x_norm,\n#               mask=jnp.tril(jnp.ones((x.shape[-2], x.shape[-2]))),\n#               deterministic=not training,\n#             )\n    \n            x = x + Mamba()(x_norm)\n\n#             x = x + nn.Sequential([\n#               nn.Dense(4 * self.embed_size),\n#               nn.relu,\n#               nn.Dropout(self.dropout_rate, deterministic=not training),\n#               nn.Dense(self.embed_size),\n#             ])(nn.LayerNorm()(x))\n\n        x = nn.LayerNorm()(x)\n        return nn.Dense(self.vocab_size)(x)","metadata":{"id":"zuiaFP6WHFyr","execution":{"iopub.status.busy":"2024-05-27T10:51:07.489585Z","iopub.execute_input":"2024-05-27T10:51:07.489859Z","iopub.status.idle":"2024-05-27T10:51:07.501456Z","shell.execute_reply.started":"2024-05-27T10:51:07.489837Z","shell.execute_reply":"2024-05-27T10:51:07.500630Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# key = jax.random.key(42)\n\n# # fin_model = MambaModel()\n# # fin_params = fin_model.init(key, xb, training=False)\n\n\n# fin_model = NanoLM(\n#     vocab_size=vocab_size,\n#     num_layers=n_layers,\n#     num_heads=8,\n#     head_size=32,\n#     dropout_rate=0.2,\n#     embed_size=n_embd,\n#     block_size=block_size,\n# )\n\n# fin_params = fin_model.init(\n#     {'params': key},\n#     jnp.ones((batch_size, block_size), dtype=jnp.int32),\n#     training=False\n# )\n\n# n_params = sum(p.size for p in jax.tree_util.tree_leaves(fin_params))\n# print(f\"Total number of parameters: {n_params:_}\")\n# # print(fin_model.tabulate(jax.random.key(42), xb,\n# #                    compute_flops=True, compute_vjp_flops=True))\n# xf = fin_model.apply(fin_params, xb, training=False)[0]\n# xb.shape, xf.shape","metadata":{"id":"fnUQPyuvHFys","outputId":"f04ebf31-d67f-4488-dd5d-7fd5b20dd1ea","execution":{"iopub.status.busy":"2024-05-27T10:51:07.502810Z","iopub.execute_input":"2024-05-27T10:51:07.503070Z","iopub.status.idle":"2024-05-27T10:51:07.514257Z","shell.execute_reply.started":"2024-05-27T10:51:07.503048Z","shell.execute_reply":"2024-05-27T10:51:07.513420Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def loss_fun(params, x, y, var_params,dropout_key):\n    logits, updated_variables = model.apply({'params': params, **var_params}, x, training=True, rngs={\"dropout\": dropout_key}, mutable=['other_variables'])\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), (updated_variables, accuracy)\n\n@jax.jit\ndef eval_step(params, x, y, var_params):\n    logits, _ = model.apply({'params': params, **var_params}, x, training=False, mutable=['other_variables'])\n    accuracy = jnp.mean(jnp.argmax(logits, axis=-1) == y)\n    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean(), accuracy","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:51:07.515203Z","iopub.execute_input":"2024-05-27T10:51:07.515431Z","iopub.status.idle":"2024-05-27T10:51:07.528158Z","shell.execute_reply.started":"2024-05-27T10:51:07.515411Z","shell.execute_reply":"2024-05-27T10:51:07.527376Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"key = jax.random.PRNGKey(42)\nkey, subkey = jax.random.split(key)\n\nmodel = NanoLM(\n    vocab_size=vocab_size,\n    num_layers=n_layers,\n    num_heads=8,\n    head_size=32,\n    dropout_rate=0.2,\n    embed_size=n_embd,\n    block_size=block_size,\n)\n\nvar_params = model.init(\n    key,\n    jnp.ones((batch_size, block_size), dtype=jnp.int32),\n    training=False,\n)\nprint(var_params.keys())\nn_params = sum(p.size for p in jax.tree_util.tree_leaves(var_params))\n\nprint(f\"Total number of parameters: {n_params:_}\")","metadata":{"id":"PKpb3864HFyt","execution":{"iopub.status.busy":"2024-05-27T10:51:07.529122Z","iopub.execute_input":"2024-05-27T10:51:07.529379Z","iopub.status.idle":"2024-05-27T10:51:17.472653Z","shell.execute_reply.started":"2024-05-27T10:51:07.529357Z","shell.execute_reply":"2024-05-27T10:51:17.471716Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"dict_keys(['params', 'other_variables'])\nTotal number of parameters: 14_680_641\n","output_type":"stream"}]},{"cell_type":"code","source":"params = var_params.pop('params')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:51:17.473734Z","iopub.execute_input":"2024-05-27T10:51:17.474005Z","iopub.status.idle":"2024-05-27T10:51:17.478531Z","shell.execute_reply.started":"2024-05-27T10:51:17.473982Z","shell.execute_reply":"2024-05-27T10:51:17.477673Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"var_params = jax.tree_map(lambda x: jnp.zeros_like(x), var_params)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:51:17.479492Z","iopub.execute_input":"2024-05-27T10:51:17.479757Z","iopub.status.idle":"2024-05-27T10:51:17.495692Z","shell.execute_reply.started":"2024-05-27T10:51:17.479723Z","shell.execute_reply":"2024-05-27T10:51:17.494978Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# decay_rate = 0.96\n# learning_rate_schedule = optax.exponential_decay(learning_rate, decay_rate, max_iters//1000)\nopt = optax.adamw(learning_rate=learning_rate)\n\nopt_state = opt.init(params)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:51:17.502652Z","iopub.execute_input":"2024-05-27T10:51:17.502912Z","iopub.status.idle":"2024-05-27T10:51:17.920110Z","shell.execute_reply.started":"2024-05-27T10:51:17.502891Z","shell.execute_reply":"2024-05-27T10:51:17.919321Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"%%time\n\nall_train_losses = []\nall_eval_losses = []\n\nall_train_accuracy =  []\nall_test_accuracy = []\n\n# we define one iteration of the optimizer and JIT this function\n@jax.jit\ndef step(key, params, var_params, opt_state):\n    key, subkey = jax.random.split(key)\n    xb, yb = get_batch(key, train_data)\n    (loss, aux_data), grad = jax.value_and_grad(loss_fun, has_aux=True)(params, xb, yb, var_params, subkey)\n    var_params, train_accuracy = aux_data\n    updates, opt_state = opt.update(grad, opt_state, params)\n    params = optax.apply_updates(params, updates)\n    return params, key, opt_state, loss, var_params, train_accuracy\n\n# for i in tqdm(range(max_iters)):\ncounter = 0\nloss = 10\nwhile counter<max_iters: # and loss > 1.0:\n\n    params, key, opt_state, loss, var_params, train_accuracy = step(key, params, var_params, opt_state)\n    \n\n    # once every N_FREQ_EVAL we compute loss on the validation set\n    if counter % eval_iters == 0:\n        key, subkey = jax.random.split(key)\n        eval_loss, eval_accuracy = eval_step(params, *get_batch(subkey, test_data), var_params)\n        all_train_losses.append(loss)\n        all_eval_losses.append(eval_loss)\n        all_train_accuracy.append(train_accuracy)\n        all_test_accuracy.append(eval_accuracy)\n        print('##########################################################')\n        print(f\"Step: {counter}\\t train loss: {loss}\\t train accuracy: {train_accuracy}\")\n        print(f\"Step: {counter}\\t eval loss: {eval_loss}\\t eval accuracy: {eval_accuracy}\")\n        \n    counter += 1\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:51:17.921217Z","iopub.execute_input":"2024-05-27T10:51:17.921531Z","iopub.status.idle":"2024-05-27T13:01:29.620743Z","shell.execute_reply.started":"2024-05-27T10:51:17.921494Z","shell.execute_reply":"2024-05-27T13:01:29.619701Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"2024-05-27 10:51:51.649824: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[512,768,64]{2,1,0}, u8[0]{0}) custom-call(f32[512,768,64]{2,1,0}, f32[768,768,3]{2,1,0}), window={size=3 pad=1_1}, dim_labels=bf0_oi0->bf0, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-05-27 10:51:53.684201: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.034560302s\nTrying algorithm eng0{} for conv (f32[512,768,64]{2,1,0}, u8[0]{0}) custom-call(f32[512,768,64]{2,1,0}, f32[768,768,3]{2,1,0}), window={size=3 pad=1_1}, dim_labels=bf0_oi0->bf0, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n","output_type":"stream"},{"name":"stdout","text":"##########################################################\nStep: 0\t train loss: 4.671715259552002\t train accuracy: 0.013824462890625\nStep: 0\t eval loss: 4.588804721832275\t eval accuracy: 0.01812744140625\n##########################################################\nStep: 100\t train loss: 1.3229022026062012\t train accuracy: 0.670257568359375\nStep: 100\t eval loss: 1.3203089237213135\t eval accuracy: 0.672882080078125\n##########################################################\nStep: 200\t train loss: 0.31188908219337463\t train accuracy: 0.924896240234375\nStep: 200\t eval loss: 0.3308897614479065\t eval accuracy: 0.919647216796875\n##########################################################\nStep: 300\t train loss: 0.19824402034282684\t train accuracy: 0.952972412109375\nStep: 300\t eval loss: 0.21010832488536835\t eval accuracy: 0.948577880859375\n##########################################################\nStep: 400\t train loss: 0.06526880711317062\t train accuracy: 0.985260009765625\nStep: 400\t eval loss: 0.07150644809007645\t eval accuracy: 0.9835205078125\n##########################################################\nStep: 500\t train loss: 0.08702528476715088\t train accuracy: 0.97735595703125\nStep: 500\t eval loss: 0.08504042029380798\t eval accuracy: 0.97857666015625\n##########################################################\nStep: 600\t train loss: 0.04176611825823784\t train accuracy: 0.989349365234375\nStep: 600\t eval loss: 0.04708319902420044\t eval accuracy: 0.98785400390625\n##########################################################\nStep: 700\t train loss: 0.08954285830259323\t train accuracy: 0.977142333984375\nStep: 700\t eval loss: 0.1274373084306717\t eval accuracy: 0.972991943359375\n##########################################################\nStep: 800\t train loss: 0.05444007366895676\t train accuracy: 0.98577880859375\nStep: 800\t eval loss: 0.05584056302905083\t eval accuracy: 0.985626220703125\n##########################################################\nStep: 900\t train loss: 0.03660061955451965\t train accuracy: 0.990203857421875\nStep: 900\t eval loss: 0.03647506237030029\t eval accuracy: 0.990081787109375\n##########################################################\nStep: 1000\t train loss: 0.03540462255477905\t train accuracy: 0.990631103515625\nStep: 1000\t eval loss: 0.03662104904651642\t eval accuracy: 0.98980712890625\n##########################################################\nStep: 1100\t train loss: 0.03175211697816849\t train accuracy: 0.990997314453125\nStep: 1100\t eval loss: 0.03558768332004547\t eval accuracy: 0.990081787109375\n##########################################################\nStep: 1200\t train loss: 0.03339478373527527\t train accuracy: 0.99072265625\nStep: 1200\t eval loss: 0.03405063599348068\t eval accuracy: 0.990325927734375\n##########################################################\nStep: 1300\t train loss: 0.032959893345832825\t train accuracy: 0.990325927734375\nStep: 1300\t eval loss: 0.034601785242557526\t eval accuracy: 0.990264892578125\n##########################################################\nStep: 1400\t train loss: 0.060222327709198\t train accuracy: 0.984130859375\nStep: 1400\t eval loss: 0.06267153471708298\t eval accuracy: 0.982757568359375\n##########################################################\nStep: 1500\t train loss: 0.08479714393615723\t train accuracy: 0.97955322265625\nStep: 1500\t eval loss: 0.08555826544761658\t eval accuracy: 0.979827880859375\n##########################################################\nStep: 1600\t train loss: 0.037757523357868195\t train accuracy: 0.98974609375\nStep: 1600\t eval loss: 0.04190376400947571\t eval accuracy: 0.98895263671875\n##########################################################\nStep: 1700\t train loss: 0.034820593893527985\t train accuracy: 0.990264892578125\nStep: 1700\t eval loss: 0.03471842035651207\t eval accuracy: 0.990478515625\n##########################################################\nStep: 1800\t train loss: 0.03991495817899704\t train accuracy: 0.988983154296875\nStep: 1800\t eval loss: 0.041627295315265656\t eval accuracy: 0.988525390625\n##########################################################\nStep: 1900\t train loss: 0.03918812796473503\t train accuracy: 0.989288330078125\nStep: 1900\t eval loss: 0.03994285315275192\t eval accuracy: 0.98919677734375\n##########################################################\nStep: 2000\t train loss: 0.056241344660520554\t train accuracy: 0.987396240234375\nStep: 2000\t eval loss: 0.08075359463691711\t eval accuracy: 0.983917236328125\n##########################################################\nStep: 2100\t train loss: 0.037560828030109406\t train accuracy: 0.99090576171875\nStep: 2100\t eval loss: 0.04133688658475876\t eval accuracy: 0.988922119140625\n##########################################################\nStep: 2200\t train loss: 0.09572790563106537\t train accuracy: 0.9757080078125\nStep: 2200\t eval loss: 0.10075503587722778\t eval accuracy: 0.97509765625\n##########################################################\nStep: 2300\t train loss: 0.0355474054813385\t train accuracy: 0.9903564453125\nStep: 2300\t eval loss: 0.037040796130895615\t eval accuracy: 0.990325927734375\n##########################################################\nStep: 2400\t train loss: 0.03684160113334656\t train accuracy: 0.989898681640625\nStep: 2400\t eval loss: 0.03705273196101189\t eval accuracy: 0.989898681640625\n##########################################################\nStep: 2500\t train loss: 0.029219362884759903\t train accuracy: 0.9918212890625\nStep: 2500\t eval loss: 0.03429807722568512\t eval accuracy: 0.99029541015625\n##########################################################\nStep: 2600\t train loss: 0.032509997487068176\t train accuracy: 0.990753173828125\nStep: 2600\t eval loss: 0.035601913928985596\t eval accuracy: 0.989990234375\n##########################################################\nStep: 2700\t train loss: 0.03000912070274353\t train accuracy: 0.9913330078125\nStep: 2700\t eval loss: 0.03318459168076515\t eval accuracy: 0.990570068359375\n##########################################################\nStep: 2800\t train loss: 0.030413653701543808\t train accuracy: 0.990936279296875\nStep: 2800\t eval loss: 0.032461777329444885\t eval accuracy: 0.990631103515625\n##########################################################\nStep: 2900\t train loss: 0.03216548264026642\t train accuracy: 0.99127197265625\nStep: 2900\t eval loss: 0.03544404357671738\t eval accuracy: 0.990264892578125\n##########################################################\nStep: 3000\t train loss: 0.031756751239299774\t train accuracy: 0.990753173828125\nStep: 3000\t eval loss: 0.03400225192308426\t eval accuracy: 0.990692138671875\n##########################################################\nStep: 3100\t train loss: 0.03171674907207489\t train accuracy: 0.99078369140625\nStep: 3100\t eval loss: 0.0324675627052784\t eval accuracy: 0.990386962890625\n##########################################################\nStep: 3200\t train loss: 0.028685402125120163\t train accuracy: 0.991485595703125\nStep: 3200\t eval loss: 0.03241231292486191\t eval accuracy: 0.990447998046875\n##########################################################\nStep: 3300\t train loss: 0.027397185564041138\t train accuracy: 0.9918212890625\nStep: 3300\t eval loss: 0.030474409461021423\t eval accuracy: 0.990997314453125\n##########################################################\nStep: 3400\t train loss: 0.029828909784555435\t train accuracy: 0.991455078125\nStep: 3400\t eval loss: 0.032208822667598724\t eval accuracy: 0.990753173828125\n##########################################################\nStep: 3500\t train loss: 0.028260089457035065\t train accuracy: 0.9913330078125\nStep: 3500\t eval loss: 0.03439367562532425\t eval accuracy: 0.990570068359375\n##########################################################\nStep: 3600\t train loss: 0.026204541325569153\t train accuracy: 0.99212646484375\nStep: 3600\t eval loss: 0.03090277872979641\t eval accuracy: 0.990966796875\n##########################################################\nStep: 3700\t train loss: 0.028922203928232193\t train accuracy: 0.9918212890625\nStep: 3700\t eval loss: 0.030873503535985947\t eval accuracy: 0.990936279296875\n##########################################################\nStep: 3800\t train loss: 0.028669174760580063\t train accuracy: 0.991790771484375\nStep: 3800\t eval loss: 0.03197503089904785\t eval accuracy: 0.99072265625\n##########################################################\nStep: 3900\t train loss: 0.028270907700061798\t train accuracy: 0.991668701171875\nStep: 3900\t eval loss: 0.03045840933918953\t eval accuracy: 0.99127197265625\n##########################################################\nStep: 4000\t train loss: 0.02879737690091133\t train accuracy: 0.991180419921875\nStep: 4000\t eval loss: 0.03327567130327225\t eval accuracy: 0.9910888671875\n##########################################################\nStep: 4100\t train loss: 0.02883036807179451\t train accuracy: 0.991668701171875\nStep: 4100\t eval loss: 0.038742370903491974\t eval accuracy: 0.9891357421875\n##########################################################\nStep: 4200\t train loss: 0.10009319335222244\t train accuracy: 0.979583740234375\nStep: 4200\t eval loss: 0.11718496680259705\t eval accuracy: 0.973663330078125\n##########################################################\nStep: 4300\t train loss: 0.027344025671482086\t train accuracy: 0.99200439453125\nStep: 4300\t eval loss: 0.030947130173444748\t eval accuracy: 0.991455078125\n##########################################################\nStep: 4400\t train loss: 0.028593208640813828\t train accuracy: 0.991455078125\nStep: 4400\t eval loss: 0.031886808574199677\t eval accuracy: 0.990875244140625\n##########################################################\nStep: 4500\t train loss: 0.027140388265252113\t train accuracy: 0.991943359375\nStep: 4500\t eval loss: 0.030801374465227127\t eval accuracy: 0.990997314453125\n##########################################################\nStep: 4600\t train loss: 0.036447882652282715\t train accuracy: 0.989349365234375\nStep: 4600\t eval loss: 0.042920470237731934\t eval accuracy: 0.988555908203125\n##########################################################\nStep: 4700\t train loss: 0.040237270295619965\t train accuracy: 0.98822021484375\nStep: 4700\t eval loss: 0.04122977703809738\t eval accuracy: 0.988128662109375\n##########################################################\nStep: 4800\t train loss: 0.030136384069919586\t train accuracy: 0.991455078125\nStep: 4800\t eval loss: 0.03171420842409134\t eval accuracy: 0.99127197265625\n##########################################################\nStep: 4900\t train loss: 0.038037046790122986\t train accuracy: 0.989593505859375\nStep: 4900\t eval loss: 0.03825211897492409\t eval accuracy: 0.9896240234375\n##########################################################\nStep: 5000\t train loss: 0.02983521856367588\t train accuracy: 0.99151611328125\nStep: 5000\t eval loss: 0.03204847127199173\t eval accuracy: 0.990966796875\n##########################################################\nStep: 5100\t train loss: 0.028442643582820892\t train accuracy: 0.991485595703125\nStep: 5100\t eval loss: 0.03247099369764328\t eval accuracy: 0.99066162109375\n##########################################################\nStep: 5200\t train loss: 0.02839455008506775\t train accuracy: 0.99151611328125\nStep: 5200\t eval loss: 0.03010387346148491\t eval accuracy: 0.990814208984375\n##########################################################\nStep: 5300\t train loss: 0.027350012212991714\t train accuracy: 0.992034912109375\nStep: 5300\t eval loss: 0.02897895872592926\t eval accuracy: 0.991485595703125\n##########################################################\nStep: 5400\t train loss: 0.02672513946890831\t train accuracy: 0.992156982421875\nStep: 5400\t eval loss: 0.03011128678917885\t eval accuracy: 0.9913330078125\n##########################################################\nStep: 5500\t train loss: 0.03290397301316261\t train accuracy: 0.99053955078125\nStep: 5500\t eval loss: 0.03692531958222389\t eval accuracy: 0.989898681640625\n##########################################################\nStep: 5600\t train loss: 0.02856929413974285\t train accuracy: 0.991455078125\nStep: 5600\t eval loss: 0.032317470759153366\t eval accuracy: 0.990936279296875\n##########################################################\nStep: 5700\t train loss: 0.025937817990779877\t train accuracy: 0.992095947265625\nStep: 5700\t eval loss: 0.029302071779966354\t eval accuracy: 0.991729736328125\n##########################################################\nStep: 5800\t train loss: 0.026884332299232483\t train accuracy: 0.991851806640625\nStep: 5800\t eval loss: 0.03079158067703247\t eval accuracy: 0.9906005859375\n##########################################################\nStep: 5900\t train loss: 0.04173275828361511\t train accuracy: 0.988861083984375\nStep: 5900\t eval loss: 0.04642889276146889\t eval accuracy: 0.987701416015625\n##########################################################\nStep: 6000\t train loss: 0.02810048684477806\t train accuracy: 0.99176025390625\nStep: 6000\t eval loss: 0.03079504892230034\t eval accuracy: 0.990753173828125\n##########################################################\nStep: 6100\t train loss: 0.028287796303629875\t train accuracy: 0.991546630859375\nStep: 6100\t eval loss: 0.032778289169073105\t eval accuracy: 0.9910888671875\n##########################################################\nStep: 6200\t train loss: 0.02522566355764866\t train accuracy: 0.9921875\nStep: 6200\t eval loss: 0.02979985810816288\t eval accuracy: 0.99114990234375\n##########################################################\nStep: 6300\t train loss: 0.027084657922387123\t train accuracy: 0.9921875\nStep: 6300\t eval loss: 0.029586296528577805\t eval accuracy: 0.991943359375\n##########################################################\nStep: 6400\t train loss: 0.027398478239774704\t train accuracy: 0.991668701171875\nStep: 6400\t eval loss: 0.03073255345225334\t eval accuracy: 0.9912109375\n##########################################################\nStep: 6500\t train loss: 0.026471033692359924\t train accuracy: 0.9918212890625\nStep: 6500\t eval loss: 0.031015926972031593\t eval accuracy: 0.9912109375\n##########################################################\nStep: 6600\t train loss: 0.02610982581973076\t train accuracy: 0.99224853515625\nStep: 6600\t eval loss: 0.028895195573568344\t eval accuracy: 0.991607666015625\n##########################################################\nStep: 6700\t train loss: 0.027887485921382904\t train accuracy: 0.991668701171875\nStep: 6700\t eval loss: 0.029742226004600525\t eval accuracy: 0.991424560546875\n##########################################################\nStep: 6800\t train loss: 0.02672407031059265\t train accuracy: 0.992340087890625\nStep: 6800\t eval loss: 0.030973169952630997\t eval accuracy: 0.991058349609375\n##########################################################\nStep: 6900\t train loss: 0.02432829886674881\t train accuracy: 0.992919921875\nStep: 6900\t eval loss: 0.02928043156862259\t eval accuracy: 0.991607666015625\n##########################################################\nStep: 7000\t train loss: 0.02675514668226242\t train accuracy: 0.99200439453125\nStep: 7000\t eval loss: 0.02934252843260765\t eval accuracy: 0.991180419921875\n##########################################################\nStep: 7100\t train loss: 0.026297274976968765\t train accuracy: 0.992034912109375\nStep: 7100\t eval loss: 0.029280217364430428\t eval accuracy: 0.99114990234375\n##########################################################\nStep: 7200\t train loss: 0.028225693851709366\t train accuracy: 0.9918212890625\nStep: 7200\t eval loss: 0.03083522990345955\t eval accuracy: 0.990966796875\n##########################################################\nStep: 7300\t train loss: 0.02552182599902153\t train accuracy: 0.992645263671875\nStep: 7300\t eval loss: 0.029651420190930367\t eval accuracy: 0.9910888671875\n##########################################################\nStep: 7400\t train loss: 0.025568852201104164\t train accuracy: 0.992462158203125\nStep: 7400\t eval loss: 0.029307495802640915\t eval accuracy: 0.99114990234375\n##########################################################\nStep: 7500\t train loss: 0.02844899520277977\t train accuracy: 0.991485595703125\nStep: 7500\t eval loss: 0.030541792511940002\t eval accuracy: 0.9913330078125\n##########################################################\nStep: 7600\t train loss: 0.040268246084451675\t train accuracy: 0.9888916015625\nStep: 7600\t eval loss: 0.042074985802173615\t eval accuracy: 0.987762451171875\n##########################################################\nStep: 7700\t train loss: 0.028656980022788048\t train accuracy: 0.991607666015625\nStep: 7700\t eval loss: 0.033112626522779465\t eval accuracy: 0.990142822265625\n##########################################################\nStep: 7800\t train loss: 0.025169093161821365\t train accuracy: 0.99261474609375\nStep: 7800\t eval loss: 0.0312187597155571\t eval accuracy: 0.990997314453125\n##########################################################\nStep: 7900\t train loss: 0.02624070644378662\t train accuracy: 0.991973876953125\nStep: 7900\t eval loss: 0.03051101230084896\t eval accuracy: 0.99127197265625\n##########################################################\nStep: 8000\t train loss: 0.02560095489025116\t train accuracy: 0.992218017578125\nStep: 8000\t eval loss: 0.02763354405760765\t eval accuracy: 0.991668701171875\n##########################################################\nStep: 8100\t train loss: 0.025815267115831375\t train accuracy: 0.992462158203125\nStep: 8100\t eval loss: 0.030607007443904877\t eval accuracy: 0.99114990234375\n##########################################################\nStep: 8200\t train loss: 0.026111319661140442\t train accuracy: 0.9921875\nStep: 8200\t eval loss: 0.02877097763121128\t eval accuracy: 0.991943359375\n##########################################################\nStep: 8300\t train loss: 0.025812778621912003\t train accuracy: 0.99261474609375\nStep: 8300\t eval loss: 0.02914923056960106\t eval accuracy: 0.991241455078125\n##########################################################\nStep: 8400\t train loss: 0.026554608717560768\t train accuracy: 0.991455078125\nStep: 8400\t eval loss: 0.028496699407696724\t eval accuracy: 0.99127197265625\n##########################################################\nStep: 8500\t train loss: 0.025694821029901505\t train accuracy: 0.9923095703125\nStep: 8500\t eval loss: 0.02987934835255146\t eval accuracy: 0.991485595703125\n##########################################################\nStep: 8600\t train loss: 0.029153920710086823\t train accuracy: 0.991485595703125\nStep: 8600\t eval loss: 0.02959613874554634\t eval accuracy: 0.991851806640625\n##########################################################\nStep: 8700\t train loss: 0.031611014157533646\t train accuracy: 0.9903564453125\nStep: 8700\t eval loss: 0.03562973812222481\t eval accuracy: 0.989837646484375\n##########################################################\nStep: 8800\t train loss: 0.02556418627500534\t train accuracy: 0.992645263671875\nStep: 8800\t eval loss: 0.029024828225374222\t eval accuracy: 0.991546630859375\n##########################################################\nStep: 8900\t train loss: 0.025830574333667755\t train accuracy: 0.991912841796875\nStep: 8900\t eval loss: 0.029971174895763397\t eval accuracy: 0.991058349609375\n##########################################################\nStep: 9000\t train loss: 0.025783173739910126\t train accuracy: 0.992095947265625\nStep: 9000\t eval loss: 0.028707511723041534\t eval accuracy: 0.991790771484375\n##########################################################\nStep: 9100\t train loss: 0.025861740112304688\t train accuracy: 0.9923095703125\nStep: 9100\t eval loss: 0.027396531775593758\t eval accuracy: 0.991912841796875\n##########################################################\nStep: 9200\t train loss: 0.026224449276924133\t train accuracy: 0.992095947265625\nStep: 9200\t eval loss: 0.02990906313061714\t eval accuracy: 0.99163818359375\n##########################################################\nStep: 9300\t train loss: 0.025818411260843277\t train accuracy: 0.9925537109375\nStep: 9300\t eval loss: 0.028677403926849365\t eval accuracy: 0.991485595703125\n##########################################################\nStep: 9400\t train loss: 0.024322131648659706\t train accuracy: 0.992645263671875\nStep: 9400\t eval loss: 0.02738213911652565\t eval accuracy: 0.99200439453125\n##########################################################\nStep: 9500\t train loss: 0.025135494768619537\t train accuracy: 0.99273681640625\nStep: 9500\t eval loss: 0.029982790350914\t eval accuracy: 0.9915771484375\n##########################################################\nStep: 9600\t train loss: 0.027723919600248337\t train accuracy: 0.99169921875\nStep: 9600\t eval loss: 0.030915310606360435\t eval accuracy: 0.991180419921875\n##########################################################\nStep: 9700\t train loss: 0.02421528473496437\t train accuracy: 0.99298095703125\nStep: 9700\t eval loss: 0.028948135673999786\t eval accuracy: 0.991546630859375\n##########################################################\nStep: 9800\t train loss: 0.02417713962495327\t train accuracy: 0.992767333984375\nStep: 9800\t eval loss: 0.028468355536460876\t eval accuracy: 0.991455078125\n##########################################################\nStep: 9900\t train loss: 0.02540392428636551\t train accuracy: 0.991973876953125\nStep: 9900\t eval loss: 0.028854556381702423\t eval accuracy: 0.991668701171875\nCPU times: user 1h 15min 39s, sys: 54min 28s, total: 2h 10min 7s\nWall time: 2h 10min 11s\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt  # Visualization\n\n# Plot loss and accuracy in subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.set_title('Loss')\nax2.set_title('Accuracy')\n\n\n\nax1.plot(all_train_losses, label='train_loss')\nax1.plot(all_eval_losses, label='eval_loss')\n\nax2.plot(all_train_accuracy, label='train_accuracy')\nax2.plot(all_test_accuracy, label='eval_accuracy')\n\nax1.legend()\nax2.legend()\nplt.show()\nplt.clf()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:29.622277Z","iopub.execute_input":"2024-05-27T13:01:29.622694Z","iopub.status.idle":"2024-05-27T13:01:30.114013Z","shell.execute_reply.started":"2024-05-27T13:01:29.622657Z","shell.execute_reply":"2024-05-27T13:01:30.113073Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x500 with 2 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"@partial(jax.jit, static_argnames=(\"length\"))\ndef generate_text(rng, params, var_params, length):\n    def _scan_generate(carry, _):\n        random_key, context = carry\n        logits = model.apply({'params': params, **var_params}, context, training=False, mutable=['other_variables'])[0]\n        rng, rng_subkey = jax.random.split(random_key)\n        new_token = jax.random.categorical(\n          rng_subkey, logits[:, -n_tokens, :], axis=-1, shape=(1, 1)\n        )\n        context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n        return (rng, context), new_token\n\n    _, new_tokens = jax.lax.scan(\n    _scan_generate,\n    (rng, jnp.zeros((1, block_size), dtype=jnp.int32)),\n    (),\n    length=length,\n    )\n    return new_tokens","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:30.115223Z","iopub.execute_input":"2024-05-27T13:01:30.115543Z","iopub.status.idle":"2024-05-27T13:01:30.123995Z","shell.execute_reply.started":"2024-05-27T13:01:30.115517Z","shell.execute_reply":"2024-05-27T13:01:30.123028Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"new_tokenz = 1000\nkey, subkey = jax.random.split(jax.random.PRNGKey(156))\n# key, subkey = jax.random.split(key)\n# token_gen = generate_text(jnp.zeros((1,block_size)).astype(jnp.int32), new_tokenz, {'params': state.params})\ntoken_gen = generate_text(key, params, var_params, new_tokenz)[:, 0, 0].tolist()\nprint(token_gen)\nprint(decode(token_gen))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:30.125218Z","iopub.execute_input":"2024-05-27T13:01:30.125588Z","iopub.status.idle":"2024-05-27T13:01:50.447511Z","shell.execute_reply.started":"2024-05-27T13:01:30.125553Z","shell.execute_reply":"2024-05-27T13:01:50.446602Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"[24, 13, 30, 32, 21, 33, 31, 10, 0, 27, 6, 1, 50, 52, 53, 52, 5, 42, 1, 57, 46, 53, 59, 50, 42, 1, 47, 52, 1, 41, 53, 50, 42, 1, 46, 39, 60, 43, 1, 21, 56, 43, 41, 39, 57, 58, 57, 1, 57, 43, 58, 1, 43, 60, 43, 56, 1, 58, 46, 43, 47, 56, 1, 56, 39, 41, 43, 1, 39, 56, 51, 57, 1, 21, 1, 51, 39, 49, 47, 52, 45, 1, 58, 46, 43, 1, 41, 47, 58, 41, 46, 10, 1, 61, 46, 43, 56, 56, 47, 43, 57, 6, 1, 61, 47, 58, 46, 1, 44, 43, 39, 56, 57, 1, 58, 53, 1, 58, 46, 43, 1, 61, 46, 39, 58, 1, 46, 39, 54, 54, 63, 8, 0, 35, 43, 1, 53, 44, 44, 47, 41, 43, 56, 1, 46, 39, 60, 43, 8, 1, 31, 54, 47, 56, 43, 6, 1, 57, 39, 63, 57, 6, 1, 39, 52, 42, 1, 46, 39, 60, 43, 1, 51, 63, 1, 46, 39, 42, 1, 39, 56, 47, 57, 8, 1, 35, 47, 58, 46, 1, 40, 39, 50, 58, 1, 46, 43, 56, 1, 57, 47, 52, 45, 40, 43, 56, 58, 1, 51, 39, 52, 1, 39, 44, 58, 47, 50, 1, 44, 53, 56, 1, 57, 53, 1, 58, 46, 43, 63, 1, 56, 43, 41, 47, 53, 59, 57, 1, 50, 53, 60, 43, 6, 1, 39, 52, 42, 6, 1, 39, 42, 1, 57, 53, 1, 51, 53, 57, 58, 47, 51, 43, 6, 1, 52, 53, 58, 1, 54, 56, 43, 57, 1, 58, 46, 43, 1, 57, 39, 56, 56, 47, 39, 45, 43, 42, 1, 39, 58, 1, 21, 1, 45, 53, 53, 42, 1, 40, 39, 56, 56, 63, 8, 0, 0, 14, 17, 26, 34, 27, 24, 21, 27, 10, 0, 57, 53, 53, 52, 1, 46, 47, 57, 1, 44, 53, 56, 58, 1, 51, 39, 56, 56, 43, 42, 1, 50, 53, 53, 49, 1, 58, 46, 47, 57, 1, 54, 39, 58, 56, 53, 52, 45, 6, 1, 40, 43, 44, 53, 56, 43, 6, 1, 58, 43, 50, 50, 11, 1, 61, 46, 43, 56, 51, 1, 39, 58, 58, 43, 56, 8, 0, 0, 19, 24, 27, 33, 15, 17, 31, 32, 17, 30, 10, 0, 25, 39, 56, 56, 43, 2, 1, 57, 53, 51, 43, 1, 63, 53, 59, 1, 54, 56, 53, 60, 39, 47, 50, 7, 56, 53, 1, 44, 39, 47, 58, 46, 1, 53, 44, 1, 52, 43, 61, 1, 21, 1, 61, 47, 50, 50, 1, 40, 43, 52, 43, 57, 57, 1, 58, 53, 1, 58, 46, 39, 58, 1, 44, 47, 50, 58, 43, 56, 6, 1, 51, 63, 1, 41, 56, 53, 61, 52, 1, 54, 43, 39, 42, 63, 11, 1, 51, 63, 1, 50, 53, 60, 43, 1, 50, 53, 53, 49, 57, 1, 51, 63, 1, 50, 53, 56, 42, 8, 0, 0, 23, 21, 26, 19, 1, 30, 21, 15, 20, 13, 30, 16, 1, 21, 21, 21, 10, 0, 27, 6, 1, 52, 53, 61, 6, 1, 40, 59, 58, 1, 40, 47, 58, 47, 53, 52, 1, 50, 43, 40, 50, 43, 1, 51, 39, 56, 41, 46, 1, 58, 46, 56, 53, 39, 49, 8, 0, 16, 47, 57, 58, 56, 59, 41, 58, 47, 42, 43, 57, 1, 58, 43, 50, 50, 1, 54, 43, 53, 54, 50, 43, 1, 53, 52, 43, 57, 6, 1, 40, 59, 58, 1, 58, 46, 43, 1, 46, 53, 52, 53, 59, 56, 1, 50, 53, 53, 49, 1, 57, 47, 56, 6, 0, 32, 46, 43, 43, 6, 1, 50, 43, 52, 49, 57, 1, 52, 53, 52, 43, 6, 1, 54, 43, 56, 47, 58, 63, 0, 40, 58, 56, 39, 52, 41, 46, 5, 42, 1, 54, 39, 56, 58, 1, 47, 58, 1, 45, 53, 6, 1, 47, 58, 57, 43, 42, 6, 1, 50, 43, 39, 60, 43, 8, 0, 32, 46, 39, 52, 1, 58, 46, 47, 57, 1, 30, 47, 41, 46, 58, 1, 58, 53, 1, 50, 39, 63, 6, 0, 27, 56, 1, 61, 46, 47, 41, 46, 1, 44, 53, 50, 42, 1, 24, 59, 41, 43, 52, 42, 1, 58, 46, 39, 58, 1, 54, 56, 39, 63, 1, 61, 43, 39, 56, 5, 57, 6, 1, 52, 53, 58, 1, 46, 39, 52, 42, 1, 28, 53, 51, 40, 6, 1, 45, 53, 42, 57, 6, 1, 40, 39, 52, 47, 57, 53, 52, 6, 0, 21, 1, 50, 47, 49, 43, 8, 0, 32, 53, 61, 39, 56, 42, 5, 57, 1, 45, 53, 53, 42, 1, 54, 50, 43, 39, 57, 43, 42, 6, 1, 46, 53, 61, 6, 1, 39, 52, 41, 43, 1, 58, 46, 47, 57, 8, 0, 0, 24, 13, 16, 37, 1, 0, 23, 47, 41, 43, 6, 1, 58, 53, 1, 41, 39, 50, 58, 1, 46, 43, 47, 56, 1, 41, 39, 52, 52, 47, 41, 53, 54, 53, 50, 50, 53, 61, 6, 1, 40, 63, 6, 1, 58, 46, 53, 59, 1, 39, 50, 50, 1, 54, 39, 56, 58, 6, 1, 58, 43, 51, 54, 50, 39, 47, 43, 42, 1, 39, 40, 53, 59, 56, 10, 1, 42, 53, 1, 58, 46, 43, 1, 43, 39, 41, 46, 1, 56, 43, 57, 53, 40, 43, 57, 6, 1, 46, 39, 57, 58, 47, 52, 45, 11, 1, 61, 43, 50, 50, 1, 52, 53, 58, 1, 54, 50, 39, 63, 1, 39, 57, 1, 58, 47, 50, 50, 2, 1, 61, 46, 53, 1, 57, 58, 39, 58, 47, 53, 52, 1, 42, 47, 43, 8, 0, 35, 53, 51, 40, 59, 51, 54, 46, 1, 51, 39, 63, 53, 59, 57, 1, 52, 53, 52, 43, 11, 1, 39, 44, 44, 53, 56, 42, 8, 0, 5, 32, 61, 43]\nLARTIUS:\nO, lnon'd should in cold have Irecasts set ever their race arms I making the citch: wherries, with fears to the what happy.\nWe officer have. Spire, says, and have my had aris. With balt her singbert man aftil for so they recious love, and, ad so mostime, not pres the sarriaged at I good barry.\n\nBENVOLIO:\nsoon his fort marred look this patrong, before, tell; wherm atter.\n\nGLOUCESTER:\nMarre! some you provail-ro faith of new I will beness to that filter, my crown peady; my love looks my lord.\n\nKING RICHARD III:\nO, now, but bition leble march throak.\nDistructides tell people ones, but the honour look sir,\nThee, lenks none, perity\nbtranch'd part it go, itsed, leave.\nThan this Richt to lay,\nOr which fold Lucend that pray wear's, not hand Pomb, gods, banison,\nI like.\nToward's good pleased, how, ance this.\n\nLADY \nKice, to calt heir cannicopollow, by, thou all part, templaied abour: do the each resobes, hasting; well not play as till! who station die.\nWombumph mayous none; afford.\n'Twe\n","output_type":"stream"}]},{"cell_type":"code","source":"dsfsdhfgjdg hfdgjdgjgfjhs'####################","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:50.448765Z","iopub.execute_input":"2024-05-27T13:01:50.449055Z","iopub.status.idle":"2024-05-27T13:01:50.454897Z","shell.execute_reply.started":"2024-05-27T13:01:50.449028Z","shell.execute_reply":"2024-05-27T13:01:50.453499Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[33], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    dsfsdhfgjdg hfdgjdgjgfjhs'####################\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"],"ename":"SyntaxError","evalue":"unterminated string literal (detected at line 1) (2630675753.py, line 1)","output_type":"error"}]},{"cell_type":"code","source":"var_params['other_variables']['Mamba_0']['hidden_state'].shape","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:50.455772Z","iopub.status.idle":"2024-05-27T13:01:50.456191Z","shell.execute_reply.started":"2024-05-27T13:01:50.455955Z","shell.execute_reply":"2024-05-27T13:01:50.455975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params.keys()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:50.457930Z","iopub.status.idle":"2024-05-27T13:01:50.458386Z","shell.execute_reply.started":"2024-05-27T13:01:50.458156Z","shell.execute_reply":"2024-05-27T13:01:50.458176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params['Dense_12']['kernel'].shape","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:50.459576Z","iopub.status.idle":"2024-05-27T13:01:50.460026Z","shell.execute_reply.started":"2024-05-27T13:01:50.459796Z","shell.execute_reply":"2024-05-27T13:01:50.459815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rngk = jax.random.PRNGKey(389)\nxs, ys = get_batch(rngk, train_data)\nprint(xs[0])\nprint(ys[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:50.461151Z","iopub.status.idle":"2024-05-27T13:01:50.461485Z","shell.execute_reply.started":"2024-05-27T13:01:50.461305Z","shell.execute_reply":"2024-05-27T13:01:50.461317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits = model.apply({'params': params, **var_params}, xs[0].reshape((1,64)), training=False, mutable=['other_variables'])[0]\nrng, rng_subkey = jax.random.split(rngk)\nfor pso in range(n_tokens):\n    new_token = jax.random.categorical(\n      rng_subkey, logits[:, -1*(n_tokens-pso), :], axis=-1, shape=(1, 1)\n    )\n    print(new_token)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:50.463377Z","iopub.status.idle":"2024-05-27T13:01:50.463843Z","shell.execute_reply.started":"2024-05-27T13:01:50.463609Z","shell.execute_reply":"2024-05-27T13:01:50.463628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_tok = [51,49,46,46,46,52]\nprint(decode(ys[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:50.464856Z","iopub.status.idle":"2024-05-27T13:01:50.465300Z","shell.execute_reply.started":"2024-05-27T13:01:50.465067Z","shell.execute_reply":"2024-05-27T13:01:50.465086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"act_tk = [60, 43, 50, 57,  1, 47]\nprint(decode(act_tk))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:50.466791Z","iopub.status.idle":"2024-05-27T13:01:50.467234Z","shell.execute_reply.started":"2024-05-27T13:01:50.466999Z","shell.execute_reply":"2024-05-27T13:01:50.467017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jax.nn.standardize(jnp.array([2.0,3.0,4.0]))","metadata":{"id":"Oe_GIDP2HFyt","outputId":"5d3dce16-fcc2-40b9-c49a-00a8c4013ca2","execution":{"iopub.status.busy":"2024-05-27T13:01:50.468945Z","iopub.status.idle":"2024-05-27T13:01:50.469395Z","shell.execute_reply.started":"2024-05-27T13:01:50.469168Z","shell.execute_reply":"2024-05-27T13:01:50.469186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@struct.dataclass\nclass Metrics(metrics.Collection):\n    accuracy: metrics.Accuracy\n    loss: metrics.Average.from_output('loss')","metadata":{"id":"s3nN1jOiHFyu","execution":{"iopub.status.busy":"2024-05-27T13:01:50.470573Z","iopub.status.idle":"2024-05-27T13:01:50.471009Z","shell.execute_reply.started":"2024-05-27T13:01:50.470784Z","shell.execute_reply":"2024-05-27T13:01:50.470803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainState(train_state.TrainState):\n    metrics: Metrics\n\ndef create_train_state(module, rng, learning_rate, train_shape):\n    \"\"\"Creates an initial `TrainState`.\"\"\"\n    params = module.init(rng, jnp.ones(train_shape).astype(jnp.int32), \n                         training=False)['params'] # initialize parameters by passing a template image\n    tx = optax.adamw(learning_rate)\n    return TrainState.create(\n      apply_fn=module.apply, params=params, tx=tx,\n      metrics=Metrics.empty(),\n    )","metadata":{"id":"7LLDTSFQHFyu","execution":{"iopub.status.busy":"2024-05-27T13:01:50.472320Z","iopub.status.idle":"2024-05-27T13:01:50.472766Z","shell.execute_reply.started":"2024-05-27T13:01:50.472543Z","shell.execute_reply":"2024-05-27T13:01:50.472561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TrainState.create(","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:50.474177Z","iopub.status.idle":"2024-05-27T13:01:50.474646Z","shell.execute_reply.started":"2024-05-27T13:01:50.474391Z","shell.execute_reply":"2024-05-27T13:01:50.474411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@jax.jit\ndef train_step(state, inputs, targets):\n    \"\"\"Train for a single step.\"\"\"\n    def loss_fn(params):\n        logits = state.apply_fn({'params': params}, inputs, training=True, \n                                rngs={\"dropout\": key})[0]\n        loss = optax.softmax_cross_entropy_with_integer_labels(\n            logits=logits, labels=targets).mean()\n        return loss\n    grad_fn = jax.grad(loss_fn)\n    grads = grad_fn(state.params)\n    state = state.apply_gradients(grads=grads)\n    return state","metadata":{"id":"zApWXUDaHFyu","execution":{"iopub.status.busy":"2024-05-27T13:01:50.475812Z","iopub.status.idle":"2024-05-27T13:01:50.476262Z","shell.execute_reply.started":"2024-05-27T13:01:50.476026Z","shell.execute_reply":"2024-05-27T13:01:50.476044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@jax.jit\ndef compute_metrics(*, state, inputs, targets):\n    logits = state.apply_fn({'params': state.params}, inputs, training=False)[0]\n    loss = optax.softmax_cross_entropy_with_integer_labels(\n        logits=logits, labels=targets).mean()\n    metric_updates = state.metrics.single_from_model_output(\n    logits=logits, labels=targets, loss=loss)\n    metrics = state.metrics.merge(metric_updates)\n    state = state.replace(metrics=metrics)\n    return state","metadata":{"id":"VzukZ4iEHFyv","execution":{"iopub.status.busy":"2024-05-27T13:01:50.477454Z","iopub.status.idle":"2024-05-27T13:01:50.477803Z","shell.execute_reply.started":"2024-05-27T13:01:50.477639Z","shell.execute_reply":"2024-05-27T13:01:50.477654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nlearning_rate = 0.005\ninit_rng = jax.random.key(0)","metadata":{"id":"ehYvMeuNHFyv","execution":{"iopub.status.busy":"2024-05-27T13:01:50.479107Z","iopub.status.idle":"2024-05-27T13:01:50.479421Z","shell.execute_reply.started":"2024-05-27T13:01:50.479269Z","shell.execute_reply":"2024-05-27T13:01:50.479281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state = create_train_state(fin_model, init_rng, learning_rate, train_shape)\ndel init_rng  # Must not be used anymore.","metadata":{"id":"D60UHLFHHFyv","execution":{"iopub.status.busy":"2024-05-27T13:01:50.481193Z","iopub.status.idle":"2024-05-27T13:01:50.481567Z","shell.execute_reply.started":"2024-05-27T13:01:50.481360Z","shell.execute_reply":"2024-05-27T13:01:50.481374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics_history = {'train_loss': [],\n                   'train_accuracy': [],\n                   'test_loss': [],\n                   'test_accuracy': []}","metadata":{"id":"Jl-9TlHEHFyv","execution":{"iopub.status.busy":"2024-05-27T13:01:50.483030Z","iopub.status.idle":"2024-05-27T13:01:50.483387Z","shell.execute_reply.started":"2024-05-27T13:01:50.483222Z","shell.execute_reply":"2024-05-27T13:01:50.483237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 442\nkey = jax.random.PRNGKey(SEED)\nloss = 10\ncounter = 0\n# for step in tqdm(range(max_iters)): # increase number of steps for good results...\nwhile counter==max_iters or loss > 1.0:\n\n      # sample a batch of data\n    xb, yb = get_batch(key, train_data)\n    state = train_step(state, xb, yb)\n    state = compute_metrics(state=state, inputs=xb, targets=yb)\n\n    key = (jax.random.split(key)[0])\n\n    if step == 0 or (step+1) % 100 == 0: # one training epoch has passed\n        for metric,value in state.metrics.compute().items(): # compute metrics\n            metrics_history[f'train_{metric}'].append(value) # record metrics\n        state = state.replace(metrics=state.metrics.empty()) # reset train_metrics for next training epoch\n\n        # Compute metrics on the test set after each training epoch\n        test_state = state\n        x_test, y_test = get_batch(key, test_data)\n    #     for test_batch in test_ds.as_numpy_iterator():\n        test_state = compute_metrics(state=test_state, inputs=x_test, targets=y_test)\n\n        for metric,value in test_state.metrics.compute().items():\n            metrics_history[f'test_{metric}'].append(value)\n\n        print(f\"train epoch: {(step+1)}, \"\n              f\"loss: {metrics_history['train_loss'][-1]}, \"\n              f\"accuracy: {metrics_history['train_accuracy'][-1] * 100}\")\n        print(f\"test epoch: {(step+1) }, \"\n          f\"loss: {metrics_history['test_loss'][-1]}, \"\n          f\"accuracy: {metrics_history['test_accuracy'][-1] * 100}\")","metadata":{"id":"CaNt9JazHFyw","outputId":"ba447ddf-9940-44a6-f4b2-d27ed78a88c2","execution":{"iopub.status.busy":"2024-05-27T13:01:50.484913Z","iopub.status.idle":"2024-05-27T13:01:50.485376Z","shell.execute_reply.started":"2024-05-27T13:01:50.485151Z","shell.execute_reply":"2024-05-27T13:01:50.485170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt  # Visualization\n\n# Plot loss and accuracy in subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.set_title('Loss')\nax2.set_title('Accuracy')\nfor dataset in ('train','test'):\n    ax1.plot(metrics_history[f'{dataset}_loss'], label=f'{dataset}_loss')\n    ax2.plot(metrics_history[f'{dataset}_accuracy'], label=f'{dataset}_accuracy')\nax1.legend()\nax2.legend()\nplt.show()\nplt.clf()","metadata":{"id":"Y40JGx1YHFyw","execution":{"iopub.status.busy":"2024-05-27T13:01:50.486911Z","iopub.status.idle":"2024-05-27T13:01:50.487363Z","shell.execute_reply.started":"2024-05-27T13:01:50.487128Z","shell.execute_reply":"2024-05-27T13:01:50.487146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlogits = fin_model.apply(fin_params, xb, training=False)[0]\nloss = optax.softmax_cross_entropy_with_integer_labels(\n            logits=logits, labels=yb).mean()\n\nprint(loss)","metadata":{"id":"7pJlFXpVHFyw","execution":{"iopub.status.busy":"2024-05-27T13:01:50.489409Z","iopub.status.idle":"2024-05-27T13:01:50.489869Z","shell.execute_reply.started":"2024-05-27T13:01:50.489641Z","shell.execute_reply":"2024-05-27T13:01:50.489660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def generate_text(idx, max_new_tokens, params):\n# # idx is (B, T) array of indices in the current context\n#     for i in range(max_new_tokens):\n#         # crop idx to the last block_size tokens\n#         idx_cond = idx[:, -block_size:]\n#         # get the predictions\n#         logits = fin_model.apply(params, idx_cond)\n#         # focus only on the last time step\n#         logits = logits[:, -1, :] # becomes (B, C)\n\n#         if i == 0:\n#             rng, rng_subkey = jax.random.split(jax.random.PRNGKey(12))\n#         else:\n#             rng, rng_subkey = jax.random.split(rng)\n\n#         idx_next = jax.random.categorical(rng_subkey, logits, axis=-1, shape=(1, 1)) # (B, 1)\n\n\n#         # append sampled index to the running sequence\n#         idx = jnp.concatenate([idx, idx_next], axis=-1) # (B, T+1)\n\n#     return idx","metadata":{"id":"9d28o-dTHFyx","execution":{"iopub.status.busy":"2024-05-27T13:01:50.490931Z","iopub.status.idle":"2024-05-27T13:01:50.491378Z","shell.execute_reply.started":"2024-05-27T13:01:50.491152Z","shell.execute_reply":"2024-05-27T13:01:50.491171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@partial(jax.jit, static_argnames=(\"self\", \"length\"))\ndef generate_text(rng, params, length):\n    def _scan_generate(carry, _):\n        random_key, context = carry\n        logits = fin_model.apply(params, context, training=False)[0]\n        rng, rng_subkey = jax.random.split(random_key)\n        new_token = jax.random.categorical(\n          rng_subkey, logits[:, -1, :], axis=-1, shape=(1, 1)\n        )\n        context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n        return (rng, context), new_token\n\n    _, new_tokens = jax.lax.scan(\n    _scan_generate,\n    (rng, jnp.zeros((1, block_size), dtype=jnp.int32)),\n    (),\n    length=length,\n    )\n    return new_tokens","metadata":{"id":"WB0og7pAHFyx","execution":{"iopub.status.busy":"2024-05-27T13:01:50.492602Z","iopub.status.idle":"2024-05-27T13:01:50.493035Z","shell.execute_reply.started":"2024-05-27T13:01:50.492812Z","shell.execute_reply":"2024-05-27T13:01:50.492831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_tokenz = 1000\nkey, subkey = jax.random.split(jax.random.PRNGKey(156))\n# key, subkey = jax.random.split(key)\n# token_gen = generate_text(jnp.zeros((1,block_size)).astype(jnp.int32), new_tokenz, {'params': state.params})\ntoken_gen = generate_text(key, {'params': state.params}, new_tokenz)[:, 0, 0].tolist()\nprint(token_gen)\nprint(decode(token_gen))","metadata":{"id":"50Vpg2lEHFyx","execution":{"iopub.status.busy":"2024-05-27T13:01:50.494643Z","iopub.status.idle":"2024-05-27T13:01:50.495094Z","shell.execute_reply.started":"2024-05-27T13:01:50.494851Z","shell.execute_reply":"2024-05-27T13:01:50.494871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdgh  fs","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:50.496790Z","iopub.status.idle":"2024-05-27T13:01:50.497235Z","shell.execute_reply.started":"2024-05-27T13:01:50.496999Z","shell.execute_reply":"2024-05-27T13:01:50.497017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state.params","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:01:50.498464Z","iopub.status.idle":"2024-05-27T13:01:50.498803Z","shell.execute_reply.started":"2024-05-27T13:01:50.498642Z","shell.execute_reply":"2024-05-27T13:01:50.498655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install mamba-ssm","metadata":{"id":"MOw_xjbrHFy0","execution":{"iopub.status.busy":"2024-05-27T13:01:50.500604Z","iopub.status.idle":"2024-05-27T13:01:50.501048Z","shell.execute_reply.started":"2024-05-27T13:01:50.500816Z","shell.execute_reply":"2024-05-27T13:01:50.500835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ones = lambda *size: torch.ones(*size).float().cuda()\nzeros = lambda *size: torch.zeros(*size).float().cuda()\narange = lambda n: torch.arange(n).float().cuda()\nrand = lambda size: torch.rand(*size).abs().float().cuda()\n\ndef create_torch(S = 128, Ba = 2, D = 4, N = 4):\n    x = rand((Ba, 1, D, S))\n    a = -ones((Ba, N, D, 1))\n    b = ones((Ba, N, 1, S)) * 0.1\n    c = rand((Ba, N, 1, S)) * 0.1\n    delta = rand((Ba, 1, D, S)) * 0.1\n    return x, a, b, c, delta","metadata":{"id":"W_PAnYcEOR22","execution":{"iopub.status.busy":"2024-05-27T13:01:50.502918Z","iopub.status.idle":"2024-05-27T13:01:50.503371Z","shell.execute_reply.started":"2024-05-27T13:01:50.503138Z","shell.execute_reply":"2024-05-27T13:01:50.503158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import selective_scan_cuda\n\nxx, aa, bb, cc, ddelta = create_torch()\ny_from_repo = selective_scan_cuda.fwd(xx.squeeze(1), ddelta.squeeze(1), aa[0].squeeze(-1).T, bb.squeeze(-2)[:, None, :, :], cc.squeeze(-2)[:, None, :, :], None, None, None, False)\ny_from_repo","metadata":{"id":"ykh4GTvtOrak","execution":{"iopub.status.busy":"2024-05-27T13:01:50.504550Z","iopub.status.idle":"2024-05-27T13:01:50.504907Z","shell.execute_reply.started":"2024-05-27T13:01:50.504744Z","shell.execute_reply":"2024-05-27T13:01:50.504758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discretize(a, b, delta):\n    da = delta * a\n    a_ = jnp.exp(da)\n    b_ = b * delta\n    return a_, b_\n\ndef ssm(x, a, b, c, delta):\n    \"Jax Implementation\"\n    y = []\n    h = 0\n    a_, b_ = discretize(a, b, delta)\n    for k in range(x.shape[-1]):\n        h = a_[..., k] * h + b_[..., k] * x[..., k]\n        y.append((c[..., k] * h).sum(1, keepdims=True))\n    return h, jnp.stack(y, -1)\n","metadata":{"id":"NEdG1yPNOtxU","execution":{"iopub.status.busy":"2024-05-27T13:01:50.505916Z","iopub.status.idle":"2024-05-27T13:01:50.506241Z","shell.execute_reply.started":"2024-05-27T13:01:50.506079Z","shell.execute_reply":"2024-05-27T13:01:50.506093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, y_ = ssm(xx.cpu().numpy(), aa.cpu().numpy(), bb.cpu().numpy(), cc.cpu().numpy(), ddelta.cpu().numpy())","metadata":{"id":"GEjNcZSZPIp_","execution":{"iopub.status.busy":"2024-05-27T13:01:50.507627Z","iopub.status.idle":"2024-05-27T13:01:50.507944Z","shell.execute_reply.started":"2024-05-27T13:01:50.507775Z","shell.execute_reply":"2024-05-27T13:01:50.507788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"tWlqZZOmPnYk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mamba_ssm import Mamba as Mamba_T\ntorch_mamba = Mamba_T(\n      # This module uses roughly 3 * expand * d_model^2 parameters\n      d_model=n_embd, # Model dimension d_model\n      d_state=16,  # SSM state expansion factor\n      d_conv=4,    # Local convolution width\n      expand=2,    # Block expansion factor\n)","metadata":{"id":"5RHAE_I1Pql9","execution":{"iopub.status.busy":"2024-05-27T13:01:50.509640Z","iopub.status.idle":"2024-05-27T13:01:50.510118Z","shell.execute_reply.started":"2024-05-27T13:01:50.509867Z","shell.execute_reply":"2024-05-27T13:01:50.509888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xm = x = rand((1, 1, n_embd, 32))\nxm.shape","metadata":{"id":"l9zw_M-USrDt","execution":{"iopub.status.busy":"2024-05-27T13:01:50.512496Z","iopub.status.idle":"2024-05-27T13:01:50.512942Z","shell.execute_reply.started":"2024-05-27T13:01:50.512713Z","shell.execute_reply":"2024-05-27T13:01:50.512732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_mamba(xm.squeeze(1))","metadata":{"id":"gGmA2EWlTCo0","execution":{"iopub.status.busy":"2024-05-27T13:01:50.514047Z","iopub.status.idle":"2024-05-27T13:01:50.514527Z","shell.execute_reply.started":"2024-05-27T13:01:50.514269Z","shell.execute_reply":"2024-05-27T13:01:50.514288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_mamba.in_proj","metadata":{"id":"73ek9mx9UBBl","execution":{"iopub.status.busy":"2024-05-27T13:01:50.516213Z","iopub.status.idle":"2024-05-27T13:01:50.516574Z","shell.execute_reply.started":"2024-05-27T13:01:50.516380Z","shell.execute_reply":"2024-05-27T13:01:50.516394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import CLIPTokenizer\ntokenizer_1 = CLIPTokenizer.from_pretrained('openai/clip-vit-base-patch32')","metadata":{"id":"P3l_ssIYbiYT","execution":{"iopub.status.busy":"2024-05-27T13:01:50.517881Z","iopub.status.idle":"2024-05-27T13:01:50.518244Z","shell.execute_reply.started":"2024-05-27T13:01:50.518069Z","shell.execute_reply":"2024-05-27T13:01:50.518084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenise_prompts(prompt):\n    inputs = []\n    for tokenizer in [tokenizer_1, tokenizer_2]:\n        text_inputs = tokenizer(\n            positive_prompt,\n            padding=\"max_length\",\n            max_length=tokenizer.model_max_length,\n            truncation=True,\n            return_tensors=\"np\",\n        )\n        inputs.append(text_inputs.input_ids)\n    return jnp.stack(inputs, axis=1)","metadata":{"id":"-X7hXQRMZhl3","execution":{"iopub.status.busy":"2024-05-27T13:01:50.519162Z","iopub.status.idle":"2024-05-27T13:01:50.519507Z","shell.execute_reply.started":"2024-05-27T13:01:50.519320Z","shell.execute_reply":"2024-05-27T13:01:50.519334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xm.squeeze(1).shape","metadata":{"id":"rJhKQ_Oua9Gy","execution":{"iopub.status.busy":"2024-05-27T13:01:50.520775Z","iopub.status.idle":"2024-05-27T13:01:50.521132Z","shell.execute_reply.started":"2024-05-27T13:01:50.520938Z","shell.execute_reply":"2024-05-27T13:01:50.520952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"mzkoYrSVkoJj"},"execution_count":null,"outputs":[]}]}